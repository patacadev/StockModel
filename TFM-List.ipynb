{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 186328 entries, 2017-01-03 00:00:00-05:00 to 2024-08-30 00:00:00-04:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Open          186328 non-null  float64\n",
      " 1   High          186328 non-null  float64\n",
      " 2   Low           186328 non-null  float64\n",
      " 3   Close         186328 non-null  float64\n",
      " 4   Volume        186328 non-null  int64  \n",
      " 5   Dividends     186328 non-null  float64\n",
      " 6   Stock Splits  186328 non-null  float64\n",
      " 7   Ticker        186328 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 12.8+ MB\n",
      "XXXXXXXXXXXXXXXX Running 3 32 layers XXXXXXXXXXXXXXXXXXXX\n",
      "Initializing model:\n",
      " - Window size: 20\n",
      " - Features: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
      " - Target: Open\n",
      "--- Preparing ^IXIC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.47700000e+03  5.44091016e+03  8.72110000e+08  1.43798828e+01\n",
      " -1.06362988e+03  1.16226960e+01 -6.03732918e+02 -1.85963467e+02]\n",
      "Feature max [1.86474492e+04 1.86592500e+04 1.19326000e+10 8.98230469e+02\n",
      " 5.16000000e+02 1.00000000e+02 3.79729000e+02 1.68559430e+02]\n",
      "Target min [5425.62011719]\n",
      "Target max [18659.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRTX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.70500031e+01  7.52200012e+01  3.00500000e+05  9.29992676e-01\n",
      " -4.39099884e+01  6.98832867e+00 -1.61057278e+01 -6.35634960e+00]\n",
      "Feature max [5.05779999e+02 5.07040009e+02 1.74930000e+07 3.32000122e+01\n",
      " 2.96399994e+01 1.00000000e+02 1.72224200e+01 7.01903411e+00]\n",
      "Target min [74.43000031]\n",
      "Target max [507.04000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PYPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93100014e+01  3.94000015e+01  1.68000000e+06  2.79998779e-01\n",
      " -3.59100037e+01  5.36242303e+00 -1.82619484e+01 -6.83508729e+00]\n",
      "Feature max [3.08529999e+02 3.09660004e+02 1.36264000e+08 2.25299988e+01\n",
      " 1.48899994e+01 1.00000000e+02 1.63896973e+01 4.70789452e+00]\n",
      "Target min [39.40000153]\n",
      "Target max [309.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GILD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.83768806e+01  4.84647914e+01  1.93100000e+06  3.33687064e-01\n",
      " -6.63972958e+00  5.76449552e+00 -2.31350265e+00 -8.99640093e-01]\n",
      "Feature max [8.53581619e+01 8.44682978e+01 9.43485000e+07 8.04050792e+00\n",
      " 7.22805871e+00 1.00000000e+02 4.20840101e+00 1.25684743e+00]\n",
      "Target min [48.46479141]\n",
      "Target max [84.46829781]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.10076256e+01  1.08333313e+01  2.58690000e+06  1.03459220e-01\n",
      " -2.80620500e+00  6.42043171e+00 -2.09796533e+00 -6.88387327e-01]\n",
      "Feature max [3.81064873e+01 3.81660578e+01 2.95518300e+08 2.47469052e+00\n",
      " 2.03002402e+00 1.00000000e+02 1.17294776e+00 5.41764642e-01]\n",
      "Target min [10.83333126]\n",
      "Target max [38.16605779]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing IDXX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.15949997e+02  1.15989998e+02  6.95000000e+04  1.01998901e+00\n",
      " -5.39599915e+01  0.00000000e+00 -4.51944855e+01 -1.18420530e+01]\n",
      "Feature max [7.05760010e+02 6.98869995e+02 2.06065000e+07 4.94200134e+01\n",
      " 2.44899902e+01 9.87477702e+01 2.80133056e+01 9.19398448e+00]\n",
      "Target min [115.98999786]\n",
      "Target max [698.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.72258148e+01  4.72942329e+01  4.40100000e+05  2.32199940e-01\n",
      " -6.70203769e+00  0.00000000e+00 -5.58792261e+00 -1.85080517e+00]\n",
      "Feature max [1.00876343e+02 1.03304346e+02 2.24557000e+07 1.05535592e+01\n",
      " 3.30012562e+00 1.00000000e+02 2.91608734e+00 1.39528294e+00]\n",
      "Target min [47.29423289]\n",
      "Target max [103.30434621]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TEAM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.47199993e+01  2.47299995e+01  2.10900000e+05  2.16999054e-01\n",
      " -4.31699982e+01  1.07833899e+01 -2.66488051e+01 -8.97255197e+00]\n",
      "Feature max [4.58130005e+02 4.55200012e+02 1.74562000e+07 4.22299805e+01\n",
      " 4.32099915e+01 1.00000000e+02 2.40637139e+01 8.94966359e+00]\n",
      "Target min [24.31999969]\n",
      "Target max [455.20001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PANW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.60033340e+01  3.61399994e+01  1.02260000e+06  3.56666565e-01\n",
      " -9.08899841e+01  3.81140920e+00 -1.38470391e+01 -1.22788064e+01]\n",
      "Feature max [3.76899994e+02 3.75450012e+02 6.53592000e+07 2.73699951e+01\n",
      " 2.68099976e+01 1.00000000e+02 1.51691964e+01 4.87990591e+00]\n",
      "Target min [36.13999939]\n",
      "Target max [375.45001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AVGO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.37303333e+01  1.37248155e+01  4.12300000e+06  1.24250219e-01\n",
      " -1.42100067e+01  0.00000000e+00 -5.06872189e+00 -3.00550723e+00]\n",
      "Feature max [1.82308105e+02 1.83376725e+02 4.35083000e+08 1.69199982e+01\n",
      " 2.13810994e+01 9.28312615e+01 1.05782566e+01 4.55284581e+00]\n",
      "Target min [13.72481551]\n",
      "Target max [183.37672469]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CEG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.08016396e+01  3.98784499e+01  2.35000000e+04  6.26233760e-01\n",
      " -1.08198405e+01  1.27016955e+01 -1.06308757e+01 -3.92755151e+00]\n",
      "Feature max [2.30487686e+02 2.31952715e+02 2.38609000e+07 2.15543379e+01\n",
      " 2.45442808e+01 1.00000000e+02 1.44754876e+01 4.38796603e+00]\n",
      "Target min [37.00563649]\n",
      "Target max [231.9527148]\n",
      "X_train shape: (637, 20, 8)\n",
      "Train_dates: 2022-01-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MSFT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.65738869e+01  5.64739966e+01  7.42560000e+06  2.90591337e-01\n",
      " -1.92852005e+01  0.00000000e+00 -1.18035322e+01 -4.62579684e+00]\n",
      "Feature max [4.66718781e+02 4.66159796e+02 1.11242100e+08 2.43750327e+01\n",
      " 2.10308153e+01 9.87202426e+01 1.16126194e+01 3.05457811e+00]\n",
      "Target min [56.47399663]\n",
      "Target max [466.15979612]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EXC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.82024403e+01  1.85263402e+01  2.00850500e+06  1.22239479e-01\n",
      " -1.93681352e+00  5.27394820e+00 -2.56103522e+00 -9.27310629e-01]\n",
      "Feature max [4.59507675e+01 4.58593246e+01 3.88453000e+07 4.14685407e+00\n",
      " 1.20619631e+00 1.00000000e+02 1.62739156e+00 5.65170222e-01]\n",
      "Target min [18.52634024]\n",
      "Target max [45.8593246]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DXCM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.11149998e+01  1.10325003e+01  8.61200000e+05  1.64999962e-01\n",
      " -4.18499985e+01  4.43708879e+00 -1.21858259e+01 -5.03116733e+00]\n",
      "Feature max [1.62815002e+02 1.64257507e+02 1.23168400e+08 1.88925018e+01\n",
      " 1.24700012e+01 1.00000000e+02 8.60785647e+00 2.40813081e+00]\n",
      "Target min [11.03250027]\n",
      "Target max [164.25750732]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FAST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65418377e+01  1.66370331e+01  7.04500000e+05  1.46829911e-01\n",
      " -3.17297661e+00  2.73467744e+00 -1.96586913e+00 -1.08293952e+00]\n",
      "Feature max [7.75266724e+01 7.77145119e+01 5.26096000e+07 4.66000366e+00\n",
      " 3.55978900e+00 1.00000000e+02 1.87048163e+00 8.56669815e-01]\n",
      "Target min [16.63703311]\n",
      "Target max [77.71451195]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ABNB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.24899979e+01  8.29700012e+01  1.72560000e+06  1.01499939e+00\n",
      " -1.80299988e+01  0.00000000e+00 -1.29513658e+01 -4.57280582e+00]\n",
      "Feature max [2.16839996e+02 2.16240005e+02 7.47864000e+07 3.05000000e+01\n",
      " 1.21199951e+01 9.29350181e+01 1.31150691e+01 3.98198040e+00]\n",
      "Target min [82.97000122]\n",
      "Target max [216.24000549]\n",
      "X_train shape: (915, 20, 8)\n",
      "Train_dates: 2020-12-11 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SNPS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.95699997e+01  5.93699989e+01  2.00200000e+05  2.60002136e-01\n",
      " -3.66699829e+01  7.61484664e+00 -2.46719247e+01 -8.22743530e+00]\n",
      "Feature max [6.21299988e+02 6.22929993e+02 3.02946000e+07 5.02700195e+01\n",
      " 4.64199829e+01 1.00000000e+02 2.12557667e+01 8.46134558e+00]\n",
      "Target min [59.27000046]\n",
      "Target max [622.92999268]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BIIB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [187.53999329 190.55999756   0.           0.         -98.07998657\n",
      "   4.79436191 -25.57434546 -11.64517675]\n",
      "Feature max [4.14709991e+02 4.23329987e+02 2.18431000e+07 1.82549988e+02\n",
      " 8.64900055e+01 1.00000000e+02 3.49582846e+01 1.62224245e+01]\n",
      "Target min [190.55999756]\n",
      "Target max [423.32998657]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing REGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.73459991e+02  2.74350006e+02  1.71600000e+05  2.76998901e+00\n",
      " -4.76300049e+01  6.11531109e+00 -2.90962700e+01 -1.14012185e+01]\n",
      "Feature max [1.20176001e+03 1.20471997e+03 7.86950000e+06 8.12899780e+01\n",
      " 9.05499878e+01 1.00000000e+02 3.48632110e+01 1.33649620e+01]\n",
      "Target min [274.3500061]\n",
      "Target max [1204.7199707]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.40612335e+01  7.38682430e+01  1.45000000e+05  3.47388791e-01\n",
      " -1.39151345e+01  7.46558779e+00 -1.02972318e+01 -4.01614540e+00]\n",
      "Feature max [2.85989990e+02 2.85000000e+02 4.24820000e+06 1.72982830e+01\n",
      " 1.09380201e+01 1.00000000e+02 7.65714256e+00 3.71764271e+00]\n",
      "Target min [73.86824302]\n",
      "Target max [285.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TSLA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.19313326e+01  1.20733328e+01  2.94018000e+07  1.66667938e-01\n",
      " -2.41000061e+01  6.91932630e+00 -2.52713333e+01 -7.67848148e+00]\n",
      "Feature max [4.09970001e+02 4.11470001e+02 9.14082000e+08 5.43266602e+01\n",
      " 3.25100098e+01 1.00000000e+02 3.80679297e+01 1.02961745e+01]\n",
      "Target min [12.07333279]\n",
      "Target max [411.47000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NVDA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35561490e+00  2.36844192e+00  9.78840000e+07  3.05890876e-02\n",
      " -1.52099991e+01  8.18789238e+00 -5.16786769e+00 -2.56494372e+00]\n",
      "Feature max [1.35580002e+02 1.39800003e+02 3.69292800e+09 1.33500061e+01\n",
      " 9.16999817e+00 1.00000000e+02 9.77617754e+00 2.89363431e+00]\n",
      "Target min [2.36844192]\n",
      "Target max [139.80000305]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CPRT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95749998e+00  6.97499990e+00  1.16560000e+06  4.75001335e-02\n",
      " -2.40999985e+00  1.07028555e+01 -2.08288713e+00 -5.95224464e-01]\n",
      "Feature max [5.80699997e+01 5.81300011e+01 2.13690400e+08 3.43000031e+00\n",
      " 1.91999817e+00 1.00000000e+02 1.68053820e+00 5.29970520e-01]\n",
      "Target min [6.94750023]\n",
      "Target max [58.13000107]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ORLY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.72850006e+02  1.72839996e+02  9.76000000e+04  1.75000000e+00\n",
      " -7.26999512e+01  9.93704967e+00 -3.18757122e+01 -1.55376421e+01]\n",
      "Feature max [1.16753003e+03 1.16473999e+03 1.28304000e+07 6.14700928e+01\n",
      " 3.95399780e+01 1.00000000e+02 2.94044788e+01 1.46112531e+01]\n",
      "Target min [172.83999634]\n",
      "Target max [1164.73999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSGP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.90799999e+01  1.86439991e+01  4.31000000e+05  1.32999420e-01\n",
      " -1.35200005e+01  3.82196899e+00 -3.91839760e+00 -1.70338203e+00]\n",
      "Feature max [9.97399979e+01 9.96600037e+01 5.40349000e+07 1.53570023e+01\n",
      " 2.22259979e+01 1.00000000e+02 3.78952594e+00 1.64810768e+00]\n",
      "Target min [18.6439991]\n",
      "Target max [99.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PDD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.71499996e+01  1.72000008e+01  1.21070000e+06  3.10001373e-01\n",
      " -2.96699982e+01  0.00000000e+00 -1.20781712e+01 -6.25067404e+00]\n",
      "Feature max [2.02820007e+02 2.11600006e+02 1.03174600e+08 2.12799988e+01\n",
      " 2.67000046e+01 9.22446129e+01 1.43527401e+01 4.73466591e+00]\n",
      "Target min [17.20000076]\n",
      "Target max [211.6000061]\n",
      "X_train shape: (1514, 20, 8)\n",
      "Train_dates: 2018-07-27 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing HON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.46234436e+01  9.52324000e+01  6.25500000e+05  4.19023023e-01\n",
      " -1.95059386e+01  4.75223206e+00 -1.40929690e+01 -4.45800894e+00]\n",
      "Feature max [2.19502518e+02 2.19940311e+02 2.82371000e+07 2.09818764e+01\n",
      " 1.90409619e+01 1.00000000e+02 8.86860848e+00 3.23137150e+00]\n",
      "Target min [95.23239999]\n",
      "Target max [219.940311]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.14207764e+01  6.16446899e+01  4.66400000e+05  4.04764943e-01\n",
      " -1.59855034e+01  0.00000000e+00 -6.96255702e+00 -3.47483258e+00]\n",
      "Feature max [2.42376740e+02 2.39537898e+02 1.91564000e+07 1.54971600e+01\n",
      " 1.14345496e+01 9.47163396e+01 9.37402072e+00 2.80709341e+00]\n",
      "Target min [61.6446899]\n",
      "Target max [239.53789776]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.30817795e+01  7.35512567e+01  5.83900000e+05  5.47719799e-01\n",
      " -1.30866329e+01  5.85091260e+00 -5.68716405e+00 -2.63117400e+00]\n",
      "Feature max [1.51820007e+02 1.50807724e+02 3.87045000e+07 1.23726575e+01\n",
      " 1.06121299e+01 1.00000000e+02 4.99350068e+00 2.11381207e+00]\n",
      "Target min [73.55125665]\n",
      "Target max [150.80772389]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.64580784e+01  1.71472504e+01  1.14310000e+06  1.73414604e-01\n",
      " -9.42169016e+00  0.00000000e+00 -3.04021958e+00 -1.40459935e+00]\n",
      "Feature max [6.87902832e+01 6.75091239e+01 1.35204800e+08 4.21353693e+00\n",
      " 3.35945352e+00 9.56385384e+01 1.17085586e+00 5.30557914e-01]\n",
      "Target min [17.14725043]\n",
      "Target max [67.50912394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WBD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.71000004e+00  6.67000008e+00  7.96300000e+05  1.29999638e-01\n",
      " -4.63999939e+00  7.36432776e+00 -5.62270475e+00 -4.52551421e+00]\n",
      "Feature max [7.72699966e+01 7.79800034e+01 1.58082500e+08 2.36100006e+01\n",
      " 3.59000015e+00 1.00000000e+02 7.78521295e+00 1.10191292e+00]\n",
      "Target min [6.67000008]\n",
      "Target max [77.98000336]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.77167328e+02  1.76918230e+02  1.00700000e+05  1.05556092e+00\n",
      " -7.16818629e+01  1.01358772e+01 -2.43843479e+01 -7.21921458e+00]\n",
      "Feature max [5.76549988e+02 5.77500000e+02 8.03490000e+06 6.23608511e+01\n",
      " 3.51599731e+01 1.00000000e+02 1.65133395e+01 6.23603536e+00]\n",
      "Target min [176.71789525]\n",
      "Target max [577.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15072536  8.44775147  0.          0.         -2.64121747  0.\n",
      " -2.42761183 -0.84240961]\n",
      "Feature max [3.84843826e+01 3.84346839e+01 7.90905000e+07 3.35121803e+00\n",
      " 2.26195987e+00 9.66591338e+01 2.24860550e+00 6.65253146e-01]\n",
      "Target min [8.44775147]\n",
      "Target max [38.43468386]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing COST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.34840027e+02  1.34848979e+02  5.43600000e+05  6.44244141e-01\n",
      " -2.94507165e+01  7.85632611e+00 -3.22091435e+01 -9.48258025e+00]\n",
      "Feature max [9.08900024e+02 9.10960022e+02 2.42330000e+07 4.41770966e+01\n",
      " 1.44715964e+01 1.00000000e+02 2.40226275e+01 6.93894982e+00]\n",
      "Target min [134.84897936]\n",
      "Target max [910.96002197]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.09898224e+01  2.08327117e+01  7.55800000e+05  1.13624069e-01\n",
      " -4.94519305e+00  1.11788406e+01 -2.60963640e+00 -8.58607194e-01]\n",
      "Feature max [8.76200027e+01 8.73300018e+01 6.55402000e+07 7.22391984e+00\n",
      " 4.14095185e+00 1.00000000e+02 2.45854722e+00 7.89947526e-01]\n",
      "Target min [20.83271174]\n",
      "Target max [87.33000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LRCX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.58611450e+01  9.56820940e+01  3.00600000e+05  6.44566123e-01\n",
      " -6.64899902e+01  8.02008287e+00 -6.76982729e+01 -2.23238752e+01]\n",
      "Feature max [1.12730005e+03 1.12977002e+03 1.34214000e+07 7.38499756e+01\n",
      " 3.86400146e+01 1.00000000e+02 3.73546175e+01 1.44478835e+01]\n",
      "Target min [95.50305848]\n",
      "Target max [1129.77001953]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MELI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65434570e+02  1.61862890e+02  1.09000000e+05  1.65614514e+00\n",
      " -1.47979980e+02  6.42065563e+00 -1.26762239e+02 -4.86753050e+01]\n",
      "Feature max [2.06165991e+03 2.03525000e+03 4.29950000e+06 1.80000000e+02\n",
      " 1.14010010e+02 1.00000000e+02 9.65798543e+01 4.12565588e+01]\n",
      "Target min [158.54062541]\n",
      "Target max [2035.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.67368317e+01  4.67459853e+01  1.82100000e+05  3.48899275e-01\n",
      " -2.61500847e+01  1.10566618e+01 -1.16426989e+01 -2.77844168e+00]\n",
      "Feature max [2.56499237e+02 2.59970663e+02 2.45494000e+07 1.57643673e+01\n",
      " 1.15215366e+01 1.00000000e+02 6.29487466e+00 2.94088429e+00]\n",
      "Target min [46.74598533]\n",
      "Target max [259.97066279]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FANG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.26427412e+01  1.29027437e+01  2.62100000e+05  7.69125709e-01\n",
      " -1.58440575e+01  1.03142457e+00 -1.19967649e+01 -3.84871261e+00]\n",
      "Feature max [2.08427399e+02 2.08555865e+02 3.30497000e+07 1.22028993e+01\n",
      " 7.94709301e+00 1.00000000e+02 7.18674563e+00 2.89178249e+00]\n",
      "Target min [12.90274369]\n",
      "Target max [208.55586459]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ZS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.49500008e+01  2.50000000e+01  1.97200000e+05  3.79999161e-01\n",
      " -3.88899994e+01  0.00000000e+00 -2.36812080e+01 -8.89085502e+00]\n",
      "Feature max [3.68779999e+02 3.72500000e+02 2.68458000e+07 5.90399780e+01\n",
      " 2.63500061e+01 9.43483988e+01 1.81146072e+01 6.76156951e+00]\n",
      "Target min [25.]\n",
      "Target max [372.5]\n",
      "X_train shape: (1605, 20, 8)\n",
      "Train_dates: 2018-03-19 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADBE data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.04139999e+02  1.03739998e+02  5.89200000e+05  6.49993896e-01\n",
      " -7.08099976e+01  1.41851355e+00 -3.26176172e+01 -1.20971259e+01]\n",
      "Feature max [6.88369995e+02 6.96280029e+02 2.78402000e+07 5.77900391e+01\n",
      " 7.15100098e+01 1.00000000e+02 3.08100807e+01 9.11981859e+00]\n",
      "Target min [103.43000031]\n",
      "Target max [696.2800293]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93002777e+01  3.92593243e+01  6.93600000e+06  1.63815054e-01\n",
      " -1.10299988e+01  1.33774083e+01 -5.19036880e+00 -2.41195015e+00]\n",
      "Feature max [1.92660004e+02 1.91750000e+02 1.24140000e+08 9.33999634e+00\n",
      " 1.80194956e+01 1.00000000e+02 5.21262163e+00 1.68897131e+00]\n",
      "Target min [38.8962372]\n",
      "Target max [191.75]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMAT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.72328186e+01  2.75991753e+01  1.40920000e+06  2.48054618e-01\n",
      " -1.45720706e+01  1.10477215e+01 -1.30488603e+01 -4.80425105e+00]\n",
      "Feature max [2.54482300e+02 2.55081164e+02 5.25842000e+07 1.67279368e+01\n",
      " 1.42822510e+01 1.00000000e+02 1.06164149e+01 3.45275434e+00]\n",
      "Target min [27.59917534]\n",
      "Target max [255.0811642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.12595596e+01  8.12424900e+01  3.50200000e+05  3.94597419e-01\n",
      " -1.50322675e+01  3.70819327e+00 -1.35625546e+01 -3.90767252e+00]\n",
      "Feature max [2.75910004e+02 2.75790009e+02 2.98376000e+07 1.78119307e+01\n",
      " 1.03888203e+01 1.00000000e+02 1.01973384e+01 2.87688119e+00]\n",
      "Target min [81.24248999]\n",
      "Target max [275.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SBUX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.25571556e+01  4.21538477e+01  1.84780000e+06  2.41612795e-01\n",
      " -1.24990496e+01  3.06340275e+00 -6.61673832e+00 -1.77160410e+00]\n",
      "Feature max [1.17301453e+02 1.17320081e+02 1.57215500e+08 8.91207916e+00\n",
      " 1.39059501e+01 1.00000000e+02 5.32951402e+00 2.47897411e+00]\n",
      "Target min [42.15384768]\n",
      "Target max [117.32008083]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTWO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.93600006e+01  4.94000015e+01  2.11600000e+05  3.89999390e-01\n",
      " -1.71000061e+01  5.25756554e+00 -1.00961129e+01 -3.59837456e+00]\n",
      "Feature max [2.13339996e+02 2.10479996e+02 2.53857000e+07 1.86999969e+01\n",
      " 1.62300034e+01 1.00000000e+02 8.60457497e+00 3.04146889e+00]\n",
      "Target min [49.34999847]\n",
      "Target max [210.47999573]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TMUS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.45139236e+01  5.45139293e+01  4.70100000e+05  2.26488207e-01\n",
      " -9.75855268e+00  9.14551088e+00 -4.12801689e+00 -2.00070149e+00]\n",
      "Feature max [2.03367172e+02 2.04613114e+02 6.69031000e+07 1.24074325e+01\n",
      " 1.02607535e+01 1.00000000e+02 5.13087043e+00 2.60923839e+00]\n",
      "Target min [54.51392929]\n",
      "Target max [204.61311436]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WDAY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.13600006e+01  6.86699982e+01  3.69100000e+05  7.19993591e-01\n",
      " -2.87099915e+01  9.22365714e+00 -1.61351526e+01 -5.44748712e+00]\n",
      "Feature max [3.07209991e+02 3.09100006e+02 1.56112000e+07 2.13899994e+01\n",
      " 3.39099884e+01 1.00000000e+02 1.38299273e+01 6.22001392e+00]\n",
      "Target min [66.75]\n",
      "Target max [309.1000061]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CRWD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.30099983e+01  3.39300003e+01  8.04900000e+05  1.25000000e+00\n",
      " -4.85399780e+01  5.38771656e+00 -3.82154109e+01 -1.52669393e+01]\n",
      "Feature max [3.92149994e+02 3.92510010e+02 5.40774000e+07 4.09899902e+01\n",
      " 6.24899902e+01 1.00000000e+02 1.92436948e+01 8.51986054e+00]\n",
      "Target min [33.93000031]\n",
      "Target max [392.51000977]\n",
      "X_train shape: (1294, 20, 8)\n",
      "Train_dates: 2019-06-13 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DDOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.80400009e+01  2.78999996e+01  5.74800000e+05  7.30003357e-01\n",
      " -2.19200058e+01  0.00000000e+00 -1.14620833e+01 -4.12330397e+00]\n",
      "Feature max [1.96559998e+02 1.97695999e+02 2.91348000e+07 2.36900024e+01\n",
      " 2.69400024e+01 9.94039849e+01 1.14713512e+01 4.87120929e+00]\n",
      "Target min [27.89999962]\n",
      "Target max [197.69599915]\n",
      "X_train shape: (1225, 20, 8)\n",
      "Train_dates: 2019-09-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PCAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.86600723e+01  2.83693925e+01  4.95450000e+05  1.76137070e-01\n",
      " -1.04065623e+01  7.26960956e+00 -3.26233711e+00 -1.44177861e+00]\n",
      "Feature max [1.23713150e+02 1.24249916e+02 1.21321500e+07 7.01745891e+00\n",
      " 3.03884653e+00 1.00000000e+02 4.25862741e+00 1.04586866e+00]\n",
      "Target min [28.36939252]\n",
      "Target max [124.24991579]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRNA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.22600002e+01  1.22600002e+01  2.72800000e+05  2.99999237e-01\n",
      " -5.01100159e+01  6.23065240e+00 -3.31765627e+01 -1.53366601e+01]\n",
      "Feature max [4.84470001e+02 4.85500000e+02 1.25130400e+08 8.40969849e+01\n",
      " 4.59499817e+01 1.00000000e+02 5.26756442e+01 1.60440938e+01]\n",
      "Target min [12.26000023]\n",
      "Target max [485.5]\n",
      "X_train shape: (1421, 20, 8)\n",
      "Train_dates: 2018-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing META data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.87276688e+01  8.98952675e+01  5.46750000e+06  5.18937895e-01\n",
      " -7.81893309e+01  9.76807065e+00 -2.89867461e+01 -9.55160496e+00]\n",
      "Feature max [5.39909973e+02 5.42349976e+02 2.32316600e+08 3.50699768e+01\n",
      " 6.46870787e+01 1.00000000e+02 2.92185320e+01 7.48696458e+00]\n",
      "Target min [89.89526752]\n",
      "Target max [542.34997559]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MNST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.07199993e+01  2.07049999e+01  9.22800000e+05  1.65000916e-01\n",
      " -5.64999771e+00  7.54052007e+00 -2.06519425e+00 -6.53749929e-01]\n",
      "Feature max [6.08499985e+01 6.10000000e+01 3.67095000e+07 4.27999878e+00\n",
      " 4.58000183e+00 1.00000000e+02 1.81693996e+00 9.25280916e-01]\n",
      "Target min [20.70499992]\n",
      "Target max [61.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.52999973e+00  9.07999992e+00  1.10358000e+07  1.19999886e-01\n",
      " -1.03399963e+01  0.00000000e+00 -9.13773987e+00 -3.97167693e+00]\n",
      "Feature max [2.11380005e+02 2.13410004e+02 3.25058400e+08 2.16999969e+01\n",
      " 1.31100006e+01 9.59459396e+01 1.14017298e+01 3.51085324e+00]\n",
      "Target min [9.07999992]\n",
      "Target max [213.41000366]\n",
      "X_train shape: (1906, 20, 8)\n",
      "Train_dates: 2017-01-05 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing QCOM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.10863152e+01  4.13346323e+01  2.12020000e+06  2.21164957e-01\n",
      " -1.19638878e+01  7.39900392e+00 -1.13783823e+01 -3.46840781e+00]\n",
      "Feature max [2.25922470e+02 2.25653869e+02 1.56019300e+08 1.56075679e+01\n",
      " 1.67030311e+01 1.00000000e+02 1.22270518e+01 3.97922183e+00]\n",
      "Target min [41.33463229]\n",
      "Target max [225.65386916]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CCEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55083256e+01  2.55731092e+01  2.18600000e+05  1.48332728e-01\n",
      " -5.48859656e+00  7.67621212e+00 -5.38139235e+00 -1.98555605e+00]\n",
      "Feature max [8.04899979e+01 8.02600021e+01 3.00719000e+07 5.47105868e+00\n",
      " 5.02390864e+00 1.00000000e+02 2.10718557e+00 1.58574567e+00]\n",
      "Target min [25.23299887]\n",
      "Target max [80.26000214]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PAYX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.40656853e+01  4.43662807e+01  4.22500000e+05  2.53874792e-01\n",
      " -6.98217401e+00  6.37100472e+00 -7.06664280e+00 -2.03882520e+00]\n",
      "Feature max [1.31301468e+02 1.30869995e+02 1.68049000e+07 1.40609675e+01\n",
      " 5.64423284e+00 1.00000000e+02 4.66590849e+00 1.34585577e+00]\n",
      "Target min [44.36628073]\n",
      "Target max [130.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CHTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.54610001e+02  2.38960007e+02  2.42700000e+05  1.79000854e+00\n",
      " -4.96099854e+01  1.00045832e+01 -3.55786821e+01 -1.27762515e+01]\n",
      "Feature max [8.21010010e+02 8.23080017e+02 1.55224000e+07 4.71099854e+01\n",
      " 4.25099792e+01 1.00000000e+02 2.18537876e+01 9.81964050e+00]\n",
      "Target min [238.96000671]\n",
      "Target max [823.08001709]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTAS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.05113617e+02  1.05187604e+02  1.12200000e+05  5.64083578e-01\n",
      " -4.39267993e+01  1.00213959e+01 -2.82557867e+01 -9.58054398e+00]\n",
      "Feature max [8.05119995e+02 8.04500000e+02 2.72700000e+06 4.61448665e+01\n",
      " 4.98478169e+01 1.00000000e+02 1.69135623e+01 6.24244921e+00]\n",
      "Target min [105.18760444]\n",
      "Target max [804.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GEHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.58701439e+01  5.28771038e+01  2.22000000e+04  4.48496557e-01\n",
      " -7.89708004e+00  0.00000000e+00 -2.75575511e+00 -9.40395579e-01]\n",
      "Feature max [9.38021851e+01 9.37422203e+01 3.33385000e+07 1.07550019e+01\n",
      " 3.51607095e+00 8.71251436e+01 4.22888858e+00 9.98581046e-01]\n",
      "Target min [52.87710382]\n",
      "Target max [93.74222026]\n",
      "X_train shape: (408, 20, 8)\n",
      "Train_dates: 2022-12-16 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRVL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.31523399e+01  1.32089134e+01  1.60940000e+06  9.52960185e-02\n",
      " -5.81999969e+00  1.28620113e+01 -4.44552211e+00 -2.03029592e+00]\n",
      "Feature max [9.03993759e+01 9.02215677e+01 9.43073000e+07 9.40218170e+00\n",
      " 1.46796512e+01 1.00000000e+02 5.29263949e+00 2.28143680e+00]\n",
      "Target min [13.13348662]\n",
      "Target max [90.2215677]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NXPI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.02686462e+01  6.05207032e+01  4.80500000e+05  1.27887285e-01\n",
      " -2.30199890e+01  8.16553100e+00 -1.30447493e+01 -4.12573877e+00]\n",
      "Feature max [2.90779999e+02 2.85390015e+02 5.31022000e+07 2.01099854e+01\n",
      " 1.25949051e+01 1.00000000e+02 9.68135969e+00 3.81693437e+00]\n",
      "Target min [60.5207032]\n",
      "Target max [285.39001465]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.71000004e+00  2.69000006e+00  6.31000000e+05  5.90000153e-02\n",
      " -1.51449966e+01  1.02722976e+01 -7.73271712e+00 -2.83294696e+00]\n",
      "Feature max [1.11639999e+02 1.11089996e+02 1.27624000e+08 1.49599991e+01\n",
      " 1.57500000e+01 1.00000000e+02 8.65914541e+00 3.44913976e+00]\n",
      "Target min [2.69000006]\n",
      "Target max [111.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKNG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.14665942e+03  1.16132802e+03  7.94000000e+04  6.03070832e+00\n",
      " -3.52589844e+02  6.38678134e+00 -1.75862492e+02 -7.18094242e+01]\n",
      "Feature max [4.11908984e+03 4.11700000e+03 3.32510000e+06 2.15700240e+02\n",
      " 3.13563991e+02 1.00000000e+02 1.22086361e+02 4.95826730e+01]\n",
      "Target min [1161.32802486]\n",
      "Target max [4117.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KDP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.17389641e+01  1.13540100e+01  3.12600000e+05  5.19934972e-02\n",
      " -2.16673267e+00  5.47438798e+00 -1.84060807e+00 -7.08470134e-01]\n",
      "Feature max [3.81241341e+01 3.81621768e+01 1.43326600e+08 4.27929837e+00\n",
      " 4.32504476e+00 1.00000000e+02 1.24850194e+00 5.03789297e-01]\n",
      "Target min [11.35401002]\n",
      "Target max [38.16217682]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ODFL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.60743732e+01  2.62781804e+01  2.93800000e+05  2.29686469e-01\n",
      " -1.23647591e+01  9.60325711e+00 -9.47054031e+00 -4.03113182e+00]\n",
      "Feature max [2.24051163e+02 2.25128094e+02 4.64676000e+07 2.78705293e+01\n",
      " 9.12876452e+00 1.00000000e+02 9.61462650e+00 3.12346527e+00]\n",
      "Target min [26.27818039]\n",
      "Target max [225.12809388]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ISRG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.99433365e+01  7.00211105e+01  4.89900000e+05  4.15557861e-01\n",
      " -1.95700073e+01  0.00000000e+00 -2.11512520e+01 -7.04575693e+00]\n",
      "Feature max [4.92630005e+02 4.92619995e+02 1.12668000e+07 2.48000031e+01\n",
      " 3.32899780e+01 9.95441593e+01 1.42319395e+01 6.40623327e+00]\n",
      "Target min [70.02111053]\n",
      "Target max [492.61999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TXN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.90602226e+01  5.90278217e+01  1.04440000e+06  2.77122064e-01\n",
      " -1.04008110e+01  0.00000000e+00 -6.09191238e+00 -2.17086585e+00]\n",
      "Feature max [2.14339996e+02 2.12580002e+02 2.51217000e+07 1.31599884e+01\n",
      " 1.25867588e+01 9.74574577e+01 7.69273127e+00 2.34828422e+00]\n",
      "Target min [59.0278217]\n",
      "Target max [212.58000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ARM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.78699989e+01  4.72200012e+01  2.26890000e+06  1.22000122e+00\n",
      " -2.08500061e+01  0.00000000e+00 -1.27820527e+01 -6.74110994e+00]\n",
      "Feature max [1.86460007e+02 1.86839996e+02 1.11349700e+08 4.53099976e+01\n",
      " 1.74000015e+01 9.62229824e+01 1.65008639e+01 6.88049836e+00]\n",
      "Target min [47.22000122]\n",
      "Target max [186.83999634]\n",
      "X_train shape: (222, 20, 8)\n",
      "Train_dates: 2023-09-15 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.95189896e+01  4.98084665e+01  5.35700000e+05  4.09831331e-01\n",
      " -2.21022887e+01  7.32260869e+00 -1.31744930e+01 -4.43503087e+00]\n",
      "Feature max [1.55210007e+02 1.63559998e+02 3.45755000e+07 1.30095107e+01\n",
      " 1.65455567e+01 1.00000000e+02 7.20230570e+00 2.52539377e+00]\n",
      "Target min [49.80846647]\n",
      "Target max [163.55999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDLZ data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.26199188e+01  3.25591459e+01  1.83380000e+06  1.95484721e-01\n",
      " -4.06838765e+00  0.00000000e+00 -3.04621880e+00 -1.02893296e+00]\n",
      "Feature max [7.60628128e+01 7.61016380e+01 2.91974000e+07 4.50139804e+00\n",
      " 3.43486217e+00 9.24410761e+01 2.31448955e+00 8.04107787e-01]\n",
      "Target min [32.55914595]\n",
      "Target max [76.10163795]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LIN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01270172e+02  1.01313936e+02  2.76400000e+05  5.60332175e-01\n",
      " -2.60358760e+01  0.00000000e+00 -1.35822622e+01 -4.32008793e+00]\n",
      "Feature max [4.76847687e+02 4.73647108e+02 5.73756000e+07 2.50221201e+01\n",
      " 1.73250947e+01 9.79872343e+01 1.39092182e+01 4.41989817e+00]\n",
      "Target min [101.31393592]\n",
      "Target max [473.64710757]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSCO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.37586002e+01  2.37744560e+01  5.72050000e+06  1.35897120e-01\n",
      " -5.72839392e+00  0.00000000e+00 -2.51348577e+00 -7.94818190e-01]\n",
      "Feature max [5.87176781e+01 5.87911180e+01 1.06928300e+08 3.98683323e+00\n",
      " 3.31000137e+00 9.41030476e+01 1.74181733e+00 6.52277731e-01]\n",
      "Target min [23.77445599]\n",
      "Target max [58.79111801]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.08447884e+02  1.05853972e+02  4.17100000e+05  4.74368466e-01\n",
      " -4.12029187e+01  4.31389479e+00 -2.91569435e+01 -1.00687249e+01]\n",
      "Feature max [6.82518799e+02 7.03358031e+02 6.66440000e+06 4.95999756e+01\n",
      " 8.54105820e+01 1.00000000e+02 2.48427016e+01 9.59888974e+00]\n",
      "Target min [105.85397237]\n",
      "Target max [703.3580307]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.01410751e+01  8.03660597e+01  8.83300000e+05  2.61090847e-01\n",
      " -1.13062698e+01  5.70037116e+00 -6.88044670e+00 -2.29319743e+00]\n",
      "Feature max [1.88991531e+02 1.89425159e+02 2.75597000e+07 1.50898149e+01\n",
      " 5.84069218e+00 1.00000000e+02 3.42618755e+00 2.29382464e+00]\n",
      "Target min [80.36605971]\n",
      "Target max [189.42515895]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ANSS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.32399979e+01  9.30100021e+01  1.40800000e+05  5.89996338e-01\n",
      " -3.09700012e+01  8.81775088e+00 -1.95951198e+01 -9.68954390e+00]\n",
      "Feature max [4.11220001e+02 4.13220001e+02 1.76134000e+07 5.81499939e+01\n",
      " 5.98500061e+01 1.00000000e+02 1.77876080e+01 8.00055630e+00]\n",
      "Target min [93.01000214]\n",
      "Target max [413.22000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SMCI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [  11.64999962   11.55000019 1300.            0.         -112.07000732\n",
      "    3.06121694  -80.8459551   -37.07896777]\n",
      "Feature max [1.18806995e+03 1.21200000e+03 3.69735000e+07 2.76719971e+02\n",
      " 1.33520020e+02 1.00000000e+02 1.39404960e+02 3.27849310e+01]\n",
      "Target min [11.55000019]\n",
      "Target max [1212.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MCHP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.59165306e+01  2.58235891e+01  9.03800000e+05  2.06648726e-01\n",
      " -4.89303413e+00  0.00000000e+00 -5.27414154e+00 -1.76700589e+00]\n",
      "Feature max [9.89445496e+01 9.94815944e+01 6.08822000e+07 6.51408535e+00\n",
      " 6.70935719e+00 9.91722379e+01 3.41370681e+00 1.65716014e+00]\n",
      "Target min [25.82358912]\n",
      "Target max [99.48159441]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DASH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.30600014e+01  4.40000000e+01  6.73000000e+05  1.04000092e+00\n",
      " -1.43899994e+01  0.00000000e+00 -1.42424126e+01 -6.22931087e+00]\n",
      "Feature max [2.45970001e+02 2.47520004e+02 4.74057000e+07 6.56900024e+01\n",
      " 3.15700073e+01 8.94834273e+01 1.00982520e+01 7.89917563e+00]\n",
      "Target min [44.]\n",
      "Target max [247.52000427]\n",
      "X_train shape: (916, 20, 8)\n",
      "Train_dates: 2020-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LULU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.79099998e+01  4.80200005e+01  3.97400000e+05  5.40000916e-01\n",
      " -6.25899963e+01  5.58157336e+00 -2.90394509e+01 -9.98076840e+00]\n",
      "Feature max [5.11290009e+02 5.13239990e+02 4.96203000e+07 4.49899902e+01\n",
      " 5.28800049e+01 1.00000000e+02 2.51784526e+01 8.66763261e+00]\n",
      "Target min [48.02000046]\n",
      "Target max [513.23999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.20500984e+02  1.20691447e+02  6.12800000e+05  8.28945424e-01\n",
      " -1.51888420e+01  4.25187927e+00 -6.90049242e+00 -3.92935187e+00]\n",
      "Feature max [3.33829987e+02 3.35086817e+02 2.39368000e+07 2.95567919e+01\n",
      " 3.45128549e+01 1.00000000e+02 1.11182756e+01 4.56750789e+00]\n",
      "Target min [117.33473539]\n",
      "Target max [335.08681669]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.69300003e+01  7.61900024e+01  2.56200000e+05  5.80001831e-01\n",
      " -4.11199951e+01  8.69419477e+00 -1.48270264e+01 -9.41658874e+00]\n",
      "Feature max [3.42269989e+02 3.42519989e+02 1.94870000e+07 2.90000076e+01\n",
      " 2.02900085e+01 1.00000000e+02 1.45651636e+01 4.69711212e+00]\n",
      "Target min [74.61000061]\n",
      "Target max [342.51998901]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTSH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88846626e+01  3.95294712e+01  6.22600000e+05  2.63455814e-01\n",
      " -7.87768142e+00  3.88436978e+00 -4.96337501e+00 -1.63582261e+00]\n",
      "Feature max [8.93110580e+01 8.89753726e+01 4.05510000e+07 7.35238977e+00\n",
      " 4.92298399e+00 1.00000000e+02 2.87893965e+00 1.48546537e+00]\n",
      "Target min [39.52947115]\n",
      "Target max [88.9753726]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CMCSA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.63607197e+01  2.63434864e+01  3.87530000e+06  1.43293802e-01\n",
      " -4.19077970e+00  4.89603961e+00 -2.20475346e+00 -7.52468733e-01]\n",
      "Feature max [5.69077454e+01 5.66128428e+01 1.05512100e+08 5.02262394e+00\n",
      " 2.79152757e+00 1.00000000e+02 1.64204573e+00 6.64990298e-01]\n",
      "Target min [26.34348644]\n",
      "Target max [56.61284285]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AAPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.68914185e+01  2.68520158e+01  2.40483000e+07  1.39069218e-01\n",
      " -2.07459821e+01  0.00000000e+00 -6.52546699e+00 -2.48303795e+00]\n",
      "Feature max [2.34548523e+02 2.36206595e+02 4.47940000e+08 1.74797677e+01\n",
      " 1.35858198e+01 9.66324712e+01 8.94504543e+00 2.34169467e+00]\n",
      "Target min [26.84042339]\n",
      "Target max [236.20659489]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DLTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.55699997e+01  6.56299973e+01  6.51800000e+05  6.50001526e-01\n",
      " -2.06100006e+01  5.95402131e+00 -8.27013588e+00 -4.05435465e+00]\n",
      "Feature max [1.74080002e+02 1.75119995e+02 2.64414000e+07 1.71399956e+01\n",
      " 2.62200012e+01 1.00000000e+02 1.03700274e+01 2.48843256e+00]\n",
      "Target min [65.62999725]\n",
      "Target max [175.11999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GFS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88100014e+01  3.79099998e+01  4.52100000e+05  4.29996490e-01\n",
      " -4.36000061e+00  7.50238102e+00 -4.23886167e+00 -2.38196636e+00]\n",
      "Feature max [7.89400024e+01 7.86999969e+01 2.59534000e+07 9.84000015e+00\n",
      " 5.52999878e+00 1.00000000e+02 5.44023126e+00 1.92129480e+00]\n",
      "Target min [37.90999985]\n",
      "Target max [78.69999695]\n",
      "X_train shape: (693, 20, 8)\n",
      "Train_dates: 2021-10-29 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.44999981e+00  8.35999966e+00  1.22410000e+06  1.59999847e-01\n",
      " -1.02299957e+01  1.19369510e+01 -7.02511537e+00 -2.54591706e+00]\n",
      "Feature max [1.08089996e+02 1.09739998e+02 9.31809000e+07 8.59999847e+00\n",
      " 5.73000336e+00 1.00000000e+02 5.08121811e+00 1.91962014e+00]\n",
      "Target min [8.35999966]\n",
      "Target max [109.73999786]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOGL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.03422012e+01  4.03287161e+01  9.31200000e+06  2.03764713e-01\n",
      " -1.11600037e+01  0.00000000e+00 -5.26264397e+00 -2.43230043e+00]\n",
      "Feature max [1.91179993e+02 1.90309998e+02 1.33178000e+08 9.50000000e+00\n",
      " 1.83489409e+01 9.87786722e+01 5.22104620e+00 1.70818585e+00]\n",
      "Target min [39.98510758]\n",
      "Target max [190.30999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.13033676e+01  2.10973018e+01  4.34960000e+06  2.94382096e-01\n",
      " -6.56426828e+00  0.00000000e+00 -1.04368766e+01 -2.87377570e+00]\n",
      "Feature max [1.53315903e+02 1.56872784e+02 1.42315800e+08 1.44873285e+01\n",
      " 1.70885489e+01 9.98188294e+01 9.21113833e+00 2.76849472e+00]\n",
      "Target min [21.09730184]\n",
      "Target max [156.87278409]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ILMN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.02626495e+01  9.14591446e+01  2.24207000e+05  1.42024231e+00\n",
      " -5.47957153e+01  1.07051311e+00 -2.98009348e+01 -1.18772369e+01]\n",
      "Feature max [5.10544739e+02 5.08336578e+02 3.66514900e+07 1.00622589e+02\n",
      " 3.87353821e+01 1.00000000e+02 2.65404856e+01 7.18644479e+00]\n",
      "Target min [91.45914459]\n",
      "Target max [508.33657837]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDNS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55699997e+01  2.53400002e+01  3.77200000e+05  1.30001068e-01\n",
      " -1.65799866e+01  6.34196911e+00 -1.44468346e+01 -5.97594400e+00]\n",
      "Feature max [3.26500000e+02 3.28790009e+02 5.72181000e+07 2.09400024e+01\n",
      " 1.50199890e+01 1.00000000e+02 8.60328681e+00 4.15512117e+00]\n",
      "Target min [25.34000015]\n",
      "Target max [328.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FTNT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.08400011e+00  6.03000021e+00  1.55300000e+06  5.60002327e-02\n",
      " -1.53400040e+01  3.96274759e+00 -4.72904041e+00 -2.60667325e+00]\n",
      "Feature max [8.02799988e+01 8.04499969e+01 1.66853000e+08 9.42400360e+00\n",
      " 9.86999893e+00 1.00000000e+02 4.39902634e+00 1.72982386e+00]\n",
      "Target min [6.03000021]\n",
      "Target max [80.44999695]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NFLX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.29179993e+02  1.27489998e+02  1.14400000e+06  8.99993896e-01\n",
      " -1.07820007e+02  2.54085690e+00 -5.92338064e+01 -1.83116588e+01]\n",
      "Feature max [7.01349976e+02 7.00359985e+02 1.33387500e+08 5.69599915e+01\n",
      " 6.36499939e+01 1.00000000e+02 2.49544334e+01 9.64348338e+00]\n",
      "Target min [124.95999908]\n",
      "Target max [700.35998535]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ASML data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01730965e+02  1.01656923e+02  1.91300000e+05  5.09020836e-01\n",
      " -8.94442496e+01  0.00000000e+00 -4.66577753e+01 -2.22673979e+01]\n",
      "Feature max [1.09691748e+03 1.10792721e+03 7.75430000e+06 7.14700317e+01\n",
      " 6.84131669e+01 9.61639905e+01 5.18699435e+01 1.62876850e+01]\n",
      "Target min [101.65692296]\n",
      "Target max [1107.92720614]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.57600002e+01  2.56200008e+01  7.45000000e+04  3.59998703e-01\n",
      " -7.29299927e+01  0.00000000e+00 -4.01420346e+01 -1.51743729e+01]\n",
      "Feature max [5.85030029e+02 5.85030029e+02 1.25421000e+07 6.22800293e+01\n",
      " 9.26100159e+01 9.67312153e+01 3.60296232e+01 1.38232539e+01]\n",
      "Target min [25.62000084]\n",
      "Target max [585.0300293]\n",
      "X_train shape: (1706, 20, 8)\n",
      "Train_dates: 2017-10-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.76626587e+01  5.97122857e+01  4.45200000e+05  3.56550028e-01\n",
      " -1.06970815e+01  0.00000000e+00 -1.68949971e+01 -4.25844633e+00]\n",
      "Feature max [2.57128174e+02 2.54701584e+02 2.58818000e+07 2.13453368e+01\n",
      " 1.87003391e+01 9.38539425e+01 7.41175557e+00 3.17530369e+00]\n",
      "Target min [59.7122857]\n",
      "Target max [254.70158394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.89899998e+01  1.91000004e+01  6.31320000e+06  1.65667040e-01\n",
      " -7.35440763e+00  0.00000000e+00 -3.67962891e+00 -1.56579357e+00]\n",
      "Feature max [6.20833321e+01 6.20287564e+01 3.00895900e+08 7.64107747e+00\n",
      " 5.65919109e+00 9.56309713e+01 2.62854927e+00 1.12867592e+00]\n",
      "Target min [19.10000038]\n",
      "Target max [62.02875642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KLAC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.84464874e+01  6.86297678e+01  2.57700000e+05  5.09411721e-01\n",
      " -4.98388271e+01  0.00000000e+00 -2.75021474e+01 -1.29123595e+01]\n",
      "Feature max [8.90720154e+02 8.94682933e+02 6.29590000e+06 7.53521125e+01\n",
      " 4.65248886e+01 9.61332173e+01 3.03164128e+01 1.17409375e+01]\n",
      "Target min [68.62976779]\n",
      "Target max [894.68293334]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.78590012e+01  3.79194984e+01  1.76260000e+07  1.59500122e-01\n",
      " -1.73200073e+01  1.14353166e+01 -1.24315006e+01 -3.31749210e+00]\n",
      "Feature max [2.00000000e+02 2.00089996e+02 3.31300000e+08 1.37949982e+01\n",
      " 1.67610016e+01 1.00000000e+02 8.13447345e+00 3.39296647e+00]\n",
      "Target min [37.89599991]\n",
      "Target max [200.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing XEL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [32.11785126 32.15771081  0.          0.         -5.25528431  4.89752525\n",
      " -3.58270584 -1.54356233]\n",
      "Feature max [7.23329086e+01 7.20338896e+01 2.27822000e+07 8.42780017e+00\n",
      " 2.38431091e+00 1.00000000e+02 1.75878069e+00 1.02005435e+00]\n",
      "Target min [32.15771081]\n",
      "Target max [72.03388965]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m5,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,921</span> (85.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,921\u001b[0m (85.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,921</span> (85.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,921\u001b[0m (85.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/102 Training model for ^IXIC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0053 - mape: 51.9235 - val_loss: 0.1038 - val_mape: 37.1234\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0475 - mape: 301.1647 - val_loss: 0.1603 - val_mape: 47.3059\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0311 - mape: 219.9285 - val_loss: 0.1363 - val_mape: 43.4839\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0262 - mape: 194.7854 - val_loss: 0.0706 - val_mape: 30.4958\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0221 - mape: 185.7576 - val_loss: 0.0660 - val_mape: 29.4038\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0203 - mape: 179.9505 - val_loss: 0.0543 - val_mape: 26.3765\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0135 - mape: 141.0885 - val_loss: 0.0484 - val_mape: 24.8426\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0085 - mape: 106.2926 - val_loss: 0.0426 - val_mape: 23.1436\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 70.8718 - val_loss: 0.0384 - val_mape: 21.9183\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 49.6701 - val_loss: 0.0376 - val_mape: 21.7581\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mape: 38.5784 - val_loss: 0.0345 - val_mape: 20.7924\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 37.2485 - val_loss: 0.0350 - val_mape: 21.0446\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 50.8867 - val_loss: 0.0352 - val_mape: 21.1368\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mape: 58.7830 - val_loss: 0.0314 - val_mape: 19.8003\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - mape: 77.0137 - val_loss: 0.0328 - val_mape: 20.3272\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mape: 81.6512 - val_loss: 0.0312 - val_mape: 19.7085\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0059 - mape: 87.0008 - val_loss: 0.0264 - val_mape: 17.8808\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0064 - mape: 89.5777 - val_loss: 0.0255 - val_mape: 17.5253\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0061 - mape: 86.2341 - val_loss: 0.0222 - val_mape: 16.1003\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0061 - mape: 89.0000 - val_loss: 0.0197 - val_mape: 15.0700\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mape: 62.5586 - val_loss: 0.0182 - val_mape: 14.4063\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mape: 54.1672 - val_loss: 0.0155 - val_mape: 13.0699\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mape: 47.3609 - val_loss: 0.0141 - val_mape: 12.3135\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 38.8998 - val_loss: 0.0141 - val_mape: 12.3624\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 42.6043 - val_loss: 0.0143 - val_mape: 12.5289\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - mape: 45.4982 - val_loss: 0.0123 - val_mape: 11.3730\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 43.6401 - val_loss: 0.0098 - val_mape: 9.8965\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 37.7578 - val_loss: 0.0090 - val_mape: 9.3732\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 41.8493 - val_loss: 0.0077 - val_mape: 8.5667\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 37.8023 - val_loss: 0.0074 - val_mape: 8.2949\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 39.9133 - val_loss: 0.0082 - val_mape: 9.0497\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 40.0177 - val_loss: 0.0071 - val_mape: 8.1195\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 46.2664 - val_loss: 0.0068 - val_mape: 7.9551\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 42.4795 - val_loss: 0.0062 - val_mape: 7.5681\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mape: 35.6643 - val_loss: 0.0056 - val_mape: 7.1394\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 45.1775 - val_loss: 0.0051 - val_mape: 6.7381\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 46.3826 - val_loss: 0.0034 - val_mape: 5.2295\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 47.4783 - val_loss: 0.0033 - val_mape: 5.1225\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 41.7681 - val_loss: 0.0027 - val_mape: 4.5676\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 56.0290 - val_loss: 0.0044 - val_mape: 6.1809\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mape: 63.2813 - val_loss: 0.0040 - val_mape: 5.8235\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 43.4834 - val_loss: 0.0041 - val_mape: 5.9282\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 39.5219 - val_loss: 0.0038 - val_mape: 5.7068\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 38.4139 - val_loss: 0.0029 - val_mape: 4.7760\n",
      "Epoch 45/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 40.3639 - val_loss: 0.0024 - val_mape: 4.2998\n",
      "Epoch 46/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 50.7434 - val_loss: 0.0033 - val_mape: 5.2304\n",
      "Epoch 47/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 57.8157 - val_loss: 0.0027 - val_mape: 4.5961\n",
      "Epoch 48/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 52.1799 - val_loss: 0.0030 - val_mape: 4.9727\n",
      "Epoch 49/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mape: 66.2972 - val_loss: 0.0026 - val_mape: 4.5672\n",
      "Epoch 50/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 46.6537 - val_loss: 0.0025 - val_mape: 4.4026\n",
      "Epoch 51/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 44.5998 - val_loss: 0.0017 - val_mape: 3.6397\n",
      "Epoch 52/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mape: 57.8631 - val_loss: 0.0024 - val_mape: 4.3885\n",
      "Epoch 53/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 60.3411 - val_loss: 0.0018 - val_mape: 3.7467\n",
      "Epoch 54/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 49.6194 - val_loss: 0.0023 - val_mape: 4.2325\n",
      "Epoch 55/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 42.6423 - val_loss: 0.0016 - val_mape: 3.5448\n",
      "Epoch 56/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0039 - mape: 61.9034 - val_loss: 0.0016 - val_mape: 3.5569\n",
      "Epoch 57/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mape: 70.1238 - val_loss: 0.0017 - val_mape: 3.6611\n",
      "Epoch 58/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 53.2771 - val_loss: 0.0021 - val_mape: 4.1045\n",
      "Epoch 59/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 42.6555 - val_loss: 0.0015 - val_mape: 3.4836\n",
      "Epoch 60/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 52.2563 - val_loss: 0.0017 - val_mape: 3.6275\n",
      "Epoch 61/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 43.7254 - val_loss: 0.0015 - val_mape: 3.4213\n",
      "Epoch 62/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mape: 58.1594 - val_loss: 0.0018 - val_mape: 3.8688\n",
      "Epoch 63/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 54.3082 - val_loss: 0.0027 - val_mape: 4.8287\n",
      "Epoch 64/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 44.9371 - val_loss: 0.0021 - val_mape: 4.1375\n",
      "Epoch 65/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 48.2457 - val_loss: 0.0019 - val_mape: 3.8404\n",
      "Epoch 66/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mape: 60.4032 - val_loss: 0.0014 - val_mape: 3.2727\n",
      "Epoch 67/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 50.6125 - val_loss: 0.0012 - val_mape: 3.1960\n",
      "Epoch 68/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mape: 55.8086 - val_loss: 0.0013 - val_mape: 3.2045\n",
      "Epoch 69/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 51.8457 - val_loss: 0.0013 - val_mape: 3.1759\n",
      "Epoch 70/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mape: 74.7970 - val_loss: 0.0014 - val_mape: 3.3082\n",
      "Epoch 71/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 69.9742 - val_loss: 0.0011 - val_mape: 3.2361\n",
      "Epoch 72/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 52.4278 - val_loss: 0.0011 - val_mape: 3.0960\n",
      "Epoch 73/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 48.1698 - val_loss: 0.0011 - val_mape: 3.0351\n",
      "Epoch 74/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 45.9703 - val_loss: 9.8362e-04 - val_mape: 2.9298\n",
      "Epoch 75/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mape: 45.4564 - val_loss: 9.8576e-04 - val_mape: 2.8640\n",
      "Epoch 76/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 50.3429 - val_loss: 9.1330e-04 - val_mape: 2.8356\n",
      "Epoch 77/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 44.6961 - val_loss: 9.2987e-04 - val_mape: 2.7412\n",
      "Epoch 78/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 53.5623 - val_loss: 8.1976e-04 - val_mape: 2.9309\n",
      "Epoch 79/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 38.8774 - val_loss: 9.5161e-04 - val_mape: 2.7945\n",
      "Epoch 80/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 52.2605 - val_loss: 9.2439e-04 - val_mape: 2.7106\n",
      "Epoch 81/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mape: 46.2723 - val_loss: 0.0011 - val_mape: 2.8988\n",
      "Epoch 82/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 48.4182 - val_loss: 8.7859e-04 - val_mape: 2.6616\n",
      "Epoch 83/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 49.6190 - val_loss: 0.0011 - val_mape: 2.9381\n",
      "Epoch 84/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mape: 73.9404 - val_loss: 0.0013 - val_mape: 3.2562\n",
      "Epoch 85/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - mape: 77.4418 - val_loss: 9.3172e-04 - val_mape: 2.9807\n",
      "Epoch 86/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mape: 66.5073 - val_loss: 0.0011 - val_mape: 2.9764\n",
      "Epoch 87/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mape: 65.7073 - val_loss: 0.0011 - val_mape: 3.0410\n",
      "Epoch 88/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0039 - mape: 68.1765 - val_loss: 8.4197e-04 - val_mape: 2.7664\n",
      "--- 2/102 Training model for VRTX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 30.3922 - val_loss: 0.0036 - val_mape: 5.8947\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mape: 50.0747 - val_loss: 0.0028 - val_mape: 5.1975\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 22.5213 - val_loss: 0.0027 - val_mape: 5.0233\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 23.3381 - val_loss: 0.0034 - val_mape: 5.8419\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 29.0147 - val_loss: 0.0028 - val_mape: 5.1862\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.2349e-04 - mape: 20.1091 - val_loss: 0.0019 - val_mape: 4.0017\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 23.3025 - val_loss: 0.0021 - val_mape: 4.2356\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0036e-04 - mape: 22.0807 - val_loss: 0.0016 - val_mape: 3.7018\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9209e-04 - mape: 18.4879 - val_loss: 0.0020 - val_mape: 4.2086\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.8106e-04 - mape: 20.6721 - val_loss: 0.0021 - val_mape: 4.3385\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.3085e-04 - mape: 20.0526 - val_loss: 0.0014 - val_mape: 3.4399\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3182e-04 - mape: 20.1870 - val_loss: 0.0017 - val_mape: 3.9372\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3053e-04 - mape: 20.6312 - val_loss: 0.0012 - val_mape: 3.0799\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.0009e-04 - mape: 20.8631 - val_loss: 0.0015 - val_mape: 3.5111\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1794e-04 - mape: 21.1404 - val_loss: 0.0017 - val_mape: 3.7985\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.8326e-04 - mape: 18.6583 - val_loss: 0.0020 - val_mape: 4.1774\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7288e-04 - mape: 19.3869 - val_loss: 0.0013 - val_mape: 3.2201\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7650e-04 - mape: 21.7028 - val_loss: 0.0012 - val_mape: 3.0040\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.1219e-04 - mape: 21.2636 - val_loss: 0.0013 - val_mape: 3.1924\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3877e-04 - mape: 20.0445 - val_loss: 0.0020 - val_mape: 4.2184\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3717e-04 - mape: 22.3856 - val_loss: 0.0018 - val_mape: 3.9483\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3586e-04 - mape: 19.4828 - val_loss: 0.0019 - val_mape: 4.2274\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.3904e-04 - mape: 20.1785 - val_loss: 0.0025 - val_mape: 4.9117\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7054e-04 - mape: 23.5176 - val_loss: 0.0030 - val_mape: 5.3736\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 32.2431 - val_loss: 0.0059 - val_mape: 7.9375\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 33.9947 - val_loss: 0.0042 - val_mape: 6.4319\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 22.5744 - val_loss: 0.0029 - val_mape: 5.2131\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 26.7955 - val_loss: 0.0030 - val_mape: 5.4342\n",
      "--- 3/102 Training model for PYPL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 99380.0938 - val_loss: 2.3496e-04 - val_mape: 17.7405\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 214030.4688 - val_loss: 8.1098e-04 - val_mape: 33.5762\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 169811.3906 - val_loss: 3.8294e-04 - val_mape: 22.1814\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 267309.6562 - val_loss: 2.6559e-04 - val_mape: 17.8799\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 57425.2148 - val_loss: 2.2609e-04 - val_mape: 15.9022\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 39810.8359 - val_loss: 1.0083e-04 - val_mape: 9.9994\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - mape: 39831.1719 - val_loss: 1.1456e-04 - val_mape: 10.8332\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 200571.9219 - val_loss: 1.2092e-04 - val_mape: 11.4989\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 41316.0781 - val_loss: 0.0018 - val_mape: 48.9612\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0053 - mape: 28411.9629 - val_loss: 0.0037 - val_mape: 71.4557\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 38019.8906 - val_loss: 1.6184e-04 - val_mape: 14.3029\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mape: 107561.6094 - val_loss: 0.0011 - val_mape: 39.0857\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mape: 294474.5625 - val_loss: 0.0020 - val_mape: 53.6617\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0067 - mape: 320853.7188 - val_loss: 5.9933e-04 - val_mape: 28.7993\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mape: 139402.0312 - val_loss: 0.0032 - val_mape: 68.3598\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - mape: 191676.5781 - val_loss: 0.0012 - val_mape: 40.0576\n",
      "--- 4/102 Training model for GILD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0054 - mape: 51365.6680 - val_loss: 0.0141 - val_mape: 16.0380\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 72242.7188 - val_loss: 0.0020 - val_mape: 5.8999\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 93681.9141 - val_loss: 0.0019 - val_mape: 6.0110\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 44625.4961 - val_loss: 0.0018 - val_mape: 5.6080\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 82898.0859 - val_loss: 0.0012 - val_mape: 4.0930\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 39362.5469 - val_loss: 9.6957e-04 - val_mape: 3.5238\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 82139.0391 - val_loss: 0.0010 - val_mape: 3.7289\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 21469.2617 - val_loss: 9.1411e-04 - val_mape: 3.3413\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 51897.5273 - val_loss: 9.5400e-04 - val_mape: 3.4097\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 69210.5859 - val_loss: 9.2592e-04 - val_mape: 3.3840\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 28673.6133 - val_loss: 7.9768e-04 - val_mape: 3.0150\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 76253.2031 - val_loss: 7.7831e-04 - val_mape: 2.9798\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 90268.9141 - val_loss: 0.0012 - val_mape: 4.2434\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 42368.0977 - val_loss: 9.0664e-04 - val_mape: 3.3796\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 39367.8789 - val_loss: 0.0011 - val_mape: 3.9445\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 44035.3359 - val_loss: 7.0223e-04 - val_mape: 2.7909\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 23828.2949 - val_loss: 7.9341e-04 - val_mape: 3.0204\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 120475.5938 - val_loss: 6.4053e-04 - val_mape: 2.6864\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 18075.9004 - val_loss: 8.1107e-04 - val_mape: 3.1813\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 29514.2344 - val_loss: 6.8200e-04 - val_mape: 2.8102\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 20985.4219 - val_loss: 0.0017 - val_mape: 5.0776\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 44579.4023 - val_loss: 7.0351e-04 - val_mape: 2.8259\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 42053.3242 - val_loss: 6.2962e-04 - val_mape: 2.7128\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 61845.3516 - val_loss: 6.9311e-04 - val_mape: 2.9362\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 1905.9125 - val_loss: 6.3564e-04 - val_mape: 2.6927\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 56368.1289 - val_loss: 7.4860e-04 - val_mape: 3.0141\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 21474.2930 - val_loss: 7.7613e-04 - val_mape: 3.0455\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 95055.8359 - val_loss: 5.9153e-04 - val_mape: 2.6527\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 67462.2031 - val_loss: 7.2226e-04 - val_mape: 2.9396\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 45929.7031 - val_loss: 5.8936e-04 - val_mape: 2.7251\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 41948.4453 - val_loss: 0.0012 - val_mape: 4.3426\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 44055.6172 - val_loss: 0.0015 - val_mape: 4.7468\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 59751.3750 - val_loss: 5.3985e-04 - val_mape: 2.6024\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 17843.5469 - val_loss: 7.5860e-04 - val_mape: 2.9848\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 96365.3359 - val_loss: 7.0129e-04 - val_mape: 2.8974\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 108648.5938 - val_loss: 0.0013 - val_mape: 4.3442\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.7956e-04 - mape: 31806.1562 - val_loss: 8.3140e-04 - val_mape: 3.3115\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 54007.8047 - val_loss: 6.3849e-04 - val_mape: 2.7918\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 37255.3047 - val_loss: 6.4405e-04 - val_mape: 2.8255\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 85166.5938 - val_loss: 7.3903e-04 - val_mape: 2.9696\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6925e-04 - mape: 43601.0195 - val_loss: 9.4762e-04 - val_mape: 3.4081\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 82114.8438 - val_loss: 0.0011 - val_mape: 3.6885\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 53061.2070 - val_loss: 7.8418e-04 - val_mape: 3.0726\n",
      "--- 5/102 Training model for CSX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 11.6859 - val_loss: 0.0013 - val_mape: 3.3811\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 10.5620 - val_loss: 0.0025 - val_mape: 5.3981\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 11.3834 - val_loss: 0.0020 - val_mape: 4.8732\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5667e-04 - mape: 8.5620 - val_loss: 0.0031 - val_mape: 6.0665\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.2164 - val_loss: 0.0028 - val_mape: 5.7041\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 10.0495 - val_loss: 0.0023 - val_mape: 5.0129\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.6712 - val_loss: 0.0025 - val_mape: 5.3012\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 9.8851 - val_loss: 0.0032 - val_mape: 6.2044\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.4958e-04 - mape: 9.0920 - val_loss: 0.0015 - val_mape: 3.9358\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8954e-04 - mape: 9.8228 - val_loss: 0.0014 - val_mape: 3.8655\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.2069 - val_loss: 0.0011 - val_mape: 3.3034\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 10.9765 - val_loss: 0.0023 - val_mape: 5.2648\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.9911 - val_loss: 0.0014 - val_mape: 4.0540\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 10.5677 - val_loss: 0.0014 - val_mape: 3.9801\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.5280 - val_loss: 9.4652e-04 - val_mape: 3.0651\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 12.0835 - val_loss: 0.0017 - val_mape: 4.4315\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 11.9772 - val_loss: 0.0017 - val_mape: 4.3630\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 11.5339 - val_loss: 0.0014 - val_mape: 3.9440\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 12.3638 - val_loss: 0.0026 - val_mape: 5.6487\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.5346 - val_loss: 0.0014 - val_mape: 3.9254\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 10.4504 - val_loss: 8.6332e-04 - val_mape: 3.0265\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.4460 - val_loss: 0.0011 - val_mape: 3.4605\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.8827 - val_loss: 6.2228e-04 - val_mape: 2.5038\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.7446 - val_loss: 9.9721e-04 - val_mape: 3.3005\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 11.0856 - val_loss: 7.2551e-04 - val_mape: 2.7060\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 11.9979 - val_loss: 5.3332e-04 - val_mape: 2.2275\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 13.5854 - val_loss: 6.8423e-04 - val_mape: 2.7469\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 13.1987 - val_loss: 0.0010 - val_mape: 3.4154\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 14.8052 - val_loss: 6.1249e-04 - val_mape: 2.4289\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 15.0076 - val_loss: 7.2213e-04 - val_mape: 2.7124\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 15.3768 - val_loss: 6.2470e-04 - val_mape: 2.2333\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 16.5129 - val_loss: 0.0012 - val_mape: 3.5496\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 13.3293 - val_loss: 0.0013 - val_mape: 3.8245\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.5110 - val_loss: 0.0015 - val_mape: 4.2409\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.6374 - val_loss: 9.7571e-04 - val_mape: 3.2283\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.5475 - val_loss: 5.3878e-04 - val_mape: 2.2929\n",
      "--- 6/102 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 44.0719 - val_loss: 7.5959e-04 - val_mape: 3.8060\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 40.0755 - val_loss: 0.0023 - val_mape: 6.6033\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0072 - mape: 83.6833 - val_loss: 0.0015 - val_mape: 5.4888\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 48.0094 - val_loss: 5.6457e-04 - val_mape: 2.9731\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0059 - mape: 74.2476 - val_loss: 3.1247e-04 - val_mape: 2.2610\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 34.3293 - val_loss: 4.7645e-04 - val_mape: 2.8885\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 45.6277 - val_loss: 0.0011 - val_mape: 4.6719\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 35.1556 - val_loss: 0.0020 - val_mape: 6.2083\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 51.3352 - val_loss: 0.0016 - val_mape: 5.5896\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 36.5180 - val_loss: 0.0038 - val_mape: 8.7982\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mape: 62.8686 - val_loss: 8.0454e-04 - val_mape: 3.8638\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 33.6618 - val_loss: 0.0014 - val_mape: 5.2984\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 35.7722 - val_loss: 0.0019 - val_mape: 6.1679\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.0835 - val_loss: 0.0011 - val_mape: 4.5465\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 39.4069 - val_loss: 0.0011 - val_mape: 4.5638\n",
      "--- 7/102 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 24.5693 - val_loss: 3.5033e-04 - val_mape: 1.8404\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 35.1263 - val_loss: 3.3118e-04 - val_mape: 2.0690\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 45.6959 - val_loss: 5.8302e-04 - val_mape: 2.3263\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 50.0133 - val_loss: 6.8578e-04 - val_mape: 2.5505\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mape: 63.4480 - val_loss: 3.7241e-04 - val_mape: 2.1296\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0064 - mape: 73.3083 - val_loss: 3.1460e-04 - val_mape: 1.8976\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - mape: 70.8942 - val_loss: 2.9802e-04 - val_mape: 1.9370\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0059 - mape: 72.4289 - val_loss: 3.9337e-04 - val_mape: 2.4440\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mape: 56.4766 - val_loss: 6.8778e-04 - val_mape: 2.5236\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 56.9728 - val_loss: 4.5016e-04 - val_mape: 2.1091\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 39.3070 - val_loss: 6.6336e-04 - val_mape: 2.3786\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 33.4716 - val_loss: 3.7815e-04 - val_mape: 2.2725\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 32.4587 - val_loss: 3.6238e-04 - val_mape: 1.9956\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 26.5872 - val_loss: 6.6639e-04 - val_mape: 2.3460\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 25.4282 - val_loss: 4.8254e-04 - val_mape: 2.0725\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 27.2796 - val_loss: 3.3909e-04 - val_mape: 2.0104\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 24.2562 - val_loss: 3.9274e-04 - val_mape: 2.0602\n",
      "--- 8/102 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0089 - mape: 306.9160 - val_loss: 1.8146e-04 - val_mape: 2.9470\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 141.8600 - val_loss: 1.8281e-04 - val_mape: 3.0453\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mape: 239.0356 - val_loss: 1.0977e-04 - val_mape: 2.2536\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 222.9994 - val_loss: 1.7443e-04 - val_mape: 2.9666\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mape: 267.4839 - val_loss: 1.3059e-04 - val_mape: 2.5600\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mape: 268.9570 - val_loss: 1.5419e-04 - val_mape: 2.7786\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0062 - mape: 252.1007 - val_loss: 9.6605e-05 - val_mape: 2.1494\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 176.9035 - val_loss: 1.5966e-04 - val_mape: 2.7644\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 153.4296 - val_loss: 8.1367e-05 - val_mape: 1.7771\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 103.3791 - val_loss: 7.5425e-05 - val_mape: 1.7647\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 97.3045 - val_loss: 6.9650e-05 - val_mape: 1.5894\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 84.9897 - val_loss: 2.5464e-04 - val_mape: 3.1994\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 103.9443 - val_loss: 7.0585e-05 - val_mape: 1.5294\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 87.8543 - val_loss: 8.5343e-05 - val_mape: 1.7337\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 113.3022 - val_loss: 1.5698e-04 - val_mape: 2.5932\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 96.9890 - val_loss: 1.0583e-04 - val_mape: 1.9969\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 108.6880 - val_loss: 2.3386e-04 - val_mape: 2.8702\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 118.9852 - val_loss: 1.3545e-04 - val_mape: 2.3778\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 97.4520 - val_loss: 1.1898e-04 - val_mape: 2.0381\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 114.8380 - val_loss: 1.9972e-04 - val_mape: 2.5862\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 119.8601 - val_loss: 1.9074e-04 - val_mape: 2.7909\n",
      "--- 9/102 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 14529.9365 - val_loss: 6.8907e-04 - val_mape: 1.9936\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 30042.6094 - val_loss: 0.0012 - val_mape: 3.4566\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 82986.4922 - val_loss: 0.0011 - val_mape: 3.1070\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 45363.0586 - val_loss: 0.0016 - val_mape: 3.8689\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 93822.8594 - val_loss: 0.0011 - val_mape: 2.9435\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 82665.3438 - val_loss: 0.0023 - val_mape: 4.8641\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 17813.4199 - val_loss: 0.0026 - val_mape: 5.1176\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 163010.8281 - val_loss: 0.0030 - val_mape: 5.4930\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 156772.7031 - val_loss: 0.0014 - val_mape: 3.1868\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 8981.0938 - val_loss: 0.0028 - val_mape: 5.1841\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 137959.5000 - val_loss: 0.0011 - val_mape: 2.8824\n",
      "--- 10/102 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 100.1214 - val_loss: 8.5623e-04 - val_mape: 2.2336\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 81.6143 - val_loss: 0.0016 - val_mape: 3.9407\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 86.2784 - val_loss: 7.4979e-04 - val_mape: 2.0966\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 76.9651 - val_loss: 0.0017 - val_mape: 4.0160\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mape: 94.7259 - val_loss: 7.6113e-04 - val_mape: 2.1121\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 72.4935 - val_loss: 0.0040 - val_mape: 7.2179\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 107.4115 - val_loss: 6.4515e-04 - val_mape: 2.3440\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4020e-04 - mape: 69.6805 - val_loss: 0.0056 - val_mape: 8.8679\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 117.5189 - val_loss: 6.9511e-04 - val_mape: 2.1888\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6360e-04 - mape: 70.1372 - val_loss: 0.0071 - val_mape: 10.0568\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 126.8958 - val_loss: 6.7365e-04 - val_mape: 2.4148\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7242e-04 - mape: 72.7017 - val_loss: 0.0097 - val_mape: 12.0362\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 134.9396 - val_loss: 7.6506e-04 - val_mape: 3.0783\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3011e-04 - mape: 69.9143 - val_loss: 0.0093 - val_mape: 11.7948\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 132.7592 - val_loss: 8.0748e-04 - val_mape: 2.1752\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.0858e-04 - mape: 58.4318 - val_loss: 0.0101 - val_mape: 12.1477\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 146.9646 - val_loss: 6.9781e-04 - val_mape: 2.1033\n",
      "--- 11/102 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.5557e-04 - mape: 19.0484 - val_loss: 0.0015 - val_mape: 3.8101\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0039 - mape: 46.2541 - val_loss: 0.0082 - val_mape: 10.5514\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0131 - mape: 80.8934 - val_loss: 0.1525 - val_mape: 45.8215\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0235 - mape: 145.1748 - val_loss: 0.0207 - val_mape: 16.1210\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0101 - mape: 90.5198 - val_loss: 0.0065 - val_mape: 8.2492\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0114 - mape: 63.2221 - val_loss: 0.1824 - val_mape: 50.2752\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0216 - mape: 138.1379 - val_loss: 0.0937 - val_mape: 35.9701\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0166 - mape: 125.0760 - val_loss: 0.0015 - val_mape: 3.6858\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - mape: 46.4846 - val_loss: 0.0017 - val_mape: 3.9238\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - mape: 45.8808 - val_loss: 0.0168 - val_mape: 14.3105\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - mape: 52.3318 - val_loss: 0.0019 - val_mape: 4.2144\n",
      "--- 12/102 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mape: 233.6190 - val_loss: 0.0049 - val_mape: 7.5026\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 167.6044 - val_loss: 0.0041 - val_mape: 6.8463\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 139.2319 - val_loss: 0.0092 - val_mape: 10.5322\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 297.5291 - val_loss: 0.0025 - val_mape: 5.0722\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 144.2691 - val_loss: 0.0119 - val_mape: 11.9892\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 287.6650 - val_loss: 0.0025 - val_mape: 4.7824\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9256e-04 - mape: 115.6092 - val_loss: 0.0040 - val_mape: 6.3263\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7267e-04 - mape: 117.1474 - val_loss: 0.0045 - val_mape: 6.8451\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 131.4970 - val_loss: 0.0060 - val_mape: 8.0228\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 121.9049 - val_loss: 0.0070 - val_mape: 8.6634\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 108.7131 - val_loss: 0.0066 - val_mape: 8.5269\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 172.7742 - val_loss: 0.0191 - val_mape: 15.2021\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 317.6205 - val_loss: 0.0038 - val_mape: 6.2799\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0018 - mape: 168.7314 - val_loss: 0.0129 - val_mape: 12.4270\n",
      "--- 13/102 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mape: 58178.7930 - val_loss: 2.4825e-04 - val_mape: 1.9668\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 70553.5000 - val_loss: 6.5570e-04 - val_mape: 3.6012\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.6738e-04 - mape: 111204.1250 - val_loss: 2.0552e-04 - val_mape: 1.7891\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - mape: 33362.6836 - val_loss: 1.6603e-04 - val_mape: 1.5292\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3741e-04 - mape: 21203.9375 - val_loss: 5.1434e-04 - val_mape: 3.1202\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8377e-04 - mape: 67112.3125 - val_loss: 3.2278e-04 - val_mape: 2.3142\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6480e-04 - mape: 46629.3359 - val_loss: 3.5469e-04 - val_mape: 2.4548\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3013e-04 - mape: 19887.9238 - val_loss: 9.6697e-04 - val_mape: 4.5509\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.1913e-04 - mape: 7324.2534 - val_loss: 2.1514e-04 - val_mape: 1.7128\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9377e-04 - mape: 19818.0664 - val_loss: 7.6062e-04 - val_mape: 3.9282\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 79408.2969 - val_loss: 5.8033e-04 - val_mape: 3.3342\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1091e-04 - mape: 70627.9453 - val_loss: 3.1170e-04 - val_mape: 2.2058\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6145e-04 - mape: 38711.0859 - val_loss: 7.4725e-04 - val_mape: 3.8332\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3923e-04 - mape: 12557.1504 - val_loss: 6.5138e-04 - val_mape: 3.5376\n",
      "--- 14/102 Training model for DXCM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 55912.1953 - val_loss: 9.3975e-04 - val_mape: 4.0630\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 58902.5430 - val_loss: 4.3894e-04 - val_mape: 2.1933\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 56888.1094 - val_loss: 9.0975e-04 - val_mape: 4.0478\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 20074.4648 - val_loss: 6.7635e-04 - val_mape: 3.2450\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 72377.4219 - val_loss: 0.0010 - val_mape: 4.2681\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 4071.7908 - val_loss: 6.4308e-04 - val_mape: 2.8486\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 67441.7031 - val_loss: 3.9431e-04 - val_mape: 1.6009\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mape: 30089.9902 - val_loss: 3.5148e-04 - val_mape: 1.4536\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 61887.0625 - val_loss: 4.0595e-04 - val_mape: 1.9199\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 72678.5234 - val_loss: 0.0011 - val_mape: 4.1711\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 33146.0508 - val_loss: 8.2368e-04 - val_mape: 3.7606\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 54895.9883 - val_loss: 0.0014 - val_mape: 4.8584\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 70894.5391 - val_loss: 4.6040e-04 - val_mape: 2.0907\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 30635.6543 - val_loss: 4.3817e-04 - val_mape: 2.0732\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 139412.6094 - val_loss: 3.8680e-04 - val_mape: 1.8581\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 63524.9609 - val_loss: 0.0012 - val_mape: 4.3979\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mape: 80199.4453 - val_loss: 6.6049e-04 - val_mape: 2.9886\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mape: 202786.6094 - val_loss: 0.0012 - val_mape: 4.2748\n",
      "--- 15/102 Training model for FAST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - mape: 173491.7500 - val_loss: 0.0012 - val_mape: 3.2526\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 11437.9922 - val_loss: 0.0020 - val_mape: 4.5461\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 44598.2773 - val_loss: 0.0026 - val_mape: 5.0919\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 21942.7520 - val_loss: 0.0022 - val_mape: 4.6920\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 4419.6226 - val_loss: 0.0056 - val_mape: 8.0973\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 99801.8125 - val_loss: 0.0041 - val_mape: 7.0438\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 53177.4258 - val_loss: 0.0144 - val_mape: 13.6430\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0070 - mape: 134663.8281 - val_loss: 0.0027 - val_mape: 5.3023\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 2982.5073 - val_loss: 0.0084 - val_mape: 10.1190\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 91496.2891 - val_loss: 0.0030 - val_mape: 5.5812\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 7674.1802 - val_loss: 0.0082 - val_mape: 9.9767\n",
      "--- 16/102 Training model for ABNB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0038 - mape: 26805.8574 - val_loss: 5.1934e-04 - val_mape: 4.4236\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - mape: 49552.0859 - val_loss: 0.0012 - val_mape: 6.7157\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - mape: 14090.9482 - val_loss: 0.0022 - val_mape: 8.7299\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - mape: 37974.8164 - val_loss: 0.0018 - val_mape: 8.6192\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - mape: 60285.7969 - val_loss: 5.8801e-04 - val_mape: 4.8794\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - mape: 82037.6172 - val_loss: 2.6934e-04 - val_mape: 3.5037\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - mape: 31317.8848 - val_loss: 1.8574e-04 - val_mape: 2.4710\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 19260.1133 - val_loss: 2.7288e-04 - val_mape: 3.2140\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 55539.0000 - val_loss: 3.4112e-04 - val_mape: 3.8419\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 25027.0215 - val_loss: 4.5858e-04 - val_mape: 4.2429\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - mape: 30104.7578 - val_loss: 4.0900e-04 - val_mape: 4.3695\n",
      "Epoch 12/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mape: 8352.3105 - val_loss: 3.7032e-04 - val_mape: 3.7210\n",
      "Epoch 13/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 2067.0098 - val_loss: 6.0932e-04 - val_mape: 5.0633\n",
      "Epoch 14/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 811.8441 - val_loss: 5.9036e-04 - val_mape: 4.7769\n",
      "Epoch 15/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - mape: 10391.4990 - val_loss: 4.3034e-04 - val_mape: 4.4559\n",
      "Epoch 16/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0034 - mape: 23354.7168 - val_loss: 3.9809e-04 - val_mape: 3.9428\n",
      "Epoch 17/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - mape: 724.9929 - val_loss: 3.6988e-04 - val_mape: 4.3379\n",
      "--- 17/102 Training model for SNPS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 82.5631 - val_loss: 0.0019 - val_mape: 4.6532\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 85.2642 - val_loss: 8.8957e-04 - val_mape: 2.9011\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 74.5184 - val_loss: 9.9409e-04 - val_mape: 3.0957\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 105.5563 - val_loss: 0.0037 - val_mape: 6.4408\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mape: 165.1896 - val_loss: 9.2583e-04 - val_mape: 2.9720\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 110.5052 - val_loss: 0.0056 - val_mape: 8.0251\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0076 - mape: 235.7879 - val_loss: 7.7834e-04 - val_mape: 2.6336\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 73.8700 - val_loss: 0.0046 - val_mape: 7.1678\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 187.5157 - val_loss: 0.0012 - val_mape: 3.3224\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 65.5435 - val_loss: 0.0029 - val_mape: 5.5323\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 161.4487 - val_loss: 8.4833e-04 - val_mape: 2.6454\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 67.2381 - val_loss: 0.0055 - val_mape: 7.7215\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 172.8552 - val_loss: 9.9556e-04 - val_mape: 2.8724\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 69.9837 - val_loss: 0.0045 - val_mape: 7.0123\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mape: 156.2345 - val_loss: 0.0018 - val_mape: 4.0611\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 64.1162 - val_loss: 0.0064 - val_mape: 8.4778\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 141.3323 - val_loss: 5.8528e-04 - val_mape: 2.0942\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 65.2229 - val_loss: 0.0013 - val_mape: 3.4694\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 114.7483 - val_loss: 0.0013 - val_mape: 3.3823\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 90.0506 - val_loss: 0.0032 - val_mape: 5.6592\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 114.8054 - val_loss: 0.0016 - val_mape: 3.7106\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 77.0890 - val_loss: 0.0018 - val_mape: 3.9550\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 95.0328 - val_loss: 0.0012 - val_mape: 3.1305\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 67.8462 - val_loss: 0.0018 - val_mape: 3.9276\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 103.4739 - val_loss: 0.0028 - val_mape: 5.1627\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 84.7266 - val_loss: 0.0017 - val_mape: 3.8721\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 74.5004 - val_loss: 0.0024 - val_mape: 4.6076\n",
      "--- 18/102 Training model for BIIB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 6624.9414 - val_loss: 4.7507e-04 - val_mape: 19.0147\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 4607.9121 - val_loss: 1.8425e-04 - val_mape: 23.1475\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 8869.5693 - val_loss: 1.8541e-04 - val_mape: 17.6236\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 500.0255 - val_loss: 2.5983e-04 - val_mape: 15.1020\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 108.5657 - val_loss: 2.4646e-04 - val_mape: 14.6439\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 12339.6904 - val_loss: 3.2043e-04 - val_mape: 15.2176\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 3256.2639 - val_loss: 1.7508e-04 - val_mape: 17.8507\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7603e-04 - mape: 6164.8257 - val_loss: 1.1470e-04 - val_mape: 16.9038\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3379e-04 - mape: 739.7138 - val_loss: 7.3289e-05 - val_mape: 20.5955\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2194e-04 - mape: 9086.2539 - val_loss: 2.4715e-04 - val_mape: 18.3250\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 2384.9844 - val_loss: 6.4290e-05 - val_mape: 24.4210\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5976e-04 - mape: 5376.3970 - val_loss: 3.7545e-04 - val_mape: 18.6926\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9004e-04 - mape: 13539.8633 - val_loss: 1.5401e-04 - val_mape: 13.6465\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5888e-04 - mape: 8611.7842 - val_loss: 1.7120e-04 - val_mape: 13.9133\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6969e-04 - mape: 19752.2598 - val_loss: 4.2137e-04 - val_mape: 21.7125\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3736e-04 - mape: 2841.3298 - val_loss: 2.1592e-04 - val_mape: 15.1156\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4512e-04 - mape: 8731.2363 - val_loss: 3.5453e-04 - val_mape: 14.7463\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5726e-04 - mape: 3267.4448 - val_loss: 1.9247e-04 - val_mape: 14.1667\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9531e-04 - mape: 235.9336 - val_loss: 9.3817e-04 - val_mape: 31.9338\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10874.8848 - val_loss: 2.0071e-04 - val_mape: 46.0571\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5907e-04 - mape: 558.8325 - val_loss: 1.3498e-04 - val_mape: 12.4990\n",
      "--- 19/102 Training model for REGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7129e-04 - mape: 18919.1348 - val_loss: 6.6243e-04 - val_mape: 2.5994\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8413e-04 - mape: 35988.3633 - val_loss: 0.0012 - val_mape: 3.6342\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4096e-04 - mape: 12391.5537 - val_loss: 6.6993e-04 - val_mape: 2.3578\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.9020e-04 - mape: 15816.9600 - val_loss: 8.6959e-04 - val_mape: 2.7353\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.6689e-04 - mape: 14631.2236 - val_loss: 0.0012 - val_mape: 3.3989\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7967e-04 - mape: 24657.5410 - val_loss: 0.0010 - val_mape: 2.9543\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1062e-04 - mape: 8191.9678 - val_loss: 9.5653e-04 - val_mape: 2.8235\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.2325e-04 - mape: 29633.0234 - val_loss: 0.0012 - val_mape: 3.2373\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7540e-04 - mape: 3643.0781 - val_loss: 0.0012 - val_mape: 3.1985\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.8205e-04 - mape: 16824.2402 - val_loss: 0.0015 - val_mape: 3.7600\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4292e-04 - mape: 634.3671 - val_loss: 0.0014 - val_mape: 3.7967\n",
      "--- 20/102 Training model for VRSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 98780.1250 - val_loss: 4.2790e-04 - val_mape: 2.3703\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 128620.5234 - val_loss: 0.0014 - val_mape: 2.9691\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 175809.2031 - val_loss: 0.0011 - val_mape: 2.9897\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 179349.9375 - val_loss: 5.6958e-04 - val_mape: 2.0823\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 71300.7109 - val_loss: 8.3605e-04 - val_mape: 2.2706\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 70671.8906 - val_loss: 5.6199e-04 - val_mape: 2.3903\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 33397.4141 - val_loss: 0.0021 - val_mape: 3.8786\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 182785.6094 - val_loss: 0.0015 - val_mape: 3.0747\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 19871.7422 - val_loss: 9.5595e-04 - val_mape: 3.4107\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 210740.8281 - val_loss: 0.0018 - val_mape: 3.4802\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 45675.1523 - val_loss: 0.0013 - val_mape: 3.4069\n",
      "--- 21/102 Training model for TSLA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 4292.5044 - val_loss: 7.8389e-04 - val_mape: 5.7010\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 2937.8667 - val_loss: 4.0763e-04 - val_mape: 4.0531\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 21472.9297 - val_loss: 2.1633e-04 - val_mape: 2.2048\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 27433.1094 - val_loss: 7.8331e-05 - val_mape: 1.4591\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 42561.7344 - val_loss: 1.4165e-04 - val_mape: 1.8535\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 14021.5137 - val_loss: 2.0258e-04 - val_mape: 2.6357\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 43392.6055 - val_loss: 1.1482e-04 - val_mape: 1.8534\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 15667.0811 - val_loss: 8.4683e-05 - val_mape: 1.4871\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 32466.2422 - val_loss: 4.7930e-04 - val_mape: 4.5384\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 14470.9053 - val_loss: 2.3696e-04 - val_mape: 2.3731\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 29829.9238 - val_loss: 2.8383e-04 - val_mape: 3.1959\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 13751.8525 - val_loss: 2.1518e-04 - val_mape: 2.8759\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 1913.7333 - val_loss: 2.6707e-04 - val_mape: 3.1544\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 23262.7988 - val_loss: 2.1988e-04 - val_mape: 2.5130\n",
      "--- 22/102 Training model for NVDA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mape: 104735.8359 - val_loss: 2.1172e-04 - val_mape: 1.7584\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 46066.1250 - val_loss: 3.2125e-04 - val_mape: 2.3990\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 89366.7344 - val_loss: 3.9945e-04 - val_mape: 2.6168\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 69446.7812 - val_loss: 3.1472e-04 - val_mape: 2.3354\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 53784.3320 - val_loss: 2.5116e-04 - val_mape: 2.0906\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 121627.7578 - val_loss: 2.4646e-04 - val_mape: 2.0580\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 131463.4531 - val_loss: 2.5227e-04 - val_mape: 2.0297\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 122148.9453 - val_loss: 3.0676e-04 - val_mape: 2.2978\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4997e-04 - mape: 57148.2148 - val_loss: 2.8437e-04 - val_mape: 2.1807\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5435e-04 - mape: 67163.7031 - val_loss: 3.1433e-04 - val_mape: 2.0322\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2958e-04 - mape: 78024.0547 - val_loss: 3.5376e-04 - val_mape: 2.4880\n",
      "--- 23/102 Training model for CPRT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 107.4726 - val_loss: 6.9868e-04 - val_mape: 2.4893\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 162.5733 - val_loss: 0.0038 - val_mape: 6.5485\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 130.8755 - val_loss: 0.0024 - val_mape: 5.1133\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 155.5335 - val_loss: 0.0024 - val_mape: 5.0687\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 136.0130 - val_loss: 0.0050 - val_mape: 7.4796\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 153.7445 - val_loss: 0.0010 - val_mape: 2.8560\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 192.7495 - val_loss: 0.0055 - val_mape: 7.9042\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 159.6097 - val_loss: 5.2957e-04 - val_mape: 1.9864\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 194.0343 - val_loss: 0.0069 - val_mape: 8.8874\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 112.6441 - val_loss: 4.1821e-04 - val_mape: 1.8787\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 175.7982 - val_loss: 0.0144 - val_mape: 13.0896\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 140.5148 - val_loss: 0.0027 - val_mape: 4.9401\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 272.0203 - val_loss: 0.0072 - val_mape: 9.1790\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 181.0966 - val_loss: 0.0035 - val_mape: 6.0211\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0063 - mape: 442.2112 - val_loss: 0.0057 - val_mape: 8.0655\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 157.8508 - val_loss: 0.0101 - val_mape: 10.5505\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mape: 458.6150 - val_loss: 0.0016 - val_mape: 3.6492\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 228.4973 - val_loss: 0.0074 - val_mape: 8.9993\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mape: 383.1022 - val_loss: 6.9087e-04 - val_mape: 2.0796\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - mape: 296.3990 - val_loss: 0.0051 - val_mape: 7.3972\n",
      "--- 24/102 Training model for ORLY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - mape: 96504.9297 - val_loss: 4.8212e-04 - val_mape: 1.8978\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 79676.5859 - val_loss: 7.4418e-04 - val_mape: 2.2344\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 147394.0156 - val_loss: 3.4016e-04 - val_mape: 1.6339\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 57564.9023 - val_loss: 0.0022 - val_mape: 4.4679\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0055 - mape: 184574.6094 - val_loss: 4.9100e-04 - val_mape: 1.8535\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7559e-04 - mape: 67138.3594 - val_loss: 8.2212e-04 - val_mape: 2.3889\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 151664.6562 - val_loss: 3.1142e-04 - val_mape: 1.6818\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9173e-04 - mape: 38632.9609 - val_loss: 9.4104e-04 - val_mape: 2.7335\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 827.2762 - val_loss: 6.9073e-04 - val_mape: 2.3350\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 83174.1953 - val_loss: 0.0013 - val_mape: 3.2377\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 106601.7734 - val_loss: 4.0416e-04 - val_mape: 1.6897\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8819e-04 - mape: 17268.0410 - val_loss: 6.1270e-04 - val_mape: 2.2062\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 96451.1250 - val_loss: 0.0021 - val_mape: 4.6901\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 62609.1602 - val_loss: 0.0010 - val_mape: 2.7318\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 8087.8003 - val_loss: 0.0017 - val_mape: 3.8106\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 2861.7126 - val_loss: 9.1891e-04 - val_mape: 2.5328\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 26009.8594 - val_loss: 0.0022 - val_mape: 4.2818\n",
      "--- 25/102 Training model for CSGP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 31.0422 - val_loss: 6.2283e-04 - val_mape: 2.3079\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 51.4626 - val_loss: 9.0018e-04 - val_mape: 3.0284\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.4022 - val_loss: 9.7298e-04 - val_mape: 3.4057\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.5028 - val_loss: 8.1337e-04 - val_mape: 2.5047\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 41.0735 - val_loss: 9.2604e-04 - val_mape: 3.1767\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 64.9062 - val_loss: 9.7092e-04 - val_mape: 2.8004\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 46.0269 - val_loss: 0.0013 - val_mape: 3.3082\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mape: 79.2686 - val_loss: 0.0010 - val_mape: 3.1118\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 48.2369 - val_loss: 0.0017 - val_mape: 3.7428\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0074 - mape: 117.4258 - val_loss: 0.0019 - val_mape: 5.1253\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 53.7324 - val_loss: 0.0029 - val_mape: 5.2507\n",
      "--- 26/102 Training model for PDD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - mape: 191130.5156 - val_loss: 0.0138 - val_mape: 18.6606\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072 - mape: 354939.6250 - val_loss: 3.0101e-04 - val_mape: 2.1850\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 15822.4326 - val_loss: 0.0011 - val_mape: 5.3231\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - mape: 76478.7109 - val_loss: 0.0018 - val_mape: 6.7043\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - mape: 74422.2734 - val_loss: 0.0040 - val_mape: 10.2018\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - mape: 24374.1055 - val_loss: 0.0040 - val_mape: 10.2866\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mape: 27108.9980 - val_loss: 0.0035 - val_mape: 9.6628\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - mape: 108395.5547 - val_loss: 9.8619e-04 - val_mape: 5.0378\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mape: 224963.5156 - val_loss: 0.0017 - val_mape: 6.2570\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 219174.2656 - val_loss: 6.7948e-04 - val_mape: 3.6751\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mape: 313256.7188 - val_loss: 2.4099e-04 - val_mape: 2.0313\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 144600.3594 - val_loss: 2.4972e-04 - val_mape: 2.1455\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 118487.2422 - val_loss: 3.6283e-04 - val_mape: 2.7283\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 93827.8359 - val_loss: 4.7648e-04 - val_mape: 3.1833\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 23296.3047 - val_loss: 2.0013e-04 - val_mape: 1.8986\n",
      "Epoch 16/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 230055.9062 - val_loss: 2.9764e-04 - val_mape: 2.3957\n",
      "Epoch 17/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 138941.3281 - val_loss: 1.1217e-04 - val_mape: 1.2369\n",
      "Epoch 18/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 73154.1562 - val_loss: 1.2574e-04 - val_mape: 1.3837\n",
      "Epoch 19/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 234332.1094 - val_loss: 1.5974e-04 - val_mape: 1.6333\n",
      "Epoch 20/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 6999.1621 - val_loss: 1.7294e-04 - val_mape: 1.6775\n",
      "Epoch 21/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 11213.6553 - val_loss: 1.1090e-04 - val_mape: 1.2512\n",
      "Epoch 22/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 157618.9844 - val_loss: 1.5945e-04 - val_mape: 1.6558\n",
      "Epoch 23/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 73085.7109 - val_loss: 1.0577e-04 - val_mape: 1.2258\n",
      "Epoch 24/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 127005.9453 - val_loss: 3.3259e-04 - val_mape: 2.4539\n",
      "Epoch 25/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mape: 155732.3125 - val_loss: 0.0020 - val_mape: 6.4081\n",
      "Epoch 26/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - mape: 96620.1641 - val_loss: 0.0011 - val_mape: 4.4924\n",
      "Epoch 27/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - mape: 214914.1406 - val_loss: 0.0031 - val_mape: 8.4079\n",
      "Epoch 28/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - mape: 181391.5156 - val_loss: 0.0048 - val_mape: 10.8296\n",
      "Epoch 29/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 65628.0078 - val_loss: 0.0022 - val_mape: 7.5200\n",
      "Epoch 30/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 124640.8672 - val_loss: 0.0016 - val_mape: 5.9345\n",
      "Epoch 31/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 252979.2188 - val_loss: 0.0010 - val_mape: 4.5773\n",
      "Epoch 32/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 291679.4688 - val_loss: 3.5462e-04 - val_mape: 2.4807\n",
      "Epoch 33/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 210933.6406 - val_loss: 2.4402e-04 - val_mape: 1.9915\n",
      "--- 27/102 Training model for HON ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 19.2188 - val_loss: 2.5310e-04 - val_mape: 1.5605\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 17.8731 - val_loss: 2.0247e-04 - val_mape: 1.2421\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 18.8212 - val_loss: 2.1340e-04 - val_mape: 1.2873\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 20.6971 - val_loss: 2.4552e-04 - val_mape: 1.5297\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 19.7352 - val_loss: 3.6252e-04 - val_mape: 1.9144\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 16.3415 - val_loss: 1.8778e-04 - val_mape: 1.3086\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 23.0524 - val_loss: 6.7795e-04 - val_mape: 2.8124\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 19.1185 - val_loss: 1.1872e-04 - val_mape: 0.9607\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 25.6618 - val_loss: 2.3064e-04 - val_mape: 1.4447\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 18.0465 - val_loss: 1.4924e-04 - val_mape: 1.0842\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 21.3544 - val_loss: 2.2628e-04 - val_mape: 1.4377\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 21.3314 - val_loss: 1.4369e-04 - val_mape: 1.0576\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 20.3620 - val_loss: 1.5522e-04 - val_mape: 1.1215\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 18.0389 - val_loss: 4.4987e-04 - val_mape: 2.1261\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 23.1092 - val_loss: 1.9747e-04 - val_mape: 1.2989\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 22.6494 - val_loss: 3.3429e-04 - val_mape: 1.7135\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 21.0866 - val_loss: 2.0576e-04 - val_mape: 1.3761\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 22.2522 - val_loss: 2.4976e-04 - val_mape: 1.5591\n",
      "--- 28/102 Training model for ADI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 45.5518 - val_loss: 2.2707e-04 - val_mape: 1.4012\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 44.0043 - val_loss: 3.2004e-04 - val_mape: 1.4871\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 40.6494 - val_loss: 9.3931e-04 - val_mape: 2.8406\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 35.6603 - val_loss: 6.3367e-04 - val_mape: 2.0120\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 36.4750 - val_loss: 0.0016 - val_mape: 3.6819\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 35.5216 - val_loss: 0.0013 - val_mape: 2.9073\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 39.1795 - val_loss: 0.0018 - val_mape: 3.7349\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 34.2540 - val_loss: 0.0020 - val_mape: 3.8175\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 45.2779 - val_loss: 0.0018 - val_mape: 3.6472\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 35.9814 - val_loss: 0.0020 - val_mape: 3.7506\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 43.4429 - val_loss: 0.0013 - val_mape: 2.8515\n",
      "--- 29/102 Training model for EA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 56937.8086 - val_loss: 2.5027e-04 - val_mape: 1.4192\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 44283.8516 - val_loss: 3.7874e-04 - val_mape: 1.8372\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 31541.0684 - val_loss: 2.1982e-04 - val_mape: 1.4222\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 68894.2500 - val_loss: 0.0013 - val_mape: 3.2678\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 33847.4219 - val_loss: 3.1575e-04 - val_mape: 1.4912\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 26853.8320 - val_loss: 0.0014 - val_mape: 3.4980\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 13323.5381 - val_loss: 8.5008e-04 - val_mape: 2.6896\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 26889.5371 - val_loss: 0.0014 - val_mape: 3.6232\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 42825.7500 - val_loss: 3.2702e-04 - val_mape: 1.4871\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 75925.6406 - val_loss: 0.0012 - val_mape: 3.2399\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 35285.2500 - val_loss: 3.5620e-04 - val_mape: 1.6685\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 17813.8789 - val_loss: 0.0012 - val_mape: 3.3733\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 9877.7080 - val_loss: 1.9386e-04 - val_mape: 1.4716\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 73196.7031 - val_loss: 0.0013 - val_mape: 3.5500\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 9535.8174 - val_loss: 2.0953e-04 - val_mape: 1.2119\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 40316.0977 - val_loss: 0.0016 - val_mape: 3.8742\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 526.6915 - val_loss: 3.2045e-04 - val_mape: 1.4282\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 51579.0938 - val_loss: 8.9450e-04 - val_mape: 2.7498\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 5500.7617 - val_loss: 4.8128e-04 - val_mape: 1.9743\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 48592.5820 - val_loss: 0.0022 - val_mape: 4.7396\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 17066.8047 - val_loss: 4.1378e-04 - val_mape: 1.8258\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 146022.7031 - val_loss: 9.6856e-04 - val_mape: 2.8340\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 37391.1914 - val_loss: 6.4274e-04 - val_mape: 2.5329\n",
      "--- 30/102 Training model for KHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 9947.6631 - val_loss: 1.4223e-05 - val_mape: 0.8455\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 8168.2700 - val_loss: 5.7281e-05 - val_mape: 1.7886\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0103 - mape: 31536.0273 - val_loss: 8.5246e-05 - val_mape: 2.1976\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0104 - mape: 11200.3389 - val_loss: 7.4034e-05 - val_mape: 2.0481\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0063 - mape: 39878.3672 - val_loss: 7.3207e-05 - val_mape: 2.1148\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 20821.7070 - val_loss: 2.5384e-05 - val_mape: 1.2116\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 36889.5312 - val_loss: 1.6510e-05 - val_mape: 0.9283\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 38.7513 - val_loss: 1.7761e-05 - val_mape: 0.9568\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 56549.2539 - val_loss: 1.5818e-05 - val_mape: 0.9028\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 30693.3105 - val_loss: 1.5228e-05 - val_mape: 0.8695\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 26128.1172 - val_loss: 2.4378e-05 - val_mape: 1.1254\n",
      "--- 31/102 Training model for WBD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7047e-04 - mape: 8.8716 - val_loss: 8.3623e-05 - val_mape: 106610.7891\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.0130e-04 - mape: 8.3806 - val_loss: 1.3335e-04 - val_mape: 115032.3906\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4290e-04 - mape: 8.0223 - val_loss: 1.0773e-04 - val_mape: 101918.4531\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8775e-04 - mape: 7.6046 - val_loss: 5.7691e-05 - val_mape: 85529.9297\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.7660e-04 - mape: 7.4553 - val_loss: 4.1279e-05 - val_mape: 79706.7422\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5342e-04 - mape: 7.8701 - val_loss: 3.5212e-04 - val_mape: 156957.6562\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4005e-04 - mape: 7.7303 - val_loss: 2.7233e-04 - val_mape: 127841.3828\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0510e-04 - mape: 6.8379 - val_loss: 1.1239e-04 - val_mape: 107178.9922\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6296e-04 - mape: 6.3780 - val_loss: 2.1451e-05 - val_mape: 48818.3828\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6700e-04 - mape: 7.3560 - val_loss: 5.0229e-04 - val_mape: 176817.0312\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.8024e-04 - mape: 6.6893 - val_loss: 4.1661e-05 - val_mape: 80277.8438\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.8999e-04 - mape: 6.8614 - val_loss: 2.0967e-05 - val_mape: 57818.5859\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.9168e-04 - mape: 6.7000 - val_loss: 1.0322e-04 - val_mape: 107360.9141\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.7814e-04 - mape: 6.4081 - val_loss: 3.8442e-05 - val_mape: 76162.0703\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5495e-04 - mape: 6.3734 - val_loss: 3.9211e-05 - val_mape: 79423.8984\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.9542e-04 - mape: 7.2918 - val_loss: 1.9239e-05 - val_mape: 50587.7344\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6438e-04 - mape: 5.9162 - val_loss: 3.7172e-05 - val_mape: 67581.8125\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7419e-04 - mape: 7.7973 - val_loss: 1.1099e-04 - val_mape: 92337.6562\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.8962e-04 - mape: 6.1910 - val_loss: 5.5929e-05 - val_mape: 55955.6953\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.7194 - val_loss: 1.5816e-05 - val_mape: 48293.1094\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1168e-04 - mape: 6.4143 - val_loss: 7.3886e-05 - val_mape: 31166.5684\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4217e-04 - mape: 8.9312 - val_loss: 2.1852e-05 - val_mape: 52449.0469\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.5636e-04 - mape: 5.1311 - val_loss: 5.6741e-05 - val_mape: 29654.2949\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.0818e-04 - mape: 7.6164 - val_loss: 1.8664e-05 - val_mape: 51308.2734\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6076e-04 - mape: 5.0821 - val_loss: 2.8463e-05 - val_mape: 61605.7812\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6411e-04 - mape: 6.5792 - val_loss: 9.5146e-05 - val_mape: 83630.6719\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7145e-04 - mape: 5.1121 - val_loss: 3.8818e-05 - val_mape: 74053.9922\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4032e-04 - mape: 6.8452 - val_loss: 5.4470e-05 - val_mape: 72368.2266\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.0041e-04 - mape: 5.2223 - val_loss: 5.4019e-05 - val_mape: 34125.4961\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1291e-04 - mape: 8.3154 - val_loss: 2.3483e-05 - val_mape: 44904.3086\n",
      "--- 32/102 Training model for ROP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 20.9164 - val_loss: 0.0026 - val_mape: 5.3657\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3872e-04 - mape: 17.7254 - val_loss: 0.0017 - val_mape: 4.1653\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 25.0218 - val_loss: 0.0013 - val_mape: 3.6255\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 21.1005 - val_loss: 0.0020 - val_mape: 4.5475\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9307e-04 - mape: 20.1492 - val_loss: 0.0014 - val_mape: 3.6335\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 32.8345 - val_loss: 0.0019 - val_mape: 4.2587\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 20.0025 - val_loss: 0.0016 - val_mape: 3.9545\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 21.2171 - val_loss: 0.0018 - val_mape: 4.3105\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 23.1795 - val_loss: 0.0022 - val_mape: 4.7594\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 33.8501 - val_loss: 0.0029 - val_mape: 5.6179\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 30.4041 - val_loss: 4.6972e-04 - val_mape: 1.8658\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 22.2436 - val_loss: 0.0033 - val_mape: 5.9174\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 19.0519 - val_loss: 0.0017 - val_mape: 4.1317\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 21.6674 - val_loss: 0.0021 - val_mape: 4.6578\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 24.6275 - val_loss: 0.0010 - val_mape: 3.0677\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mape: 32.9304 - val_loss: 0.0020 - val_mape: 4.5562\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 26.1898 - val_loss: 0.0022 - val_mape: 4.6863\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 20.3972 - val_loss: 0.0039 - val_mape: 6.5325\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 23.3141 - val_loss: 9.2281e-04 - val_mape: 2.8111\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 29.0772 - val_loss: 0.0041 - val_mape: 6.7004\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 28.6780 - val_loss: 0.0026 - val_mape: 5.1908\n",
      "--- 33/102 Training model for BKR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 64577.5586 - val_loss: 6.4744e-04 - val_mape: 2.2402\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 6711.5605 - val_loss: 7.0157e-04 - val_mape: 3.1793\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 36000.7773 - val_loss: 3.3300e-04 - val_mape: 1.5605\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 22899.2852 - val_loss: 1.7915e-04 - val_mape: 1.4413\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 16043.9707 - val_loss: 2.2111e-04 - val_mape: 1.2131\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 24737.1445 - val_loss: 1.6923e-04 - val_mape: 1.1525\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 42268.3906 - val_loss: 1.5720e-04 - val_mape: 1.1414\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 20028.2676 - val_loss: 1.7650e-04 - val_mape: 1.3030\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 1334.5977 - val_loss: 3.8219e-04 - val_mape: 2.2512\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 12447.7031 - val_loss: 2.2074e-04 - val_mape: 1.2376\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 12131.8994 - val_loss: 1.8671e-04 - val_mape: 1.3469\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 29040.7910 - val_loss: 1.3475e-04 - val_mape: 0.9530\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 22123.9414 - val_loss: 1.1568e-04 - val_mape: 0.9213\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 31364.4121 - val_loss: 1.9771e-04 - val_mape: 1.5177\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 39693.8594 - val_loss: 1.2421e-04 - val_mape: 0.9218\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 1760.7313 - val_loss: 1.3034e-04 - val_mape: 1.1077\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 14980.8770 - val_loss: 1.2015e-04 - val_mape: 0.9140\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 56991.1016 - val_loss: 2.9893e-04 - val_mape: 1.9359\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 20619.7871 - val_loss: 5.7627e-04 - val_mape: 2.5967\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 17406.4590 - val_loss: 4.5569e-04 - val_mape: 2.4756\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 16567.5117 - val_loss: 1.9955e-04 - val_mape: 1.2204\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 15798.7588 - val_loss: 9.0605e-05 - val_mape: 0.8783\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 5593.0034 - val_loss: 1.5800e-04 - val_mape: 1.1905\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 49371.7578 - val_loss: 8.4627e-04 - val_mape: 3.4657\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 7377.4604 - val_loss: 8.1042e-04 - val_mape: 2.9484\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 41230.4688 - val_loss: 4.2683e-04 - val_mape: 2.1314\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 25407.5898 - val_loss: 4.8324e-04 - val_mape: 2.4656\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 20095.8340 - val_loss: 1.2667e-04 - val_mape: 0.9727\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 7301.3159 - val_loss: 2.8479e-04 - val_mape: 1.8546\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 31660.8926 - val_loss: 7.1410e-05 - val_mape: 0.7367\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 52773.8672 - val_loss: 1.0103e-04 - val_mape: 0.8447\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 28844.4688 - val_loss: 2.5958e-04 - val_mape: 1.6827\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 33425.8750 - val_loss: 9.1545e-05 - val_mape: 0.8495\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 28522.6328 - val_loss: 3.9341e-04 - val_mape: 2.2236\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 37948.3477 - val_loss: 3.4680e-04 - val_mape: 2.1393\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.1787e-04 - mape: 47121.8828 - val_loss: 3.2011e-04 - val_mape: 2.0381\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 40985.3984 - val_loss: 6.8828e-04 - val_mape: 3.1289\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 19874.7012 - val_loss: 4.5264e-04 - val_mape: 2.4293\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 26085.2129 - val_loss: 0.0019 - val_mape: 5.3033\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 22088.3496 - val_loss: 0.0011 - val_mape: 4.0022\n",
      "--- 34/102 Training model for COST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mape: 60839.4922 - val_loss: 0.0026 - val_mape: 5.5348\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mape: 61057.7305 - val_loss: 7.8167e-04 - val_mape: 2.7899\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0041 - mape: 64253.7109 - val_loss: 6.9381e-04 - val_mape: 2.7305\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mape: 11928.2148 - val_loss: 2.8485e-04 - val_mape: 1.5967\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mape: 267570.0000 - val_loss: 4.4634e-04 - val_mape: 2.1609\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - mape: 76456.7109 - val_loss: 1.8284e-04 - val_mape: 1.2935\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mape: 72724.3438 - val_loss: 1.4617e-04 - val_mape: 1.3132\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 189955.8906 - val_loss: 1.6512e-04 - val_mape: 1.4212\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 182755.2969 - val_loss: 1.4785e-04 - val_mape: 1.3218\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 167404.9531 - val_loss: 1.3478e-04 - val_mape: 1.2435\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 30352.5996 - val_loss: 1.7659e-04 - val_mape: 1.4647\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mape: 27425.7188 - val_loss: 3.9451e-04 - val_mape: 2.1297\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 137940.9844 - val_loss: 2.8217e-04 - val_mape: 1.7585\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 178282.3438 - val_loss: 4.6651e-04 - val_mape: 2.3471\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 46837.7695 - val_loss: 2.8967e-04 - val_mape: 1.7701\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 34806.3125 - val_loss: 1.0515e-04 - val_mape: 1.1065\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mape: 57015.4492 - val_loss: 1.9540e-04 - val_mape: 1.4748\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 100467.7578 - val_loss: 3.9404e-04 - val_mape: 2.1648\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 58202.8750 - val_loss: 1.7699e-04 - val_mape: 1.4136\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mape: 70023.9609 - val_loss: 2.5198e-04 - val_mape: 1.7231\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 22389.0918 - val_loss: 1.9128e-04 - val_mape: 1.5170\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 89539.1562 - val_loss: 1.4052e-04 - val_mape: 1.2976\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 4083.6401 - val_loss: 1.9594e-04 - val_mape: 1.2485\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mape: 84331.2812 - val_loss: 1.4362e-04 - val_mape: 1.2581\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 30229.9062 - val_loss: 5.0885e-04 - val_mape: 1.9823\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 60384.6836 - val_loss: 2.9306e-04 - val_mape: 1.5086\n",
      "--- 35/102 Training model for AZN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 45.4163 - val_loss: 4.5789e-04 - val_mape: 2.4200\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 38.1418 - val_loss: 2.0482e-04 - val_mape: 1.2049\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 32.6571 - val_loss: 1.4637e-04 - val_mape: 1.1366\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 32.1507 - val_loss: 1.7610e-04 - val_mape: 1.4975\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 36.4532 - val_loss: 5.8621e-04 - val_mape: 2.1526\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 34.3495 - val_loss: 4.4751e-04 - val_mape: 2.2619\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 36.9622 - val_loss: 7.4731e-04 - val_mape: 2.3226\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3074e-04 - mape: 29.8503 - val_loss: 4.7619e-04 - val_mape: 2.2716\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 35.7400 - val_loss: 6.8947e-04 - val_mape: 2.0491\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 35.0489 - val_loss: 3.8291e-04 - val_mape: 2.2014\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5183e-04 - mape: 28.0272 - val_loss: 3.3681e-04 - val_mape: 1.4978\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 33.8195 - val_loss: 4.0567e-04 - val_mape: 2.3831\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 31.9040 - val_loss: 6.6803e-04 - val_mape: 2.1024\n",
      "--- 36/102 Training model for LRCX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 110.1210 - val_loss: 0.0010 - val_mape: 3.2976\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mape: 103.3376 - val_loss: 0.0016 - val_mape: 4.4666\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 86.8019 - val_loss: 0.0017 - val_mape: 4.4219\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 82.8386 - val_loss: 0.0022 - val_mape: 5.2346\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 92.5654 - val_loss: 0.0022 - val_mape: 5.0271\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 69.3706 - val_loss: 0.0049 - val_mape: 8.2917\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 87.0818 - val_loss: 0.0018 - val_mape: 4.2885\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 80.3685 - val_loss: 0.0044 - val_mape: 7.7055\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 81.4443 - val_loss: 0.0025 - val_mape: 5.3419\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 71.7897 - val_loss: 0.0057 - val_mape: 8.9383\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 78.1020 - val_loss: 0.0023 - val_mape: 4.8579\n",
      "--- 37/102 Training model for MELI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 54.6220 - val_loss: 0.0212 - val_mape: 17.2388\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 104.1533 - val_loss: 0.0053 - val_mape: 8.7937\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 50.3646 - val_loss: 0.0153 - val_mape: 15.0940\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mape: 112.2828 - val_loss: 0.0015 - val_mape: 4.3954\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 82.4841 - val_loss: 2.1721e-04 - val_mape: 1.4186\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 72.2700 - val_loss: 0.0012 - val_mape: 4.0162\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mape: 94.6662 - val_loss: 1.1286e-04 - val_mape: 1.0852\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 67.8597 - val_loss: 6.4369e-04 - val_mape: 2.8073\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 95.8213 - val_loss: 1.2530e-04 - val_mape: 1.1403\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 67.9129 - val_loss: 0.0013 - val_mape: 4.3145\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - mape: 101.8469 - val_loss: 1.6543e-04 - val_mape: 1.2450\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 65.2502 - val_loss: 0.0035 - val_mape: 6.8799\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 92.3165 - val_loss: 9.3502e-05 - val_mape: 0.9750\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 43.7911 - val_loss: 0.0018 - val_mape: 5.0163\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mape: 84.0213 - val_loss: 2.1850e-04 - val_mape: 1.3545\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 45.0392 - val_loss: 0.0013 - val_mape: 4.2243\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 70.6371 - val_loss: 6.0906e-04 - val_mape: 2.6367\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 67.0635 - val_loss: 1.8506e-04 - val_mape: 1.3399\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 52.2900 - val_loss: 3.7956e-04 - val_mape: 1.7281\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 56.8835 - val_loss: 1.4716e-04 - val_mape: 1.1482\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 49.1003 - val_loss: 3.5576e-04 - val_mape: 1.9750\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 63.3565 - val_loss: 3.6551e-04 - val_mape: 1.6608\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 49.9824 - val_loss: 1.7896e-04 - val_mape: 1.3534\n",
      "--- 38/102 Training model for CDW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 42.4442 - val_loss: 0.0024 - val_mape: 5.4817\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 103.3525 - val_loss: 2.7189e-04 - val_mape: 1.5177\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 40.2795 - val_loss: 0.0022 - val_mape: 4.9673\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 60.8304 - val_loss: 0.0015 - val_mape: 4.1008\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 39.3801 - val_loss: 0.0027 - val_mape: 5.5220\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 53.0043 - val_loss: 7.9545e-04 - val_mape: 2.5553\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 37.9846 - val_loss: 0.0019 - val_mape: 4.3286\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 53.1546 - val_loss: 0.0014 - val_mape: 3.6812\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 39.2660 - val_loss: 0.0028 - val_mape: 5.5953\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 54.8893 - val_loss: 0.0015 - val_mape: 3.8288\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 44.6123 - val_loss: 0.0018 - val_mape: 4.3123\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 56.9676 - val_loss: 0.0026 - val_mape: 5.1594\n",
      "--- 39/102 Training model for FANG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.5177e-04 - mape: 11296.0283 - val_loss: 0.0011 - val_mape: 3.2662\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.1241e-04 - mape: 46300.8828 - val_loss: 0.0015 - val_mape: 3.6106\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.8266e-04 - mape: 23656.4492 - val_loss: 0.0020 - val_mape: 4.1626\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.7212e-04 - mape: 27520.8906 - val_loss: 0.0019 - val_mape: 3.9330\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.5668e-04 - mape: 4230.1655 - val_loss: 0.0036 - val_mape: 5.8449\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.4170e-04 - mape: 11410.8486 - val_loss: 0.0029 - val_mape: 4.8447\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.8855e-04 - mape: 4044.0969 - val_loss: 0.0024 - val_mape: 4.4239\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6506e-04 - mape: 6181.6616 - val_loss: 0.0031 - val_mape: 5.1583\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.8251e-04 - mape: 9000.9629 - val_loss: 0.0036 - val_mape: 5.4818\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.1786e-04 - mape: 16011.0059 - val_loss: 0.0029 - val_mape: 4.9193\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.0450e-04 - mape: 13576.6641 - val_loss: 0.0026 - val_mape: 4.5460\n",
      "--- 40/102 Training model for ZS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 10196.3135 - val_loss: 6.3031e-04 - val_mape: 3.4611\n",
      "Epoch 2/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 63402.2812 - val_loss: 0.0016 - val_mape: 7.3814\n",
      "Epoch 3/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - mape: 43184.0391 - val_loss: 3.9624e-04 - val_mape: 3.8431\n",
      "Epoch 4/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 143320.3750 - val_loss: 1.4163e-04 - val_mape: 2.1284\n",
      "Epoch 5/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - mape: 79474.4688 - val_loss: 1.6833e-04 - val_mape: 2.4544\n",
      "Epoch 6/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 263612.5312 - val_loss: 3.5475e-04 - val_mape: 3.7409\n",
      "Epoch 7/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - mape: 303561.4375 - val_loss: 2.4147e-04 - val_mape: 2.3932\n",
      "Epoch 8/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 75389.9375 - val_loss: 0.0014 - val_mape: 6.4412\n",
      "Epoch 9/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - mape: 377793.2500 - val_loss: 5.2682e-04 - val_mape: 4.5144\n",
      "Epoch 10/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - mape: 237808.1406 - val_loss: 6.9976e-04 - val_mape: 4.8975\n",
      "Epoch 11/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 262754.0312 - val_loss: 4.7540e-04 - val_mape: 4.3777\n",
      "Epoch 12/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - mape: 135903.2344 - val_loss: 8.7306e-04 - val_mape: 5.5695\n",
      "Epoch 13/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - mape: 195591.3438 - val_loss: 3.1333e-04 - val_mape: 3.4933\n",
      "Epoch 14/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 368875.5312 - val_loss: 4.1975e-04 - val_mape: 4.0529\n",
      "--- 41/102 Training model for ADBE ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 44.3538 - val_loss: 4.9173e-04 - val_mape: 2.8353\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 33.5790 - val_loss: 0.0070 - val_mape: 10.8880\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 70.4694 - val_loss: 7.6927e-04 - val_mape: 3.1055\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0117 - mape: 86.6354 - val_loss: 0.0040 - val_mape: 7.3066\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0101 - mape: 133.7448 - val_loss: 1.7015e-04 - val_mape: 1.4019\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 54.4877 - val_loss: 1.4861e-04 - val_mape: 1.2785\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mape: 39.9844 - val_loss: 6.0280e-04 - val_mape: 2.8701\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 39.2130 - val_loss: 1.1891e-04 - val_mape: 1.1002\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 35.7836 - val_loss: 1.1578e-04 - val_mape: 1.1047\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 40.2504 - val_loss: 2.1509e-04 - val_mape: 1.4630\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 36.1908 - val_loss: 1.4603e-04 - val_mape: 1.1903\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 34.1773 - val_loss: 1.0579e-04 - val_mape: 0.9388\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 36.3197 - val_loss: 1.2524e-04 - val_mape: 1.0776\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 40.0624 - val_loss: 1.2810e-04 - val_mape: 1.2115\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 44.2804 - val_loss: 2.0599e-04 - val_mape: 1.6401\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 35.3971 - val_loss: 3.5851e-04 - val_mape: 1.9196\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 33.1413 - val_loss: 0.0018 - val_mape: 5.4088\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 50.2013 - val_loss: 1.2305e-04 - val_mape: 1.1749\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 34.9701 - val_loss: 5.3553e-04 - val_mape: 2.8926\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 40.3318 - val_loss: 2.3059e-04 - val_mape: 1.5356\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 35.9886 - val_loss: 9.5085e-04 - val_mape: 4.0007\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 42.3696 - val_loss: 1.3770e-04 - val_mape: 1.2565\n",
      "--- 42/102 Training model for GOOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0018 - mape: 66.4120 - val_loss: 3.2870e-04 - val_mape: 1.5045\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 75.0047 - val_loss: 5.4281e-04 - val_mape: 2.1604\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 88.8310 - val_loss: 2.1094e-04 - val_mape: 1.3409\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 78.4440 - val_loss: 2.6720e-04 - val_mape: 1.5094\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 113.1378 - val_loss: 4.3317e-04 - val_mape: 2.2926\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 100.3753 - val_loss: 5.4016e-04 - val_mape: 2.5013\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 119.3178 - val_loss: 6.9498e-04 - val_mape: 2.9483\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 104.5755 - val_loss: 6.8488e-04 - val_mape: 2.8587\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mape: 92.2995 - val_loss: 6.5114e-04 - val_mape: 2.6240\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 72.9022 - val_loss: 6.3086e-04 - val_mape: 2.6837\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 88.2608 - val_loss: 8.0549e-04 - val_mape: 2.5831\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mape: 89.8689 - val_loss: 7.5756e-04 - val_mape: 2.8097\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 69.6019 - val_loss: 7.8741e-04 - val_mape: 2.7916\n",
      "--- 43/102 Training model for AMAT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 49252.7656 - val_loss: 0.0014 - val_mape: 3.8675\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 15590.6074 - val_loss: 4.2208e-04 - val_mape: 1.7231\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 65080.5273 - val_loss: 8.1173e-04 - val_mape: 2.7785\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 69236.3438 - val_loss: 4.7528e-04 - val_mape: 1.8243\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 10776.4375 - val_loss: 7.9280e-04 - val_mape: 2.7310\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 61608.0195 - val_loss: 6.5172e-04 - val_mape: 2.2392\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 14505.0684 - val_loss: 5.5094e-04 - val_mape: 1.9839\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 45480.5547 - val_loss: 9.9431e-04 - val_mape: 2.9710\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30958.4355 - val_loss: 8.2293e-04 - val_mape: 2.5193\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 42316.7266 - val_loss: 0.0014 - val_mape: 3.7209\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 22358.6562 - val_loss: 0.0011 - val_mape: 2.9914\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 42138.4414 - val_loss: 0.0019 - val_mape: 4.4867\n",
      "--- 44/102 Training model for ADP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 72240.8594 - val_loss: 3.5841e-04 - val_mape: 1.5379\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 22207.3613 - val_loss: 5.4875e-04 - val_mape: 2.2126\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 175131.0312 - val_loss: 4.1997e-04 - val_mape: 1.7298\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 240267.9219 - val_loss: 2.7705e-04 - val_mape: 1.3597\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 193571.4844 - val_loss: 6.3857e-04 - val_mape: 2.4348\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 39640.8438 - val_loss: 4.3129e-04 - val_mape: 1.7129\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 84196.1875 - val_loss: 4.9675e-04 - val_mape: 1.8477\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 139340.0781 - val_loss: 0.0017 - val_mape: 4.3615\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 4811.9961 - val_loss: 9.5738e-04 - val_mape: 2.8357\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mape: 324013.9688 - val_loss: 6.9578e-04 - val_mape: 2.6080\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 262471.7188 - val_loss: 0.0016 - val_mape: 3.8399\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mape: 22211.6797 - val_loss: 6.9122e-04 - val_mape: 2.5066\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 81741.9062 - val_loss: 5.0435e-04 - val_mape: 1.9141\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 76042.5859 - val_loss: 8.6660e-04 - val_mape: 2.9240\n",
      "--- 45/102 Training model for SBUX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 6993.3574 - val_loss: 1.7147e-04 - val_mape: 1.5285\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 67638.7031 - val_loss: 0.0012 - val_mape: 5.3917\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 6581.4873 - val_loss: 2.7852e-04 - val_mape: 2.4464\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 15490.4893 - val_loss: 1.3647e-04 - val_mape: 1.1853\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 15692.8887 - val_loss: 6.2889e-04 - val_mape: 3.9278\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 53486.2188 - val_loss: 1.5548e-04 - val_mape: 1.3937\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 48920.9883 - val_loss: 2.6338e-04 - val_mape: 2.2860\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 411.3574 - val_loss: 1.4030e-04 - val_mape: 1.2735\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 28085.3633 - val_loss: 2.9680e-04 - val_mape: 2.4534\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 61374.0703 - val_loss: 3.2018e-04 - val_mape: 2.5256\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 34832.0742 - val_loss: 5.6491e-04 - val_mape: 3.6089\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 65099.3789 - val_loss: 1.3139e-04 - val_mape: 1.3755\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 20327.0469 - val_loss: 7.0767e-04 - val_mape: 4.0203\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 1699.1646 - val_loss: 6.0492e-04 - val_mape: 3.8966\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 44808.6992 - val_loss: 1.4913e-04 - val_mape: 1.6403\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 10091.3418 - val_loss: 3.9802e-04 - val_mape: 2.9522\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 6139.8091 - val_loss: 3.6744e-04 - val_mape: 2.8442\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 19170.7969 - val_loss: 9.2588e-05 - val_mape: 0.9984\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 20713.0176 - val_loss: 3.8076e-04 - val_mape: 3.0120\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mape: 39113.4023 - val_loss: 1.5030e-04 - val_mape: 1.6368\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mape: 35788.3438 - val_loss: 1.3953e-04 - val_mape: 1.5565\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mape: 9783.7441 - val_loss: 6.3911e-04 - val_mape: 4.0181\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 109758.8594 - val_loss: 9.2847e-04 - val_mape: 4.8584\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 92072.4219 - val_loss: 3.4433e-04 - val_mape: 2.8393\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 57487.9453 - val_loss: 8.0951e-05 - val_mape: 0.9590\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 60930.1641 - val_loss: 3.2436e-04 - val_mape: 2.5239\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 34791.5273 - val_loss: 9.2241e-05 - val_mape: 1.1337\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 38558.9922 - val_loss: 3.6664e-04 - val_mape: 2.7052\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 21420.2227 - val_loss: 1.2397e-04 - val_mape: 1.3997\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 7211.7163 - val_loss: 1.1770e-04 - val_mape: 1.3687\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 146636.4062 - val_loss: 9.6817e-05 - val_mape: 1.1195\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 63818.3594 - val_loss: 1.7954e-04 - val_mape: 1.9049\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 8176.9585 - val_loss: 1.5687e-04 - val_mape: 1.4961\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 20429.2715 - val_loss: 1.0128e-04 - val_mape: 1.2139\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 19591.1895 - val_loss: 3.0760e-04 - val_mape: 2.8474\n",
      "--- 46/102 Training model for TTWO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7748e-04 - mape: 17.2898 - val_loss: 1.1848e-04 - val_mape: 1.5000\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.2493e-04 - mape: 12.0966 - val_loss: 5.1959e-05 - val_mape: 0.8655\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 16.6057 - val_loss: 5.3827e-05 - val_mape: 0.8855\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1303e-04 - mape: 15.3549 - val_loss: 1.5113e-04 - val_mape: 1.6035\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8032e-04 - mape: 14.9286 - val_loss: 1.1628e-04 - val_mape: 1.3910\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2478e-04 - mape: 14.6366 - val_loss: 1.6713e-04 - val_mape: 1.7007\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 17.4037 - val_loss: 6.5297e-04 - val_mape: 3.6453\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 15.5016 - val_loss: 8.8051e-04 - val_mape: 4.2318\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 15.3271 - val_loss: 0.0022 - val_mape: 6.8509\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 21.2553 - val_loss: 0.0035 - val_mape: 8.7293\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 18.2138 - val_loss: 0.0051 - val_mape: 10.6549\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mape: 18.0198 - val_loss: 0.0052 - val_mape: 10.8105\n",
      "--- 47/102 Training model for TMUS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 57284.6328 - val_loss: 5.8313e-04 - val_mape: 2.4650\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mape: 116439.1016 - val_loss: 0.0014 - val_mape: 4.1289\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mape: 53456.2305 - val_loss: 0.0017 - val_mape: 4.7656\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 79313.3359 - val_loss: 0.0013 - val_mape: 3.8539\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mape: 21914.8047 - val_loss: 9.0385e-04 - val_mape: 2.9942\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mape: 169973.0000 - val_loss: 0.0010 - val_mape: 3.3148\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0070 - mape: 148186.8594 - val_loss: 6.9679e-04 - val_mape: 2.6154\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0083 - mape: 136760.8438 - val_loss: 4.4562e-04 - val_mape: 1.8657\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0077 - mape: 98427.2109 - val_loss: 2.3507e-04 - val_mape: 1.3655\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0054 - mape: 95382.2109 - val_loss: 2.1754e-04 - val_mape: 1.3682\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 91900.7812 - val_loss: 2.2377e-04 - val_mape: 1.3982\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 156402.8906 - val_loss: 3.1830e-04 - val_mape: 1.4261\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 87140.5469 - val_loss: 5.8684e-04 - val_mape: 2.1578\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 39441.0391 - val_loss: 7.1230e-04 - val_mape: 2.4516\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 6524.0679 - val_loss: 8.0844e-04 - val_mape: 2.5660\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 34860.5078 - val_loss: 0.0011 - val_mape: 3.0214\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 170838.2031 - val_loss: 8.4035e-04 - val_mape: 2.4295\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 41591.5859 - val_loss: 0.0013 - val_mape: 3.4439\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 4172.7666 - val_loss: 0.0014 - val_mape: 3.5226\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 62518.9883 - val_loss: 0.0019 - val_mape: 4.3938\n",
      "--- 48/102 Training model for WDAY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 23.2280 - val_loss: 2.6745e-04 - val_mape: 1.9029\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 16.8343 - val_loss: 1.5058e-04 - val_mape: 1.3901\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 20.1730 - val_loss: 4.2878e-04 - val_mape: 2.4211\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 16.5328 - val_loss: 5.8308e-04 - val_mape: 2.9209\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 17.9943 - val_loss: 3.6615e-04 - val_mape: 2.0534\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 16.4750 - val_loss: 4.4370e-04 - val_mape: 2.5293\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 17.3551 - val_loss: 3.6989e-04 - val_mape: 1.8609\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 14.2369 - val_loss: 1.8148e-04 - val_mape: 1.3489\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 14.7027 - val_loss: 3.9923e-04 - val_mape: 2.0834\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 15.9264 - val_loss: 2.2928e-04 - val_mape: 1.5834\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 17.5997 - val_loss: 2.7520e-04 - val_mape: 1.5010\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1158e-04 - mape: 13.0368 - val_loss: 1.8264e-04 - val_mape: 1.3079\n",
      "--- 49/102 Training model for CRWD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021 - mape: 34603.5938 - val_loss: 3.9861e-04 - val_mape: 1.7174\n",
      "Epoch 2/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.2865e-04 - mape: 114761.4375 - val_loss: 5.0339e-04 - val_mape: 2.0085\n",
      "Epoch 3/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - mape: 11374.9482 - val_loss: 3.9955e-04 - val_mape: 1.7627\n",
      "Epoch 4/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - mape: 89662.9141 - val_loss: 7.1227e-04 - val_mape: 2.8002\n",
      "Epoch 5/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.5607e-04 - mape: 24162.4648 - val_loss: 4.5574e-04 - val_mape: 1.9103\n",
      "Epoch 6/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - mape: 58355.6758 - val_loss: 7.6224e-04 - val_mape: 2.7316\n",
      "Epoch 7/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.8454e-04 - mape: 92177.6328 - val_loss: 8.5783e-04 - val_mape: 3.0484\n",
      "Epoch 8/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.7562e-04 - mape: 13596.1289 - val_loss: 5.1948e-04 - val_mape: 2.1717\n",
      "Epoch 9/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 92579.9609 - val_loss: 4.3842e-04 - val_mape: 1.8532\n",
      "Epoch 10/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 46852.6133 - val_loss: 8.6559e-04 - val_mape: 2.8387\n",
      "Epoch 11/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 12633.0801 - val_loss: 0.0013 - val_mape: 3.9869\n",
      "--- 50/102 Training model for DDOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - mape: 145690.1250 - val_loss: 3.5660e-04 - val_mape: 3.3319\n",
      "Epoch 2/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 5575.8525 - val_loss: 5.4933e-05 - val_mape: 1.0387\n",
      "Epoch 3/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 66.9883 - val_loss: 4.2752e-04 - val_mape: 3.3501\n",
      "Epoch 4/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 355436.2500 - val_loss: 4.2404e-04 - val_mape: 3.6745\n",
      "Epoch 5/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 198988.2500 - val_loss: 4.4394e-05 - val_mape: 0.9594\n",
      "Epoch 6/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 260705.9688 - val_loss: 3.1418e-04 - val_mape: 2.9653\n",
      "Epoch 7/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 348629.8125 - val_loss: 9.5480e-05 - val_mape: 1.5037\n",
      "Epoch 8/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 81881.3281 - val_loss: 1.2086e-04 - val_mape: 1.5448\n",
      "Epoch 9/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 130842.4688 - val_loss: 3.5298e-04 - val_mape: 3.2786\n",
      "Epoch 10/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 274083.3125 - val_loss: 6.7321e-05 - val_mape: 1.1411\n",
      "Epoch 11/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - mape: 92155.3281 - val_loss: 1.4353e-04 - val_mape: 1.8409\n",
      "Epoch 12/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 76838.7031 - val_loss: 1.7258e-04 - val_mape: 2.2515\n",
      "Epoch 13/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 282348.3438 - val_loss: 9.8564e-04 - val_mape: 5.2955\n",
      "Epoch 14/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - mape: 163617.0469 - val_loss: 3.2631e-04 - val_mape: 3.1021\n",
      "Epoch 15/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - mape: 100307.8516 - val_loss: 1.0163e-04 - val_mape: 1.5213\n",
      "--- 51/102 Training model for PCAR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 42273.7969 - val_loss: 0.0018 - val_mape: 4.9352\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mape: 33065.6250 - val_loss: 0.0016 - val_mape: 4.4255\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 42298.9062 - val_loss: 3.4693e-04 - val_mape: 1.9808\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0044 - mape: 40142.4375 - val_loss: 0.0019 - val_mape: 4.9593\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mape: 30850.6680 - val_loss: 3.0465e-04 - val_mape: 1.8553\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0038 - mape: 19006.1191 - val_loss: 0.0017 - val_mape: 4.8345\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mape: 41437.3008 - val_loss: 1.3723e-04 - val_mape: 1.2492\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 16090.2393 - val_loss: 4.3239e-04 - val_mape: 2.2526\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 66103.2969 - val_loss: 2.2294e-04 - val_mape: 1.5235\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 22958.3535 - val_loss: 1.9087e-04 - val_mape: 1.3985\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 67702.5859 - val_loss: 1.4263e-04 - val_mape: 1.2684\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 33362.5977 - val_loss: 1.4247e-04 - val_mape: 1.2297\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 19075.3867 - val_loss: 2.2686e-04 - val_mape: 1.5708\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 9699.9707 - val_loss: 1.4048e-04 - val_mape: 1.2270\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 16069.3604 - val_loss: 4.2840e-04 - val_mape: 2.0739\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 16393.0820 - val_loss: 2.6867e-04 - val_mape: 1.5881\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 3806.8606 - val_loss: 2.8579e-04 - val_mape: 1.5488\n",
      "--- 52/102 Training model for MRNA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - mape: 180198.0312 - val_loss: 3.6427e-04 - val_mape: 9.2047\n",
      "Epoch 2/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - mape: 7421.6055 - val_loss: 5.0251e-04 - val_mape: 10.4583\n",
      "Epoch 3/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 71167.0391 - val_loss: 5.1584e-04 - val_mape: 10.9654\n",
      "Epoch 4/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0033 - mape: 1202.9473 - val_loss: 1.0618e-04 - val_mape: 4.1940\n",
      "Epoch 5/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 165802.7188 - val_loss: 1.6926e-04 - val_mape: 6.1141\n",
      "Epoch 6/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - mape: 60952.4531 - val_loss: 1.0569e-04 - val_mape: 4.1750\n",
      "Epoch 7/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 74390.1406 - val_loss: 8.1024e-05 - val_mape: 4.0920\n",
      "Epoch 8/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 63924.6875 - val_loss: 7.0332e-05 - val_mape: 3.4775\n",
      "Epoch 9/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 72843.4219 - val_loss: 5.0851e-05 - val_mape: 3.1442\n",
      "Epoch 10/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 42818.3984 - val_loss: 1.3703e-04 - val_mape: 5.3362\n",
      "Epoch 11/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 76547.5234 - val_loss: 9.4699e-05 - val_mape: 4.5298\n",
      "Epoch 12/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - mape: 5626.0503 - val_loss: 1.0086e-04 - val_mape: 4.5620\n",
      "Epoch 13/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 41579.3047 - val_loss: 1.6904e-04 - val_mape: 6.1834\n",
      "Epoch 14/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - mape: 70323.1562 - val_loss: 1.6603e-04 - val_mape: 5.9027\n",
      "Epoch 15/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 47241.7852 - val_loss: 2.1335e-04 - val_mape: 6.8665\n",
      "Epoch 16/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 38227.7227 - val_loss: 2.3206e-04 - val_mape: 7.1981\n",
      "Epoch 17/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - mape: 108239.5391 - val_loss: 1.3255e-04 - val_mape: 5.3715\n",
      "Epoch 18/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 33008.8594 - val_loss: 3.6815e-05 - val_mape: 2.1435\n",
      "Epoch 19/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mape: 17806.6562 - val_loss: 5.9511e-05 - val_mape: 3.5304\n",
      "Epoch 20/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 14835.9980 - val_loss: 4.0992e-05 - val_mape: 2.4867\n",
      "Epoch 21/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mape: 12066.0254 - val_loss: 3.1029e-05 - val_mape: 2.3478\n",
      "Epoch 22/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 50368.5469 - val_loss: 2.9114e-05 - val_mape: 2.2489\n",
      "Epoch 23/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mape: 8584.5840 - val_loss: 3.4952e-05 - val_mape: 2.4844\n",
      "Epoch 24/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 99552.7109 - val_loss: 2.1770e-05 - val_mape: 1.6479\n",
      "Epoch 25/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 67617.5312 - val_loss: 5.5873e-05 - val_mape: 3.3496\n",
      "Epoch 26/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 8838.8174 - val_loss: 4.1339e-05 - val_mape: 2.7537\n",
      "Epoch 27/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 81068.8984 - val_loss: 5.8187e-05 - val_mape: 3.3957\n",
      "Epoch 28/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 121523.5156 - val_loss: 7.6908e-05 - val_mape: 4.1678\n",
      "Epoch 29/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 100641.4453 - val_loss: 8.9072e-05 - val_mape: 4.3884\n",
      "Epoch 30/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 83972.3125 - val_loss: 3.1134e-05 - val_mape: 2.4275\n",
      "Epoch 31/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - mape: 49631.4531 - val_loss: 7.6238e-05 - val_mape: 4.0003\n",
      "Epoch 32/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.9402e-04 - mape: 25054.8125 - val_loss: 2.3190e-05 - val_mape: 1.8651\n",
      "Epoch 33/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 62454.1055 - val_loss: 2.4238e-05 - val_mape: 1.7902\n",
      "Epoch 34/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mape: 82540.5938 - val_loss: 2.4033e-05 - val_mape: 1.7752\n",
      "--- 53/102 Training model for META ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1066e-04 - mape: 993.3054 - val_loss: 6.1433e-04 - val_mape: 2.6750\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1906e-04 - mape: 4051.6919 - val_loss: 7.2188e-04 - val_mape: 2.5679\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2264e-04 - mape: 1283.4019 - val_loss: 0.0018 - val_mape: 4.5102\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5089e-04 - mape: 2191.2695 - val_loss: 0.0018 - val_mape: 4.0790\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0442e-04 - mape: 550.8392 - val_loss: 0.0018 - val_mape: 4.0140\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.7418e-04 - mape: 345.1180 - val_loss: 0.0023 - val_mape: 4.7525\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2914e-04 - mape: 5891.0122 - val_loss: 0.0025 - val_mape: 4.7624\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5102e-04 - mape: 3347.5017 - val_loss: 0.0025 - val_mape: 4.7306\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.3704e-04 - mape: 336.0840 - val_loss: 0.0033 - val_mape: 5.4330\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.8901e-04 - mape: 4403.8662 - val_loss: 0.0039 - val_mape: 6.1176\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4055e-04 - mape: 734.5818 - val_loss: 0.0055 - val_mape: 7.3406\n",
      "--- 54/102 Training model for MNST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.8943e-04 - mape: 255356.9219 - val_loss: 2.7371e-04 - val_mape: 1.6029\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8150e-04 - mape: 63840.5352 - val_loss: 0.0045 - val_mape: 7.9278\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 132494.5156 - val_loss: 0.0072 - val_mape: 10.1963\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 193430.3438 - val_loss: 7.6356e-04 - val_mape: 3.0929\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 113396.6484 - val_loss: 0.0029 - val_mape: 6.2918\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9735.9902 - val_loss: 8.4299e-04 - val_mape: 3.3635\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 122170.0078 - val_loss: 3.0873e-04 - val_mape: 1.8768\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.2453e-04 - mape: 105958.3516 - val_loss: 1.6539e-04 - val_mape: 1.1505\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7653e-04 - mape: 41319.2031 - val_loss: 2.6015e-04 - val_mape: 1.6692\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.6949e-04 - mape: 25828.1973 - val_loss: 3.8856e-04 - val_mape: 2.1865\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.2291e-04 - mape: 6227.5225 - val_loss: 2.9427e-04 - val_mape: 1.4255\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5285e-04 - mape: 95617.9062 - val_loss: 2.3502e-04 - val_mape: 1.5747\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7333e-04 - mape: 214995.0781 - val_loss: 7.0736e-04 - val_mape: 3.0655\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.0894e-04 - mape: 133722.1094 - val_loss: 2.4922e-04 - val_mape: 1.5400\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5772e-04 - mape: 206057.8594 - val_loss: 2.8329e-04 - val_mape: 1.8231\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7834e-04 - mape: 81861.1250 - val_loss: 3.2415e-04 - val_mape: 1.9702\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7020e-04 - mape: 85671.8906 - val_loss: 1.4541e-04 - val_mape: 1.1784\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2672e-04 - mape: 83900.5234 - val_loss: 2.1618e-04 - val_mape: 1.4856\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 275326.1250 - val_loss: 4.5515e-04 - val_mape: 2.3621\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9195e-04 - mape: 16043.1562 - val_loss: 6.0289e-04 - val_mape: 2.6524\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 244888.0000 - val_loss: 2.5741e-04 - val_mape: 1.7413\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 143834.2188 - val_loss: 1.8133e-04 - val_mape: 1.4168\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4044e-04 - mape: 137867.4531 - val_loss: 5.2322e-04 - val_mape: 2.3545\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6738e-04 - mape: 59488.1953 - val_loss: 5.9635e-04 - val_mape: 2.8050\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5747e-04 - mape: 122407.4375 - val_loss: 1.1743e-04 - val_mape: 0.9501\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2140e-04 - mape: 54722.4531 - val_loss: 1.9862e-04 - val_mape: 1.4655\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 43249.2109 - val_loss: 1.4773e-04 - val_mape: 1.0441\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 115675.6641 - val_loss: 1.2808e-04 - val_mape: 1.0406\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 147637.7656 - val_loss: 1.9770e-04 - val_mape: 1.4905\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 23456.0645 - val_loss: 3.0933e-04 - val_mape: 1.6062\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 173596.0156 - val_loss: 9.6357e-04 - val_mape: 3.6821\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 282367.9688 - val_loss: 7.0455e-04 - val_mape: 2.9212\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 290278.3125 - val_loss: 1.2566e-04 - val_mape: 0.9386\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 102223.1953 - val_loss: 7.4850e-04 - val_mape: 3.1855\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9964e-04 - mape: 93322.3828 - val_loss: 5.7098e-04 - val_mape: 2.7262\n",
      "--- 55/102 Training model for AMD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 48873.2812 - val_loss: 5.1693e-04 - val_mape: 2.3443\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 33350.2383 - val_loss: 0.0013 - val_mape: 4.0260\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 62012.2344 - val_loss: 5.8878e-04 - val_mape: 2.5078\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mape: 14562.5732 - val_loss: 0.0012 - val_mape: 3.8331\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0064 - mape: 20839.9258 - val_loss: 0.0010 - val_mape: 3.4316\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0071 - mape: 22352.5078 - val_loss: 0.0013 - val_mape: 4.0650\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0071 - mape: 2963.7520 - val_loss: 0.0025 - val_mape: 5.9184\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0067 - mape: 49052.5586 - val_loss: 9.0270e-04 - val_mape: 3.2077\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mape: 14430.0195 - val_loss: 0.0014 - val_mape: 4.0007\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 32845.6523 - val_loss: 9.3123e-04 - val_mape: 2.9422\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 1867.7744 - val_loss: 8.1626e-04 - val_mape: 2.5882\n",
      "--- 56/102 Training model for QCOM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 98076.7031 - val_loss: 3.9502e-04 - val_mape: 2.5542\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 2610.2112 - val_loss: 1.6183e-04 - val_mape: 1.5184\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 55740.7773 - val_loss: 1.9629e-04 - val_mape: 1.7781\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 25518.0332 - val_loss: 2.1620e-04 - val_mape: 1.8954\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 107076.7500 - val_loss: 2.8550e-04 - val_mape: 2.1665\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 25869.2871 - val_loss: 2.0102e-04 - val_mape: 1.7552\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 132030.7656 - val_loss: 2.1599e-04 - val_mape: 1.8202\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 16641.7168 - val_loss: 2.6038e-04 - val_mape: 2.0608\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 29308.5762 - val_loss: 7.4451e-04 - val_mape: 3.5225\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 131994.3281 - val_loss: 3.8609e-04 - val_mape: 2.4730\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 88480.8594 - val_loss: 2.6638e-04 - val_mape: 1.9718\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 39316.3711 - val_loss: 2.0525e-04 - val_mape: 1.2324\n",
      "--- 57/102 Training model for CCEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.7645e-04 - mape: 16.1884 - val_loss: 2.3147e-04 - val_mape: 1.6113\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 18.9852 - val_loss: 6.2991e-04 - val_mape: 2.7967\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6593e-04 - mape: 16.7816 - val_loss: 6.2595e-04 - val_mape: 2.4790\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5606e-04 - mape: 15.5120 - val_loss: 2.3622e-04 - val_mape: 1.3901\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 19.5432 - val_loss: 1.3441e-04 - val_mape: 1.2506\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 22.3512 - val_loss: 6.8141e-05 - val_mape: 0.7078\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7208e-04 - mape: 18.9270 - val_loss: 0.0016 - val_mape: 4.5645\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.3669e-04 - mape: 16.6156 - val_loss: 0.0012 - val_mape: 3.5422\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9858e-04 - mape: 16.1494 - val_loss: 3.2155e-04 - val_mape: 1.5754\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.4329e-04 - mape: 17.9814 - val_loss: 1.6691e-04 - val_mape: 1.0333\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 22.0252 - val_loss: 1.1821e-04 - val_mape: 0.8224\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3823e-04 - mape: 17.2385 - val_loss: 0.0013 - val_mape: 3.9633\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.4351e-04 - mape: 14.4554 - val_loss: 9.3970e-04 - val_mape: 3.0016\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1957e-04 - mape: 14.2082 - val_loss: 5.9841e-04 - val_mape: 2.1987\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1670e-04 - mape: 15.8013 - val_loss: 5.6954e-04 - val_mape: 2.2906\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9678e-04 - mape: 18.3720 - val_loss: 0.0023 - val_mape: 5.4342\n",
      "--- 58/102 Training model for PAYX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 124675.6328 - val_loss: 6.3006e-04 - val_mape: 2.5079\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 38167.1133 - val_loss: 2.2920e-04 - val_mape: 1.3022\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 30312.0254 - val_loss: 4.4155e-04 - val_mape: 2.1980\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 152894.7031 - val_loss: 5.8267e-04 - val_mape: 2.1991\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 124008.3516 - val_loss: 3.4604e-04 - val_mape: 1.8639\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 92736.1328 - val_loss: 7.7905e-04 - val_mape: 2.9110\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 5851.8198 - val_loss: 4.7132e-04 - val_mape: 2.2626\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 110631.6328 - val_loss: 2.3807e-04 - val_mape: 1.4873\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 40778.6250 - val_loss: 6.6905e-04 - val_mape: 2.7127\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 89717.5234 - val_loss: 0.0033 - val_mape: 6.1375\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 33017.3789 - val_loss: 4.5381e-04 - val_mape: 2.2765\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 145032.8438 - val_loss: 0.0064 - val_mape: 8.7665\n",
      "--- 59/102 Training model for CHTR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 13.9236 - val_loss: 5.5961e-04 - val_mape: 247998.7188\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 15.8466 - val_loss: 0.0018 - val_mape: 470770.9375\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 18.6858 - val_loss: 9.5729e-04 - val_mape: 383030.4062\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 18.3014 - val_loss: 0.0016 - val_mape: 464628.0625\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 21.2479 - val_loss: 0.0013 - val_mape: 429121.4688\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 20.4930 - val_loss: 9.5550e-04 - val_mape: 385311.0312\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 18.7575 - val_loss: 1.7285e-04 - val_mape: 127227.5703\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 17.5964 - val_loss: 9.1144e-05 - val_mape: 174361.7344\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 16.7359 - val_loss: 2.4450e-04 - val_mape: 282130.5000\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 15.1862 - val_loss: 1.8312e-04 - val_mape: 256389.5781\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 15.0826 - val_loss: 1.0131e-04 - val_mape: 220891.1250\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 15.0713 - val_loss: 3.3936e-04 - val_mape: 305011.4688\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 14.8813 - val_loss: 1.5956e-04 - val_mape: 254995.6875\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 15.4802 - val_loss: 2.3180e-04 - val_mape: 275438.9688\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5938e-04 - mape: 14.7352 - val_loss: 1.4266e-04 - val_mape: 238157.2500\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9148e-04 - mape: 14.3764 - val_loss: 1.8368e-04 - val_mape: 261327.2500\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6132e-04 - mape: 14.0710 - val_loss: 1.6905e-04 - val_mape: 254763.0781\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5814e-04 - mape: 13.5871 - val_loss: 7.3875e-05 - val_mape: 193056.4219\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7265e-04 - mape: 14.5415 - val_loss: 1.2696e-04 - val_mape: 225311.8281\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3307e-04 - mape: 13.6582 - val_loss: 1.4455e-04 - val_mape: 239621.9688\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 14.7783 - val_loss: 2.9169e-04 - val_mape: 280900.6875\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1290e-04 - mape: 13.7667 - val_loss: 1.0521e-04 - val_mape: 224482.0938\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3400e-04 - mape: 14.3010 - val_loss: 1.2555e-04 - val_mape: 236423.1250\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2134e-04 - mape: 13.3914 - val_loss: 1.6484e-04 - val_mape: 251913.7656\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7471e-04 - mape: 14.4838 - val_loss: 9.7269e-05 - val_mape: 218867.1875\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7388e-04 - mape: 13.0484 - val_loss: 9.1597e-05 - val_mape: 215163.2188\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6927e-04 - mape: 13.6208 - val_loss: 8.0116e-05 - val_mape: 207199.8750\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3390e-04 - mape: 14.1797 - val_loss: 2.0539e-04 - val_mape: 261292.9688\n",
      "--- 60/102 Training model for CTAS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 184.8956 - val_loss: 1.3541e-04 - val_mape: 1.1889\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 177.9923 - val_loss: 1.1551e-04 - val_mape: 1.1022\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 227.8257 - val_loss: 4.9248e-05 - val_mape: 0.6578\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 161.7841 - val_loss: 1.4268e-04 - val_mape: 1.1793\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 201.4157 - val_loss: 9.5581e-05 - val_mape: 0.9034\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 138.6082 - val_loss: 4.7212e-04 - val_mape: 2.4169\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 188.5392 - val_loss: 8.5967e-05 - val_mape: 0.7995\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 125.3973 - val_loss: 5.0503e-04 - val_mape: 2.4604\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 174.6760 - val_loss: 2.7586e-04 - val_mape: 1.7199\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 120.5124 - val_loss: 7.7547e-04 - val_mape: 3.0425\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 173.0103 - val_loss: 3.9761e-04 - val_mape: 2.0195\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.9314e-04 - mape: 139.1808 - val_loss: 9.2999e-04 - val_mape: 3.3955\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 145.1503 - val_loss: 8.8977e-04 - val_mape: 3.2345\n",
      "--- 61/102 Training model for GEHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - mape: 5.1915 - val_loss: 1.5468e-04 - val_mape: 1.4170\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.9978e-04 - mape: 4.3631 - val_loss: 1.1797e-04 - val_mape: 1.2142\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - mape: 4.6666 - val_loss: 1.6040e-04 - val_mape: 1.3963\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.9708e-04 - mape: 4.3083 - val_loss: 1.3113e-04 - val_mape: 1.2381\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - mape: 4.7240 - val_loss: 9.6228e-05 - val_mape: 1.0859\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.4612e-04 - mape: 4.1721 - val_loss: 5.6527e-04 - val_mape: 3.1329\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - mape: 4.4549 - val_loss: 1.1508e-04 - val_mape: 1.1760\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.3031e-04 - mape: 4.3670 - val_loss: 4.5698e-04 - val_mape: 2.7130\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - mape: 4.1758 - val_loss: 8.6874e-05 - val_mape: 1.0261\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.5262e-04 - mape: 4.3338 - val_loss: 1.2406e-04 - val_mape: 1.2159\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - mape: 4.4417 - val_loss: 1.4437e-04 - val_mape: 1.3694\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - mape: 4.5152 - val_loss: 5.5080e-04 - val_mape: 3.0927\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - mape: 4.4914 - val_loss: 1.1486e-04 - val_mape: 1.2071\n",
      "Epoch 14/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - mape: 4.5111 - val_loss: 3.8561e-04 - val_mape: 2.4329\n",
      "Epoch 15/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - mape: 4.1715 - val_loss: 8.8084e-05 - val_mape: 1.0197\n",
      "Epoch 16/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.3379e-04 - mape: 4.0808 - val_loss: 1.1610e-04 - val_mape: 1.2049\n",
      "Epoch 17/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.9585e-04 - mape: 3.8858 - val_loss: 7.7543e-05 - val_mape: 0.9564\n",
      "Epoch 18/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.1497e-04 - mape: 3.7054 - val_loss: 8.2632e-05 - val_mape: 1.0305\n",
      "Epoch 19/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.8328e-04 - mape: 3.8862 - val_loss: 1.3625e-04 - val_mape: 1.2825\n",
      "Epoch 20/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - mape: 4.3617 - val_loss: 1.1864e-04 - val_mape: 1.2000\n",
      "Epoch 21/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - mape: 4.1002 - val_loss: 7.5743e-05 - val_mape: 0.9445\n",
      "Epoch 22/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.2311e-04 - mape: 3.9172 - val_loss: 1.5627e-04 - val_mape: 1.3939\n",
      "Epoch 23/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.9533e-04 - mape: 3.7128 - val_loss: 8.1202e-05 - val_mape: 1.0115\n",
      "Epoch 24/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.2675e-04 - mape: 3.8922 - val_loss: 1.0914e-04 - val_mape: 1.1166\n",
      "Epoch 25/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.1199e-04 - mape: 3.9659 - val_loss: 9.8591e-05 - val_mape: 1.0882\n",
      "Epoch 26/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.8796e-04 - mape: 4.1010 - val_loss: 7.8163e-05 - val_mape: 0.9712\n",
      "Epoch 27/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.0670e-04 - mape: 4.1113 - val_loss: 1.2324e-04 - val_mape: 1.2503\n",
      "Epoch 28/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.2778e-04 - mape: 3.8386 - val_loss: 9.8161e-05 - val_mape: 1.1350\n",
      "Epoch 29/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1451e-04 - mape: 3.7406 - val_loss: 1.3681e-04 - val_mape: 1.3101\n",
      "Epoch 30/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.4155e-04 - mape: 3.6966 - val_loss: 8.7023e-05 - val_mape: 1.0167\n",
      "Epoch 31/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.7136e-04 - mape: 3.8944 - val_loss: 6.8848e-05 - val_mape: 0.8790\n",
      "Epoch 32/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.7807e-04 - mape: 3.9895 - val_loss: 1.3495e-04 - val_mape: 1.2774\n",
      "Epoch 33/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.3810e-04 - mape: 3.6388 - val_loss: 7.3789e-05 - val_mape: 0.9153\n",
      "Epoch 34/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.4394e-04 - mape: 4.0561 - val_loss: 9.9617e-05 - val_mape: 1.1012\n",
      "Epoch 35/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.5412e-04 - mape: 3.6327 - val_loss: 8.8417e-05 - val_mape: 1.0557\n",
      "Epoch 36/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.4817e-04 - mape: 3.9136 - val_loss: 1.6905e-04 - val_mape: 1.5244\n",
      "Epoch 37/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.5383e-04 - mape: 3.4597 - val_loss: 8.1410e-05 - val_mape: 1.0106\n",
      "Epoch 38/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.8476e-04 - mape: 3.8249 - val_loss: 7.3577e-05 - val_mape: 0.9167\n",
      "Epoch 39/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.0648e-04 - mape: 3.3189 - val_loss: 9.0513e-05 - val_mape: 1.0226\n",
      "Epoch 40/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.0187e-04 - mape: 4.0393 - val_loss: 7.4035e-05 - val_mape: 0.9281\n",
      "Epoch 41/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6760e-04 - mape: 3.9976 - val_loss: 7.8322e-05 - val_mape: 0.9652\n",
      "--- 62/102 Training model for MRVL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 102.7515 - val_loss: 4.5435e-04 - val_mape: 2.7651\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 73.9074 - val_loss: 1.9328e-04 - val_mape: 1.6510\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 80.3369 - val_loss: 8.2663e-05 - val_mape: 0.9730\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 82.8149 - val_loss: 7.1964e-04 - val_mape: 3.2240\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 74.9698 - val_loss: 5.2475e-04 - val_mape: 3.0109\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 72.5588 - val_loss: 4.3468e-04 - val_mape: 2.5401\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 72.9526 - val_loss: 2.5094e-04 - val_mape: 1.8496\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 67.4882 - val_loss: 3.7378e-04 - val_mape: 2.5005\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 103.8243 - val_loss: 7.5284e-04 - val_mape: 3.4695\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 71.7124 - val_loss: 7.5616e-04 - val_mape: 3.4056\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 77.5951 - val_loss: 4.6936e-04 - val_mape: 2.7635\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 90.8528 - val_loss: 0.0012 - val_mape: 4.5782\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 84.4023 - val_loss: 6.6213e-05 - val_mape: 0.9327\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 74.8203 - val_loss: 3.4611e-04 - val_mape: 2.3899\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 71.1310 - val_loss: 4.0452e-04 - val_mape: 2.4767\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 65.5385 - val_loss: 1.1608e-04 - val_mape: 1.2586\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 58.2918 - val_loss: 9.8037e-04 - val_mape: 4.1941\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 73.8352 - val_loss: 1.4685e-04 - val_mape: 1.3027\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 63.9704 - val_loss: 1.9918e-04 - val_mape: 1.6593\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 61.0359 - val_loss: 2.4266e-04 - val_mape: 1.8557\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 57.2078 - val_loss: 7.7565e-04 - val_mape: 3.5812\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 67.5898 - val_loss: 2.3017e-04 - val_mape: 1.8395\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 61.6833 - val_loss: 5.4388e-04 - val_mape: 3.0116\n",
      "--- 63/102 Training model for NXPI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 17813.9199 - val_loss: 0.0012 - val_mape: 3.5291\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 25092.0566 - val_loss: 6.1989e-04 - val_mape: 2.1577\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.2238e-04 - mape: 16125.3418 - val_loss: 0.0012 - val_mape: 3.4553\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1041e-04 - mape: 20420.2090 - val_loss: 0.0014 - val_mape: 3.4104\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4877e-04 - mape: 21120.0254 - val_loss: 0.0015 - val_mape: 3.6748\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7798e-04 - mape: 45587.1367 - val_loss: 0.0012 - val_mape: 3.0315\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.8188e-04 - mape: 3582.4839 - val_loss: 0.0015 - val_mape: 3.7721\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3354e-04 - mape: 23010.1797 - val_loss: 0.0023 - val_mape: 4.6280\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.0870e-04 - mape: 12289.3818 - val_loss: 0.0021 - val_mape: 4.5188\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2167e-04 - mape: 2855.5933 - val_loss: 0.0027 - val_mape: 5.3124\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7410e-04 - mape: 51987.4961 - val_loss: 0.0018 - val_mape: 4.1841\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2603e-04 - mape: 25371.6152 - val_loss: 0.0056 - val_mape: 8.2346\n",
      "--- 64/102 Training model for TTD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 186.0062 - val_loss: 0.0024 - val_mape: 6.4793\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 189.1248 - val_loss: 0.0081 - val_mape: 10.6279\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0090 - mape: 592.9778 - val_loss: 3.3763e-04 - val_mape: 1.9350\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - mape: 399.6696 - val_loss: 2.8798e-04 - val_mape: 1.8571\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 327.2210 - val_loss: 1.6738e-04 - val_mape: 1.1623\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 190.5592 - val_loss: 5.5704e-04 - val_mape: 2.6793\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 133.3453 - val_loss: 1.8460e-04 - val_mape: 1.2854\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 150.4771 - val_loss: 3.2250e-04 - val_mape: 1.9827\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 171.8372 - val_loss: 2.7394e-04 - val_mape: 1.7407\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 188.8380 - val_loss: 2.3923e-04 - val_mape: 1.6372\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 156.7757 - val_loss: 3.9980e-04 - val_mape: 2.1264\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 158.2253 - val_loss: 1.8023e-04 - val_mape: 1.1706\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 144.0120 - val_loss: 8.6899e-04 - val_mape: 3.3561\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mape: 220.8477 - val_loss: 3.4655e-04 - val_mape: 2.0548\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mape: 141.4009 - val_loss: 0.0026 - val_mape: 6.1146\n",
      "--- 65/102 Training model for BKNG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5383e-04 - mape: 49112.8477 - val_loss: 4.3703e-04 - val_mape: 2.2502\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5726e-04 - mape: 29916.7246 - val_loss: 3.9417e-04 - val_mape: 1.6095\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1601e-04 - mape: 36787.9492 - val_loss: 5.6081e-04 - val_mape: 1.9984\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5611e-04 - mape: 1408.7384 - val_loss: 8.5690e-04 - val_mape: 2.7272\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5024e-04 - mape: 1635.2336 - val_loss: 9.6838e-04 - val_mape: 2.8550\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.1292e-04 - mape: 26935.0547 - val_loss: 0.0011 - val_mape: 3.1700\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.4127e-04 - mape: 55321.4258 - val_loss: 0.0014 - val_mape: 3.6312\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.9816e-04 - mape: 3159.8992 - val_loss: 0.0017 - val_mape: 4.2119\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.1640e-04 - mape: 1394.3865 - val_loss: 0.0020 - val_mape: 4.5977\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.8222e-04 - mape: 17706.9766 - val_loss: 0.0018 - val_mape: 4.3444\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.0594e-04 - mape: 8731.8086 - val_loss: 0.0017 - val_mape: 4.0804\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.6227e-04 - mape: 11532.3496 - val_loss: 0.0023 - val_mape: 4.9623\n",
      "--- 66/102 Training model for KDP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mape: 66454.2578 - val_loss: 0.0011 - val_mape: 3.6070\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 182795.3438 - val_loss: 0.0022 - val_mape: 5.0183\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 28541.4824 - val_loss: 0.0046 - val_mape: 7.2929\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 66489.9531 - val_loss: 0.0045 - val_mape: 6.4792\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 42030.4648 - val_loss: 0.0039 - val_mape: 6.9468\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - mape: 146282.4219 - val_loss: 0.0078 - val_mape: 9.4616\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0110 - mape: 122768.3594 - val_loss: 0.0101 - val_mape: 12.1806\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 60223.4531 - val_loss: 0.0060 - val_mape: 9.1149\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 6687.5562 - val_loss: 0.0037 - val_mape: 7.2293\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 196561.1562 - val_loss: 7.7358e-04 - val_mape: 3.1878\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 6908.8472 - val_loss: 6.8433e-04 - val_mape: 3.0148\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 108016.2344 - val_loss: 3.4717e-04 - val_mape: 2.0922\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 4349.0112 - val_loss: 4.5000e-04 - val_mape: 2.4443\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 46187.6523 - val_loss: 2.8157e-04 - val_mape: 1.8978\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 176095.8125 - val_loss: 5.9941e-04 - val_mape: 2.8741\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mape: 86570.6484 - val_loss: 5.3084e-04 - val_mape: 2.7475\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 107804.4922 - val_loss: 0.0010 - val_mape: 3.8348\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 78870.1328 - val_loss: 5.4058e-04 - val_mape: 2.7823\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 69329.6094 - val_loss: 0.0010 - val_mape: 3.7936\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 148452.5938 - val_loss: 0.0010 - val_mape: 3.8755\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 50658.9727 - val_loss: 0.0011 - val_mape: 3.9909\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 48497.4375 - val_loss: 8.4718e-04 - val_mape: 3.5286\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 72163.7812 - val_loss: 0.0015 - val_mape: 4.7122\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 99647.0859 - val_loss: 8.1913e-04 - val_mape: 3.4737\n",
      "--- 67/102 Training model for ODFL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mape: 231658.8281 - val_loss: 0.0014 - val_mape: 3.2250\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mape: 276204.0625 - val_loss: 8.2106e-04 - val_mape: 2.4469\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026 - mape: 78838.3438 - val_loss: 0.0018 - val_mape: 3.6365\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0055 - mape: 175523.6719 - val_loss: 0.0011 - val_mape: 2.6390\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 65037.3867 - val_loss: 0.0012 - val_mape: 2.6804\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 188083.1406 - val_loss: 0.0013 - val_mape: 2.8230\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 31223.5449 - val_loss: 0.0011 - val_mape: 2.5785\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 145912.4844 - val_loss: 9.3054e-04 - val_mape: 2.4158\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 149847.1094 - val_loss: 9.9430e-04 - val_mape: 2.4520\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 43447.0273 - val_loss: 0.0012 - val_mape: 2.7377\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 31342.3516 - val_loss: 8.3111e-04 - val_mape: 2.2696\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 66821.2031 - val_loss: 8.0360e-04 - val_mape: 2.3025\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 93246.6250 - val_loss: 9.6209e-04 - val_mape: 2.4069\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 17307.5254 - val_loss: 8.3230e-04 - val_mape: 2.2511\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 78576.5469 - val_loss: 8.4561e-04 - val_mape: 2.2885\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 55853.2734 - val_loss: 8.0118e-04 - val_mape: 2.2193\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 207301.2812 - val_loss: 0.0012 - val_mape: 2.8645\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 12646.3652 - val_loss: 6.6565e-04 - val_mape: 2.1271\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 586.3870 - val_loss: 6.9093e-04 - val_mape: 2.1279\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 26338.7031 - val_loss: 5.9135e-04 - val_mape: 2.1327\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 90597.4766 - val_loss: 5.8454e-04 - val_mape: 2.1881\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 185383.5938 - val_loss: 6.8522e-04 - val_mape: 2.0899\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 26698.0840 - val_loss: 5.5016e-04 - val_mape: 2.0629\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mape: 73288.8594 - val_loss: 5.1082e-04 - val_mape: 2.0986\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 79911.6875 - val_loss: 5.0322e-04 - val_mape: 1.8597\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 134914.4375 - val_loss: 5.4477e-04 - val_mape: 2.0876\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 103029.2578 - val_loss: 5.1641e-04 - val_mape: 2.0238\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 65883.0625 - val_loss: 5.4042e-04 - val_mape: 1.9898\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 197623.6250 - val_loss: 8.1010e-04 - val_mape: 2.9738\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 82030.1172 - val_loss: 6.6325e-04 - val_mape: 2.4298\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 18348.8730 - val_loss: 7.0742e-04 - val_mape: 2.5440\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 28996.5391 - val_loss: 6.7721e-04 - val_mape: 2.1887\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 24618.1250 - val_loss: 6.1598e-04 - val_mape: 2.2190\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 153333.7812 - val_loss: 6.3643e-04 - val_mape: 2.2351\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 141784.4375 - val_loss: 5.0652e-04 - val_mape: 2.0871\n",
      "--- 68/102 Training model for ISRG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mape: 42.4289 - val_loss: 2.7878e-04 - val_mape: 1.5847\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 55.6041 - val_loss: 4.0224e-04 - val_mape: 2.0888\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mape: 40.2836 - val_loss: 5.5867e-04 - val_mape: 2.4193\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 32.1627 - val_loss: 2.6836e-04 - val_mape: 1.1225\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 32.0263 - val_loss: 3.4027e-04 - val_mape: 1.3944\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 37.6207 - val_loss: 3.0105e-04 - val_mape: 1.1836\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 35.2535 - val_loss: 5.1746e-04 - val_mape: 1.9284\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 37.0628 - val_loss: 3.3350e-04 - val_mape: 1.1981\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6974e-04 - mape: 33.1231 - val_loss: 4.9607e-04 - val_mape: 1.5425\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.0491e-04 - mape: 28.9529 - val_loss: 5.4499e-04 - val_mape: 1.5608\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4090e-04 - mape: 32.3640 - val_loss: 7.5391e-04 - val_mape: 2.0166\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9384e-04 - mape: 31.6146 - val_loss: 7.9301e-04 - val_mape: 2.1548\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7566e-04 - mape: 31.2264 - val_loss: 0.0011 - val_mape: 3.0108\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 37.8359 - val_loss: 0.0011 - val_mape: 2.8454\n",
      "--- 69/102 Training model for TXN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mape: 40.5905 - val_loss: 6.0438e-04 - val_mape: 1.9894\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 41.2694 - val_loss: 4.2458e-04 - val_mape: 1.5552\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 34.7080 - val_loss: 0.0016 - val_mape: 3.7384\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 39.6005 - val_loss: 0.0013 - val_mape: 3.1266\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 39.1406 - val_loss: 8.8301e-04 - val_mape: 2.3702\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 38.0472 - val_loss: 9.1225e-04 - val_mape: 2.7425\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 34.8762 - val_loss: 0.0011 - val_mape: 3.2553\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 37.7342 - val_loss: 0.0013 - val_mape: 2.9748\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 42.9838 - val_loss: 0.0011 - val_mape: 2.9823\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 36.6470 - val_loss: 0.0012 - val_mape: 3.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 46.6341 - val_loss: 8.9040e-04 - val_mape: 2.4268\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 42.3937 - val_loss: 0.0023 - val_mape: 4.3688\n",
      "--- 70/102 Training model for ARM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - mape: 108356.7969 - val_loss: 0.0027 - val_mape: 6.7823\n",
      "Epoch 2/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - mape: 1054570.2500 - val_loss: 0.0013 - val_mape: 4.6099\n",
      "Epoch 3/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0017 - mape: 1193500.7500 - val_loss: 0.0013 - val_mape: 4.4876\n",
      "Epoch 4/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - mape: 78563.1875 - val_loss: 0.0018 - val_mape: 5.7589\n",
      "Epoch 5/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0018 - mape: 540024.0000 - val_loss: 0.0011 - val_mape: 3.9404\n",
      "Epoch 6/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0021 - mape: 496822.0312 - val_loss: 8.1773e-04 - val_mape: 3.5538\n",
      "Epoch 7/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0016 - mape: 323344.5312 - val_loss: 7.8562e-04 - val_mape: 3.4077\n",
      "Epoch 8/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - mape: 1019995.1250 - val_loss: 6.9794e-04 - val_mape: 3.3136\n",
      "Epoch 9/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - mape: 670471.0000 - val_loss: 5.5133e-04 - val_mape: 3.2724\n",
      "Epoch 10/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0017 - mape: 826442.0000 - val_loss: 5.3936e-04 - val_mape: 3.1552\n",
      "Epoch 11/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - mape: 157370.5000 - val_loss: 6.5377e-04 - val_mape: 3.1210\n",
      "Epoch 12/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.8013e-04 - mape: 18759.2305 - val_loss: 7.4277e-04 - val_mape: 3.3638\n",
      "Epoch 13/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0018 - mape: 474497.4375 - val_loss: 8.3741e-04 - val_mape: 3.5316\n",
      "Epoch 14/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - mape: 442529.5625 - val_loss: 7.7853e-04 - val_mape: 3.4683\n",
      "Epoch 15/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - mape: 340987.8125 - val_loss: 9.4159e-04 - val_mape: 3.7848\n",
      "Epoch 16/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - mape: 276306.3125 - val_loss: 0.0012 - val_mape: 4.5028\n",
      "Epoch 17/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - mape: 446689.7500 - val_loss: 8.2003e-04 - val_mape: 3.6606\n",
      "Epoch 18/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0018 - mape: 6368.4429 - val_loss: 7.9541e-04 - val_mape: 3.8327\n",
      "Epoch 19/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0020 - mape: 424853.8438 - val_loss: 0.0013 - val_mape: 5.0547\n",
      "Epoch 20/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - mape: 471425.1250 - val_loss: 0.0012 - val_mape: 4.5500\n",
      "--- 71/102 Training model for ROST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9215e-04 - mape: 48477.8320 - val_loss: 9.5228e-05 - val_mape: 0.7553\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9607e-04 - mape: 9401.5342 - val_loss: 8.7154e-05 - val_mape: 0.7226\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8047e-04 - mape: 61376.2188 - val_loss: 1.2912e-04 - val_mape: 0.8913\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8642e-04 - mape: 117286.6641 - val_loss: 1.5748e-04 - val_mape: 1.0157\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1618e-04 - mape: 161332.1250 - val_loss: 2.4592e-04 - val_mape: 1.4993\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1359e-04 - mape: 95036.0000 - val_loss: 2.9817e-04 - val_mape: 1.6544\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0805e-04 - mape: 35188.2227 - val_loss: 2.7975e-04 - val_mape: 1.6327\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4826e-04 - mape: 9660.5264 - val_loss: 1.4889e-04 - val_mape: 0.9322\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9568e-04 - mape: 165435.5000 - val_loss: 2.7052e-04 - val_mape: 1.5225\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5917e-04 - mape: 8450.7930 - val_loss: 2.3494e-04 - val_mape: 1.3492\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9457e-04 - mape: 22349.0039 - val_loss: 2.7337e-04 - val_mape: 1.4473\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2018e-04 - mape: 60676.0781 - val_loss: 2.3904e-04 - val_mape: 1.2543\n",
      "--- 72/102 Training model for MDLZ ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 16658.5254 - val_loss: 1.2182e-04 - val_mape: 1.0348\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 12090.1074 - val_loss: 2.6901e-04 - val_mape: 1.6442\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 4063.7495 - val_loss: 6.2863e-04 - val_mape: 2.4166\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 1149.3075 - val_loss: 0.0020 - val_mape: 5.0747\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 19027.3457 - val_loss: 1.7847e-04 - val_mape: 1.2056\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - mape: 109280.0547 - val_loss: 3.4147e-04 - val_mape: 1.8429\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0064 - mape: 79722.1016 - val_loss: 0.0011 - val_mape: 3.5357\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 80113.5469 - val_loss: 5.3696e-04 - val_mape: 2.5196\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mape: 91854.5781 - val_loss: 3.0246e-04 - val_mape: 1.6700\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 47233.9844 - val_loss: 1.2077e-04 - val_mape: 0.9341\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 45158.4570 - val_loss: 2.1220e-04 - val_mape: 1.3569\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 70938.9219 - val_loss: 1.1065e-04 - val_mape: 0.8931\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 68470.7656 - val_loss: 1.7761e-04 - val_mape: 1.2534\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 27419.2832 - val_loss: 3.4934e-04 - val_mape: 1.8843\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 18960.2207 - val_loss: 3.4362e-04 - val_mape: 1.9400\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 58349.4922 - val_loss: 8.1920e-04 - val_mape: 3.1603\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 24345.2148 - val_loss: 2.9884e-04 - val_mape: 1.7876\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 34263.9453 - val_loss: 1.1146e-04 - val_mape: 0.8796\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 60296.8320 - val_loss: 1.5007e-04 - val_mape: 1.1647\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 24219.3457 - val_loss: 2.8875e-04 - val_mape: 1.7554\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8923e-04 - mape: 2030.7917 - val_loss: 9.5763e-05 - val_mape: 0.8514\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 31333.9043 - val_loss: 1.0309e-04 - val_mape: 0.8930\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 57144.6016 - val_loss: 1.5791e-04 - val_mape: 1.0814\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 20860.6816 - val_loss: 4.3230e-04 - val_mape: 1.9974\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 69262.7266 - val_loss: 0.0011 - val_mape: 3.6889\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 141426.7031 - val_loss: 2.6658e-04 - val_mape: 1.6029\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 75036.7422 - val_loss: 2.3578e-04 - val_mape: 1.2751\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 25744.2188 - val_loss: 5.9777e-04 - val_mape: 2.6668\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 60080.9453 - val_loss: 2.4905e-04 - val_mape: 1.5514\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 26690.7715 - val_loss: 3.1372e-04 - val_mape: 1.6417\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 98414.6562 - val_loss: 4.4337e-04 - val_mape: 2.1763\n",
      "--- 73/102 Training model for LIN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 224.7348 - val_loss: 1.6632e-04 - val_mape: 1.1911\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 187.1513 - val_loss: 5.9898e-04 - val_mape: 2.5442\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 190.3968 - val_loss: 4.8770e-04 - val_mape: 2.0734\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 268.6607 - val_loss: 0.0013 - val_mape: 3.7070\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 175.7440 - val_loss: 0.0023 - val_mape: 5.0057\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mape: 479.2397 - val_loss: 0.0016 - val_mape: 4.3062\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 188.0785 - val_loss: 0.0041 - val_mape: 6.7776\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0086 - mape: 746.9883 - val_loss: 0.0010 - val_mape: 3.2127\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 204.5691 - val_loss: 0.0047 - val_mape: 7.2469\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0084 - mape: 775.6735 - val_loss: 3.6293e-04 - val_mape: 1.6416\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 297.7547 - val_loss: 0.0035 - val_mape: 6.3074\n",
      "--- 74/102 Training model for CSCO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 28.3040 - val_loss: 1.9665e-04 - val_mape: 1.7725\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 24.2792 - val_loss: 4.7106e-05 - val_mape: 0.7694\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 24.8573 - val_loss: 5.4229e-05 - val_mape: 0.8261\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7197e-04 - mape: 22.3518 - val_loss: 6.4495e-05 - val_mape: 0.9192\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 24.5852 - val_loss: 8.4174e-05 - val_mape: 1.1014\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 24.2632 - val_loss: 8.1638e-05 - val_mape: 1.0958\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 24.4453 - val_loss: 4.1062e-05 - val_mape: 0.7284\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 26.9768 - val_loss: 4.2190e-05 - val_mape: 0.7218\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 24.0205 - val_loss: 2.7890e-04 - val_mape: 2.2940\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 27.0502 - val_loss: 6.4909e-05 - val_mape: 0.9902\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 27.9680 - val_loss: 4.8085e-05 - val_mape: 0.8098\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 26.2935 - val_loss: 3.6550e-05 - val_mape: 0.6958\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 25.9301 - val_loss: 3.3432e-05 - val_mape: 0.6531\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 25.0442 - val_loss: 4.9246e-05 - val_mape: 0.8324\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 27.5351 - val_loss: 5.9112e-05 - val_mape: 0.8958\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mape: 27.2458 - val_loss: 4.6121e-05 - val_mape: 0.7812\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.1211 - val_loss: 1.2662e-04 - val_mape: 1.4985\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 31.1609 - val_loss: 5.8008e-05 - val_mape: 0.9003\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.4311 - val_loss: 2.2746e-04 - val_mape: 2.0778\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 29.3367 - val_loss: 9.5000e-05 - val_mape: 1.2104\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 28.8456 - val_loss: 1.3085e-04 - val_mape: 1.5266\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mape: 30.0219 - val_loss: 6.6829e-05 - val_mape: 0.9336\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mape: 33.5791 - val_loss: 9.2790e-05 - val_mape: 1.2045\n",
      "--- 75/102 Training model for INTU ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mape: 14639.3154 - val_loss: 2.9007e-04 - val_mape: 1.7416\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 92657.3047 - val_loss: 1.4777e-04 - val_mape: 1.1130\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 114466.8750 - val_loss: 1.9294e-04 - val_mape: 1.3194\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mape: 142725.6719 - val_loss: 8.5317e-05 - val_mape: 0.8991\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 34178.9023 - val_loss: 1.3268e-04 - val_mape: 1.0692\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 151319.3125 - val_loss: 4.8344e-04 - val_mape: 2.2888\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mape: 249216.9375 - val_loss: 5.7730e-04 - val_mape: 2.5285\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - mape: 183183.2188 - val_loss: 8.0895e-04 - val_mape: 2.9778\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0027 - mape: 330391.8125 - val_loss: 0.0036 - val_mape: 6.7432\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mape: 9984.1172 - val_loss: 0.0032 - val_mape: 6.4427\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0025 - mape: 40278.3242 - val_loss: 0.0042 - val_mape: 7.3284\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - mape: 104102.1719 - val_loss: 0.0066 - val_mape: 9.1985\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0071 - mape: 415394.2188 - val_loss: 0.0034 - val_mape: 6.6056\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 120717.9141 - val_loss: 1.7411e-04 - val_mape: 1.2268\n",
      "--- 76/102 Training model for PEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 8608.8057 - val_loss: 2.7753e-04 - val_mape: 1.8460\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 18074.7559 - val_loss: 2.8770e-04 - val_mape: 1.9051\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 6001.7837 - val_loss: 8.7705e-05 - val_mape: 0.8564\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - mape: 40043.6367 - val_loss: 1.9277e-04 - val_mape: 1.5010\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 44508.4141 - val_loss: 1.6911e-04 - val_mape: 1.3799\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 12910.8164 - val_loss: 1.0356e-04 - val_mape: 0.9847\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 45360.5781 - val_loss: 1.4476e-04 - val_mape: 1.2618\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 52645.3203 - val_loss: 2.2977e-04 - val_mape: 1.6333\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 5871.0522 - val_loss: 2.1900e-04 - val_mape: 1.5813\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 9946.8789 - val_loss: 3.4555e-04 - val_mape: 2.0694\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 10048.0996 - val_loss: 1.6078e-04 - val_mape: 1.3103\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 7798.4702 - val_loss: 3.2439e-04 - val_mape: 2.0131\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 56603.2188 - val_loss: 1.5265e-04 - val_mape: 1.2806\n",
      "--- 77/102 Training model for ANSS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mape: 81.6039 - val_loss: 1.6621e-04 - val_mape: 1.3797\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mape: 58.3552 - val_loss: 2.8651e-04 - val_mape: 1.8624\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 70.3680 - val_loss: 8.6598e-05 - val_mape: 0.8175\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 79.9600 - val_loss: 1.4584e-04 - val_mape: 1.3051\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 106.8216 - val_loss: 1.1867e-04 - val_mape: 1.1515\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 41.2991 - val_loss: 2.2279e-04 - val_mape: 1.7128\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 51.4391 - val_loss: 8.7393e-05 - val_mape: 0.8853\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 48.7521 - val_loss: 3.3962e-04 - val_mape: 2.3014\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 92.1870 - val_loss: 1.7021e-04 - val_mape: 1.5449\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 51.6450 - val_loss: 5.1899e-04 - val_mape: 2.7650\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 85.4500 - val_loss: 7.6876e-05 - val_mape: 0.7753\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 75.1631 - val_loss: 7.3082e-04 - val_mape: 3.5348\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 148.4847 - val_loss: 1.0951e-04 - val_mape: 1.0845\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 37.8315 - val_loss: 1.5212e-04 - val_mape: 1.4139\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 93.8254 - val_loss: 8.9485e-05 - val_mape: 0.9266\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 86.9998 - val_loss: 5.6739e-04 - val_mape: 2.9231\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 140.6064 - val_loss: 9.2488e-05 - val_mape: 0.9116\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mape: 41.9035 - val_loss: 2.2256e-04 - val_mape: 1.7825\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 106.3787 - val_loss: 9.6989e-05 - val_mape: 1.0680\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 46.3720 - val_loss: 4.0903e-04 - val_mape: 2.5824\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 94.5753 - val_loss: 5.3307e-05 - val_mape: 0.5733\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 84.0394 - val_loss: 2.1725e-04 - val_mape: 1.7753\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 71.2220 - val_loss: 8.8220e-05 - val_mape: 0.8782\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 63.0828 - val_loss: 6.6580e-05 - val_mape: 0.7556\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mape: 72.1612 - val_loss: 1.2537e-04 - val_mape: 1.2684\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 49.3368 - val_loss: 7.1759e-05 - val_mape: 0.7738\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 56.0217 - val_loss: 2.2237e-04 - val_mape: 1.7996\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 56.3267 - val_loss: 3.7663e-04 - val_mape: 2.4634\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 85.3832 - val_loss: 1.6218e-04 - val_mape: 1.4764\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 100.3492 - val_loss: 0.0013 - val_mape: 4.8154\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mape: 118.1800 - val_loss: 2.9028e-04 - val_mape: 2.0968\n",
      "--- 78/102 Training model for SMCI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0027 - mape: 44493.7578 - val_loss: 0.0083 - val_mape: 12.0333\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 51831.7969 - val_loss: 0.0107 - val_mape: 13.6536\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 55645.6719 - val_loss: 0.0125 - val_mape: 14.7402\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 49010.4531 - val_loss: 0.0149 - val_mape: 16.1343\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mape: 118700.1719 - val_loss: 0.0175 - val_mape: 17.7759\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 47571.4414 - val_loss: 0.0193 - val_mape: 18.5631\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 42184.9258 - val_loss: 0.0219 - val_mape: 19.7397\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 78948.5078 - val_loss: 0.0244 - val_mape: 20.8091\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 46986.9414 - val_loss: 0.0274 - val_mape: 21.9807\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 91140.9531 - val_loss: 0.0295 - val_mape: 22.9908\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 27842.6270 - val_loss: 0.0316 - val_mape: 23.9255\n",
      "--- 79/102 Training model for MCHP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mape: 53685.3398 - val_loss: 1.3579e-04 - val_mape: 1.0227\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 30599.0801 - val_loss: 0.0017 - val_mape: 4.5367\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 52617.0703 - val_loss: 0.0011 - val_mape: 3.5665\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 37547.0000 - val_loss: 4.0191e-04 - val_mape: 1.9035\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 34806.4688 - val_loss: 2.3827e-04 - val_mape: 1.3306\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 22806.8887 - val_loss: 5.7502e-04 - val_mape: 2.3734\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 11296.8008 - val_loss: 5.7638e-04 - val_mape: 2.3667\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 26230.1758 - val_loss: 7.4877e-04 - val_mape: 2.8139\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 61132.3867 - val_loss: 2.9458e-04 - val_mape: 1.4652\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 42064.2539 - val_loss: 7.9037e-04 - val_mape: 2.6532\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1517e-04 - mape: 22239.2695 - val_loss: 4.0243e-04 - val_mape: 1.7189\n",
      "--- 80/102 Training model for DASH ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - mape: 33513.7539 - val_loss: 3.9923e-05 - val_mape: 1.2527\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 30250.7656 - val_loss: 3.2667e-05 - val_mape: 1.1991\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 46117.1875 - val_loss: 3.5164e-05 - val_mape: 1.2848\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 17516.7891 - val_loss: 1.4524e-04 - val_mape: 3.2227\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 74551.6641 - val_loss: 3.9542e-05 - val_mape: 1.3459\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 948.4103 - val_loss: 5.9467e-05 - val_mape: 1.5565\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 21994.2812 - val_loss: 1.4249e-04 - val_mape: 2.6576\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 39890.1133 - val_loss: 1.9544e-04 - val_mape: 3.5624\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 31571.4844 - val_loss: 8.0478e-05 - val_mape: 1.7386\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 8792.5361 - val_loss: 2.9070e-04 - val_mape: 4.5927\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - mape: 26422.2559 - val_loss: 1.6007e-04 - val_mape: 2.5291\n",
      "Epoch 12/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - mape: 8899.1533 - val_loss: 1.9668e-04 - val_mape: 3.5945\n",
      "--- 81/102 Training model for LULU ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 96010.7422 - val_loss: 6.8442e-04 - val_mape: 2.3676\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mape: 35066.5039 - val_loss: 0.0011 - val_mape: 4.6001\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mape: 111937.6953 - val_loss: 6.0072e-04 - val_mape: 2.6417\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mape: 173024.5312 - val_loss: 0.0014 - val_mape: 5.2214\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 15779.3262 - val_loss: 0.0026 - val_mape: 5.2197\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0054 - mape: 210113.7500 - val_loss: 5.8100e-04 - val_mape: 3.3435\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0041 - mape: 212823.0625 - val_loss: 0.0035 - val_mape: 6.2379\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0054 - mape: 286588.3125 - val_loss: 9.7811e-05 - val_mape: 0.9294\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0079 - mape: 226528.0938 - val_loss: 0.0018 - val_mape: 4.2356\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - mape: 224582.4531 - val_loss: 1.8337e-04 - val_mape: 1.4698\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 52118.1758 - val_loss: 2.9198e-04 - val_mape: 1.4776\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 116001.5781 - val_loss: 3.5647e-04 - val_mape: 1.5714\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 132863.0469 - val_loss: 1.2075e-04 - val_mape: 1.0454\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 114052.3516 - val_loss: 2.9188e-04 - val_mape: 1.4294\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 3307.3069 - val_loss: 2.2991e-04 - val_mape: 1.6336\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 53283.1328 - val_loss: 3.8755e-04 - val_mape: 1.8034\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 1804.9872 - val_loss: 2.9698e-04 - val_mape: 1.9194\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 2781.8870 - val_loss: 8.6604e-04 - val_mape: 2.9747\n",
      "--- 82/102 Training model for AMGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - mape: 67.7361 - val_loss: 4.4564e-04 - val_mape: 2.3217\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 23.1050 - val_loss: 3.8207e-04 - val_mape: 1.8190\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 29.2375 - val_loss: 1.6408e-04 - val_mape: 1.0105\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 22.7371 - val_loss: 2.3593e-04 - val_mape: 1.1916\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 22.8909 - val_loss: 3.6186e-04 - val_mape: 1.6055\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 22.2257 - val_loss: 5.0104e-04 - val_mape: 2.0728\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9846e-04 - mape: 20.7554 - val_loss: 6.5249e-04 - val_mape: 2.3804\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 21.7275 - val_loss: 8.1620e-04 - val_mape: 2.7511\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 22.8945 - val_loss: 4.2639e-04 - val_mape: 1.5689\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8458e-04 - mape: 21.8287 - val_loss: 7.9686e-04 - val_mape: 2.5179\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.5938e-04 - mape: 21.9447 - val_loss: 9.0282e-04 - val_mape: 2.7900\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8037e-04 - mape: 19.9333 - val_loss: 7.0109e-04 - val_mape: 2.1318\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.7267e-04 - mape: 20.6840 - val_loss: 0.0010 - val_mape: 2.9833\n",
      "--- 83/102 Training model for ADSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 24.8867 - val_loss: 8.2682e-05 - val_mape: 1.1799\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 25.1273 - val_loss: 2.0260e-04 - val_mape: 1.9860\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 23.4120 - val_loss: 5.5695e-04 - val_mape: 3.0303\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 24.1565 - val_loss: 3.2535e-04 - val_mape: 2.4922\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 24.2425 - val_loss: 2.8756e-04 - val_mape: 2.4125\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 25.9006 - val_loss: 3.0669e-04 - val_mape: 2.5927\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 21.9431 - val_loss: 3.0133e-04 - val_mape: 2.4940\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 26.3116 - val_loss: 2.1644e-04 - val_mape: 2.1372\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 23.1448 - val_loss: 1.3139e-04 - val_mape: 1.6697\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 24.0757 - val_loss: 5.3649e-05 - val_mape: 0.9786\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 23.7837 - val_loss: 8.1076e-05 - val_mape: 1.2074\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 21.0214 - val_loss: 1.7181e-04 - val_mape: 1.8095\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 25.8181 - val_loss: 4.5006e-04 - val_mape: 3.1394\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 26.1067 - val_loss: 5.8376e-04 - val_mape: 3.7244\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 25.4053 - val_loss: 6.0454e-04 - val_mape: 3.6259\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 23.2747 - val_loss: 0.0012 - val_mape: 5.3851\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 21.9505 - val_loss: 6.8497e-04 - val_mape: 4.1290\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 24.6139 - val_loss: 4.2433e-04 - val_mape: 3.1975\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 25.6330 - val_loss: 5.3502e-04 - val_mape: 3.5774\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 25.5165 - val_loss: 5.0256e-04 - val_mape: 3.4940\n",
      "--- 84/102 Training model for CTSH ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.8613e-04 - mape: 31715.7363 - val_loss: 4.6604e-05 - val_mape: 0.8179\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.2546e-04 - mape: 29211.3574 - val_loss: 2.0499e-04 - val_mape: 1.7862\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.4777e-04 - mape: 47799.9297 - val_loss: 0.0012 - val_mape: 4.5383\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.2299e-04 - mape: 13205.2021 - val_loss: 3.4187e-04 - val_mape: 2.5739\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.8308e-04 - mape: 19543.7344 - val_loss: 6.0380e-05 - val_mape: 0.9315\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.9537e-04 - mape: 55753.6133 - val_loss: 2.8595e-05 - val_mape: 0.6299\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.8609e-04 - mape: 61945.2305 - val_loss: 1.4648e-04 - val_mape: 1.4971\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1638e-04 - mape: 25319.3711 - val_loss: 7.9950e-05 - val_mape: 1.1499\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6892e-04 - mape: 35559.4453 - val_loss: 5.8128e-05 - val_mape: 0.9177\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3368e-04 - mape: 5780.6719 - val_loss: 1.5942e-04 - val_mape: 1.5402\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4414e-04 - mape: 3115.2236 - val_loss: 1.1246e-04 - val_mape: 1.4034\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.1115e-04 - mape: 58189.7461 - val_loss: 5.6335e-04 - val_mape: 2.7948\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7753e-04 - mape: 22056.9668 - val_loss: 9.2499e-05 - val_mape: 1.3013\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.8478e-04 - mape: 19414.1016 - val_loss: 2.4712e-04 - val_mape: 1.7524\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.3121e-04 - mape: 10.9055 - val_loss: 6.4225e-05 - val_mape: 1.0057\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.9178e-04 - mape: 11.6469 - val_loss: 4.7456e-05 - val_mape: 0.8511\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.6637e-04 - mape: 10.7439 - val_loss: 9.1458e-05 - val_mape: 1.2701\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.1503e-04 - mape: 11.0473 - val_loss: 2.1446e-04 - val_mape: 2.0540\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.4486e-04 - mape: 11.0466 - val_loss: 1.6225e-04 - val_mape: 1.8131\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.8158e-04 - mape: 13.6594 - val_loss: 6.5412e-04 - val_mape: 3.7966\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7076e-04 - mape: 15.9412 - val_loss: 1.8446e-04 - val_mape: 1.8167\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.4960e-04 - mape: 13.7459 - val_loss: 9.9235e-04 - val_mape: 4.6631\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.2915e-04 - mape: 12.1086 - val_loss: 6.3885e-04 - val_mape: 3.7290\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.4321e-04 - mape: 13.8446 - val_loss: 0.0011 - val_mape: 5.0537\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.8606e-04 - mape: 13.2560 - val_loss: 7.2465e-04 - val_mape: 3.9790\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.2636e-04 - mape: 14.7708 - val_loss: 0.0019 - val_mape: 6.5043\n",
      "--- 47/102 Training model for TMUS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - mape: 64872.5273 - val_loss: 2.7427e-04 - val_mape: 1.3566\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - mape: 111878.2891 - val_loss: 5.9892e-04 - val_mape: 2.6398\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.6905e-04 - mape: 32750.5371 - val_loss: 5.3605e-04 - val_mape: 2.3458\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.0807e-04 - mape: 9539.6582 - val_loss: 2.3328e-04 - val_mape: 1.2275\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.7437e-04 - mape: 775.4811 - val_loss: 5.2474e-04 - val_mape: 2.2667\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.7657e-04 - mape: 51869.8945 - val_loss: 5.3774e-04 - val_mape: 2.2446\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.1196e-04 - mape: 87537.5781 - val_loss: 6.1069e-04 - val_mape: 2.4164\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.0754e-04 - mape: 84064.7031 - val_loss: 5.1066e-04 - val_mape: 1.9715\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.8327e-04 - mape: 64976.3477 - val_loss: 9.0196e-04 - val_mape: 2.9880\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.6336e-04 - mape: 8237.4062 - val_loss: 9.5205e-04 - val_mape: 2.9493\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.8385e-04 - mape: 14113.3037 - val_loss: 9.2285e-04 - val_mape: 2.8700\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.7689e-04 - mape: 26061.5391 - val_loss: 0.0010 - val_mape: 3.0995\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.4331e-04 - mape: 82106.0234 - val_loss: 0.0012 - val_mape: 3.3389\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.6501e-04 - mape: 10568.9033 - val_loss: 0.0012 - val_mape: 3.3760\n",
      "--- 48/102 Training model for WDAY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.8447e-04 - mape: 10.7325 - val_loss: 6.2355e-04 - val_mape: 2.8912\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.6003e-04 - mape: 11.9986 - val_loss: 3.5007e-04 - val_mape: 1.9349\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.7509e-04 - mape: 11.6524 - val_loss: 8.7861e-04 - val_mape: 3.3836\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.0391e-04 - mape: 10.9479 - val_loss: 7.7624e-04 - val_mape: 3.1832\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.3287e-04 - mape: 12.2048 - val_loss: 9.0403e-04 - val_mape: 2.8132\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - mape: 15.3984 - val_loss: 0.0020 - val_mape: 4.4825\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mape: 14.2975 - val_loss: 0.0048 - val_mape: 7.7617\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mape: 17.0479 - val_loss: 0.0048 - val_mape: 7.5671\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3995e-04 - mape: 12.8538 - val_loss: 0.0018 - val_mape: 4.5867\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.7489e-04 - mape: 12.1911 - val_loss: 2.6676e-04 - val_mape: 1.8378\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.6896e-04 - mape: 13.1505 - val_loss: 5.8881e-04 - val_mape: 2.9211\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.8030e-04 - mape: 15.9586 - val_loss: 3.4345e-04 - val_mape: 2.0949\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3860e-04 - mape: 15.4575 - val_loss: 5.2809e-04 - val_mape: 2.3413\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.8595e-04 - mape: 16.1738 - val_loss: 6.5705e-04 - val_mape: 2.6046\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.9478e-04 - mape: 11.4363 - val_loss: 3.7757e-04 - val_mape: 2.0183\n",
      "Epoch 16/150\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.0960e-04 - mape: 13.1512"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.data.make_dataset import load_list, get_stock_data\n",
    "from src.models.StockModel import StockModel\n",
    "window_size = 20\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2024-09-01'\n",
    "feature_columns = ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
    "target = \"Open\"\n",
    "\n",
    "# Load symbols\n",
    "nasdaq_symbols = load_list(\"NASDAQ\")\n",
    "sp500_symbols = load_list(\"SP500\")\n",
    "\n",
    "# Test tickers, sp500 symbols not also in nasdaq\n",
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:100]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC']\n",
    "train_tickers = ['^IXIC'] + nasdaq_symbols\n",
    "#train_tickers = train_tickers[:51]\n",
    "\n",
    "# Download data\n",
    "combined_data = get_stock_data(train_tickers, \"1d\", start_date, end_date)\n",
    "combined_data.info()\n",
    "# Test data\n",
    "test_data = get_stock_data(test_tickers, \"1d\", start_date, end_date)\n",
    "\n",
    "layer_config = [(3,32),(3,64)]\n",
    "for i in layer_config:\n",
    "    print(f\"XXXXXXXXXXXXXXXX Running {i[0]} {i[1]} layers XXXXXXXXXXXXXXXXXXXX\")\n",
    "    # Create and train model\n",
    "    stock_model = StockModel(window_size=window_size, feature_columns=feature_columns, target_name=target, export=True)\n",
    "    \n",
    "    stock_model.train(combined_data, patience=10, epochs=150, graph=False, layers=i[0], units_per_layer=i[1])\n",
    "    metrics_dict, metrics_summary = stock_model.evaluate_many(test_data, graph=False)\n",
    "    print(metrics_dict)\n",
    "    print(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:5]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC', '^DJI']\n",
    "# Test data\n",
    "test_data = get_stock_data([\"^GSPC\", \"^DJI\"], \"1d\", start_date, end_date)\n",
    "\n",
    "metrics_dict, mean_metrics = stock_model.evaluate_many(test_data, graph=True)\n",
    "print(metrics_dict)\n",
    "print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
