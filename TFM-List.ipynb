{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 186328 entries, 2017-01-03 00:00:00-05:00 to 2024-08-30 00:00:00-04:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Open          186328 non-null  float64\n",
      " 1   High          186328 non-null  float64\n",
      " 2   Low           186328 non-null  float64\n",
      " 3   Close         186328 non-null  float64\n",
      " 4   Volume        186328 non-null  int64  \n",
      " 5   Dividends     186328 non-null  float64\n",
      " 6   Stock Splits  186328 non-null  float64\n",
      " 7   Ticker        186328 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 12.8+ MB\n",
      "XXXXXXXXXXXXXXXX Running 3 32 layers XXXXXXXXXXXXXXXXXXXX\n",
      "Initializing model:\n",
      " - Window size: 20\n",
      " - Features: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
      " - Target: Open\n",
      "--- Preparing ^IXIC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.47700000e+03  5.44091016e+03  8.72110000e+08  1.43798828e+01\n",
      " -1.06362988e+03  1.16226960e+01 -6.03732918e+02 -1.85963467e+02]\n",
      "Feature max [1.86474492e+04 1.86592500e+04 1.19326000e+10 8.98230469e+02\n",
      " 5.16000000e+02 1.00000000e+02 3.79729000e+02 1.68559430e+02]\n",
      "Target min [5425.62011719]\n",
      "Target max [18659.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRTX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.70500031e+01  7.52200012e+01  3.00500000e+05  9.29992676e-01\n",
      " -4.39099884e+01  6.98832867e+00 -1.61057278e+01 -6.35634960e+00]\n",
      "Feature max [5.05779999e+02 5.07040009e+02 1.74930000e+07 3.32000122e+01\n",
      " 2.96399994e+01 1.00000000e+02 1.72224200e+01 7.01903411e+00]\n",
      "Target min [74.43000031]\n",
      "Target max [507.04000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PYPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93100014e+01  3.94000015e+01  1.68000000e+06  2.79998779e-01\n",
      " -3.59100037e+01  5.36242303e+00 -1.82619484e+01 -6.83508729e+00]\n",
      "Feature max [3.08529999e+02 3.09660004e+02 1.36264000e+08 2.25299988e+01\n",
      " 1.48899994e+01 1.00000000e+02 1.63896973e+01 4.70789452e+00]\n",
      "Target min [39.40000153]\n",
      "Target max [309.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GILD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.83768806e+01  4.84647914e+01  1.93100000e+06  3.33687064e-01\n",
      " -6.63972958e+00  5.76449552e+00 -2.31350265e+00 -8.99640093e-01]\n",
      "Feature max [8.53581619e+01 8.44682978e+01 9.43485000e+07 8.04050792e+00\n",
      " 7.22805871e+00 1.00000000e+02 4.20840101e+00 1.25684743e+00]\n",
      "Target min [48.46479141]\n",
      "Target max [84.46829781]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.10076256e+01  1.08333313e+01  2.58690000e+06  1.03459220e-01\n",
      " -2.80620500e+00  6.42043171e+00 -2.09796533e+00 -6.88387327e-01]\n",
      "Feature max [3.81064873e+01 3.81660578e+01 2.95518300e+08 2.47469052e+00\n",
      " 2.03002402e+00 1.00000000e+02 1.17294776e+00 5.41764642e-01]\n",
      "Target min [10.83333126]\n",
      "Target max [38.16605779]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing IDXX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.15949997e+02  1.15989998e+02  6.95000000e+04  1.01998901e+00\n",
      " -5.39599915e+01  0.00000000e+00 -4.51944855e+01 -1.18420530e+01]\n",
      "Feature max [7.05760010e+02 6.98869995e+02 2.06065000e+07 4.94200134e+01\n",
      " 2.44899902e+01 9.87477702e+01 2.80133056e+01 9.19398448e+00]\n",
      "Target min [115.98999786]\n",
      "Target max [698.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.72258148e+01  4.72942329e+01  4.40100000e+05  2.32199940e-01\n",
      " -6.70203769e+00  0.00000000e+00 -5.58792261e+00 -1.85080517e+00]\n",
      "Feature max [1.00876343e+02 1.03304346e+02 2.24557000e+07 1.05535592e+01\n",
      " 3.30012562e+00 1.00000000e+02 2.91608734e+00 1.39528294e+00]\n",
      "Target min [47.29423289]\n",
      "Target max [103.30434621]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TEAM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.47199993e+01  2.47299995e+01  2.10900000e+05  2.16999054e-01\n",
      " -4.31699982e+01  1.07833899e+01 -2.66488051e+01 -8.97255197e+00]\n",
      "Feature max [4.58130005e+02 4.55200012e+02 1.74562000e+07 4.22299805e+01\n",
      " 4.32099915e+01 1.00000000e+02 2.40637139e+01 8.94966359e+00]\n",
      "Target min [24.31999969]\n",
      "Target max [455.20001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PANW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.60033340e+01  3.61399994e+01  1.02260000e+06  3.56666565e-01\n",
      " -9.08899841e+01  3.81140920e+00 -1.38470391e+01 -1.22788064e+01]\n",
      "Feature max [3.76899994e+02 3.75450012e+02 6.53592000e+07 2.73699951e+01\n",
      " 2.68099976e+01 1.00000000e+02 1.51691964e+01 4.87990591e+00]\n",
      "Target min [36.13999939]\n",
      "Target max [375.45001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AVGO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.37303333e+01  1.37248155e+01  4.12300000e+06  1.24250219e-01\n",
      " -1.42100067e+01  0.00000000e+00 -5.06872189e+00 -3.00550723e+00]\n",
      "Feature max [1.82308105e+02 1.83376725e+02 4.35083000e+08 1.69199982e+01\n",
      " 2.13810994e+01 9.28312615e+01 1.05782566e+01 4.55284581e+00]\n",
      "Target min [13.72481551]\n",
      "Target max [183.37672469]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CEG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.08016396e+01  3.98784499e+01  2.35000000e+04  6.26233760e-01\n",
      " -1.08198405e+01  1.27016955e+01 -1.06308757e+01 -3.92755151e+00]\n",
      "Feature max [2.30487686e+02 2.31952715e+02 2.38609000e+07 2.15543379e+01\n",
      " 2.45442808e+01 1.00000000e+02 1.44754876e+01 4.38796603e+00]\n",
      "Target min [37.00563649]\n",
      "Target max [231.9527148]\n",
      "X_train shape: (637, 20, 8)\n",
      "Train_dates: 2022-01-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MSFT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.65738869e+01  5.64739966e+01  7.42560000e+06  2.90591337e-01\n",
      " -1.92852005e+01  0.00000000e+00 -1.18035322e+01 -4.62579684e+00]\n",
      "Feature max [4.66718781e+02 4.66159796e+02 1.11242100e+08 2.43750327e+01\n",
      " 2.10308153e+01 9.87202426e+01 1.16126194e+01 3.05457811e+00]\n",
      "Target min [56.47399663]\n",
      "Target max [466.15979612]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EXC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.82024403e+01  1.85263402e+01  2.00850500e+06  1.22239479e-01\n",
      " -1.93681352e+00  5.27394820e+00 -2.56103522e+00 -9.27310629e-01]\n",
      "Feature max [4.59507675e+01 4.58593246e+01 3.88453000e+07 4.14685407e+00\n",
      " 1.20619631e+00 1.00000000e+02 1.62739156e+00 5.65170222e-01]\n",
      "Target min [18.52634024]\n",
      "Target max [45.8593246]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DXCM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.11149998e+01  1.10325003e+01  8.61200000e+05  1.64999962e-01\n",
      " -4.18499985e+01  4.43708879e+00 -1.21858259e+01 -5.03116733e+00]\n",
      "Feature max [1.62815002e+02 1.64257507e+02 1.23168400e+08 1.88925018e+01\n",
      " 1.24700012e+01 1.00000000e+02 8.60785647e+00 2.40813081e+00]\n",
      "Target min [11.03250027]\n",
      "Target max [164.25750732]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FAST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65418377e+01  1.66370331e+01  7.04500000e+05  1.46829911e-01\n",
      " -3.17297661e+00  2.73467744e+00 -1.96586913e+00 -1.08293952e+00]\n",
      "Feature max [7.75266724e+01 7.77145119e+01 5.26096000e+07 4.66000366e+00\n",
      " 3.55978900e+00 1.00000000e+02 1.87048163e+00 8.56669815e-01]\n",
      "Target min [16.63703311]\n",
      "Target max [77.71451195]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ABNB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.24899979e+01  8.29700012e+01  1.72560000e+06  1.01499939e+00\n",
      " -1.80299988e+01  0.00000000e+00 -1.29513658e+01 -4.57280582e+00]\n",
      "Feature max [2.16839996e+02 2.16240005e+02 7.47864000e+07 3.05000000e+01\n",
      " 1.21199951e+01 9.29350181e+01 1.31150691e+01 3.98198040e+00]\n",
      "Target min [82.97000122]\n",
      "Target max [216.24000549]\n",
      "X_train shape: (915, 20, 8)\n",
      "Train_dates: 2020-12-11 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SNPS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.95699997e+01  5.93699989e+01  2.00200000e+05  2.60002136e-01\n",
      " -3.66699829e+01  7.61484664e+00 -2.46719247e+01 -8.22743530e+00]\n",
      "Feature max [6.21299988e+02 6.22929993e+02 3.02946000e+07 5.02700195e+01\n",
      " 4.64199829e+01 1.00000000e+02 2.12557667e+01 8.46134558e+00]\n",
      "Target min [59.27000046]\n",
      "Target max [622.92999268]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BIIB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [187.53999329 190.55999756   0.           0.         -98.07998657\n",
      "   4.79436191 -25.57434546 -11.64517675]\n",
      "Feature max [4.14709991e+02 4.23329987e+02 2.18431000e+07 1.82549988e+02\n",
      " 8.64900055e+01 1.00000000e+02 3.49582846e+01 1.62224245e+01]\n",
      "Target min [190.55999756]\n",
      "Target max [423.32998657]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing REGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.73459991e+02  2.74350006e+02  1.71600000e+05  2.76998901e+00\n",
      " -4.76300049e+01  6.11531109e+00 -2.90962700e+01 -1.14012185e+01]\n",
      "Feature max [1.20176001e+03 1.20471997e+03 7.86950000e+06 8.12899780e+01\n",
      " 9.05499878e+01 1.00000000e+02 3.48632110e+01 1.33649620e+01]\n",
      "Target min [274.3500061]\n",
      "Target max [1204.7199707]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.40612335e+01  7.38682430e+01  1.45000000e+05  3.47388791e-01\n",
      " -1.39151345e+01  7.46558779e+00 -1.02972318e+01 -4.01614540e+00]\n",
      "Feature max [2.85989990e+02 2.85000000e+02 4.24820000e+06 1.72982830e+01\n",
      " 1.09380201e+01 1.00000000e+02 7.65714256e+00 3.71764271e+00]\n",
      "Target min [73.86824302]\n",
      "Target max [285.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TSLA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.19313326e+01  1.20733328e+01  2.94018000e+07  1.66667938e-01\n",
      " -2.41000061e+01  6.91932630e+00 -2.52713333e+01 -7.67848148e+00]\n",
      "Feature max [4.09970001e+02 4.11470001e+02 9.14082000e+08 5.43266602e+01\n",
      " 3.25100098e+01 1.00000000e+02 3.80679297e+01 1.02961745e+01]\n",
      "Target min [12.07333279]\n",
      "Target max [411.47000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NVDA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35561490e+00  2.36844192e+00  9.78840000e+07  3.05890876e-02\n",
      " -1.52099991e+01  8.18789238e+00 -5.16786769e+00 -2.56494372e+00]\n",
      "Feature max [1.35580002e+02 1.39800003e+02 3.69292800e+09 1.33500061e+01\n",
      " 9.16999817e+00 1.00000000e+02 9.77617754e+00 2.89363431e+00]\n",
      "Target min [2.36844192]\n",
      "Target max [139.80000305]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CPRT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95749998e+00  6.97499990e+00  1.16560000e+06  4.75001335e-02\n",
      " -2.40999985e+00  1.07028555e+01 -2.08288713e+00 -5.95224464e-01]\n",
      "Feature max [5.80699997e+01 5.81300011e+01 2.13690400e+08 3.43000031e+00\n",
      " 1.91999817e+00 1.00000000e+02 1.68053820e+00 5.29970520e-01]\n",
      "Target min [6.94750023]\n",
      "Target max [58.13000107]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ORLY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.72850006e+02  1.72839996e+02  9.76000000e+04  1.75000000e+00\n",
      " -7.26999512e+01  9.93704967e+00 -3.18757122e+01 -1.55376421e+01]\n",
      "Feature max [1.16753003e+03 1.16473999e+03 1.28304000e+07 6.14700928e+01\n",
      " 3.95399780e+01 1.00000000e+02 2.94044788e+01 1.46112531e+01]\n",
      "Target min [172.83999634]\n",
      "Target max [1164.73999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSGP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.90799999e+01  1.86439991e+01  4.31000000e+05  1.32999420e-01\n",
      " -1.35200005e+01  3.82196899e+00 -3.91839760e+00 -1.70338203e+00]\n",
      "Feature max [9.97399979e+01 9.96600037e+01 5.40349000e+07 1.53570023e+01\n",
      " 2.22259979e+01 1.00000000e+02 3.78952594e+00 1.64810768e+00]\n",
      "Target min [18.6439991]\n",
      "Target max [99.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PDD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.71499996e+01  1.72000008e+01  1.21070000e+06  3.10001373e-01\n",
      " -2.96699982e+01  0.00000000e+00 -1.20781712e+01 -6.25067404e+00]\n",
      "Feature max [2.02820007e+02 2.11600006e+02 1.03174600e+08 2.12799988e+01\n",
      " 2.67000046e+01 9.22446129e+01 1.43527401e+01 4.73466591e+00]\n",
      "Target min [17.20000076]\n",
      "Target max [211.6000061]\n",
      "X_train shape: (1514, 20, 8)\n",
      "Train_dates: 2018-07-27 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing HON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.46234436e+01  9.52324000e+01  6.25500000e+05  4.19023023e-01\n",
      " -1.95059386e+01  4.75223206e+00 -1.40929690e+01 -4.45800894e+00]\n",
      "Feature max [2.19502518e+02 2.19940311e+02 2.82371000e+07 2.09818764e+01\n",
      " 1.90409619e+01 1.00000000e+02 8.86860848e+00 3.23137150e+00]\n",
      "Target min [95.23239999]\n",
      "Target max [219.940311]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.14207764e+01  6.16446899e+01  4.66400000e+05  4.04764943e-01\n",
      " -1.59855034e+01  0.00000000e+00 -6.96255702e+00 -3.47483258e+00]\n",
      "Feature max [2.42376740e+02 2.39537898e+02 1.91564000e+07 1.54971600e+01\n",
      " 1.14345496e+01 9.47163396e+01 9.37402072e+00 2.80709341e+00]\n",
      "Target min [61.6446899]\n",
      "Target max [239.53789776]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.30817795e+01  7.35512567e+01  5.83900000e+05  5.47719799e-01\n",
      " -1.30866329e+01  5.85091260e+00 -5.68716405e+00 -2.63117400e+00]\n",
      "Feature max [1.51820007e+02 1.50807724e+02 3.87045000e+07 1.23726575e+01\n",
      " 1.06121299e+01 1.00000000e+02 4.99350068e+00 2.11381207e+00]\n",
      "Target min [73.55125665]\n",
      "Target max [150.80772389]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.64580784e+01  1.71472504e+01  1.14310000e+06  1.73414604e-01\n",
      " -9.42169016e+00  0.00000000e+00 -3.04021958e+00 -1.40459935e+00]\n",
      "Feature max [6.87902832e+01 6.75091239e+01 1.35204800e+08 4.21353693e+00\n",
      " 3.35945352e+00 9.56385384e+01 1.17085586e+00 5.30557914e-01]\n",
      "Target min [17.14725043]\n",
      "Target max [67.50912394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WBD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.71000004e+00  6.67000008e+00  7.96300000e+05  1.29999638e-01\n",
      " -4.63999939e+00  7.36432776e+00 -5.62270475e+00 -4.52551421e+00]\n",
      "Feature max [7.72699966e+01 7.79800034e+01 1.58082500e+08 2.36100006e+01\n",
      " 3.59000015e+00 1.00000000e+02 7.78521295e+00 1.10191292e+00]\n",
      "Target min [6.67000008]\n",
      "Target max [77.98000336]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.77167328e+02  1.76918230e+02  1.00700000e+05  1.05556092e+00\n",
      " -7.16818629e+01  1.01358772e+01 -2.43843479e+01 -7.21921458e+00]\n",
      "Feature max [5.76549988e+02 5.77500000e+02 8.03490000e+06 6.23608511e+01\n",
      " 3.51599731e+01 1.00000000e+02 1.65133395e+01 6.23603536e+00]\n",
      "Target min [176.71789525]\n",
      "Target max [577.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15072536  8.44775147  0.          0.         -2.64121747  0.\n",
      " -2.42761183 -0.84240961]\n",
      "Feature max [3.84843826e+01 3.84346839e+01 7.90905000e+07 3.35121803e+00\n",
      " 2.26195987e+00 9.66591338e+01 2.24860550e+00 6.65253146e-01]\n",
      "Target min [8.44775147]\n",
      "Target max [38.43468386]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing COST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.34840027e+02  1.34848979e+02  5.43600000e+05  6.44244141e-01\n",
      " -2.94507165e+01  7.85632611e+00 -3.22091435e+01 -9.48258025e+00]\n",
      "Feature max [9.08900024e+02 9.10960022e+02 2.42330000e+07 4.41770966e+01\n",
      " 1.44715964e+01 1.00000000e+02 2.40226275e+01 6.93894982e+00]\n",
      "Target min [134.84897936]\n",
      "Target max [910.96002197]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.09898224e+01  2.08327117e+01  7.55800000e+05  1.13624069e-01\n",
      " -4.94519305e+00  1.11788406e+01 -2.60963640e+00 -8.58607194e-01]\n",
      "Feature max [8.76200027e+01 8.73300018e+01 6.55402000e+07 7.22391984e+00\n",
      " 4.14095185e+00 1.00000000e+02 2.45854722e+00 7.89947526e-01]\n",
      "Target min [20.83271174]\n",
      "Target max [87.33000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LRCX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.58611450e+01  9.56820940e+01  3.00600000e+05  6.44566123e-01\n",
      " -6.64899902e+01  8.02008287e+00 -6.76982729e+01 -2.23238752e+01]\n",
      "Feature max [1.12730005e+03 1.12977002e+03 1.34214000e+07 7.38499756e+01\n",
      " 3.86400146e+01 1.00000000e+02 3.73546175e+01 1.44478835e+01]\n",
      "Target min [95.50305848]\n",
      "Target max [1129.77001953]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MELI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65434570e+02  1.61862890e+02  1.09000000e+05  1.65614514e+00\n",
      " -1.47979980e+02  6.42065563e+00 -1.26762239e+02 -4.86753050e+01]\n",
      "Feature max [2.06165991e+03 2.03525000e+03 4.29950000e+06 1.80000000e+02\n",
      " 1.14010010e+02 1.00000000e+02 9.65798543e+01 4.12565588e+01]\n",
      "Target min [158.54062541]\n",
      "Target max [2035.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.67368317e+01  4.67459853e+01  1.82100000e+05  3.48899275e-01\n",
      " -2.61500847e+01  1.10566618e+01 -1.16426989e+01 -2.77844168e+00]\n",
      "Feature max [2.56499237e+02 2.59970663e+02 2.45494000e+07 1.57643673e+01\n",
      " 1.15215366e+01 1.00000000e+02 6.29487466e+00 2.94088429e+00]\n",
      "Target min [46.74598533]\n",
      "Target max [259.97066279]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FANG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.26427412e+01  1.29027437e+01  2.62100000e+05  7.69125709e-01\n",
      " -1.58440575e+01  1.03142457e+00 -1.19967649e+01 -3.84871261e+00]\n",
      "Feature max [2.08427399e+02 2.08555865e+02 3.30497000e+07 1.22028993e+01\n",
      " 7.94709301e+00 1.00000000e+02 7.18674563e+00 2.89178249e+00]\n",
      "Target min [12.90274369]\n",
      "Target max [208.55586459]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ZS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.49500008e+01  2.50000000e+01  1.97200000e+05  3.79999161e-01\n",
      " -3.88899994e+01  0.00000000e+00 -2.36812080e+01 -8.89085502e+00]\n",
      "Feature max [3.68779999e+02 3.72500000e+02 2.68458000e+07 5.90399780e+01\n",
      " 2.63500061e+01 9.43483988e+01 1.81146072e+01 6.76156951e+00]\n",
      "Target min [25.]\n",
      "Target max [372.5]\n",
      "X_train shape: (1605, 20, 8)\n",
      "Train_dates: 2018-03-19 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADBE data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.04139999e+02  1.03739998e+02  5.89200000e+05  6.49993896e-01\n",
      " -7.08099976e+01  1.41851355e+00 -3.26176172e+01 -1.20971259e+01]\n",
      "Feature max [6.88369995e+02 6.96280029e+02 2.78402000e+07 5.77900391e+01\n",
      " 7.15100098e+01 1.00000000e+02 3.08100807e+01 9.11981859e+00]\n",
      "Target min [103.43000031]\n",
      "Target max [696.2800293]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93002777e+01  3.92593243e+01  6.93600000e+06  1.63815054e-01\n",
      " -1.10299988e+01  1.33774083e+01 -5.19036880e+00 -2.41195015e+00]\n",
      "Feature max [1.92660004e+02 1.91750000e+02 1.24140000e+08 9.33999634e+00\n",
      " 1.80194956e+01 1.00000000e+02 5.21262163e+00 1.68897131e+00]\n",
      "Target min [38.8962372]\n",
      "Target max [191.75]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMAT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.72328186e+01  2.75991753e+01  1.40920000e+06  2.48054618e-01\n",
      " -1.45720706e+01  1.10477215e+01 -1.30488603e+01 -4.80425105e+00]\n",
      "Feature max [2.54482300e+02 2.55081164e+02 5.25842000e+07 1.67279368e+01\n",
      " 1.42822510e+01 1.00000000e+02 1.06164149e+01 3.45275434e+00]\n",
      "Target min [27.59917534]\n",
      "Target max [255.0811642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.12595596e+01  8.12424900e+01  3.50200000e+05  3.94597419e-01\n",
      " -1.50322675e+01  3.70819327e+00 -1.35625546e+01 -3.90767252e+00]\n",
      "Feature max [2.75910004e+02 2.75790009e+02 2.98376000e+07 1.78119307e+01\n",
      " 1.03888203e+01 1.00000000e+02 1.01973384e+01 2.87688119e+00]\n",
      "Target min [81.24248999]\n",
      "Target max [275.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SBUX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.25571556e+01  4.21538477e+01  1.84780000e+06  2.41612795e-01\n",
      " -1.24990496e+01  3.06340275e+00 -6.61673832e+00 -1.77160410e+00]\n",
      "Feature max [1.17301453e+02 1.17320081e+02 1.57215500e+08 8.91207916e+00\n",
      " 1.39059501e+01 1.00000000e+02 5.32951402e+00 2.47897411e+00]\n",
      "Target min [42.15384768]\n",
      "Target max [117.32008083]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTWO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.93600006e+01  4.94000015e+01  2.11600000e+05  3.89999390e-01\n",
      " -1.71000061e+01  5.25756554e+00 -1.00961129e+01 -3.59837456e+00]\n",
      "Feature max [2.13339996e+02 2.10479996e+02 2.53857000e+07 1.86999969e+01\n",
      " 1.62300034e+01 1.00000000e+02 8.60457497e+00 3.04146889e+00]\n",
      "Target min [49.34999847]\n",
      "Target max [210.47999573]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TMUS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.45139236e+01  5.45139293e+01  4.70100000e+05  2.26488207e-01\n",
      " -9.75855268e+00  9.14551088e+00 -4.12801689e+00 -2.00070149e+00]\n",
      "Feature max [2.03367172e+02 2.04613114e+02 6.69031000e+07 1.24074325e+01\n",
      " 1.02607535e+01 1.00000000e+02 5.13087043e+00 2.60923839e+00]\n",
      "Target min [54.51392929]\n",
      "Target max [204.61311436]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WDAY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.13600006e+01  6.86699982e+01  3.69100000e+05  7.19993591e-01\n",
      " -2.87099915e+01  9.22365714e+00 -1.61351526e+01 -5.44748712e+00]\n",
      "Feature max [3.07209991e+02 3.09100006e+02 1.56112000e+07 2.13899994e+01\n",
      " 3.39099884e+01 1.00000000e+02 1.38299273e+01 6.22001392e+00]\n",
      "Target min [66.75]\n",
      "Target max [309.1000061]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CRWD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.30099983e+01  3.39300003e+01  8.04900000e+05  1.25000000e+00\n",
      " -4.85399780e+01  5.38771656e+00 -3.82154109e+01 -1.52669393e+01]\n",
      "Feature max [3.92149994e+02 3.92510010e+02 5.40774000e+07 4.09899902e+01\n",
      " 6.24899902e+01 1.00000000e+02 1.92436948e+01 8.51986054e+00]\n",
      "Target min [33.93000031]\n",
      "Target max [392.51000977]\n",
      "X_train shape: (1294, 20, 8)\n",
      "Train_dates: 2019-06-13 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DDOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.80400009e+01  2.78999996e+01  5.74800000e+05  7.30003357e-01\n",
      " -2.19200058e+01  0.00000000e+00 -1.14620833e+01 -4.12330397e+00]\n",
      "Feature max [1.96559998e+02 1.97695999e+02 2.91348000e+07 2.36900024e+01\n",
      " 2.69400024e+01 9.94039849e+01 1.14713512e+01 4.87120929e+00]\n",
      "Target min [27.89999962]\n",
      "Target max [197.69599915]\n",
      "X_train shape: (1225, 20, 8)\n",
      "Train_dates: 2019-09-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PCAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.86600723e+01  2.83693925e+01  4.95450000e+05  1.76137070e-01\n",
      " -1.04065623e+01  7.26960956e+00 -3.26233711e+00 -1.44177861e+00]\n",
      "Feature max [1.23713150e+02 1.24249916e+02 1.21321500e+07 7.01745891e+00\n",
      " 3.03884653e+00 1.00000000e+02 4.25862741e+00 1.04586866e+00]\n",
      "Target min [28.36939252]\n",
      "Target max [124.24991579]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRNA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.22600002e+01  1.22600002e+01  2.72800000e+05  2.99999237e-01\n",
      " -5.01100159e+01  6.23065240e+00 -3.31765627e+01 -1.53366601e+01]\n",
      "Feature max [4.84470001e+02 4.85500000e+02 1.25130400e+08 8.40969849e+01\n",
      " 4.59499817e+01 1.00000000e+02 5.26756442e+01 1.60440938e+01]\n",
      "Target min [12.26000023]\n",
      "Target max [485.5]\n",
      "X_train shape: (1421, 20, 8)\n",
      "Train_dates: 2018-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing META data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.87276688e+01  8.98952675e+01  5.46750000e+06  5.18937895e-01\n",
      " -7.81893309e+01  9.76807065e+00 -2.89867461e+01 -9.55160496e+00]\n",
      "Feature max [5.39909973e+02 5.42349976e+02 2.32316600e+08 3.50699768e+01\n",
      " 6.46870787e+01 1.00000000e+02 2.92185320e+01 7.48696458e+00]\n",
      "Target min [89.89526752]\n",
      "Target max [542.34997559]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MNST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.07199993e+01  2.07049999e+01  9.22800000e+05  1.65000916e-01\n",
      " -5.64999771e+00  7.54052007e+00 -2.06519425e+00 -6.53749929e-01]\n",
      "Feature max [6.08499985e+01 6.10000000e+01 3.67095000e+07 4.27999878e+00\n",
      " 4.58000183e+00 1.00000000e+02 1.81693996e+00 9.25280916e-01]\n",
      "Target min [20.70499992]\n",
      "Target max [61.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.52999973e+00  9.07999992e+00  1.10358000e+07  1.19999886e-01\n",
      " -1.03399963e+01  0.00000000e+00 -9.13773987e+00 -3.97167693e+00]\n",
      "Feature max [2.11380005e+02 2.13410004e+02 3.25058400e+08 2.16999969e+01\n",
      " 1.31100006e+01 9.59459396e+01 1.14017298e+01 3.51085324e+00]\n",
      "Target min [9.07999992]\n",
      "Target max [213.41000366]\n",
      "X_train shape: (1906, 20, 8)\n",
      "Train_dates: 2017-01-05 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing QCOM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.10863152e+01  4.13346323e+01  2.12020000e+06  2.21164957e-01\n",
      " -1.19638878e+01  7.39900392e+00 -1.13783823e+01 -3.46840781e+00]\n",
      "Feature max [2.25922470e+02 2.25653869e+02 1.56019300e+08 1.56075679e+01\n",
      " 1.67030311e+01 1.00000000e+02 1.22270518e+01 3.97922183e+00]\n",
      "Target min [41.33463229]\n",
      "Target max [225.65386916]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CCEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55083256e+01  2.55731092e+01  2.18600000e+05  1.48332728e-01\n",
      " -5.48859656e+00  7.67621212e+00 -5.38139235e+00 -1.98555605e+00]\n",
      "Feature max [8.04899979e+01 8.02600021e+01 3.00719000e+07 5.47105868e+00\n",
      " 5.02390864e+00 1.00000000e+02 2.10718557e+00 1.58574567e+00]\n",
      "Target min [25.23299887]\n",
      "Target max [80.26000214]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PAYX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.40656853e+01  4.43662807e+01  4.22500000e+05  2.53874792e-01\n",
      " -6.98217401e+00  6.37100472e+00 -7.06664280e+00 -2.03882520e+00]\n",
      "Feature max [1.31301468e+02 1.30869995e+02 1.68049000e+07 1.40609675e+01\n",
      " 5.64423284e+00 1.00000000e+02 4.66590849e+00 1.34585577e+00]\n",
      "Target min [44.36628073]\n",
      "Target max [130.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CHTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.54610001e+02  2.38960007e+02  2.42700000e+05  1.79000854e+00\n",
      " -4.96099854e+01  1.00045832e+01 -3.55786821e+01 -1.27762515e+01]\n",
      "Feature max [8.21010010e+02 8.23080017e+02 1.55224000e+07 4.71099854e+01\n",
      " 4.25099792e+01 1.00000000e+02 2.18537876e+01 9.81964050e+00]\n",
      "Target min [238.96000671]\n",
      "Target max [823.08001709]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTAS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.05113617e+02  1.05187604e+02  1.12200000e+05  5.64083578e-01\n",
      " -4.39267993e+01  1.00213959e+01 -2.82557867e+01 -9.58054398e+00]\n",
      "Feature max [8.05119995e+02 8.04500000e+02 2.72700000e+06 4.61448665e+01\n",
      " 4.98478169e+01 1.00000000e+02 1.69135623e+01 6.24244921e+00]\n",
      "Target min [105.18760444]\n",
      "Target max [804.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GEHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.58701439e+01  5.28771038e+01  2.22000000e+04  4.48496557e-01\n",
      " -7.89708004e+00  0.00000000e+00 -2.75575511e+00 -9.40395579e-01]\n",
      "Feature max [9.38021851e+01 9.37422203e+01 3.33385000e+07 1.07550019e+01\n",
      " 3.51607095e+00 8.71251436e+01 4.22888858e+00 9.98581046e-01]\n",
      "Target min [52.87710382]\n",
      "Target max [93.74222026]\n",
      "X_train shape: (408, 20, 8)\n",
      "Train_dates: 2022-12-16 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRVL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.31523399e+01  1.32089134e+01  1.60940000e+06  9.52960185e-02\n",
      " -5.81999969e+00  1.28620113e+01 -4.44552211e+00 -2.03029592e+00]\n",
      "Feature max [9.03993759e+01 9.02215677e+01 9.43073000e+07 9.40218170e+00\n",
      " 1.46796512e+01 1.00000000e+02 5.29263949e+00 2.28143680e+00]\n",
      "Target min [13.13348662]\n",
      "Target max [90.2215677]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NXPI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.02686462e+01  6.05207032e+01  4.80500000e+05  1.27887285e-01\n",
      " -2.30199890e+01  8.16553100e+00 -1.30447493e+01 -4.12573877e+00]\n",
      "Feature max [2.90779999e+02 2.85390015e+02 5.31022000e+07 2.01099854e+01\n",
      " 1.25949051e+01 1.00000000e+02 9.68135969e+00 3.81693437e+00]\n",
      "Target min [60.5207032]\n",
      "Target max [285.39001465]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.71000004e+00  2.69000006e+00  6.31000000e+05  5.90000153e-02\n",
      " -1.51449966e+01  1.02722976e+01 -7.73271712e+00 -2.83294696e+00]\n",
      "Feature max [1.11639999e+02 1.11089996e+02 1.27624000e+08 1.49599991e+01\n",
      " 1.57500000e+01 1.00000000e+02 8.65914541e+00 3.44913976e+00]\n",
      "Target min [2.69000006]\n",
      "Target max [111.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKNG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.14665942e+03  1.16132802e+03  7.94000000e+04  6.03070832e+00\n",
      " -3.52589844e+02  6.38678134e+00 -1.75862492e+02 -7.18094242e+01]\n",
      "Feature max [4.11908984e+03 4.11700000e+03 3.32510000e+06 2.15700240e+02\n",
      " 3.13563991e+02 1.00000000e+02 1.22086361e+02 4.95826730e+01]\n",
      "Target min [1161.32802486]\n",
      "Target max [4117.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KDP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.17389641e+01  1.13540100e+01  3.12600000e+05  5.19934972e-02\n",
      " -2.16673267e+00  5.47438798e+00 -1.84060807e+00 -7.08470134e-01]\n",
      "Feature max [3.81241341e+01 3.81621768e+01 1.43326600e+08 4.27929837e+00\n",
      " 4.32504476e+00 1.00000000e+02 1.24850194e+00 5.03789297e-01]\n",
      "Target min [11.35401002]\n",
      "Target max [38.16217682]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ODFL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.60743732e+01  2.62781804e+01  2.93800000e+05  2.29686469e-01\n",
      " -1.23647591e+01  9.60325711e+00 -9.47054031e+00 -4.03113182e+00]\n",
      "Feature max [2.24051163e+02 2.25128094e+02 4.64676000e+07 2.78705293e+01\n",
      " 9.12876452e+00 1.00000000e+02 9.61462650e+00 3.12346527e+00]\n",
      "Target min [26.27818039]\n",
      "Target max [225.12809388]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ISRG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.99433365e+01  7.00211105e+01  4.89900000e+05  4.15557861e-01\n",
      " -1.95700073e+01  0.00000000e+00 -2.11512520e+01 -7.04575693e+00]\n",
      "Feature max [4.92630005e+02 4.92619995e+02 1.12668000e+07 2.48000031e+01\n",
      " 3.32899780e+01 9.95441593e+01 1.42319395e+01 6.40623327e+00]\n",
      "Target min [70.02111053]\n",
      "Target max [492.61999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TXN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.90602226e+01  5.90278217e+01  1.04440000e+06  2.77122064e-01\n",
      " -1.04008110e+01  0.00000000e+00 -6.09191238e+00 -2.17086585e+00]\n",
      "Feature max [2.14339996e+02 2.12580002e+02 2.51217000e+07 1.31599884e+01\n",
      " 1.25867588e+01 9.74574577e+01 7.69273127e+00 2.34828422e+00]\n",
      "Target min [59.0278217]\n",
      "Target max [212.58000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ARM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.78699989e+01  4.72200012e+01  2.26890000e+06  1.22000122e+00\n",
      " -2.08500061e+01  0.00000000e+00 -1.27820527e+01 -6.74110994e+00]\n",
      "Feature max [1.86460007e+02 1.86839996e+02 1.11349700e+08 4.53099976e+01\n",
      " 1.74000015e+01 9.62229824e+01 1.65008639e+01 6.88049836e+00]\n",
      "Target min [47.22000122]\n",
      "Target max [186.83999634]\n",
      "X_train shape: (222, 20, 8)\n",
      "Train_dates: 2023-09-15 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.95189896e+01  4.98084665e+01  5.35700000e+05  4.09831331e-01\n",
      " -2.21022887e+01  7.32260869e+00 -1.31744930e+01 -4.43503087e+00]\n",
      "Feature max [1.55210007e+02 1.63559998e+02 3.45755000e+07 1.30095107e+01\n",
      " 1.65455567e+01 1.00000000e+02 7.20230570e+00 2.52539377e+00]\n",
      "Target min [49.80846647]\n",
      "Target max [163.55999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDLZ data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.26199188e+01  3.25591459e+01  1.83380000e+06  1.95484721e-01\n",
      " -4.06838765e+00  0.00000000e+00 -3.04621880e+00 -1.02893296e+00]\n",
      "Feature max [7.60628128e+01 7.61016380e+01 2.91974000e+07 4.50139804e+00\n",
      " 3.43486217e+00 9.24410761e+01 2.31448955e+00 8.04107787e-01]\n",
      "Target min [32.55914595]\n",
      "Target max [76.10163795]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LIN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01270172e+02  1.01313936e+02  2.76400000e+05  5.60332175e-01\n",
      " -2.60358760e+01  0.00000000e+00 -1.35822622e+01 -4.32008793e+00]\n",
      "Feature max [4.76847687e+02 4.73647108e+02 5.73756000e+07 2.50221201e+01\n",
      " 1.73250947e+01 9.79872343e+01 1.39092182e+01 4.41989817e+00]\n",
      "Target min [101.31393592]\n",
      "Target max [473.64710757]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSCO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.37586002e+01  2.37744560e+01  5.72050000e+06  1.35897120e-01\n",
      " -5.72839392e+00  0.00000000e+00 -2.51348577e+00 -7.94818190e-01]\n",
      "Feature max [5.87176781e+01 5.87911180e+01 1.06928300e+08 3.98683323e+00\n",
      " 3.31000137e+00 9.41030476e+01 1.74181733e+00 6.52277731e-01]\n",
      "Target min [23.77445599]\n",
      "Target max [58.79111801]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.08447884e+02  1.05853972e+02  4.17100000e+05  4.74368466e-01\n",
      " -4.12029187e+01  4.31389479e+00 -2.91569435e+01 -1.00687249e+01]\n",
      "Feature max [6.82518799e+02 7.03358031e+02 6.66440000e+06 4.95999756e+01\n",
      " 8.54105820e+01 1.00000000e+02 2.48427016e+01 9.59888974e+00]\n",
      "Target min [105.85397237]\n",
      "Target max [703.3580307]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.01410751e+01  8.03660597e+01  8.83300000e+05  2.61090847e-01\n",
      " -1.13062698e+01  5.70037116e+00 -6.88044670e+00 -2.29319743e+00]\n",
      "Feature max [1.88991531e+02 1.89425159e+02 2.75597000e+07 1.50898149e+01\n",
      " 5.84069218e+00 1.00000000e+02 3.42618755e+00 2.29382464e+00]\n",
      "Target min [80.36605971]\n",
      "Target max [189.42515895]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ANSS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.32399979e+01  9.30100021e+01  1.40800000e+05  5.89996338e-01\n",
      " -3.09700012e+01  8.81775088e+00 -1.95951198e+01 -9.68954390e+00]\n",
      "Feature max [4.11220001e+02 4.13220001e+02 1.76134000e+07 5.81499939e+01\n",
      " 5.98500061e+01 1.00000000e+02 1.77876080e+01 8.00055630e+00]\n",
      "Target min [93.01000214]\n",
      "Target max [413.22000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SMCI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [  11.64999962   11.55000019 1300.            0.         -112.07000732\n",
      "    3.06121694  -80.8459551   -37.07896777]\n",
      "Feature max [1.18806995e+03 1.21200000e+03 3.69735000e+07 2.76719971e+02\n",
      " 1.33520020e+02 1.00000000e+02 1.39404960e+02 3.27849310e+01]\n",
      "Target min [11.55000019]\n",
      "Target max [1212.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MCHP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.59165306e+01  2.58235891e+01  9.03800000e+05  2.06648726e-01\n",
      " -4.89303413e+00  0.00000000e+00 -5.27414154e+00 -1.76700589e+00]\n",
      "Feature max [9.89445496e+01 9.94815944e+01 6.08822000e+07 6.51408535e+00\n",
      " 6.70935719e+00 9.91722379e+01 3.41370681e+00 1.65716014e+00]\n",
      "Target min [25.82358912]\n",
      "Target max [99.48159441]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DASH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.30600014e+01  4.40000000e+01  6.73000000e+05  1.04000092e+00\n",
      " -1.43899994e+01  0.00000000e+00 -1.42424126e+01 -6.22931087e+00]\n",
      "Feature max [2.45970001e+02 2.47520004e+02 4.74057000e+07 6.56900024e+01\n",
      " 3.15700073e+01 8.94834273e+01 1.00982520e+01 7.89917563e+00]\n",
      "Target min [44.]\n",
      "Target max [247.52000427]\n",
      "X_train shape: (916, 20, 8)\n",
      "Train_dates: 2020-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LULU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.79099998e+01  4.80200005e+01  3.97400000e+05  5.40000916e-01\n",
      " -6.25899963e+01  5.58157336e+00 -2.90394509e+01 -9.98076840e+00]\n",
      "Feature max [5.11290009e+02 5.13239990e+02 4.96203000e+07 4.49899902e+01\n",
      " 5.28800049e+01 1.00000000e+02 2.51784526e+01 8.66763261e+00]\n",
      "Target min [48.02000046]\n",
      "Target max [513.23999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.20500984e+02  1.20691447e+02  6.12800000e+05  8.28945424e-01\n",
      " -1.51888420e+01  4.25187927e+00 -6.90049242e+00 -3.92935187e+00]\n",
      "Feature max [3.33829987e+02 3.35086817e+02 2.39368000e+07 2.95567919e+01\n",
      " 3.45128549e+01 1.00000000e+02 1.11182756e+01 4.56750789e+00]\n",
      "Target min [117.33473539]\n",
      "Target max [335.08681669]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.69300003e+01  7.61900024e+01  2.56200000e+05  5.80001831e-01\n",
      " -4.11199951e+01  8.69419477e+00 -1.48270264e+01 -9.41658874e+00]\n",
      "Feature max [3.42269989e+02 3.42519989e+02 1.94870000e+07 2.90000076e+01\n",
      " 2.02900085e+01 1.00000000e+02 1.45651636e+01 4.69711212e+00]\n",
      "Target min [74.61000061]\n",
      "Target max [342.51998901]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTSH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88846626e+01  3.95294712e+01  6.22600000e+05  2.63455814e-01\n",
      " -7.87768142e+00  3.88436978e+00 -4.96337501e+00 -1.63582261e+00]\n",
      "Feature max [8.93110580e+01 8.89753726e+01 4.05510000e+07 7.35238977e+00\n",
      " 4.92298399e+00 1.00000000e+02 2.87893965e+00 1.48546537e+00]\n",
      "Target min [39.52947115]\n",
      "Target max [88.9753726]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CMCSA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.63607197e+01  2.63434864e+01  3.87530000e+06  1.43293802e-01\n",
      " -4.19077970e+00  4.89603961e+00 -2.20475346e+00 -7.52468733e-01]\n",
      "Feature max [5.69077454e+01 5.66128428e+01 1.05512100e+08 5.02262394e+00\n",
      " 2.79152757e+00 1.00000000e+02 1.64204573e+00 6.64990298e-01]\n",
      "Target min [26.34348644]\n",
      "Target max [56.61284285]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AAPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.68914185e+01  2.68520158e+01  2.40483000e+07  1.39069218e-01\n",
      " -2.07459821e+01  0.00000000e+00 -6.52546699e+00 -2.48303795e+00]\n",
      "Feature max [2.34548523e+02 2.36206595e+02 4.47940000e+08 1.74797677e+01\n",
      " 1.35858198e+01 9.66324712e+01 8.94504543e+00 2.34169467e+00]\n",
      "Target min [26.84042339]\n",
      "Target max [236.20659489]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DLTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.55699997e+01  6.56299973e+01  6.51800000e+05  6.50001526e-01\n",
      " -2.06100006e+01  5.95402131e+00 -8.27013588e+00 -4.05435465e+00]\n",
      "Feature max [1.74080002e+02 1.75119995e+02 2.64414000e+07 1.71399956e+01\n",
      " 2.62200012e+01 1.00000000e+02 1.03700274e+01 2.48843256e+00]\n",
      "Target min [65.62999725]\n",
      "Target max [175.11999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GFS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88100014e+01  3.79099998e+01  4.52100000e+05  4.29996490e-01\n",
      " -4.36000061e+00  7.50238102e+00 -4.23886167e+00 -2.38196636e+00]\n",
      "Feature max [7.89400024e+01 7.86999969e+01 2.59534000e+07 9.84000015e+00\n",
      " 5.52999878e+00 1.00000000e+02 5.44023126e+00 1.92129480e+00]\n",
      "Target min [37.90999985]\n",
      "Target max [78.69999695]\n",
      "X_train shape: (693, 20, 8)\n",
      "Train_dates: 2021-10-29 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.44999981e+00  8.35999966e+00  1.22410000e+06  1.59999847e-01\n",
      " -1.02299957e+01  1.19369510e+01 -7.02511537e+00 -2.54591706e+00]\n",
      "Feature max [1.08089996e+02 1.09739998e+02 9.31809000e+07 8.59999847e+00\n",
      " 5.73000336e+00 1.00000000e+02 5.08121811e+00 1.91962014e+00]\n",
      "Target min [8.35999966]\n",
      "Target max [109.73999786]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOGL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.03422012e+01  4.03287161e+01  9.31200000e+06  2.03764713e-01\n",
      " -1.11600037e+01  0.00000000e+00 -5.26264397e+00 -2.43230043e+00]\n",
      "Feature max [1.91179993e+02 1.90309998e+02 1.33178000e+08 9.50000000e+00\n",
      " 1.83489409e+01 9.87786722e+01 5.22104620e+00 1.70818585e+00]\n",
      "Target min [39.98510758]\n",
      "Target max [190.30999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.13033676e+01  2.10973018e+01  4.34960000e+06  2.94382096e-01\n",
      " -6.56426828e+00  0.00000000e+00 -1.04368766e+01 -2.87377570e+00]\n",
      "Feature max [1.53315903e+02 1.56872784e+02 1.42315800e+08 1.44873285e+01\n",
      " 1.70885489e+01 9.98188294e+01 9.21113833e+00 2.76849472e+00]\n",
      "Target min [21.09730184]\n",
      "Target max [156.87278409]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ILMN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.02626495e+01  9.14591446e+01  2.24207000e+05  1.42024231e+00\n",
      " -5.47957153e+01  1.07051311e+00 -2.98009348e+01 -1.18772369e+01]\n",
      "Feature max [5.10544739e+02 5.08336578e+02 3.66514900e+07 1.00622589e+02\n",
      " 3.87353821e+01 1.00000000e+02 2.65404856e+01 7.18644479e+00]\n",
      "Target min [91.45914459]\n",
      "Target max [508.33657837]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDNS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55699997e+01  2.53400002e+01  3.77200000e+05  1.30001068e-01\n",
      " -1.65799866e+01  6.34196911e+00 -1.44468346e+01 -5.97594400e+00]\n",
      "Feature max [3.26500000e+02 3.28790009e+02 5.72181000e+07 2.09400024e+01\n",
      " 1.50199890e+01 1.00000000e+02 8.60328681e+00 4.15512117e+00]\n",
      "Target min [25.34000015]\n",
      "Target max [328.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FTNT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.08400011e+00  6.03000021e+00  1.55300000e+06  5.60002327e-02\n",
      " -1.53400040e+01  3.96274759e+00 -4.72904041e+00 -2.60667325e+00]\n",
      "Feature max [8.02799988e+01 8.04499969e+01 1.66853000e+08 9.42400360e+00\n",
      " 9.86999893e+00 1.00000000e+02 4.39902634e+00 1.72982386e+00]\n",
      "Target min [6.03000021]\n",
      "Target max [80.44999695]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NFLX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.29179993e+02  1.27489998e+02  1.14400000e+06  8.99993896e-01\n",
      " -1.07820007e+02  2.54085690e+00 -5.92338064e+01 -1.83116588e+01]\n",
      "Feature max [7.01349976e+02 7.00359985e+02 1.33387500e+08 5.69599915e+01\n",
      " 6.36499939e+01 1.00000000e+02 2.49544334e+01 9.64348338e+00]\n",
      "Target min [124.95999908]\n",
      "Target max [700.35998535]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ASML data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01730965e+02  1.01656923e+02  1.91300000e+05  5.09020836e-01\n",
      " -8.94442496e+01  0.00000000e+00 -4.66577753e+01 -2.22673979e+01]\n",
      "Feature max [1.09691748e+03 1.10792721e+03 7.75430000e+06 7.14700317e+01\n",
      " 6.84131669e+01 9.61639905e+01 5.18699435e+01 1.62876850e+01]\n",
      "Target min [101.65692296]\n",
      "Target max [1107.92720614]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.57600002e+01  2.56200008e+01  7.45000000e+04  3.59998703e-01\n",
      " -7.29299927e+01  0.00000000e+00 -4.01420346e+01 -1.51743729e+01]\n",
      "Feature max [5.85030029e+02 5.85030029e+02 1.25421000e+07 6.22800293e+01\n",
      " 9.26100159e+01 9.67312153e+01 3.60296232e+01 1.38232539e+01]\n",
      "Target min [25.62000084]\n",
      "Target max [585.0300293]\n",
      "X_train shape: (1706, 20, 8)\n",
      "Train_dates: 2017-10-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.76626587e+01  5.97122857e+01  4.45200000e+05  3.56550028e-01\n",
      " -1.06970815e+01  0.00000000e+00 -1.68949971e+01 -4.25844633e+00]\n",
      "Feature max [2.57128174e+02 2.54701584e+02 2.58818000e+07 2.13453368e+01\n",
      " 1.87003391e+01 9.38539425e+01 7.41175557e+00 3.17530369e+00]\n",
      "Target min [59.7122857]\n",
      "Target max [254.70158394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.89899998e+01  1.91000004e+01  6.31320000e+06  1.65667040e-01\n",
      " -7.35440763e+00  0.00000000e+00 -3.67962891e+00 -1.56579357e+00]\n",
      "Feature max [6.20833321e+01 6.20287564e+01 3.00895900e+08 7.64107747e+00\n",
      " 5.65919109e+00 9.56309713e+01 2.62854927e+00 1.12867592e+00]\n",
      "Target min [19.10000038]\n",
      "Target max [62.02875642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KLAC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.84464874e+01  6.86297678e+01  2.57700000e+05  5.09411721e-01\n",
      " -4.98388271e+01  0.00000000e+00 -2.75021474e+01 -1.29123595e+01]\n",
      "Feature max [8.90720154e+02 8.94682933e+02 6.29590000e+06 7.53521125e+01\n",
      " 4.65248886e+01 9.61332173e+01 3.03164128e+01 1.17409375e+01]\n",
      "Target min [68.62976779]\n",
      "Target max [894.68293334]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.78590012e+01  3.79194984e+01  1.76260000e+07  1.59500122e-01\n",
      " -1.73200073e+01  1.14353166e+01 -1.24315006e+01 -3.31749210e+00]\n",
      "Feature max [2.00000000e+02 2.00089996e+02 3.31300000e+08 1.37949982e+01\n",
      " 1.67610016e+01 1.00000000e+02 8.13447345e+00 3.39296647e+00]\n",
      "Target min [37.89599991]\n",
      "Target max [200.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing XEL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [32.11785126 32.15771081  0.          0.         -5.25528431  4.89752525\n",
      " -3.58270584 -1.54356233]\n",
      "Feature max [7.23329086e+01 7.20338896e+01 2.27822000e+07 8.42780017e+00\n",
      " 2.38431091e+00 1.00000000e+02 1.75878069e+00 1.02005435e+00]\n",
      "Target min [32.15771081]\n",
      "Target max [72.03388965]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m5,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,921</span> (85.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,921\u001b[0m (85.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,921</span> (85.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,921\u001b[0m (85.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/102 Training model for ^IXIC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0053 - mape: 51.9235 - val_loss: 0.1038 - val_mape: 37.1234\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0475 - mape: 301.1647 - val_loss: 0.1603 - val_mape: 47.3059\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0311 - mape: 219.9285 - val_loss: 0.1363 - val_mape: 43.4839\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0262 - mape: 194.7854 - val_loss: 0.0706 - val_mape: 30.4958\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0221 - mape: 185.7576 - val_loss: 0.0660 - val_mape: 29.4038\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0203 - mape: 179.9505 - val_loss: 0.0543 - val_mape: 26.3765\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0135 - mape: 141.0885 - val_loss: 0.0484 - val_mape: 24.8426\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0085 - mape: 106.2926 - val_loss: 0.0426 - val_mape: 23.1436\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 70.8718 - val_loss: 0.0384 - val_mape: 21.9183\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 49.6701 - val_loss: 0.0376 - val_mape: 21.7581\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mape: 38.5784 - val_loss: 0.0345 - val_mape: 20.7924\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 37.2485 - val_loss: 0.0350 - val_mape: 21.0446\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 50.8867 - val_loss: 0.0352 - val_mape: 21.1368\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mape: 58.7830 - val_loss: 0.0314 - val_mape: 19.8003\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - mape: 77.0137 - val_loss: 0.0328 - val_mape: 20.3272\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mape: 81.6512 - val_loss: 0.0312 - val_mape: 19.7085\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0059 - mape: 87.0008 - val_loss: 0.0264 - val_mape: 17.8808\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0064 - mape: 89.5777 - val_loss: 0.0255 - val_mape: 17.5253\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0061 - mape: 86.2341 - val_loss: 0.0222 - val_mape: 16.1003\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0061 - mape: 89.0000 - val_loss: 0.0197 - val_mape: 15.0700\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mape: 62.5586 - val_loss: 0.0182 - val_mape: 14.4063\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mape: 54.1672 - val_loss: 0.0155 - val_mape: 13.0699\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mape: 47.3609 - val_loss: 0.0141 - val_mape: 12.3135\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 38.8998 - val_loss: 0.0141 - val_mape: 12.3624\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 42.6043 - val_loss: 0.0143 - val_mape: 12.5289\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - mape: 45.4982 - val_loss: 0.0123 - val_mape: 11.3730\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 43.6401 - val_loss: 0.0098 - val_mape: 9.8965\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 37.7578 - val_loss: 0.0090 - val_mape: 9.3732\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 41.8493 - val_loss: 0.0077 - val_mape: 8.5667\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 37.8023 - val_loss: 0.0074 - val_mape: 8.2949\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 39.9133 - val_loss: 0.0082 - val_mape: 9.0497\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 40.0177 - val_loss: 0.0071 - val_mape: 8.1195\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 46.2664 - val_loss: 0.0068 - val_mape: 7.9551\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 42.4795 - val_loss: 0.0062 - val_mape: 7.5681\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mape: 35.6643 - val_loss: 0.0056 - val_mape: 7.1394\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 45.1775 - val_loss: 0.0051 - val_mape: 6.7381\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 46.3826 - val_loss: 0.0034 - val_mape: 5.2295\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 47.4783 - val_loss: 0.0033 - val_mape: 5.1225\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 41.7681 - val_loss: 0.0027 - val_mape: 4.5676\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 56.0290 - val_loss: 0.0044 - val_mape: 6.1809\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mape: 63.2813 - val_loss: 0.0040 - val_mape: 5.8235\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 43.4834 - val_loss: 0.0041 - val_mape: 5.9282\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 39.5219 - val_loss: 0.0038 - val_mape: 5.7068\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 38.4139 - val_loss: 0.0029 - val_mape: 4.7760\n",
      "Epoch 45/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 40.3639 - val_loss: 0.0024 - val_mape: 4.2998\n",
      "Epoch 46/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 50.7434 - val_loss: 0.0033 - val_mape: 5.2304\n",
      "Epoch 47/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 57.8157 - val_loss: 0.0027 - val_mape: 4.5961\n",
      "Epoch 48/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mape: 52.1799 - val_loss: 0.0030 - val_mape: 4.9727\n",
      "Epoch 49/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mape: 66.2972 - val_loss: 0.0026 - val_mape: 4.5672\n",
      "Epoch 50/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 46.6537 - val_loss: 0.0025 - val_mape: 4.4026\n",
      "Epoch 51/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 44.5998 - val_loss: 0.0017 - val_mape: 3.6397\n",
      "Epoch 52/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mape: 57.8631 - val_loss: 0.0024 - val_mape: 4.3885\n",
      "Epoch 53/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 60.3411 - val_loss: 0.0018 - val_mape: 3.7467\n",
      "Epoch 54/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 49.6194 - val_loss: 0.0023 - val_mape: 4.2325\n",
      "Epoch 55/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 42.6423 - val_loss: 0.0016 - val_mape: 3.5448\n",
      "Epoch 56/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0039 - mape: 61.9034 - val_loss: 0.0016 - val_mape: 3.5569\n",
      "Epoch 57/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mape: 70.1238 - val_loss: 0.0017 - val_mape: 3.6611\n",
      "Epoch 58/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 53.2771 - val_loss: 0.0021 - val_mape: 4.1045\n",
      "Epoch 59/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 42.6555 - val_loss: 0.0015 - val_mape: 3.4836\n",
      "Epoch 60/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 52.2563 - val_loss: 0.0017 - val_mape: 3.6275\n",
      "Epoch 61/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 43.7254 - val_loss: 0.0015 - val_mape: 3.4213\n",
      "Epoch 62/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mape: 58.1594 - val_loss: 0.0018 - val_mape: 3.8688\n",
      "Epoch 63/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 54.3082 - val_loss: 0.0027 - val_mape: 4.8287\n",
      "Epoch 64/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 44.9371 - val_loss: 0.0021 - val_mape: 4.1375\n",
      "Epoch 65/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 48.2457 - val_loss: 0.0019 - val_mape: 3.8404\n",
      "Epoch 66/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mape: 60.4032 - val_loss: 0.0014 - val_mape: 3.2727\n",
      "Epoch 67/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 50.6125 - val_loss: 0.0012 - val_mape: 3.1960\n",
      "Epoch 68/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mape: 55.8086 - val_loss: 0.0013 - val_mape: 3.2045\n",
      "Epoch 69/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 51.8457 - val_loss: 0.0013 - val_mape: 3.1759\n",
      "Epoch 70/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mape: 74.7970 - val_loss: 0.0014 - val_mape: 3.3082\n",
      "Epoch 71/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 69.9742 - val_loss: 0.0011 - val_mape: 3.2361\n",
      "Epoch 72/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mape: 52.4278 - val_loss: 0.0011 - val_mape: 3.0960\n",
      "Epoch 73/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mape: 48.1698 - val_loss: 0.0011 - val_mape: 3.0351\n",
      "Epoch 74/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 45.9703 - val_loss: 9.8362e-04 - val_mape: 2.9298\n",
      "Epoch 75/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mape: 45.4564 - val_loss: 9.8576e-04 - val_mape: 2.8640\n",
      "Epoch 76/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 50.3429 - val_loss: 9.1330e-04 - val_mape: 2.8356\n",
      "Epoch 77/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mape: 44.6961 - val_loss: 9.2987e-04 - val_mape: 2.7412\n",
      "Epoch 78/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mape: 53.5623 - val_loss: 8.1976e-04 - val_mape: 2.9309\n",
      "Epoch 79/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 38.8774 - val_loss: 9.5161e-04 - val_mape: 2.7945\n",
      "Epoch 80/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 52.2605 - val_loss: 9.2439e-04 - val_mape: 2.7106\n",
      "Epoch 81/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mape: 46.2723 - val_loss: 0.0011 - val_mape: 2.8988\n",
      "Epoch 82/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mape: 48.4182 - val_loss: 8.7859e-04 - val_mape: 2.6616\n",
      "Epoch 83/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mape: 49.6190 - val_loss: 0.0011 - val_mape: 2.9381\n",
      "Epoch 84/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mape: 73.9404 - val_loss: 0.0013 - val_mape: 3.2562\n",
      "Epoch 85/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - mape: 77.4418 - val_loss: 9.3172e-04 - val_mape: 2.9807\n",
      "Epoch 86/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mape: 66.5073 - val_loss: 0.0011 - val_mape: 2.9764\n",
      "Epoch 87/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mape: 65.7073 - val_loss: 0.0011 - val_mape: 3.0410\n",
      "Epoch 88/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0039 - mape: 68.1765 - val_loss: 8.4197e-04 - val_mape: 2.7664\n",
      "--- 2/102 Training model for VRTX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 30.3922 - val_loss: 0.0036 - val_mape: 5.8947\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mape: 50.0747 - val_loss: 0.0028 - val_mape: 5.1975\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 22.5213 - val_loss: 0.0027 - val_mape: 5.0233\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 23.3381 - val_loss: 0.0034 - val_mape: 5.8419\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mape: 29.0147 - val_loss: 0.0028 - val_mape: 5.1862\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.2349e-04 - mape: 20.1091 - val_loss: 0.0019 - val_mape: 4.0017\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 23.3025 - val_loss: 0.0021 - val_mape: 4.2356\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0036e-04 - mape: 22.0807 - val_loss: 0.0016 - val_mape: 3.7018\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9209e-04 - mape: 18.4879 - val_loss: 0.0020 - val_mape: 4.2086\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.8106e-04 - mape: 20.6721 - val_loss: 0.0021 - val_mape: 4.3385\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.3085e-04 - mape: 20.0526 - val_loss: 0.0014 - val_mape: 3.4399\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3182e-04 - mape: 20.1870 - val_loss: 0.0017 - val_mape: 3.9372\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3053e-04 - mape: 20.6312 - val_loss: 0.0012 - val_mape: 3.0799\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.0009e-04 - mape: 20.8631 - val_loss: 0.0015 - val_mape: 3.5111\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1794e-04 - mape: 21.1404 - val_loss: 0.0017 - val_mape: 3.7985\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.8326e-04 - mape: 18.6583 - val_loss: 0.0020 - val_mape: 4.1774\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7288e-04 - mape: 19.3869 - val_loss: 0.0013 - val_mape: 3.2201\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7650e-04 - mape: 21.7028 - val_loss: 0.0012 - val_mape: 3.0040\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.1219e-04 - mape: 21.2636 - val_loss: 0.0013 - val_mape: 3.1924\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3877e-04 - mape: 20.0445 - val_loss: 0.0020 - val_mape: 4.2184\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3717e-04 - mape: 22.3856 - val_loss: 0.0018 - val_mape: 3.9483\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3586e-04 - mape: 19.4828 - val_loss: 0.0019 - val_mape: 4.2274\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.3904e-04 - mape: 20.1785 - val_loss: 0.0025 - val_mape: 4.9117\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7054e-04 - mape: 23.5176 - val_loss: 0.0030 - val_mape: 5.3736\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 32.2431 - val_loss: 0.0059 - val_mape: 7.9375\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 33.9947 - val_loss: 0.0042 - val_mape: 6.4319\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 22.5744 - val_loss: 0.0029 - val_mape: 5.2131\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 26.7955 - val_loss: 0.0030 - val_mape: 5.4342\n",
      "--- 3/102 Training model for PYPL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 99380.0938 - val_loss: 2.3496e-04 - val_mape: 17.7405\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 214030.4688 - val_loss: 8.1098e-04 - val_mape: 33.5762\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 169811.3906 - val_loss: 3.8294e-04 - val_mape: 22.1814\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mape: 267309.6562 - val_loss: 2.6559e-04 - val_mape: 17.8799\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 57425.2148 - val_loss: 2.2609e-04 - val_mape: 15.9022\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 39810.8359 - val_loss: 1.0083e-04 - val_mape: 9.9994\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - mape: 39831.1719 - val_loss: 1.1456e-04 - val_mape: 10.8332\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 200571.9219 - val_loss: 1.2092e-04 - val_mape: 11.4989\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 41316.0781 - val_loss: 0.0018 - val_mape: 48.9612\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0053 - mape: 28411.9629 - val_loss: 0.0037 - val_mape: 71.4557\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 38019.8906 - val_loss: 1.6184e-04 - val_mape: 14.3029\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mape: 107561.6094 - val_loss: 0.0011 - val_mape: 39.0857\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mape: 294474.5625 - val_loss: 0.0020 - val_mape: 53.6617\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0067 - mape: 320853.7188 - val_loss: 5.9933e-04 - val_mape: 28.7993\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mape: 139402.0312 - val_loss: 0.0032 - val_mape: 68.3598\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - mape: 191676.5781 - val_loss: 0.0012 - val_mape: 40.0576\n",
      "--- 4/102 Training model for GILD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0054 - mape: 51365.6680 - val_loss: 0.0141 - val_mape: 16.0380\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 72242.7188 - val_loss: 0.0020 - val_mape: 5.8999\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 93681.9141 - val_loss: 0.0019 - val_mape: 6.0110\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mape: 44625.4961 - val_loss: 0.0018 - val_mape: 5.6080\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 82898.0859 - val_loss: 0.0012 - val_mape: 4.0930\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 39362.5469 - val_loss: 9.6957e-04 - val_mape: 3.5238\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 82139.0391 - val_loss: 0.0010 - val_mape: 3.7289\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 21469.2617 - val_loss: 9.1411e-04 - val_mape: 3.3413\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 51897.5273 - val_loss: 9.5400e-04 - val_mape: 3.4097\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 69210.5859 - val_loss: 9.2592e-04 - val_mape: 3.3840\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 28673.6133 - val_loss: 7.9768e-04 - val_mape: 3.0150\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 76253.2031 - val_loss: 7.7831e-04 - val_mape: 2.9798\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 90268.9141 - val_loss: 0.0012 - val_mape: 4.2434\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 42368.0977 - val_loss: 9.0664e-04 - val_mape: 3.3796\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 39367.8789 - val_loss: 0.0011 - val_mape: 3.9445\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 44035.3359 - val_loss: 7.0223e-04 - val_mape: 2.7909\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 23828.2949 - val_loss: 7.9341e-04 - val_mape: 3.0204\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 120475.5938 - val_loss: 6.4053e-04 - val_mape: 2.6864\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 18075.9004 - val_loss: 8.1107e-04 - val_mape: 3.1813\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 29514.2344 - val_loss: 6.8200e-04 - val_mape: 2.8102\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 20985.4219 - val_loss: 0.0017 - val_mape: 5.0776\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 44579.4023 - val_loss: 7.0351e-04 - val_mape: 2.8259\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 42053.3242 - val_loss: 6.2962e-04 - val_mape: 2.7128\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 61845.3516 - val_loss: 6.9311e-04 - val_mape: 2.9362\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 1905.9125 - val_loss: 6.3564e-04 - val_mape: 2.6927\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 56368.1289 - val_loss: 7.4860e-04 - val_mape: 3.0141\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 21474.2930 - val_loss: 7.7613e-04 - val_mape: 3.0455\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 95055.8359 - val_loss: 5.9153e-04 - val_mape: 2.6527\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 67462.2031 - val_loss: 7.2226e-04 - val_mape: 2.9396\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 45929.7031 - val_loss: 5.8936e-04 - val_mape: 2.7251\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mape: 41948.4453 - val_loss: 0.0012 - val_mape: 4.3426\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 44055.6172 - val_loss: 0.0015 - val_mape: 4.7468\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 59751.3750 - val_loss: 5.3985e-04 - val_mape: 2.6024\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 17843.5469 - val_loss: 7.5860e-04 - val_mape: 2.9848\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 96365.3359 - val_loss: 7.0129e-04 - val_mape: 2.8974\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 108648.5938 - val_loss: 0.0013 - val_mape: 4.3442\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.7956e-04 - mape: 31806.1562 - val_loss: 8.3140e-04 - val_mape: 3.3115\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 54007.8047 - val_loss: 6.3849e-04 - val_mape: 2.7918\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 37255.3047 - val_loss: 6.4405e-04 - val_mape: 2.8255\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 85166.5938 - val_loss: 7.3903e-04 - val_mape: 2.9696\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6925e-04 - mape: 43601.0195 - val_loss: 9.4762e-04 - val_mape: 3.4081\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 82114.8438 - val_loss: 0.0011 - val_mape: 3.6885\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 53061.2070 - val_loss: 7.8418e-04 - val_mape: 3.0726\n",
      "--- 5/102 Training model for CSX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 11.6859 - val_loss: 0.0013 - val_mape: 3.3811\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 10.5620 - val_loss: 0.0025 - val_mape: 5.3981\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mape: 11.3834 - val_loss: 0.0020 - val_mape: 4.8732\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5667e-04 - mape: 8.5620 - val_loss: 0.0031 - val_mape: 6.0665\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.2164 - val_loss: 0.0028 - val_mape: 5.7041\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 10.0495 - val_loss: 0.0023 - val_mape: 5.0129\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.6712 - val_loss: 0.0025 - val_mape: 5.3012\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mape: 9.8851 - val_loss: 0.0032 - val_mape: 6.2044\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.4958e-04 - mape: 9.0920 - val_loss: 0.0015 - val_mape: 3.9358\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8954e-04 - mape: 9.8228 - val_loss: 0.0014 - val_mape: 3.8655\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.2069 - val_loss: 0.0011 - val_mape: 3.3034\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 10.9765 - val_loss: 0.0023 - val_mape: 5.2648\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 9.9911 - val_loss: 0.0014 - val_mape: 4.0540\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 10.5677 - val_loss: 0.0014 - val_mape: 3.9801\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.5280 - val_loss: 9.4652e-04 - val_mape: 3.0651\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 12.0835 - val_loss: 0.0017 - val_mape: 4.4315\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 11.9772 - val_loss: 0.0017 - val_mape: 4.3630\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 11.5339 - val_loss: 0.0014 - val_mape: 3.9440\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 12.3638 - val_loss: 0.0026 - val_mape: 5.6487\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.5346 - val_loss: 0.0014 - val_mape: 3.9254\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 10.4504 - val_loss: 8.6332e-04 - val_mape: 3.0265\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.4460 - val_loss: 0.0011 - val_mape: 3.4605\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.8827 - val_loss: 6.2228e-04 - val_mape: 2.5038\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10.7446 - val_loss: 9.9721e-04 - val_mape: 3.3005\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 11.0856 - val_loss: 7.2551e-04 - val_mape: 2.7060\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 11.9979 - val_loss: 5.3332e-04 - val_mape: 2.2275\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 13.5854 - val_loss: 6.8423e-04 - val_mape: 2.7469\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 13.1987 - val_loss: 0.0010 - val_mape: 3.4154\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 14.8052 - val_loss: 6.1249e-04 - val_mape: 2.4289\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 15.0076 - val_loss: 7.2213e-04 - val_mape: 2.7124\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 15.3768 - val_loss: 6.2470e-04 - val_mape: 2.2333\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 16.5129 - val_loss: 0.0012 - val_mape: 3.5496\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 13.3293 - val_loss: 0.0013 - val_mape: 3.8245\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.5110 - val_loss: 0.0015 - val_mape: 4.2409\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.6374 - val_loss: 9.7571e-04 - val_mape: 3.2283\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 11.5475 - val_loss: 5.3878e-04 - val_mape: 2.2929\n",
      "--- 6/102 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 44.0719 - val_loss: 7.5959e-04 - val_mape: 3.8060\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 40.0755 - val_loss: 0.0023 - val_mape: 6.6033\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0072 - mape: 83.6833 - val_loss: 0.0015 - val_mape: 5.4888\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mape: 48.0094 - val_loss: 5.6457e-04 - val_mape: 2.9731\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0059 - mape: 74.2476 - val_loss: 3.1247e-04 - val_mape: 2.2610\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 34.3293 - val_loss: 4.7645e-04 - val_mape: 2.8885\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 45.6277 - val_loss: 0.0011 - val_mape: 4.6719\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 35.1556 - val_loss: 0.0020 - val_mape: 6.2083\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 51.3352 - val_loss: 0.0016 - val_mape: 5.5896\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 36.5180 - val_loss: 0.0038 - val_mape: 8.7982\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mape: 62.8686 - val_loss: 8.0454e-04 - val_mape: 3.8638\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 33.6618 - val_loss: 0.0014 - val_mape: 5.2984\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 35.7722 - val_loss: 0.0019 - val_mape: 6.1679\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.0835 - val_loss: 0.0011 - val_mape: 4.5465\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 39.4069 - val_loss: 0.0011 - val_mape: 4.5638\n",
      "--- 7/102 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 24.5693 - val_loss: 3.5033e-04 - val_mape: 1.8404\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 35.1263 - val_loss: 3.3118e-04 - val_mape: 2.0690\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mape: 45.6959 - val_loss: 5.8302e-04 - val_mape: 2.3263\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 50.0133 - val_loss: 6.8578e-04 - val_mape: 2.5505\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mape: 63.4480 - val_loss: 3.7241e-04 - val_mape: 2.1296\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0064 - mape: 73.3083 - val_loss: 3.1460e-04 - val_mape: 1.8976\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - mape: 70.8942 - val_loss: 2.9802e-04 - val_mape: 1.9370\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0059 - mape: 72.4289 - val_loss: 3.9337e-04 - val_mape: 2.4440\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mape: 56.4766 - val_loss: 6.8778e-04 - val_mape: 2.5236\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 56.9728 - val_loss: 4.5016e-04 - val_mape: 2.1091\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 39.3070 - val_loss: 6.6336e-04 - val_mape: 2.3786\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 33.4716 - val_loss: 3.7815e-04 - val_mape: 2.2725\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 32.4587 - val_loss: 3.6238e-04 - val_mape: 1.9956\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 26.5872 - val_loss: 6.6639e-04 - val_mape: 2.3460\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 25.4282 - val_loss: 4.8254e-04 - val_mape: 2.0725\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 27.2796 - val_loss: 3.3909e-04 - val_mape: 2.0104\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 24.2562 - val_loss: 3.9274e-04 - val_mape: 2.0602\n",
      "--- 8/102 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0089 - mape: 306.9160 - val_loss: 1.8146e-04 - val_mape: 2.9470\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mape: 141.8600 - val_loss: 1.8281e-04 - val_mape: 3.0453\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mape: 239.0356 - val_loss: 1.0977e-04 - val_mape: 2.2536\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 222.9994 - val_loss: 1.7443e-04 - val_mape: 2.9666\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mape: 267.4839 - val_loss: 1.3059e-04 - val_mape: 2.5600\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mape: 268.9570 - val_loss: 1.5419e-04 - val_mape: 2.7786\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0062 - mape: 252.1007 - val_loss: 9.6605e-05 - val_mape: 2.1494\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mape: 176.9035 - val_loss: 1.5966e-04 - val_mape: 2.7644\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 153.4296 - val_loss: 8.1367e-05 - val_mape: 1.7771\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 103.3791 - val_loss: 7.5425e-05 - val_mape: 1.7647\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 97.3045 - val_loss: 6.9650e-05 - val_mape: 1.5894\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 84.9897 - val_loss: 2.5464e-04 - val_mape: 3.1994\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 103.9443 - val_loss: 7.0585e-05 - val_mape: 1.5294\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 87.8543 - val_loss: 8.5343e-05 - val_mape: 1.7337\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 113.3022 - val_loss: 1.5698e-04 - val_mape: 2.5932\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 96.9890 - val_loss: 1.0583e-04 - val_mape: 1.9969\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 108.6880 - val_loss: 2.3386e-04 - val_mape: 2.8702\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mape: 118.9852 - val_loss: 1.3545e-04 - val_mape: 2.3778\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 97.4520 - val_loss: 1.1898e-04 - val_mape: 2.0381\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 114.8380 - val_loss: 1.9972e-04 - val_mape: 2.5862\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 119.8601 - val_loss: 1.9074e-04 - val_mape: 2.7909\n",
      "--- 9/102 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 14529.9365 - val_loss: 6.8907e-04 - val_mape: 1.9936\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 30042.6094 - val_loss: 0.0012 - val_mape: 3.4566\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 82986.4922 - val_loss: 0.0011 - val_mape: 3.1070\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 45363.0586 - val_loss: 0.0016 - val_mape: 3.8689\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 93822.8594 - val_loss: 0.0011 - val_mape: 2.9435\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 82665.3438 - val_loss: 0.0023 - val_mape: 4.8641\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 17813.4199 - val_loss: 0.0026 - val_mape: 5.1176\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 163010.8281 - val_loss: 0.0030 - val_mape: 5.4930\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 156772.7031 - val_loss: 0.0014 - val_mape: 3.1868\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 8981.0938 - val_loss: 0.0028 - val_mape: 5.1841\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 137959.5000 - val_loss: 0.0011 - val_mape: 2.8824\n",
      "--- 10/102 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 100.1214 - val_loss: 8.5623e-04 - val_mape: 2.2336\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 81.6143 - val_loss: 0.0016 - val_mape: 3.9407\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 86.2784 - val_loss: 7.4979e-04 - val_mape: 2.0966\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 76.9651 - val_loss: 0.0017 - val_mape: 4.0160\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mape: 94.7259 - val_loss: 7.6113e-04 - val_mape: 2.1121\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mape: 72.4935 - val_loss: 0.0040 - val_mape: 7.2179\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 107.4115 - val_loss: 6.4515e-04 - val_mape: 2.3440\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4020e-04 - mape: 69.6805 - val_loss: 0.0056 - val_mape: 8.8679\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 117.5189 - val_loss: 6.9511e-04 - val_mape: 2.1888\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6360e-04 - mape: 70.1372 - val_loss: 0.0071 - val_mape: 10.0568\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 126.8958 - val_loss: 6.7365e-04 - val_mape: 2.4148\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7242e-04 - mape: 72.7017 - val_loss: 0.0097 - val_mape: 12.0362\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 134.9396 - val_loss: 7.6506e-04 - val_mape: 3.0783\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3011e-04 - mape: 69.9143 - val_loss: 0.0093 - val_mape: 11.7948\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 132.7592 - val_loss: 8.0748e-04 - val_mape: 2.1752\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.0858e-04 - mape: 58.4318 - val_loss: 0.0101 - val_mape: 12.1477\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 146.9646 - val_loss: 6.9781e-04 - val_mape: 2.1033\n",
      "--- 11/102 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.5557e-04 - mape: 19.0484 - val_loss: 0.0015 - val_mape: 3.8101\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0039 - mape: 46.2541 - val_loss: 0.0082 - val_mape: 10.5514\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0131 - mape: 80.8934 - val_loss: 0.1525 - val_mape: 45.8215\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0235 - mape: 145.1748 - val_loss: 0.0207 - val_mape: 16.1210\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0101 - mape: 90.5198 - val_loss: 0.0065 - val_mape: 8.2492\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0114 - mape: 63.2221 - val_loss: 0.1824 - val_mape: 50.2752\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0216 - mape: 138.1379 - val_loss: 0.0937 - val_mape: 35.9701\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0166 - mape: 125.0760 - val_loss: 0.0015 - val_mape: 3.6858\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - mape: 46.4846 - val_loss: 0.0017 - val_mape: 3.9238\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - mape: 45.8808 - val_loss: 0.0168 - val_mape: 14.3105\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - mape: 52.3318 - val_loss: 0.0019 - val_mape: 4.2144\n",
      "--- 12/102 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mape: 233.6190 - val_loss: 0.0049 - val_mape: 7.5026\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 167.6044 - val_loss: 0.0041 - val_mape: 6.8463\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 139.2319 - val_loss: 0.0092 - val_mape: 10.5322\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 297.5291 - val_loss: 0.0025 - val_mape: 5.0722\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 144.2691 - val_loss: 0.0119 - val_mape: 11.9892\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 287.6650 - val_loss: 0.0025 - val_mape: 4.7824\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9256e-04 - mape: 115.6092 - val_loss: 0.0040 - val_mape: 6.3263\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7267e-04 - mape: 117.1474 - val_loss: 0.0045 - val_mape: 6.8451\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 131.4970 - val_loss: 0.0060 - val_mape: 8.0228\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 121.9049 - val_loss: 0.0070 - val_mape: 8.6634\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 108.7131 - val_loss: 0.0066 - val_mape: 8.5269\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 172.7742 - val_loss: 0.0191 - val_mape: 15.2021\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 317.6205 - val_loss: 0.0038 - val_mape: 6.2799\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0018 - mape: 168.7314 - val_loss: 0.0129 - val_mape: 12.4270\n",
      "--- 13/102 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mape: 58178.7930 - val_loss: 2.4825e-04 - val_mape: 1.9668\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 70553.5000 - val_loss: 6.5570e-04 - val_mape: 3.6012\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.6738e-04 - mape: 111204.1250 - val_loss: 2.0552e-04 - val_mape: 1.7891\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - mape: 33362.6836 - val_loss: 1.6603e-04 - val_mape: 1.5292\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3741e-04 - mape: 21203.9375 - val_loss: 5.1434e-04 - val_mape: 3.1202\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8377e-04 - mape: 67112.3125 - val_loss: 3.2278e-04 - val_mape: 2.3142\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6480e-04 - mape: 46629.3359 - val_loss: 3.5469e-04 - val_mape: 2.4548\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3013e-04 - mape: 19887.9238 - val_loss: 9.6697e-04 - val_mape: 4.5509\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.1913e-04 - mape: 7324.2534 - val_loss: 2.1514e-04 - val_mape: 1.7128\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9377e-04 - mape: 19818.0664 - val_loss: 7.6062e-04 - val_mape: 3.9282\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 79408.2969 - val_loss: 5.8033e-04 - val_mape: 3.3342\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1091e-04 - mape: 70627.9453 - val_loss: 3.1170e-04 - val_mape: 2.2058\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6145e-04 - mape: 38711.0859 - val_loss: 7.4725e-04 - val_mape: 3.8332\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3923e-04 - mape: 12557.1504 - val_loss: 6.5138e-04 - val_mape: 3.5376\n",
      "--- 14/102 Training model for DXCM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 55912.1953 - val_loss: 9.3975e-04 - val_mape: 4.0630\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 58902.5430 - val_loss: 4.3894e-04 - val_mape: 2.1933\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 56888.1094 - val_loss: 9.0975e-04 - val_mape: 4.0478\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 20074.4648 - val_loss: 6.7635e-04 - val_mape: 3.2450\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 72377.4219 - val_loss: 0.0010 - val_mape: 4.2681\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 4071.7908 - val_loss: 6.4308e-04 - val_mape: 2.8486\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 67441.7031 - val_loss: 3.9431e-04 - val_mape: 1.6009\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mape: 30089.9902 - val_loss: 3.5148e-04 - val_mape: 1.4536\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 61887.0625 - val_loss: 4.0595e-04 - val_mape: 1.9199\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 72678.5234 - val_loss: 0.0011 - val_mape: 4.1711\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 33146.0508 - val_loss: 8.2368e-04 - val_mape: 3.7606\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 54895.9883 - val_loss: 0.0014 - val_mape: 4.8584\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 70894.5391 - val_loss: 4.6040e-04 - val_mape: 2.0907\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mape: 30635.6543 - val_loss: 4.3817e-04 - val_mape: 2.0732\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mape: 139412.6094 - val_loss: 3.8680e-04 - val_mape: 1.8581\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 63524.9609 - val_loss: 0.0012 - val_mape: 4.3979\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mape: 80199.4453 - val_loss: 6.6049e-04 - val_mape: 2.9886\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mape: 202786.6094 - val_loss: 0.0012 - val_mape: 4.2748\n",
      "--- 15/102 Training model for FAST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - mape: 173491.7500 - val_loss: 0.0012 - val_mape: 3.2526\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mape: 11437.9922 - val_loss: 0.0020 - val_mape: 4.5461\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 44598.2773 - val_loss: 0.0026 - val_mape: 5.0919\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 21942.7520 - val_loss: 0.0022 - val_mape: 4.6920\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 4419.6226 - val_loss: 0.0056 - val_mape: 8.0973\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mape: 99801.8125 - val_loss: 0.0041 - val_mape: 7.0438\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 53177.4258 - val_loss: 0.0144 - val_mape: 13.6430\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0070 - mape: 134663.8281 - val_loss: 0.0027 - val_mape: 5.3023\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 2982.5073 - val_loss: 0.0084 - val_mape: 10.1190\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 91496.2891 - val_loss: 0.0030 - val_mape: 5.5812\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 7674.1802 - val_loss: 0.0082 - val_mape: 9.9767\n",
      "--- 16/102 Training model for ABNB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0038 - mape: 26805.8574 - val_loss: 5.1934e-04 - val_mape: 4.4236\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - mape: 49552.0859 - val_loss: 0.0012 - val_mape: 6.7157\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - mape: 14090.9482 - val_loss: 0.0022 - val_mape: 8.7299\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - mape: 37974.8164 - val_loss: 0.0018 - val_mape: 8.6192\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - mape: 60285.7969 - val_loss: 5.8801e-04 - val_mape: 4.8794\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - mape: 82037.6172 - val_loss: 2.6934e-04 - val_mape: 3.5037\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - mape: 31317.8848 - val_loss: 1.8574e-04 - val_mape: 2.4710\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 19260.1133 - val_loss: 2.7288e-04 - val_mape: 3.2140\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 55539.0000 - val_loss: 3.4112e-04 - val_mape: 3.8419\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 25027.0215 - val_loss: 4.5858e-04 - val_mape: 4.2429\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - mape: 30104.7578 - val_loss: 4.0900e-04 - val_mape: 4.3695\n",
      "Epoch 12/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mape: 8352.3105 - val_loss: 3.7032e-04 - val_mape: 3.7210\n",
      "Epoch 13/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 2067.0098 - val_loss: 6.0932e-04 - val_mape: 5.0633\n",
      "Epoch 14/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 811.8441 - val_loss: 5.9036e-04 - val_mape: 4.7769\n",
      "Epoch 15/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - mape: 10391.4990 - val_loss: 4.3034e-04 - val_mape: 4.4559\n",
      "Epoch 16/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0034 - mape: 23354.7168 - val_loss: 3.9809e-04 - val_mape: 3.9428\n",
      "Epoch 17/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - mape: 724.9929 - val_loss: 3.6988e-04 - val_mape: 4.3379\n",
      "--- 17/102 Training model for SNPS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 82.5631 - val_loss: 0.0019 - val_mape: 4.6532\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 85.2642 - val_loss: 8.8957e-04 - val_mape: 2.9011\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 74.5184 - val_loss: 9.9409e-04 - val_mape: 3.0957\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 105.5563 - val_loss: 0.0037 - val_mape: 6.4408\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mape: 165.1896 - val_loss: 9.2583e-04 - val_mape: 2.9720\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 110.5052 - val_loss: 0.0056 - val_mape: 8.0251\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0076 - mape: 235.7879 - val_loss: 7.7834e-04 - val_mape: 2.6336\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 73.8700 - val_loss: 0.0046 - val_mape: 7.1678\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mape: 187.5157 - val_loss: 0.0012 - val_mape: 3.3224\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 65.5435 - val_loss: 0.0029 - val_mape: 5.5323\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 161.4487 - val_loss: 8.4833e-04 - val_mape: 2.6454\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 67.2381 - val_loss: 0.0055 - val_mape: 7.7215\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mape: 172.8552 - val_loss: 9.9556e-04 - val_mape: 2.8724\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 69.9837 - val_loss: 0.0045 - val_mape: 7.0123\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mape: 156.2345 - val_loss: 0.0018 - val_mape: 4.0611\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 64.1162 - val_loss: 0.0064 - val_mape: 8.4778\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 141.3323 - val_loss: 5.8528e-04 - val_mape: 2.0942\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 65.2229 - val_loss: 0.0013 - val_mape: 3.4694\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 114.7483 - val_loss: 0.0013 - val_mape: 3.3823\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 90.0506 - val_loss: 0.0032 - val_mape: 5.6592\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 114.8054 - val_loss: 0.0016 - val_mape: 3.7106\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 77.0890 - val_loss: 0.0018 - val_mape: 3.9550\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 95.0328 - val_loss: 0.0012 - val_mape: 3.1305\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 67.8462 - val_loss: 0.0018 - val_mape: 3.9276\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 103.4739 - val_loss: 0.0028 - val_mape: 5.1627\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 84.7266 - val_loss: 0.0017 - val_mape: 3.8721\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 74.5004 - val_loss: 0.0024 - val_mape: 4.6076\n",
      "--- 18/102 Training model for BIIB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 6624.9414 - val_loss: 4.7507e-04 - val_mape: 19.0147\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 4607.9121 - val_loss: 1.8425e-04 - val_mape: 23.1475\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 8869.5693 - val_loss: 1.8541e-04 - val_mape: 17.6236\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 500.0255 - val_loss: 2.5983e-04 - val_mape: 15.1020\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 108.5657 - val_loss: 2.4646e-04 - val_mape: 14.6439\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 12339.6904 - val_loss: 3.2043e-04 - val_mape: 15.2176\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 3256.2639 - val_loss: 1.7508e-04 - val_mape: 17.8507\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7603e-04 - mape: 6164.8257 - val_loss: 1.1470e-04 - val_mape: 16.9038\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3379e-04 - mape: 739.7138 - val_loss: 7.3289e-05 - val_mape: 20.5955\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2194e-04 - mape: 9086.2539 - val_loss: 2.4715e-04 - val_mape: 18.3250\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 2384.9844 - val_loss: 6.4290e-05 - val_mape: 24.4210\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5976e-04 - mape: 5376.3970 - val_loss: 3.7545e-04 - val_mape: 18.6926\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9004e-04 - mape: 13539.8633 - val_loss: 1.5401e-04 - val_mape: 13.6465\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5888e-04 - mape: 8611.7842 - val_loss: 1.7120e-04 - val_mape: 13.9133\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6969e-04 - mape: 19752.2598 - val_loss: 4.2137e-04 - val_mape: 21.7125\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3736e-04 - mape: 2841.3298 - val_loss: 2.1592e-04 - val_mape: 15.1156\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4512e-04 - mape: 8731.2363 - val_loss: 3.5453e-04 - val_mape: 14.7463\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5726e-04 - mape: 3267.4448 - val_loss: 1.9247e-04 - val_mape: 14.1667\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9531e-04 - mape: 235.9336 - val_loss: 9.3817e-04 - val_mape: 31.9338\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 10874.8848 - val_loss: 2.0071e-04 - val_mape: 46.0571\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5907e-04 - mape: 558.8325 - val_loss: 1.3498e-04 - val_mape: 12.4990\n",
      "--- 19/102 Training model for REGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7129e-04 - mape: 18919.1348 - val_loss: 6.6243e-04 - val_mape: 2.5994\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8413e-04 - mape: 35988.3633 - val_loss: 0.0012 - val_mape: 3.6342\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4096e-04 - mape: 12391.5537 - val_loss: 6.6993e-04 - val_mape: 2.3578\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.9020e-04 - mape: 15816.9600 - val_loss: 8.6959e-04 - val_mape: 2.7353\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.6689e-04 - mape: 14631.2236 - val_loss: 0.0012 - val_mape: 3.3989\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7967e-04 - mape: 24657.5410 - val_loss: 0.0010 - val_mape: 2.9543\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1062e-04 - mape: 8191.9678 - val_loss: 9.5653e-04 - val_mape: 2.8235\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.2325e-04 - mape: 29633.0234 - val_loss: 0.0012 - val_mape: 3.2373\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7540e-04 - mape: 3643.0781 - val_loss: 0.0012 - val_mape: 3.1985\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.8205e-04 - mape: 16824.2402 - val_loss: 0.0015 - val_mape: 3.7600\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4292e-04 - mape: 634.3671 - val_loss: 0.0014 - val_mape: 3.7967\n",
      "--- 20/102 Training model for VRSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 98780.1250 - val_loss: 4.2790e-04 - val_mape: 2.3703\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 128620.5234 - val_loss: 0.0014 - val_mape: 2.9691\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 175809.2031 - val_loss: 0.0011 - val_mape: 2.9897\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 179349.9375 - val_loss: 5.6958e-04 - val_mape: 2.0823\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 71300.7109 - val_loss: 8.3605e-04 - val_mape: 2.2706\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 70671.8906 - val_loss: 5.6199e-04 - val_mape: 2.3903\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mape: 33397.4141 - val_loss: 0.0021 - val_mape: 3.8786\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 182785.6094 - val_loss: 0.0015 - val_mape: 3.0747\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 19871.7422 - val_loss: 9.5595e-04 - val_mape: 3.4107\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 210740.8281 - val_loss: 0.0018 - val_mape: 3.4802\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 45675.1523 - val_loss: 0.0013 - val_mape: 3.4069\n",
      "--- 21/102 Training model for TSLA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mape: 4292.5044 - val_loss: 7.8389e-04 - val_mape: 5.7010\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 2937.8667 - val_loss: 4.0763e-04 - val_mape: 4.0531\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 21472.9297 - val_loss: 2.1633e-04 - val_mape: 2.2048\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mape: 27433.1094 - val_loss: 7.8331e-05 - val_mape: 1.4591\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 42561.7344 - val_loss: 1.4165e-04 - val_mape: 1.8535\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 14021.5137 - val_loss: 2.0258e-04 - val_mape: 2.6357\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 43392.6055 - val_loss: 1.1482e-04 - val_mape: 1.8534\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 15667.0811 - val_loss: 8.4683e-05 - val_mape: 1.4871\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 32466.2422 - val_loss: 4.7930e-04 - val_mape: 4.5384\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 14470.9053 - val_loss: 2.3696e-04 - val_mape: 2.3731\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 29829.9238 - val_loss: 2.8383e-04 - val_mape: 3.1959\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 13751.8525 - val_loss: 2.1518e-04 - val_mape: 2.8759\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 1913.7333 - val_loss: 2.6707e-04 - val_mape: 3.1544\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 23262.7988 - val_loss: 2.1988e-04 - val_mape: 2.5130\n",
      "--- 22/102 Training model for NVDA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mape: 104735.8359 - val_loss: 2.1172e-04 - val_mape: 1.7584\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 46066.1250 - val_loss: 3.2125e-04 - val_mape: 2.3990\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mape: 89366.7344 - val_loss: 3.9945e-04 - val_mape: 2.6168\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 69446.7812 - val_loss: 3.1472e-04 - val_mape: 2.3354\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 53784.3320 - val_loss: 2.5116e-04 - val_mape: 2.0906\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 121627.7578 - val_loss: 2.4646e-04 - val_mape: 2.0580\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 131463.4531 - val_loss: 2.5227e-04 - val_mape: 2.0297\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 122148.9453 - val_loss: 3.0676e-04 - val_mape: 2.2978\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4997e-04 - mape: 57148.2148 - val_loss: 2.8437e-04 - val_mape: 2.1807\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5435e-04 - mape: 67163.7031 - val_loss: 3.1433e-04 - val_mape: 2.0322\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2958e-04 - mape: 78024.0547 - val_loss: 3.5376e-04 - val_mape: 2.4880\n",
      "--- 23/102 Training model for CPRT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 107.4726 - val_loss: 6.9868e-04 - val_mape: 2.4893\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 162.5733 - val_loss: 0.0038 - val_mape: 6.5485\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 130.8755 - val_loss: 0.0024 - val_mape: 5.1133\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 155.5335 - val_loss: 0.0024 - val_mape: 5.0687\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 136.0130 - val_loss: 0.0050 - val_mape: 7.4796\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 153.7445 - val_loss: 0.0010 - val_mape: 2.8560\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 192.7495 - val_loss: 0.0055 - val_mape: 7.9042\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 159.6097 - val_loss: 5.2957e-04 - val_mape: 1.9864\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 194.0343 - val_loss: 0.0069 - val_mape: 8.8874\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 112.6441 - val_loss: 4.1821e-04 - val_mape: 1.8787\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mape: 175.7982 - val_loss: 0.0144 - val_mape: 13.0896\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 140.5148 - val_loss: 0.0027 - val_mape: 4.9401\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mape: 272.0203 - val_loss: 0.0072 - val_mape: 9.1790\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mape: 181.0966 - val_loss: 0.0035 - val_mape: 6.0211\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0063 - mape: 442.2112 - val_loss: 0.0057 - val_mape: 8.0655\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 157.8508 - val_loss: 0.0101 - val_mape: 10.5505\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mape: 458.6150 - val_loss: 0.0016 - val_mape: 3.6492\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mape: 228.4973 - val_loss: 0.0074 - val_mape: 8.9993\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mape: 383.1022 - val_loss: 6.9087e-04 - val_mape: 2.0796\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - mape: 296.3990 - val_loss: 0.0051 - val_mape: 7.3972\n",
      "--- 24/102 Training model for ORLY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - mape: 96504.9297 - val_loss: 4.8212e-04 - val_mape: 1.8978\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mape: 79676.5859 - val_loss: 7.4418e-04 - val_mape: 2.2344\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 147394.0156 - val_loss: 3.4016e-04 - val_mape: 1.6339\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 57564.9023 - val_loss: 0.0022 - val_mape: 4.4679\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0055 - mape: 184574.6094 - val_loss: 4.9100e-04 - val_mape: 1.8535\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.7559e-04 - mape: 67138.3594 - val_loss: 8.2212e-04 - val_mape: 2.3889\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 151664.6562 - val_loss: 3.1142e-04 - val_mape: 1.6818\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9173e-04 - mape: 38632.9609 - val_loss: 9.4104e-04 - val_mape: 2.7335\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mape: 827.2762 - val_loss: 6.9073e-04 - val_mape: 2.3350\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 83174.1953 - val_loss: 0.0013 - val_mape: 3.2377\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 106601.7734 - val_loss: 4.0416e-04 - val_mape: 1.6897\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8819e-04 - mape: 17268.0410 - val_loss: 6.1270e-04 - val_mape: 2.2062\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mape: 96451.1250 - val_loss: 0.0021 - val_mape: 4.6901\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mape: 62609.1602 - val_loss: 0.0010 - val_mape: 2.7318\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 8087.8003 - val_loss: 0.0017 - val_mape: 3.8106\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 2861.7126 - val_loss: 9.1891e-04 - val_mape: 2.5328\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 26009.8594 - val_loss: 0.0022 - val_mape: 4.2818\n",
      "--- 25/102 Training model for CSGP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mape: 31.0422 - val_loss: 6.2283e-04 - val_mape: 2.3079\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mape: 51.4626 - val_loss: 9.0018e-04 - val_mape: 3.0284\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.4022 - val_loss: 9.7298e-04 - val_mape: 3.4057\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mape: 30.5028 - val_loss: 8.1337e-04 - val_mape: 2.5047\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 41.0735 - val_loss: 9.2604e-04 - val_mape: 3.1767\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mape: 64.9062 - val_loss: 9.7092e-04 - val_mape: 2.8004\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mape: 46.0269 - val_loss: 0.0013 - val_mape: 3.3082\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mape: 79.2686 - val_loss: 0.0010 - val_mape: 3.1118\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mape: 48.2369 - val_loss: 0.0017 - val_mape: 3.7428\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0074 - mape: 117.4258 - val_loss: 0.0019 - val_mape: 5.1253\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mape: 53.7324 - val_loss: 0.0029 - val_mape: 5.2507\n",
      "--- 26/102 Training model for PDD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - mape: 191130.5156 - val_loss: 0.0138 - val_mape: 18.6606\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072 - mape: 354939.6250 - val_loss: 3.0101e-04 - val_mape: 2.1850\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 15822.4326 - val_loss: 0.0011 - val_mape: 5.3231\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - mape: 76478.7109 - val_loss: 0.0018 - val_mape: 6.7043\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - mape: 74422.2734 - val_loss: 0.0040 - val_mape: 10.2018\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - mape: 24374.1055 - val_loss: 0.0040 - val_mape: 10.2866\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mape: 27108.9980 - val_loss: 0.0035 - val_mape: 9.6628\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - mape: 108395.5547 - val_loss: 9.8619e-04 - val_mape: 5.0378\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mape: 224963.5156 - val_loss: 0.0017 - val_mape: 6.2570\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 219174.2656 - val_loss: 6.7948e-04 - val_mape: 3.6751\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mape: 313256.7188 - val_loss: 2.4099e-04 - val_mape: 2.0313\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 144600.3594 - val_loss: 2.4972e-04 - val_mape: 2.1455\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 118487.2422 - val_loss: 3.6283e-04 - val_mape: 2.7283\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 93827.8359 - val_loss: 4.7648e-04 - val_mape: 3.1833\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mape: 23296.3047 - val_loss: 2.0013e-04 - val_mape: 1.8986\n",
      "Epoch 16/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 230055.9062 - val_loss: 2.9764e-04 - val_mape: 2.3957\n",
      "Epoch 17/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 138941.3281 - val_loss: 1.1217e-04 - val_mape: 1.2369\n",
      "Epoch 18/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mape: 73154.1562 - val_loss: 1.2574e-04 - val_mape: 1.3837\n",
      "Epoch 19/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 234332.1094 - val_loss: 1.5974e-04 - val_mape: 1.6333\n",
      "Epoch 20/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 6999.1621 - val_loss: 1.7294e-04 - val_mape: 1.6775\n",
      "Epoch 21/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 11213.6553 - val_loss: 1.1090e-04 - val_mape: 1.2512\n",
      "Epoch 22/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mape: 157618.9844 - val_loss: 1.5945e-04 - val_mape: 1.6558\n",
      "Epoch 23/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 73085.7109 - val_loss: 1.0577e-04 - val_mape: 1.2258\n",
      "Epoch 24/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mape: 127005.9453 - val_loss: 3.3259e-04 - val_mape: 2.4539\n",
      "Epoch 25/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mape: 155732.3125 - val_loss: 0.0020 - val_mape: 6.4081\n",
      "Epoch 26/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - mape: 96620.1641 - val_loss: 0.0011 - val_mape: 4.4924\n",
      "Epoch 27/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - mape: 214914.1406 - val_loss: 0.0031 - val_mape: 8.4079\n",
      "Epoch 28/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - mape: 181391.5156 - val_loss: 0.0048 - val_mape: 10.8296\n",
      "Epoch 29/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 65628.0078 - val_loss: 0.0022 - val_mape: 7.5200\n",
      "Epoch 30/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mape: 124640.8672 - val_loss: 0.0016 - val_mape: 5.9345\n",
      "Epoch 31/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mape: 252979.2188 - val_loss: 0.0010 - val_mape: 4.5773\n",
      "Epoch 32/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mape: 291679.4688 - val_loss: 3.5462e-04 - val_mape: 2.4807\n",
      "Epoch 33/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - mape: 210933.6406 - val_loss: 2.4402e-04 - val_mape: 1.9915\n",
      "--- 27/102 Training model for HON ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 19.2188 - val_loss: 2.5310e-04 - val_mape: 1.5605\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mape: 17.8731 - val_loss: 2.0247e-04 - val_mape: 1.2421\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 18.8212 - val_loss: 2.1340e-04 - val_mape: 1.2873\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 20.6971 - val_loss: 2.4552e-04 - val_mape: 1.5297\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 19.7352 - val_loss: 3.6252e-04 - val_mape: 1.9144\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 16.3415 - val_loss: 1.8778e-04 - val_mape: 1.3086\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mape: 23.0524 - val_loss: 6.7795e-04 - val_mape: 2.8124\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 19.1185 - val_loss: 1.1872e-04 - val_mape: 0.9607\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mape: 25.6618 - val_loss: 2.3064e-04 - val_mape: 1.4447\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mape: 18.0465 - val_loss: 1.4924e-04 - val_mape: 1.0842\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mape: 21.3544 - val_loss: 2.2628e-04 - val_mape: 1.4377\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mape: 21.3314 - val_loss: 1.4369e-04 - val_mape: 1.0576\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mape: 20.5559"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.data.make_dataset import load_list, get_stock_data\n",
    "from src.models.StockModel import StockModel\n",
    "window_size = 20\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2024-09-01'\n",
    "feature_columns = ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
    "target = \"Open\"\n",
    "\n",
    "# Load symbols\n",
    "nasdaq_symbols = load_list(\"NASDAQ\")\n",
    "sp500_symbols = load_list(\"SP500\")\n",
    "\n",
    "# Test tickers, sp500 symbols not also in nasdaq\n",
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:100]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC']\n",
    "train_tickers = ['^IXIC'] + nasdaq_symbols\n",
    "#train_tickers = train_tickers[:51]\n",
    "\n",
    "# Download data\n",
    "combined_data = get_stock_data(train_tickers, \"1d\", start_date, end_date)\n",
    "combined_data.info()\n",
    "# Test data\n",
    "test_data = get_stock_data(test_tickers, \"1d\", start_date, end_date)\n",
    "\n",
    "layer_config = [(3,32),(3,64)]\n",
    "for i in layer_config:\n",
    "    print(f\"XXXXXXXXXXXXXXXX Running {i[0]} {i[1]} layers XXXXXXXXXXXXXXXXXXXX\")\n",
    "    # Create and train model\n",
    "    stock_model = StockModel(window_size=window_size, feature_columns=feature_columns, target_name=target, export=True)\n",
    "    \n",
    "    stock_model.train(combined_data, patience=10, epochs=150, graph=False, layers=i[0], units_per_layer=i[1])\n",
    "    metrics_dict, metrics_summary = stock_model.evaluate_many(test_data, graph=False)\n",
    "    print(metrics_dict)\n",
    "    print(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:5]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC', '^DJI']\n",
    "# Test data\n",
    "test_data = get_stock_data([\"^GSPC\", \"^DJI\"], \"1d\", start_date, end_date)\n",
    "\n",
    "metrics_dict, mean_metrics = stock_model.evaluate_many(test_data, graph=True)\n",
    "print(metrics_dict)\n",
    "print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
