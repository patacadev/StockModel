{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 94076 entries, 2017-01-03 00:00:00-05:00 to 2024-08-30 00:00:00-04:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          94076 non-null  float64\n",
      " 1   High          94076 non-null  float64\n",
      " 2   Low           94076 non-null  float64\n",
      " 3   Close         94076 non-null  float64\n",
      " 4   Volume        94076 non-null  int64  \n",
      " 5   Dividends     94076 non-null  float64\n",
      " 6   Stock Splits  94076 non-null  float64\n",
      " 7   Ticker        94076 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 6.5+ MB\n",
      "XXXXXXXXXXXXXXXX Running 1 128 layers XXXXXXXXXXXXXXXXXXXX\n",
      "Initializing model:\n",
      " - Window size: 20\n",
      " - Features: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
      " - Target: Open\n",
      "--- Preparing ^IXIC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.47700000e+03  5.44091016e+03  8.72110000e+08  1.43798828e+01\n",
      " -1.06362988e+03  1.16226960e+01 -6.03732918e+02 -1.85963467e+02]\n",
      "Feature max [1.86474492e+04 1.86592500e+04 1.19326000e+10 8.98230469e+02\n",
      " 5.16000000e+02 1.00000000e+02 3.79729000e+02 1.68559430e+02]\n",
      "Target min [5425.62011719]\n",
      "Target max [18659.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRTX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.70500031e+01  7.52200012e+01  3.00500000e+05  9.29992676e-01\n",
      " -4.39099884e+01  6.98832867e+00 -1.61057278e+01 -6.35634960e+00]\n",
      "Feature max [5.05779999e+02 5.07040009e+02 1.74930000e+07 3.32000122e+01\n",
      " 2.96399994e+01 1.00000000e+02 1.72224200e+01 7.01903411e+00]\n",
      "Target min [74.43000031]\n",
      "Target max [507.04000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PYPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93100014e+01  3.94000015e+01  1.68000000e+06  2.79998779e-01\n",
      " -3.59100037e+01  5.36242303e+00 -1.82619484e+01 -6.83508729e+00]\n",
      "Feature max [3.08529999e+02 3.09660004e+02 1.36264000e+08 2.25299988e+01\n",
      " 1.48899994e+01 1.00000000e+02 1.63896973e+01 4.70789452e+00]\n",
      "Target min [39.40000153]\n",
      "Target max [309.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GILD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.83768921e+01  4.84647841e+01  1.93100000e+06  3.33687013e-01\n",
      " -6.63972958e+00  5.76429643e+00 -2.31350264e+00 -8.99640092e-01]\n",
      "Feature max [8.53581619e+01 8.44682978e+01 9.43485000e+07 8.04050698e+00\n",
      " 7.22807397e+00 1.00000000e+02 4.20840186e+00 1.25684670e+00]\n",
      "Target min [48.46478409]\n",
      "Target max [84.46829781]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.10076237e+01  1.08333294e+01  2.58690000e+06  1.03459220e-01\n",
      " -2.80620499e+00  6.42020381e+00 -2.09796529e+00 -6.88387246e-01]\n",
      "Feature max [3.81064873e+01 3.81660578e+01 2.95518300e+08 2.47469078e+00\n",
      " 2.03002009e+00 1.00000000e+02 1.17294696e+00 5.41764687e-01]\n",
      "Target min [10.83332938]\n",
      "Target max [38.16605779]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing IDXX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.15949997e+02  1.15989998e+02  6.95000000e+04  1.01998901e+00\n",
      " -5.39599915e+01  0.00000000e+00 -4.51944855e+01 -1.18420530e+01]\n",
      "Feature max [7.05760010e+02 6.98869995e+02 2.06065000e+07 4.94200134e+01\n",
      " 2.44899902e+01 9.87477702e+01 2.80133056e+01 9.19398448e+00]\n",
      "Target min [115.98999786]\n",
      "Target max [698.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.72258072e+01  4.72942329e+01  4.40100000e+05  2.32199924e-01\n",
      " -6.70203006e+00  0.00000000e+00 -5.58792171e+00 -1.85080567e+00]\n",
      "Feature max [1.00876343e+02 1.03304346e+02 2.24557000e+07 1.05535592e+01\n",
      " 3.30011799e+00 1.00000000e+02 2.91608734e+00 1.39528234e+00]\n",
      "Target min [47.29423289]\n",
      "Target max [103.30434621]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TEAM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.47199993e+01  2.47299995e+01  2.10900000e+05  2.16999054e-01\n",
      " -4.31699982e+01  1.07833899e+01 -2.66488051e+01 -8.97255197e+00]\n",
      "Feature max [4.58130005e+02 4.55200012e+02 1.74562000e+07 4.22299805e+01\n",
      " 4.32099915e+01 1.00000000e+02 2.40637139e+01 8.94966359e+00]\n",
      "Target min [24.31999969]\n",
      "Target max [455.20001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PANW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.60033340e+01  3.61399994e+01  1.02260000e+06  3.56666565e-01\n",
      " -9.08899841e+01  3.81140920e+00 -1.38470391e+01 -1.22788064e+01]\n",
      "Feature max [3.76899994e+02 3.75450012e+02 6.53592000e+07 2.73699951e+01\n",
      " 2.68099976e+01 1.00000000e+02 1.51691964e+01 4.87990591e+00]\n",
      "Target min [36.13999939]\n",
      "Target max [375.45001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AVGO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.37303324e+01  1.37248174e+01  4.12300000e+06  1.24250219e-01\n",
      " -1.42100067e+01  0.00000000e+00 -5.06872189e+00 -3.00550723e+00]\n",
      "Feature max [1.82308105e+02 1.83376725e+02 4.35083000e+08 1.69199982e+01\n",
      " 2.13810994e+01 9.28312266e+01 1.05782566e+01 4.55284581e+00]\n",
      "Target min [13.72481739]\n",
      "Target max [183.37672469]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CEG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.08016357e+01  3.98784499e+01  2.35000000e+04  6.26233823e-01\n",
      " -1.08198405e+01  1.27016955e+01 -1.06308757e+01 -3.92755151e+00]\n",
      "Feature max [2.30487686e+02 2.31952715e+02 2.38609000e+07 2.15543358e+01\n",
      " 2.45442808e+01 1.00000000e+02 1.44754867e+01 4.38796659e+00]\n",
      "Target min [37.00563649]\n",
      "Target max [231.9527148]\n",
      "X_train shape: (637, 20, 8)\n",
      "Train_dates: 2022-01-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MSFT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.65738716e+01  5.64739814e+01  7.42560000e+06  2.90591318e-01\n",
      " -1.92852005e+01  0.00000000e+00 -1.18035322e+01 -4.62579684e+00]\n",
      "Feature max [4.66718781e+02 4.66159796e+02 1.11242100e+08 2.43750285e+01\n",
      " 2.10308765e+01 9.87205903e+01 1.16126197e+01 3.05457761e+00]\n",
      "Target min [56.4739814]\n",
      "Target max [466.15979612]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EXC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.82024384e+01  1.85263383e+01  2.00850500e+06  1.22239479e-01\n",
      " -1.93681767e+00  5.27401978e+00 -2.56103502e+00 -9.27310413e-01]\n",
      "Feature max [4.59507675e+01 4.58593246e+01 3.88453000e+07 4.14685444e+00\n",
      " 1.20619631e+00 1.00000000e+02 1.62739185e+00 5.65170278e-01]\n",
      "Target min [18.52633834]\n",
      "Target max [45.8593246]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DXCM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.11149998e+01  1.10325003e+01  8.61200000e+05  1.64999962e-01\n",
      " -4.18499985e+01  4.43708879e+00 -1.21858259e+01 -5.03116733e+00]\n",
      "Feature max [1.62815002e+02 1.64257507e+02 1.23168400e+08 1.88925018e+01\n",
      " 1.24700012e+01 1.00000000e+02 8.60785647e+00 2.40813081e+00]\n",
      "Target min [11.03250027]\n",
      "Target max [164.25750732]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FAST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65418415e+01  1.66370276e+01  7.04500000e+05  1.46829925e-01\n",
      " -3.17296730e+00  2.73472132e+00 -1.96586911e+00 -1.08293915e+00]\n",
      "Feature max [7.75266724e+01 7.77145119e+01 5.26096000e+07 4.66000366e+00\n",
      " 3.55978900e+00 1.00000000e+02 1.87048215e+00 8.56669819e-01]\n",
      "Target min [16.63702755]\n",
      "Target max [77.71451195]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ABNB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.24899979e+01  8.29700012e+01  1.72560000e+06  1.01499939e+00\n",
      " -1.80299988e+01  0.00000000e+00 -1.29513658e+01 -4.57280582e+00]\n",
      "Feature max [2.16839996e+02 2.16240005e+02 7.47864000e+07 3.05000000e+01\n",
      " 1.21199951e+01 9.29350181e+01 1.31150691e+01 3.98198040e+00]\n",
      "Target min [82.97000122]\n",
      "Target max [216.24000549]\n",
      "X_train shape: (915, 20, 8)\n",
      "Train_dates: 2020-12-11 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SNPS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.95699997e+01  5.93699989e+01  2.00200000e+05  2.60002136e-01\n",
      " -3.66699829e+01  7.61484664e+00 -2.46719247e+01 -8.22743530e+00]\n",
      "Feature max [6.21299988e+02 6.22929993e+02 3.02946000e+07 5.02700195e+01\n",
      " 4.64199829e+01 1.00000000e+02 2.12557667e+01 8.46134558e+00]\n",
      "Target min [59.27000046]\n",
      "Target max [622.92999268]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BIIB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [187.53999329 190.55999756   0.           0.         -98.07998657\n",
      "   4.79436191 -25.57434546 -11.64517675]\n",
      "Feature max [4.14709991e+02 4.23329987e+02 2.18431000e+07 1.82549988e+02\n",
      " 8.64900055e+01 1.00000000e+02 3.49582846e+01 1.62224245e+01]\n",
      "Target min [190.55999756]\n",
      "Target max [423.32998657]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing REGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.73459991e+02  2.74350006e+02  1.71600000e+05  2.76998901e+00\n",
      " -4.76300049e+01  6.11531109e+00 -2.90962700e+01 -1.14012185e+01]\n",
      "Feature max [1.20176001e+03 1.20471997e+03 7.86950000e+06 8.12899780e+01\n",
      " 9.05499878e+01 1.00000000e+02 3.48632110e+01 1.33649620e+01]\n",
      "Target min [274.3500061]\n",
      "Target max [1204.7199707]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.40612183e+01  7.38682278e+01  1.45000000e+05  3.47388758e-01\n",
      " -1.39151339e+01  7.46563833e+00 -1.02972301e+01 -4.01614363e+00]\n",
      "Feature max [2.85989990e+02 2.85000000e+02 4.24820000e+06 1.72982830e+01\n",
      " 1.09380049e+01 1.00000000e+02 7.65713957e+00 3.71764210e+00]\n",
      "Target min [73.8682278]\n",
      "Target max [285.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TSLA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.19313326e+01  1.20733328e+01  2.94018000e+07  1.66667938e-01\n",
      " -2.41000061e+01  6.91932630e+00 -2.52713333e+01 -7.67848148e+00]\n",
      "Feature max [4.09970001e+02 4.11470001e+02 9.14082000e+08 5.43266602e+01\n",
      " 3.25100098e+01 1.00000000e+02 3.80679297e+01 1.02961745e+01]\n",
      "Target min [12.07333279]\n",
      "Target max [411.47000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NVDA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35561490e+00  2.36844215e+00  9.78840000e+07  3.05890986e-02\n",
      " -1.52099991e+01  8.18788925e+00 -5.16786769e+00 -2.56494372e+00]\n",
      "Feature max [1.35580002e+02 1.39800003e+02 3.69292800e+09 1.33500061e+01\n",
      " 9.16999817e+00 1.00000000e+02 9.77617753e+00 2.89363431e+00]\n",
      "Target min [2.36844215]\n",
      "Target max [139.80000305]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CPRT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95749998e+00  6.97499990e+00  1.16560000e+06  4.75001335e-02\n",
      " -2.40999985e+00  1.07028555e+01 -2.08288713e+00 -5.95224464e-01]\n",
      "Feature max [5.80699997e+01 5.81300011e+01 2.13690400e+08 3.43000031e+00\n",
      " 1.91999817e+00 1.00000000e+02 1.68053820e+00 5.29970520e-01]\n",
      "Target min [6.94750023]\n",
      "Target max [58.13000107]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ORLY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.72850006e+02  1.72839996e+02  9.76000000e+04  1.75000000e+00\n",
      " -7.26999512e+01  9.93704967e+00 -3.18757122e+01 -1.55376421e+01]\n",
      "Feature max [1.16753003e+03 1.16473999e+03 1.28304000e+07 6.14700928e+01\n",
      " 3.95399780e+01 1.00000000e+02 2.94044788e+01 1.46112531e+01]\n",
      "Target min [172.83999634]\n",
      "Target max [1164.73999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSGP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.90799999e+01  1.86439991e+01  4.31000000e+05  1.32999420e-01\n",
      " -1.35200005e+01  3.82196899e+00 -3.91839760e+00 -1.70338203e+00]\n",
      "Feature max [9.97399979e+01 9.96600037e+01 5.40349000e+07 1.53570023e+01\n",
      " 2.22259979e+01 1.00000000e+02 3.78952594e+00 1.64810768e+00]\n",
      "Target min [18.6439991]\n",
      "Target max [99.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PDD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.71499996e+01  1.72000008e+01  1.21070000e+06  3.10001373e-01\n",
      " -2.96699982e+01  0.00000000e+00 -1.20781712e+01 -6.25067404e+00]\n",
      "Feature max [2.02820007e+02 2.11600006e+02 1.03174600e+08 2.12799988e+01\n",
      " 2.67000046e+01 9.22446129e+01 1.43527401e+01 4.73466591e+00]\n",
      "Target min [17.20000076]\n",
      "Target max [211.6000061]\n",
      "X_train shape: (1514, 20, 8)\n",
      "Train_dates: 2018-07-27 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing HON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.46234360e+01  9.52324076e+01  6.25500000e+05  4.19023052e-01\n",
      " -1.95059016e+01  4.75278607e+00 -1.40929698e+01 -4.45800843e+00]\n",
      "Feature max [2.19502502e+02 2.19940296e+02 2.82371000e+07 2.09818749e+01\n",
      " 1.90410089e+01 1.00000000e+02 8.86861072e+00 3.23137307e+00]\n",
      "Target min [95.2324076]\n",
      "Target max [219.94029556]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.14207611e+01  6.16446746e+01  4.66400000e+05  4.04764990e-01\n",
      " -1.59855186e+01  0.00000000e+00 -6.96255526e+00 -3.47483258e+00]\n",
      "Feature max [2.42376740e+02 2.39537898e+02 1.91564000e+07 1.54971600e+01\n",
      " 1.14345345e+01 9.47163396e+01 9.37402072e+00 2.80709341e+00]\n",
      "Target min [61.64467465]\n",
      "Target max [239.53789776]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.30818100e+01  7.35512493e+01  5.83900000e+05  5.47719845e-01\n",
      " -1.30866480e+01  5.85108252e+00 -5.68716510e+00 -2.63117508e+00]\n",
      "Feature max [1.51820007e+02 1.50807724e+02 3.87045000e+07 1.23726545e+01\n",
      " 1.06121148e+01 1.00000000e+02 4.99350087e+00 2.11381268e+00]\n",
      "Target min [73.55124929]\n",
      "Target max [150.80772389]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.64580727e+01  1.71472504e+01  1.14310000e+06  1.73414616e-01\n",
      " -9.42169789e+00  0.00000000e+00 -3.04021934e+00 -1.40459929e+00]\n",
      "Feature max [6.87902832e+01 6.75091317e+01 1.35204800e+08 4.21353693e+00\n",
      " 3.35944971e+00 9.56385384e+01 1.17085491e+00 5.30558464e-01]\n",
      "Target min [17.14725043]\n",
      "Target max [67.50913169]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WBD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.71000004e+00  6.67000008e+00  7.96300000e+05  1.29999638e-01\n",
      " -4.63999939e+00  7.36432776e+00 -5.62270475e+00 -4.52551421e+00]\n",
      "Feature max [7.72699966e+01 7.79800034e+01 1.58082500e+08 2.36100006e+01\n",
      " 3.59000015e+00 1.00000000e+02 7.78521295e+00 1.10191292e+00]\n",
      "Target min [6.67000008]\n",
      "Target max [77.98000336]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.77167328e+02  1.76918230e+02  1.00700000e+05  1.05556125e+00\n",
      " -7.16817807e+01  1.01359214e+01 -2.43843415e+01 -7.21921351e+00]\n",
      "Feature max [5.76549988e+02 5.77500000e+02 8.03490000e+06 6.23608649e+01\n",
      " 3.51599731e+01 1.00000000e+02 1.65133374e+01 6.23603615e+00]\n",
      "Target min [176.71795625]\n",
      "Target max [577.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15072441  8.44775229  0.          0.         -2.64121934  0.\n",
      " -2.42761184 -0.84240932]\n",
      "Feature max [3.84843826e+01 3.84346839e+01 7.90905000e+07 3.35121803e+00\n",
      " 2.26196184e+00 9.66592825e+01 2.24860583e+00 6.65253741e-01]\n",
      "Target min [8.44775229]\n",
      "Target max [38.43468386]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing COST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.34840027e+02  1.34848979e+02  5.43600000e+05  6.44244141e-01\n",
      " -2.94507776e+01  7.85629341e+00 -3.22091486e+01 -9.48258088e+00]\n",
      "Feature max [9.08900024e+02 9.10960022e+02 2.42330000e+07 4.41770966e+01\n",
      " 1.44716264e+01 1.00000000e+02 2.40226275e+01 6.93894978e+00]\n",
      "Target min [134.84897936]\n",
      "Target max [910.96002197]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.09898186e+01  2.08327099e+01  7.55800000e+05  1.13624071e-01\n",
      " -4.94520049e+00  1.11788092e+01 -2.60963603e+00 -8.58607909e-01]\n",
      "Feature max [8.76200027e+01 8.73300018e+01 6.55402000e+07 7.22391984e+00\n",
      " 4.14095187e+00 1.00000000e+02 2.45854722e+00 7.89947576e-01]\n",
      "Target min [20.83270988]\n",
      "Target max [87.33000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LRCX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.58611450e+01  9.56820789e+01  3.00600000e+05  6.44566123e-01\n",
      " -6.64899902e+01  8.02011760e+00 -6.76982729e+01 -2.23238752e+01]\n",
      "Feature max [1.12730005e+03 1.12977002e+03 1.34214000e+07 7.38499756e+01\n",
      " 3.86400146e+01 1.00000000e+02 3.73546198e+01 1.44478835e+01]\n",
      "Target min [95.50305089]\n",
      "Target max [1129.77001953]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MELI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65434570e+02  1.61862890e+02  1.09000000e+05  1.65614527e+00\n",
      " -1.47979980e+02  6.42065563e+00 -1.26762239e+02 -4.86753050e+01]\n",
      "Feature max [2.06165991e+03 2.03525000e+03 4.29950000e+06 1.80000000e+02\n",
      " 1.14010010e+02 1.00000000e+02 9.65798543e+01 4.12565588e+01]\n",
      "Target min [158.54064047]\n",
      "Target max [2035.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.67368202e+01  4.67459702e+01  1.82100000e+05  3.48899250e-01\n",
      " -2.61501151e+01  1.10567815e+01 -1.16427000e+01 -2.77844166e+00]\n",
      "Feature max [2.56499237e+02 2.59970663e+02 2.45494000e+07 1.57643685e+01\n",
      " 1.15215616e+01 1.00000000e+02 6.29487366e+00 2.94088535e+00]\n",
      "Target min [46.74597021]\n",
      "Target max [259.97066279]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FANG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.26427393e+01  1.29027437e+01  2.62100000e+05  7.69125581e-01\n",
      " -1.58440536e+01  1.03147586e+00 -1.19967650e+01 -3.84871246e+00]\n",
      "Feature max [2.08427399e+02 2.08555865e+02 3.30497000e+07 1.22028993e+01\n",
      " 7.94710827e+00 1.00000000e+02 7.18674571e+00 2.89178313e+00]\n",
      "Target min [12.90274369]\n",
      "Target max [208.55586459]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ZS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.49500008e+01  2.50000000e+01  1.97200000e+05  3.79999161e-01\n",
      " -3.88899994e+01  0.00000000e+00 -2.36812080e+01 -8.89085502e+00]\n",
      "Feature max [3.68779999e+02 3.72500000e+02 2.68458000e+07 5.90399780e+01\n",
      " 2.63500061e+01 9.43483988e+01 1.81146072e+01 6.76156951e+00]\n",
      "Target min [25.]\n",
      "Target max [372.5]\n",
      "X_train shape: (1605, 20, 8)\n",
      "Train_dates: 2018-03-19 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADBE data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.04139999e+02  1.03739998e+02  5.89200000e+05  6.49993896e-01\n",
      " -7.08099976e+01  1.41851355e+00 -3.26176172e+01 -1.20971259e+01]\n",
      "Feature max [6.88369995e+02 6.96280029e+02 2.78402000e+07 5.77900391e+01\n",
      " 7.15100098e+01 1.00000000e+02 3.08100807e+01 9.11981859e+00]\n",
      "Target min [103.43000031]\n",
      "Target max [696.2800293]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93002777e+01  3.92593243e+01  6.93600000e+06  1.63815054e-01\n",
      " -1.10299988e+01  1.33774083e+01 -5.19036880e+00 -2.41195015e+00]\n",
      "Feature max [1.92660004e+02 1.91750000e+02 1.24140000e+08 9.33999634e+00\n",
      " 1.80194956e+01 1.00000000e+02 5.21262163e+00 1.68897131e+00]\n",
      "Target min [38.8962372]\n",
      "Target max [191.75]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMAT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.72328167e+01  2.75991753e+01  1.40920000e+06  2.48054590e-01\n",
      " -1.45720706e+01  1.10477914e+01 -1.30488603e+01 -4.80425105e+00]\n",
      "Feature max [2.54482300e+02 2.55081164e+02 5.25842000e+07 1.67279368e+01\n",
      " 1.42822510e+01 1.00000000e+02 1.06164147e+01 3.45275434e+00]\n",
      "Target min [27.59917534]\n",
      "Target max [255.0811642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.12595749e+01  8.12424824e+01  3.50200000e+05  3.94597419e-01\n",
      " -1.50322602e+01  3.70819088e+00 -1.35625543e+01 -3.90767243e+00]\n",
      "Feature max [2.75910004e+02 2.75790009e+02 2.98376000e+07 1.78119307e+01\n",
      " 1.03888203e+01 1.00000000e+02 1.01973409e+01 2.87688222e+00]\n",
      "Target min [81.24248244]\n",
      "Target max [275.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SBUX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.25571442e+01  4.21538439e+01  1.84780000e+06  2.41612853e-01\n",
      " -1.24990574e+01  3.06340275e+00 -6.61673815e+00 -1.77160421e+00]\n",
      "Feature max [1.17301460e+02 1.17320081e+02 1.57215500e+08 8.91208038e+00\n",
      " 1.39059501e+01 1.00000000e+02 5.32951402e+00 2.47897411e+00]\n",
      "Target min [42.15384393]\n",
      "Target max [117.32008083]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTWO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.93600006e+01  4.94000015e+01  2.11600000e+05  3.89999390e-01\n",
      " -1.71000061e+01  5.25756554e+00 -1.00961129e+01 -3.59837456e+00]\n",
      "Feature max [2.13339996e+02 2.10479996e+02 2.53857000e+07 1.86999969e+01\n",
      " 1.62300034e+01 1.00000000e+02 8.60457497e+00 3.04146889e+00]\n",
      "Target min [49.34999847]\n",
      "Target max [210.47999573]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TMUS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.45139275e+01  5.45139255e+01  4.70100000e+05  2.26488207e-01\n",
      " -9.75855268e+00  9.14573089e+00 -4.12801837e+00 -2.00070086e+00]\n",
      "Feature max [2.03367172e+02 2.04613114e+02 6.69031000e+07 1.24074312e+01\n",
      " 1.02607535e+01 1.00000000e+02 5.13087004e+00 2.60923757e+00]\n",
      "Target min [54.51392553]\n",
      "Target max [204.61311436]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WDAY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.13600006e+01  6.86699982e+01  3.69100000e+05  7.19993591e-01\n",
      " -2.87099915e+01  9.22365714e+00 -1.61351526e+01 -5.44748712e+00]\n",
      "Feature max [3.07209991e+02 3.09100006e+02 1.56112000e+07 2.13899994e+01\n",
      " 3.39099884e+01 1.00000000e+02 1.38299273e+01 6.22001392e+00]\n",
      "Target min [66.75]\n",
      "Target max [309.1000061]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CRWD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.30099983e+01  3.39300003e+01  8.04900000e+05  1.25000000e+00\n",
      " -4.85399780e+01  5.38771656e+00 -3.82154109e+01 -1.52669393e+01]\n",
      "Feature max [3.92149994e+02 3.92510010e+02 5.40774000e+07 4.09899902e+01\n",
      " 6.24899902e+01 1.00000000e+02 1.92436948e+01 8.51986054e+00]\n",
      "Target min [33.93000031]\n",
      "Target max [392.51000977]\n",
      "X_train shape: (1294, 20, 8)\n",
      "Train_dates: 2019-06-13 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DDOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.80400009e+01  2.78999996e+01  5.74800000e+05  7.30003357e-01\n",
      " -2.19200058e+01  0.00000000e+00 -1.14620833e+01 -4.12330397e+00]\n",
      "Feature max [1.96559998e+02 1.97695999e+02 2.91348000e+07 2.36900024e+01\n",
      " 2.69400024e+01 9.94039849e+01 1.14713512e+01 4.87120929e+00]\n",
      "Target min [27.89999962]\n",
      "Target max [197.69599915]\n",
      "X_train shape: (1225, 20, 8)\n",
      "Train_dates: 2019-09-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PCAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.86600723e+01  2.83693944e+01  4.95450000e+05  1.76137070e-01\n",
      " -1.04065623e+01  7.26975186e+00 -3.26233711e+00 -1.44177860e+00]\n",
      "Feature max [1.23713150e+02 1.24249916e+02 1.21321500e+07 7.01745891e+00\n",
      " 3.03884635e+00 1.00000000e+02 4.25862738e+00 1.04586866e+00]\n",
      "Target min [28.36939438]\n",
      "Target max [124.24991579]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">70,144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m70,144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,273</span> (274.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,273\u001b[0m (274.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,273</span> (274.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,273\u001b[0m (274.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/51 Training model for ^IXIC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0060 - mape: 66.4183 - val_loss: 0.0319 - val_mape: 18.3628\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0465 - mape: 314.7893 - val_loss: 0.0387 - val_mape: 22.6429\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0149 - mape: 171.3475 - val_loss: 0.0181 - val_mape: 15.3375\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - mape: 113.2003 - val_loss: 0.0065 - val_mape: 8.9519\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mape: 59.2133 - val_loss: 7.5253e-04 - val_mape: 2.8940\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8082e-04 - mape: 28.8168 - val_loss: 7.6011e-04 - val_mape: 3.0885\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3037e-04 - mape: 29.7631 - val_loss: 2.4403e-04 - val_mape: 1.4939\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3982e-04 - mape: 21.7394 - val_loss: 5.5117e-04 - val_mape: 2.6305\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0575e-04 - mape: 26.0365 - val_loss: 5.0761e-04 - val_mape: 2.4810\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mape: 46.7323 - val_loss: 6.6601e-04 - val_mape: 2.8227\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mape: 50.5661 - val_loss: 5.6765e-04 - val_mape: 2.4113\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mape: 48.1361 - val_loss: 7.7936e-04 - val_mape: 3.2333\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2047e-04 - mape: 29.5668 - val_loss: 7.3592e-04 - val_mape: 3.1046\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5393e-04 - mape: 33.5538 - val_loss: 3.1618e-04 - val_mape: 1.8667\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7168e-04 - mape: 18.0636 - val_loss: 3.3102e-04 - val_mape: 1.9352\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8655e-04 - mape: 27.8722 - val_loss: 3.8543e-04 - val_mape: 2.1094\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9111e-04 - mape: 34.0900 - val_loss: 3.5310e-04 - val_mape: 2.0189\n",
      "--- 2/51 Training model for VRTX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6567e-04 - mape: 12.4392 - val_loss: 7.4663e-04 - val_mape: 2.9354\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4786e-04 - mape: 18.0383 - val_loss: 0.0025 - val_mape: 5.6976\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mape: 29.6364 - val_loss: 7.2949e-04 - val_mape: 2.9457\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6906e-04 - mape: 10.8844 - val_loss: 3.0400e-04 - val_mape: 1.7252\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7315e-04 - mape: 22.7665 - val_loss: 3.7921e-04 - val_mape: 1.7705\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 22.2060 - val_loss: 0.0030 - val_mape: 6.1476\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - mape: 36.3465 - val_loss: 0.0019 - val_mape: 4.6915\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mape: 34.1239 - val_loss: 5.3145e-04 - val_mape: 2.2498\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mape: 31.4545 - val_loss: 1.8737e-04 - val_mape: 1.3823\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6271e-04 - mape: 11.8025 - val_loss: 5.5727e-04 - val_mape: 2.2769\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4137e-04 - mape: 9.1541 - val_loss: 9.7535e-04 - val_mape: 3.2382\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4214e-04 - mape: 17.6715 - val_loss: 3.1904e-04 - val_mape: 1.6214\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1663e-04 - mape: 17.5076 - val_loss: 0.0015 - val_mape: 4.2054\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1615e-04 - mape: 24.4375 - val_loss: 6.1461e-04 - val_mape: 2.4672\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9686e-04 - mape: 12.8832 - val_loss: 3.8681e-04 - val_mape: 1.8530\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9236e-04 - mape: 10.1315 - val_loss: 1.7899e-04 - val_mape: 1.3423\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9878e-04 - mape: 8.8839 - val_loss: 2.4335e-04 - val_mape: 1.3765\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4758e-04 - mape: 10.0633 - val_loss: 1.7587e-04 - val_mape: 1.3622\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6901e-04 - mape: 10.0150 - val_loss: 4.2203e-04 - val_mape: 1.9146\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7552e-04 - mape: 12.9508 - val_loss: 4.0521e-04 - val_mape: 1.8459\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9298e-04 - mape: 13.3783 - val_loss: 5.3146e-04 - val_mape: 2.2938\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5727e-04 - mape: 12.5098 - val_loss: 0.0012 - val_mape: 3.7830\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9656e-04 - mape: 10.4450 - val_loss: 8.9096e-04 - val_mape: 3.1597\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3697e-04 - mape: 9.2225 - val_loss: 0.0018 - val_mape: 4.5584\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 30.2981 - val_loss: 6.7148e-04 - val_mape: 2.6826\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5688e-04 - mape: 22.0941 - val_loss: 0.0022 - val_mape: 5.0590\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mape: 34.2698 - val_loss: 8.7371e-04 - val_mape: 2.9876\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0930e-04 - mape: 18.9651 - val_loss: 9.1979e-04 - val_mape: 3.1580\n",
      "--- 3/51 Training model for PYPL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0554e-04 - mape: 177664.2031 - val_loss: 2.5619e-04 - val_mape: 19.0383\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 106146.9922 - val_loss: 1.1094e-04 - val_mape: 10.9280\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 4589.2544 - val_loss: 4.3363e-04 - val_mape: 23.3154\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mape: 20707.9062 - val_loss: 1.3402e-04 - val_mape: 10.1640\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mape: 112943.8125 - val_loss: 0.0021 - val_mape: 53.4515\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mape: 17778.1797 - val_loss: 6.7660e-04 - val_mape: 29.1686\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - mape: 59225.1406 - val_loss: 1.3374e-04 - val_mape: 12.6265\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - mape: 145472.1719 - val_loss: 7.5934e-04 - val_mape: 31.9697\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0107 - mape: 233964.7656 - val_loss: 3.2719e-04 - val_mape: 19.7824\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - mape: 102850.4766 - val_loss: 7.4685e-04 - val_mape: 30.4439\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - mape: 243167.4219 - val_loss: 0.0010 - val_mape: 35.3381\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - mape: 78594.7734 - val_loss: 0.0015 - val_mape: 41.6925\n",
      "--- 4/51 Training model for GILD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - mape: 67747.0703 - val_loss: 6.8041e-04 - val_mape: 3.0521\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0570e-04 - mape: 25856.9629 - val_loss: 9.4395e-04 - val_mape: 3.9182\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6677e-04 - mape: 29876.6914 - val_loss: 0.0018 - val_mape: 5.8768\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9811e-04 - mape: 19396.8477 - val_loss: 0.0034 - val_mape: 8.7119\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 14352.3408 - val_loss: 0.0016 - val_mape: 5.6787\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6698e-04 - mape: 27028.9395 - val_loss: 0.0014 - val_mape: 5.3090\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8421e-04 - mape: 21809.1660 - val_loss: 0.0022 - val_mape: 6.7854\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8357e-04 - mape: 20938.5859 - val_loss: 0.0012 - val_mape: 4.6445\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3358e-04 - mape: 18354.6602 - val_loss: 0.0011 - val_mape: 4.4975\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6057e-04 - mape: 10724.0469 - val_loss: 8.6780e-04 - val_mape: 3.9247\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7446e-04 - mape: 3559.5415 - val_loss: 0.0010 - val_mape: 4.3289\n",
      "--- 5/51 Training model for CSX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 9.9248 - val_loss: 0.0021 - val_mape: 4.9764\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4484e-04 - mape: 8.7528 - val_loss: 5.2113e-04 - val_mape: 2.2138\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5395e-04 - mape: 8.8605 - val_loss: 2.3318e-04 - val_mape: 1.3734\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1464e-04 - mape: 8.0750 - val_loss: 2.5920e-04 - val_mape: 1.5431\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mape: 11.9354 - val_loss: 3.8013e-04 - val_mape: 1.9874\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 12.2778 - val_loss: 2.7832e-04 - val_mape: 1.5414\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9833e-04 - mape: 7.0449 - val_loss: 8.4629e-04 - val_mape: 3.1029\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7701e-04 - mape: 8.4811 - val_loss: 1.7268e-04 - val_mape: 1.1452\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9226e-04 - mape: 5.9057 - val_loss: 1.5047e-04 - val_mape: 1.0586\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7275e-04 - mape: 5.9526 - val_loss: 1.0448e-04 - val_mape: 0.8964\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6152e-04 - mape: 6.8239 - val_loss: 1.4921e-04 - val_mape: 1.0861\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3543e-04 - mape: 7.7632 - val_loss: 9.9672e-05 - val_mape: 0.8554\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8852e-04 - mape: 9.3648 - val_loss: 1.5019e-04 - val_mape: 1.0808\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3803e-04 - mape: 8.1449 - val_loss: 1.3613e-04 - val_mape: 1.0154\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0504e-04 - mape: 7.1554 - val_loss: 1.5758e-04 - val_mape: 1.1463\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5347e-04 - mape: 8.2244 - val_loss: 5.3305e-04 - val_mape: 2.4155\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8460e-04 - mape: 6.5124 - val_loss: 1.1847e-04 - val_mape: 0.9934\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5904e-04 - mape: 8.8202 - val_loss: 1.2817e-04 - val_mape: 1.1005\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3991e-04 - mape: 7.0914 - val_loss: 2.2104e-04 - val_mape: 1.5056\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6370e-04 - mape: 5.6502 - val_loss: 4.4796e-04 - val_mape: 2.1774\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6189e-04 - mape: 6.3578 - val_loss: 1.0605e-04 - val_mape: 0.8813\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1850e-04 - mape: 5.4160 - val_loss: 3.2512e-04 - val_mape: 1.7977\n",
      "--- 6/51 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mape: 30.7629 - val_loss: 5.3415e-04 - val_mape: 3.0561\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6798e-04 - mape: 25.9151 - val_loss: 9.1140e-04 - val_mape: 4.2429\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7359e-04 - mape: 16.2343 - val_loss: 0.0011 - val_mape: 4.6900\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7227e-04 - mape: 13.0159 - val_loss: 3.9362e-04 - val_mape: 2.5869\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4832e-04 - mape: 17.9808 - val_loss: 4.6402e-04 - val_mape: 2.8319\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0583e-04 - mape: 9.9538 - val_loss: 9.1921e-04 - val_mape: 4.1701\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1731e-04 - mape: 13.3710 - val_loss: 9.6544e-05 - val_mape: 1.0972\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6738e-04 - mape: 20.5440 - val_loss: 0.0025 - val_mape: 7.1381\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2655e-04 - mape: 16.2669 - val_loss: 8.8163e-05 - val_mape: 1.0433\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mape: 42.4127 - val_loss: 0.0014 - val_mape: 5.2715\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6353e-04 - mape: 19.9732 - val_loss: 8.9227e-05 - val_mape: 1.0290\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7853e-04 - mape: 19.3875 - val_loss: 1.8076e-04 - val_mape: 1.5984\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7201e-04 - mape: 9.0222 - val_loss: 1.1475e-04 - val_mape: 1.2114\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5930e-04 - mape: 16.5156 - val_loss: 3.3848e-04 - val_mape: 2.3692\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0833e-04 - mape: 8.9207 - val_loss: 1.0529e-04 - val_mape: 1.1404\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7149e-04 - mape: 13.1404 - val_loss: 0.0011 - val_mape: 4.5786\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5632e-04 - mape: 17.2404 - val_loss: 6.8077e-04 - val_mape: 3.4334\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4499e-04 - mape: 13.6784 - val_loss: 9.8754e-05 - val_mape: 1.0987\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 28.0345 - val_loss: 6.6484e-04 - val_mape: 3.4798\n",
      "--- 7/51 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mape: 35.9336 - val_loss: 5.6302e-04 - val_mape: 2.6307\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2457e-04 - mape: 9.3570 - val_loss: 5.0708e-04 - val_mape: 2.2412\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0729e-04 - mape: 8.0369 - val_loss: 3.9846e-04 - val_mape: 1.9044\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1599e-04 - mape: 8.8584 - val_loss: 5.9814e-04 - val_mape: 2.3823\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8024e-04 - mape: 8.0173 - val_loss: 8.4906e-04 - val_mape: 2.9599\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9598e-04 - mape: 9.2012 - val_loss: 0.0013 - val_mape: 3.9303\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9537e-04 - mape: 12.3258 - val_loss: 0.0012 - val_mape: 3.4063\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6149e-04 - mape: 14.8107 - val_loss: 0.0017 - val_mape: 4.3063\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2138e-04 - mape: 21.4219 - val_loss: 0.0044 - val_mape: 7.9278\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mape: 29.3756 - val_loss: 0.0064 - val_mape: 9.4347\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - mape: 47.6585 - val_loss: 0.0101 - val_mape: 11.9311\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - mape: 64.8724 - val_loss: 0.0080 - val_mape: 9.5580\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - mape: 76.2050 - val_loss: 0.0029 - val_mape: 5.9167\n",
      "--- 8/51 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7568e-04 - mape: 33.5477 - val_loss: 0.0024 - val_mape: 10.7287\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - mape: 217.3160 - val_loss: 0.0046 - val_mape: 16.4036\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mape: 141.8413 - val_loss: 0.0044 - val_mape: 16.3131\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mape: 110.4051 - val_loss: 0.0039 - val_mape: 15.3429\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mape: 96.5085 - val_loss: 0.0042 - val_mape: 15.9178\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mape: 112.7937 - val_loss: 0.0037 - val_mape: 14.7162\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mape: 129.0562 - val_loss: 0.0036 - val_mape: 14.4431\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mape: 143.6387 - val_loss: 0.0034 - val_mape: 13.9430\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - mape: 154.4898 - val_loss: 0.0032 - val_mape: 13.4035\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - mape: 156.3370 - val_loss: 0.0016 - val_mape: 9.1790\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - mape: 175.6711 - val_loss: 0.0011 - val_mape: 7.4541\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - mape: 176.2065 - val_loss: 8.0951e-04 - val_mape: 6.1046\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - mape: 171.4244 - val_loss: 1.7363e-04 - val_mape: 2.8039\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - mape: 172.5335 - val_loss: 1.4749e-04 - val_mape: 2.5414\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mape: 151.2640 - val_loss: 2.8149e-04 - val_mape: 3.6799\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mape: 132.3294 - val_loss: 2.8505e-04 - val_mape: 3.6071\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - mape: 104.5316 - val_loss: 3.7593e-04 - val_mape: 4.2343\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6022e-04 - mape: 78.1721 - val_loss: 2.4564e-04 - val_mape: 3.2694\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8634e-04 - mape: 50.2133 - val_loss: 1.6467e-04 - val_mape: 2.4922\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9486e-04 - mape: 27.2192 - val_loss: 1.3634e-04 - val_mape: 2.2165\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3683e-04 - mape: 18.9071 - val_loss: 9.0440e-05 - val_mape: 1.7938\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4449e-04 - mape: 21.9040 - val_loss: 6.2272e-05 - val_mape: 1.5711\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2382e-04 - mape: 21.2746 - val_loss: 5.6696e-05 - val_mape: 1.4888\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5183e-04 - mape: 23.2395 - val_loss: 6.2443e-05 - val_mape: 1.5326\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3204e-04 - mape: 22.0612 - val_loss: 5.6478e-05 - val_mape: 1.5486\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5387e-04 - mape: 29.4104 - val_loss: 4.5578e-05 - val_mape: 1.3681\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4541e-04 - mape: 28.9588 - val_loss: 5.4315e-05 - val_mape: 1.5320\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3481e-04 - mape: 25.8370 - val_loss: 5.0876e-05 - val_mape: 1.4771\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1918e-04 - mape: 25.5468 - val_loss: 5.8421e-05 - val_mape: 1.5824\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4612e-04 - mape: 28.9931 - val_loss: 7.9131e-05 - val_mape: 1.8727\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3039e-04 - mape: 26.0005 - val_loss: 8.9858e-05 - val_mape: 2.0288\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6541e-04 - mape: 29.7502 - val_loss: 6.5803e-05 - val_mape: 1.6827\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0257e-04 - mape: 35.0719 - val_loss: 1.1510e-04 - val_mape: 2.3381\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9945e-04 - mape: 32.4993 - val_loss: 1.2348e-04 - val_mape: 2.4013\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4476e-04 - mape: 42.1070 - val_loss: 9.7605e-05 - val_mape: 2.0938\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9781e-04 - mape: 45.7786 - val_loss: 1.0112e-04 - val_mape: 2.1197\n",
      "--- 9/51 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6022e-04 - mape: 33698.4883 - val_loss: 0.0011 - val_mape: 3.7806\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8648e-04 - mape: 79486.4609 - val_loss: 3.2452e-04 - val_mape: 1.6418\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2925e-04 - mape: 29797.0215 - val_loss: 3.1971e-04 - val_mape: 1.5608\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3641e-04 - mape: 1916.7365 - val_loss: 2.8308e-04 - val_mape: 1.4563\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1672e-04 - mape: 47987.5195 - val_loss: 3.5446e-04 - val_mape: 1.7715\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8979e-05 - mape: 40451.6953 - val_loss: 2.8535e-04 - val_mape: 1.4880\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5494e-05 - mape: 10358.7246 - val_loss: 2.7796e-04 - val_mape: 1.4556\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0442e-04 - mape: 10177.2988 - val_loss: 2.9017e-04 - val_mape: 1.4216\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4393e-04 - mape: 27777.4395 - val_loss: 2.5784e-04 - val_mape: 1.3137\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0046e-04 - mape: 8459.6914 - val_loss: 2.7567e-04 - val_mape: 1.4191\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3731e-04 - mape: 38848.5586 - val_loss: 4.6200e-04 - val_mape: 2.1803\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3707e-04 - mape: 41372.8711 - val_loss: 3.1571e-04 - val_mape: 1.4998\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2273e-04 - mape: 31167.9902 - val_loss: 2.5275e-04 - val_mape: 1.2440\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2479e-04 - mape: 17153.8828 - val_loss: 2.3404e-04 - val_mape: 1.2306\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0826e-04 - mape: 23294.1504 - val_loss: 3.0711e-04 - val_mape: 1.4520\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5430e-04 - mape: 69165.2266 - val_loss: 3.7010e-04 - val_mape: 1.8609\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0536e-05 - mape: 44282.5664 - val_loss: 2.2589e-04 - val_mape: 1.1878\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0273e-04 - mape: 4380.3989 - val_loss: 2.7910e-04 - val_mape: 1.4487\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5309e-04 - mape: 15166.7920 - val_loss: 4.9351e-04 - val_mape: 2.3112\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3652e-04 - mape: 34778.8242 - val_loss: 2.6402e-04 - val_mape: 1.2852\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2679e-04 - mape: 30547.3359 - val_loss: 0.0010 - val_mape: 3.5869\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0804e-04 - mape: 77579.2578 - val_loss: 3.0521e-04 - val_mape: 1.4336\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5549e-04 - mape: 37516.2266 - val_loss: 4.0326e-04 - val_mape: 1.9913\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1483e-04 - mape: 40902.0898 - val_loss: 3.5960e-04 - val_mape: 1.7826\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3267e-04 - mape: 29020.9082 - val_loss: 0.0011 - val_mape: 3.7838\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1871e-04 - mape: 62184.5352 - val_loss: 2.8794e-04 - val_mape: 1.4018\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3450e-04 - mape: 11140.4424 - val_loss: 0.0014 - val_mape: 4.2694\n",
      "--- 10/51 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6775e-04 - mape: 56.7962 - val_loss: 6.7715e-04 - val_mape: 2.8213\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2577e-04 - mape: 61.2190 - val_loss: 0.0017 - val_mape: 4.9003\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7270e-04 - mape: 43.4575 - val_loss: 3.0629e-04 - val_mape: 1.4941\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2352e-05 - mape: 19.2243 - val_loss: 3.9287e-04 - val_mape: 1.7023\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6236e-05 - mape: 18.5019 - val_loss: 3.8921e-04 - val_mape: 1.6953\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9727e-05 - mape: 17.7537 - val_loss: 4.0978e-04 - val_mape: 1.7601\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8512e-05 - mape: 17.3009 - val_loss: 3.5522e-04 - val_mape: 1.5864\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2222e-05 - mape: 18.4101 - val_loss: 3.9723e-04 - val_mape: 1.7386\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4132e-05 - mape: 16.0838 - val_loss: 4.4211e-04 - val_mape: 1.8893\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0809e-05 - mape: 18.0657 - val_loss: 2.8256e-04 - val_mape: 1.4059\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5008e-05 - mape: 20.0516 - val_loss: 4.2080e-04 - val_mape: 1.8190\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4708e-05 - mape: 16.8608 - val_loss: 3.2609e-04 - val_mape: 1.4924\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3830e-05 - mape: 16.5959 - val_loss: 3.9706e-04 - val_mape: 1.7380\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6621e-05 - mape: 16.8318 - val_loss: 2.9359e-04 - val_mape: 1.3967\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4623e-05 - mape: 18.1135 - val_loss: 3.8788e-04 - val_mape: 1.6871\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4621e-05 - mape: 19.0297 - val_loss: 3.3315e-04 - val_mape: 1.5151\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9989e-05 - mape: 22.0032 - val_loss: 6.1972e-04 - val_mape: 2.4831\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3181e-05 - mape: 23.3660 - val_loss: 2.9223e-04 - val_mape: 1.4114\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1666e-04 - mape: 26.9001 - val_loss: 5.2271e-04 - val_mape: 2.1156\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5478e-04 - mape: 31.2958 - val_loss: 3.0481e-04 - val_mape: 1.5059\n",
      "--- 11/51 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5980e-04 - mape: 12.1624 - val_loss: 5.4778e-04 - val_mape: 2.1792\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5751e-04 - mape: 17.1089 - val_loss: 9.9963e-04 - val_mape: 3.0662\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7994e-04 - mape: 21.1107 - val_loss: 7.7923e-04 - val_mape: 2.8432\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - mape: 59.2862 - val_loss: 6.8154e-04 - val_mape: 2.4895\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8126e-04 - mape: 23.2340 - val_loss: 0.0011 - val_mape: 3.3400\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - mape: 56.6392 - val_loss: 8.8059e-04 - val_mape: 2.8907\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - mape: 48.1717 - val_loss: 0.0024 - val_mape: 5.2540\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - mape: 94.8205 - val_loss: 4.7921e-04 - val_mape: 2.0309\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3712e-04 - mape: 12.2853 - val_loss: 0.0033 - val_mape: 6.5353\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mape: 45.6484 - val_loss: 5.9960e-04 - val_mape: 2.3557\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mape: 32.4359 - val_loss: 9.5303e-04 - val_mape: 3.0619\n",
      "Epoch 12/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4423e-04 - mape: 10.0829 - val_loss: 8.0817e-04 - val_mape: 2.7516\n",
      "Epoch 13/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6296e-04 - mape: 11.8455 - val_loss: 6.6801e-04 - val_mape: 2.4514\n",
      "Epoch 14/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7085e-04 - mape: 19.0686 - val_loss: 6.5658e-04 - val_mape: 2.4189\n",
      "Epoch 15/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9386e-04 - mape: 8.9121 - val_loss: 7.5896e-04 - val_mape: 2.6388\n",
      "Epoch 16/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7535e-04 - mape: 9.2774 - val_loss: 6.6619e-04 - val_mape: 2.4575\n",
      "Epoch 17/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6988e-04 - mape: 18.3958 - val_loss: 8.4184e-04 - val_mape: 2.8815\n",
      "Epoch 18/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6270e-04 - mape: 23.2998 - val_loss: 8.6952e-04 - val_mape: 2.8791\n",
      "--- 12/51 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5102e-04 - mape: 67.8654 - val_loss: 3.6033e-04 - val_mape: 1.8096\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4727e-04 - mape: 49.3717 - val_loss: 1.5298e-04 - val_mape: 1.1278\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0249e-04 - mape: 72.1466 - val_loss: 2.2614e-04 - val_mape: 1.4020\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9456e-04 - mape: 84.7677 - val_loss: 1.3061e-04 - val_mape: 1.0616\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 177.9604 - val_loss: 2.0092e-04 - val_mape: 1.2710\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1055e-04 - mape: 115.3115 - val_loss: 3.3182e-04 - val_mape: 1.8318\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6762e-04 - mape: 136.6486 - val_loss: 1.3192e-04 - val_mape: 1.0105\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2598e-04 - mape: 60.4456 - val_loss: 8.2947e-05 - val_mape: 0.8117\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6853e-04 - mape: 41.4160 - val_loss: 1.0297e-04 - val_mape: 0.8742\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7956e-04 - mape: 46.4417 - val_loss: 1.0705e-04 - val_mape: 0.9615\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0587e-04 - mape: 51.8238 - val_loss: 7.6705e-05 - val_mape: 0.8070\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1438e-04 - mape: 141.0177 - val_loss: 1.6180e-04 - val_mape: 1.1192\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1730e-04 - mape: 141.5450 - val_loss: 2.1338e-04 - val_mape: 1.3723\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mape: 197.4921 - val_loss: 4.2083e-04 - val_mape: 2.0655\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 195.2142 - val_loss: 5.8696e-04 - val_mape: 2.4658\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mape: 279.7639 - val_loss: 2.1177e-04 - val_mape: 1.3121\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mape: 203.3407 - val_loss: 8.5618e-04 - val_mape: 3.1015\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mape: 255.0775 - val_loss: 3.2109e-04 - val_mape: 1.6085\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7414e-04 - mape: 157.1088 - val_loss: 3.5171e-04 - val_mape: 1.9240\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6225e-04 - mape: 170.6222 - val_loss: 2.1956e-04 - val_mape: 1.3069\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0195e-04 - mape: 136.6246 - val_loss: 0.0012 - val_mape: 3.7450\n",
      "--- 13/51 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5346e-04 - mape: 59695.2539 - val_loss: 3.1047e-04 - val_mape: 2.4915\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3708e-04 - mape: 89733.4141 - val_loss: 6.3434e-05 - val_mape: 0.9063\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3307e-04 - mape: 41585.9141 - val_loss: 3.6482e-04 - val_mape: 2.6519\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4223e-04 - mape: 35754.1836 - val_loss: 9.4119e-05 - val_mape: 1.1157\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0983e-04 - mape: 3416.3364 - val_loss: 7.9105e-05 - val_mape: 1.0165\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3528e-04 - mape: 20863.0703 - val_loss: 1.6541e-04 - val_mape: 1.7979\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2761e-04 - mape: 260.6189 - val_loss: 7.0122e-05 - val_mape: 0.9615\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2935e-04 - mape: 25144.9590 - val_loss: 1.2521e-04 - val_mape: 1.4441\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3928e-04 - mape: 4003.0186 - val_loss: 5.6003e-04 - val_mape: 3.4220\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6919e-04 - mape: 12242.7314 - val_loss: 6.2212e-05 - val_mape: 0.8658\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8205e-04 - mape: 30237.9805 - val_loss: 6.6002e-05 - val_mape: 0.9053\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9635e-04 - mape: 16529.8672 - val_loss: 5.8983e-05 - val_mape: 0.8727\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2240e-04 - mape: 8061.3677 - val_loss: 1.8213e-04 - val_mape: 1.7792\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3298e-04 - mape: 4771.4438 - val_loss: 9.0858e-05 - val_mape: 1.1986\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0002e-04 - mape: 13138.3486 - val_loss: 1.4025e-04 - val_mape: 1.5295\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1752e-04 - mape: 52565.4180 - val_loss: 6.5923e-05 - val_mape: 0.9283\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9035e-04 - mape: 33520.4492 - val_loss: 5.8331e-05 - val_mape: 0.8551\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7518e-04 - mape: 2263.7502 - val_loss: 6.4510e-05 - val_mape: 0.8897\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1604e-04 - mape: 18406.8711 - val_loss: 8.7789e-05 - val_mape: 1.1382\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1526e-04 - mape: 14543.5322 - val_loss: 1.3876e-04 - val_mape: 1.4752\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2196e-04 - mape: 28833.2363 - val_loss: 7.1282e-05 - val_mape: 1.0357\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8294e-04 - mape: 28352.7129 - val_loss: 5.5899e-05 - val_mape: 0.8500\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8463e-04 - mape: 3477.6633 - val_loss: 1.1316e-04 - val_mape: 1.4189\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8889e-04 - mape: 20494.9355 - val_loss: 5.6039e-05 - val_mape: 0.8354\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0879e-04 - mape: 21381.0117 - val_loss: 1.5436e-04 - val_mape: 1.5999\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8447e-04 - mape: 21126.2715 - val_loss: 6.8370e-05 - val_mape: 0.9584\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1602e-04 - mape: 5096.5352 - val_loss: 6.0952e-05 - val_mape: 0.8310\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1095e-04 - mape: 4426.6611 - val_loss: 1.3613e-04 - val_mape: 1.5598\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2261e-04 - mape: 46896.7070 - val_loss: 1.6239e-04 - val_mape: 1.7192\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7184e-04 - mape: 43237.9453 - val_loss: 1.8366e-04 - val_mape: 1.9241\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5690e-04 - mape: 328.2029 - val_loss: 6.2094e-05 - val_mape: 0.9324\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1507e-04 - mape: 39780.7148 - val_loss: 2.5126e-04 - val_mape: 2.2049\n",
      "--- 14/51 Training model for DXCM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5350e-04 - mape: 52879.9297 - val_loss: 1.3909e-04 - val_mape: 1.4041\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2398e-04 - mape: 9334.8779 - val_loss: 7.1254e-05 - val_mape: 0.7924\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3198e-04 - mape: 17334.2441 - val_loss: 7.5022e-05 - val_mape: 0.8636\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1310e-04 - mape: 5794.7725 - val_loss: 3.0294e-04 - val_mape: 2.2352\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0181e-04 - mape: 6542.4307 - val_loss: 1.4698e-04 - val_mape: 1.4425\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8616e-04 - mape: 22978.4824 - val_loss: 3.3907e-04 - val_mape: 2.3755\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3091e-04 - mape: 1726.9943 - val_loss: 8.1040e-05 - val_mape: 0.8997\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2580e-04 - mape: 10607.0234 - val_loss: 8.4565e-05 - val_mape: 0.9592\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3057e-04 - mape: 2864.1641 - val_loss: 7.2444e-05 - val_mape: 0.8129\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3373e-04 - mape: 7524.3901 - val_loss: 1.0182e-04 - val_mape: 1.1464\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2032e-04 - mape: 24163.8262 - val_loss: 6.4691e-05 - val_mape: 0.7526\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5234e-04 - mape: 37032.0781 - val_loss: 3.2823e-04 - val_mape: 2.3165\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4798e-04 - mape: 5776.9658 - val_loss: 3.2839e-04 - val_mape: 2.5460\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6252e-04 - mape: 3414.4758 - val_loss: 2.3248e-04 - val_mape: 1.9208\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7216e-04 - mape: 2902.3601 - val_loss: 5.4947e-04 - val_mape: 3.3033\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0909e-04 - mape: 1854.7758 - val_loss: 1.9700e-04 - val_mape: 1.7084\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6605e-04 - mape: 11359.0820 - val_loss: 1.1738e-04 - val_mape: 1.3347\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5558e-04 - mape: 18237.1953 - val_loss: 1.5282e-04 - val_mape: 1.5201\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1729e-04 - mape: 9064.0947 - val_loss: 8.9834e-05 - val_mape: 1.0336\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1067e-04 - mape: 4013.2039 - val_loss: 1.3556e-04 - val_mape: 1.4119\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5384e-04 - mape: 17079.5645 - val_loss: 1.1720e-04 - val_mape: 1.2550\n",
      "--- 15/51 Training model for FAST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8890e-04 - mape: 6216.7832 - val_loss: 1.1332e-04 - val_mape: 0.9092\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0818e-04 - mape: 14237.3213 - val_loss: 1.0321e-04 - val_mape: 0.8270\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9029e-04 - mape: 32419.7715 - val_loss: 1.9692e-04 - val_mape: 1.3520\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5875e-04 - mape: 5801.6421 - val_loss: 7.6869e-05 - val_mape: 0.6771\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8528e-04 - mape: 4844.2979 - val_loss: 1.0740e-04 - val_mape: 1.0478\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6226e-04 - mape: 79438.8984 - val_loss: 7.9815e-05 - val_mape: 0.7215\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8118e-04 - mape: 7321.9893 - val_loss: 8.3840e-05 - val_mape: 0.7407\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4125e-04 - mape: 22782.6289 - val_loss: 1.0060e-04 - val_mape: 0.8723\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6724e-04 - mape: 20078.2910 - val_loss: 7.8761e-05 - val_mape: 0.7095\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9191e-04 - mape: 13619.4346 - val_loss: 7.0564e-05 - val_mape: 0.7927\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8056e-04 - mape: 25368.9043 - val_loss: 2.3162e-04 - val_mape: 1.4154\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5918e-04 - mape: 2776.5173 - val_loss: 5.0290e-04 - val_mape: 2.3938\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 36273.0117 - val_loss: 1.0769e-04 - val_mape: 0.8951\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8328e-04 - mape: 15507.0127 - val_loss: 1.5812e-04 - val_mape: 1.2149\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 32310.0488 - val_loss: 2.2898e-04 - val_mape: 1.3916\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6548e-04 - mape: 40673.8359 - val_loss: 2.7813e-04 - val_mape: 1.6405\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mape: 67296.9531 - val_loss: 3.8803e-04 - val_mape: 1.9686\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 1847.0809 - val_loss: 0.0010 - val_mape: 3.5063\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - mape: 57844.1367 - val_loss: 1.6450e-04 - val_mape: 1.1895\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4492e-04 - mape: 32478.9160 - val_loss: 7.9393e-05 - val_mape: 0.7630\n",
      "--- 16/51 Training model for ABNB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mape: 24016.4238 - val_loss: 4.3078e-05 - val_mape: 1.2179\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mape: 16835.8945 - val_loss: 6.8824e-05 - val_mape: 1.5785\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mape: 17822.0957 - val_loss: 1.8402e-04 - val_mape: 2.8294\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - mape: 27548.4746 - val_loss: 4.6986e-04 - val_mape: 4.3648\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - mape: 33391.8984 - val_loss: 7.3911e-04 - val_mape: 5.2029\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - mape: 36744.0742 - val_loss: 0.0013 - val_mape: 6.6151\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - mape: 37103.3828 - val_loss: 0.0022 - val_mape: 8.7557\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - mape: 50048.0000 - val_loss: 0.0028 - val_mape: 10.6097\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - mape: 10638.4111 - val_loss: 0.0014 - val_mape: 8.1013\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mape: 6361.8115 - val_loss: 3.3481e-04 - val_mape: 3.8584\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9057e-04 - mape: 8850.8174 - val_loss: 1.6970e-04 - val_mape: 2.7680\n",
      "--- 17/51 Training model for SNPS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1811e-04 - mape: 40.8492 - val_loss: 1.5680e-04 - val_mape: 1.0484\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4130e-04 - mape: 22.2113 - val_loss: 1.2919e-04 - val_mape: 0.9390\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5559e-04 - mape: 25.3509 - val_loss: 1.6449e-04 - val_mape: 1.0835\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4586e-04 - mape: 23.6919 - val_loss: 1.3394e-04 - val_mape: 0.9548\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4433e-04 - mape: 23.0190 - val_loss: 1.4018e-04 - val_mape: 1.0307\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7509e-04 - mape: 35.6222 - val_loss: 1.0265e-04 - val_mape: 0.8131\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4709e-04 - mape: 24.0974 - val_loss: 1.0167e-04 - val_mape: 0.8367\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6844e-04 - mape: 26.8203 - val_loss: 9.2933e-05 - val_mape: 0.7674\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4969e-04 - mape: 22.7753 - val_loss: 8.7192e-05 - val_mape: 0.7497\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8627e-04 - mape: 27.3808 - val_loss: 1.5754e-04 - val_mape: 1.0716\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7608e-04 - mape: 36.6500 - val_loss: 1.4007e-04 - val_mape: 1.0414\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5516e-04 - mape: 46.5685 - val_loss: 1.4174e-04 - val_mape: 1.0496\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7003e-04 - mape: 43.1161 - val_loss: 2.3728e-04 - val_mape: 1.4996\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8589e-04 - mape: 77.8117 - val_loss: 1.9863e-04 - val_mape: 1.2332\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 78.8693 - val_loss: 9.6005e-04 - val_mape: 3.3455\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - mape: 118.6169 - val_loss: 1.4035e-04 - val_mape: 0.9965\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8145e-04 - mape: 79.7559 - val_loss: 8.3568e-04 - val_mape: 3.1348\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 86.1390 - val_loss: 9.3514e-05 - val_mape: 0.7837\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4949e-04 - mape: 33.3472 - val_loss: 1.4828e-04 - val_mape: 1.1098\n",
      "--- 18/51 Training model for BIIB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4249e-04 - mape: 1023.8392 - val_loss: 5.7897e-05 - val_mape: 6.9759\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8251e-04 - mape: 5448.9946 - val_loss: 2.9703e-05 - val_mape: 5.5407\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8249e-04 - mape: 401.0019 - val_loss: 2.9323e-05 - val_mape: 7.8493\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5423e-04 - mape: 852.8242 - val_loss: 2.9943e-05 - val_mape: 5.2984\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6915e-04 - mape: 2242.5308 - val_loss: 2.3845e-05 - val_mape: 6.5661\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8385e-04 - mape: 1383.0179 - val_loss: 2.7338e-05 - val_mape: 5.4319\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5691e-04 - mape: 544.0123 - val_loss: 2.4481e-05 - val_mape: 6.1624\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5098e-04 - mape: 6715.5723 - val_loss: 3.0001e-05 - val_mape: 5.9776\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7462e-04 - mape: 3308.8010 - val_loss: 2.8631e-05 - val_mape: 5.0491\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4821e-04 - mape: 3811.6323 - val_loss: 3.0310e-05 - val_mape: 4.8244\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3935e-04 - mape: 2100.6641 - val_loss: 7.9069e-05 - val_mape: 12.6980\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0703e-04 - mape: 317.9811 - val_loss: 2.2337e-04 - val_mape: 24.1781\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9123e-04 - mape: 2340.6699 - val_loss: 2.1460e-05 - val_mape: 3.7014\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3749e-04 - mape: 3534.5002 - val_loss: 2.1861e-05 - val_mape: 4.1996\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2835e-04 - mape: 1787.3397 - val_loss: 2.2909e-05 - val_mape: 4.5690\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3237e-04 - mape: 109.4372 - val_loss: 5.3532e-05 - val_mape: 14.5491\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6338e-04 - mape: 2300.0857 - val_loss: 7.5330e-05 - val_mape: 11.5075\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4390e-04 - mape: 1094.3834 - val_loss: 2.2650e-05 - val_mape: 6.2845\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2182e-04 - mape: 2126.0798 - val_loss: 3.2619e-05 - val_mape: 7.6189\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1576e-04 - mape: 3141.1189 - val_loss: 2.4697e-05 - val_mape: 5.7328\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0718e-04 - mape: 2570.0769 - val_loss: 5.5648e-05 - val_mape: 12.3670\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1092e-04 - mape: 134.2879 - val_loss: 1.9963e-05 - val_mape: 5.1377\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2922e-04 - mape: 304.6257 - val_loss: 5.0843e-05 - val_mape: 13.4408\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1104e-04 - mape: 753.2560 - val_loss: 1.8581e-05 - val_mape: 5.2487\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1152e-04 - mape: 2867.8938 - val_loss: 1.4973e-05 - val_mape: 3.6482\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9195e-04 - mape: 791.7903 - val_loss: 1.3017e-04 - val_mape: 20.6613\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2387e-04 - mape: 6633.9985 - val_loss: 1.4786e-05 - val_mape: 3.8301\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8733e-04 - mape: 958.8351 - val_loss: 2.0251e-05 - val_mape: 3.6472\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2726e-04 - mape: 1287.9586 - val_loss: 4.5388e-04 - val_mape: 41.8542\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3073e-04 - mape: 3806.5938 - val_loss: 7.8654e-05 - val_mape: 17.4894\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1034e-04 - mape: 1252.0962 - val_loss: 8.0123e-05 - val_mape: 10.5760\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9161e-04 - mape: 1570.7400 - val_loss: 3.2242e-04 - val_mape: 34.1088\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2569e-04 - mape: 783.5572 - val_loss: 4.3230e-05 - val_mape: 10.8998\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0142e-04 - mape: 1252.1749 - val_loss: 1.0982e-05 - val_mape: 4.5487\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7031e-04 - mape: 3018.1326 - val_loss: 1.3324e-04 - val_mape: 25.1442\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8314e-04 - mape: 3336.2761 - val_loss: 4.9108e-05 - val_mape: 16.8000\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0724e-04 - mape: 763.0202 - val_loss: 1.4665e-04 - val_mape: 25.4018\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1494e-04 - mape: 477.3026 - val_loss: 1.0563e-04 - val_mape: 20.3297\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0926e-04 - mape: 3390.8835 - val_loss: 1.0776e-04 - val_mape: 21.7630\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0786e-04 - mape: 37.6855 - val_loss: 1.9822e-04 - val_mape: 25.8625\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9800e-04 - mape: 614.0297 - val_loss: 4.3266e-05 - val_mape: 12.4693\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7166e-04 - mape: 3107.8635 - val_loss: 1.1379e-05 - val_mape: 2.7919\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6610e-04 - mape: 1240.3077 - val_loss: 5.6472e-05 - val_mape: 18.7580\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0492e-04 - mape: 4984.1123 - val_loss: 2.2250e-04 - val_mape: 30.8019\n",
      "--- 19/51 Training model for REGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9452e-04 - mape: 8361.0537 - val_loss: 1.2929e-04 - val_mape: 1.3316\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3538e-04 - mape: 2078.6562 - val_loss: 7.3795e-05 - val_mape: 1.0057\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3249e-04 - mape: 7648.9453 - val_loss: 3.3402e-05 - val_mape: 0.6109\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4170e-04 - mape: 1892.0190 - val_loss: 3.8598e-05 - val_mape: 0.6998\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3517e-04 - mape: 8000.0664 - val_loss: 4.0717e-05 - val_mape: 0.6960\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3078e-04 - mape: 10173.7041 - val_loss: 5.8524e-05 - val_mape: 0.9123\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3361e-04 - mape: 5250.7764 - val_loss: 2.1666e-05 - val_mape: 0.4959\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3707e-04 - mape: 6629.0029 - val_loss: 1.9300e-05 - val_mape: 0.4367\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4704e-04 - mape: 164.2118 - val_loss: 1.0838e-04 - val_mape: 1.2232\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1551e-04 - mape: 6552.5298 - val_loss: 6.5725e-05 - val_mape: 0.9101\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5196e-04 - mape: 5859.3354 - val_loss: 4.9353e-05 - val_mape: 0.7781\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3747e-04 - mape: 4111.6509 - val_loss: 5.5577e-05 - val_mape: 0.8110\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5093e-04 - mape: 12427.0439 - val_loss: 8.1113e-05 - val_mape: 0.9984\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4176e-04 - mape: 24066.6445 - val_loss: 4.2787e-05 - val_mape: 0.6730\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2152e-04 - mape: 615.3500 - val_loss: 7.1028e-05 - val_mape: 0.8667\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2353e-04 - mape: 4827.3965 - val_loss: 9.7310e-05 - val_mape: 1.0252\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1912e-04 - mape: 2774.3525 - val_loss: 2.8655e-05 - val_mape: 0.5864\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3665e-04 - mape: 2080.0076 - val_loss: 2.3770e-05 - val_mape: 0.5177\n",
      "--- 20/51 Training model for VRSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9263e-04 - mape: 53737.6055 - val_loss: 2.6721e-05 - val_mape: 0.4825\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3512e-04 - mape: 16756.3691 - val_loss: 1.8543e-05 - val_mape: 0.3914\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0758e-04 - mape: 19341.1621 - val_loss: 2.4800e-05 - val_mape: 0.4403\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2301e-04 - mape: 82366.8516 - val_loss: 3.3407e-04 - val_mape: 2.1473\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2962e-04 - mape: 17910.5156 - val_loss: 1.2096e-04 - val_mape: 1.2367\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2715e-04 - mape: 16066.7812 - val_loss: 5.0038e-04 - val_mape: 2.5900\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8124e-04 - mape: 59775.3711 - val_loss: 9.3278e-05 - val_mape: 0.9666\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9887e-04 - mape: 10411.9561 - val_loss: 4.3221e-04 - val_mape: 2.4325\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4887e-04 - mape: 10375.3457 - val_loss: 9.9379e-05 - val_mape: 1.0553\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4022e-04 - mape: 87833.8359 - val_loss: 2.8059e-04 - val_mape: 1.8815\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0916e-04 - mape: 55812.0234 - val_loss: 5.0114e-05 - val_mape: 0.6446\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0369e-04 - mape: 60889.5547 - val_loss: 3.8146e-05 - val_mape: 0.5579\n",
      "--- 21/51 Training model for TSLA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2953e-04 - mape: 2660.1606 - val_loss: 6.5746e-05 - val_mape: 1.3679\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4502e-04 - mape: 12500.9043 - val_loss: 1.4510e-04 - val_mape: 2.3942\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 4399.9224 - val_loss: 2.1894e-04 - val_mape: 3.0996\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6142e-04 - mape: 18469.1973 - val_loss: 2.9508e-05 - val_mape: 0.9726\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5583e-04 - mape: 6297.0791 - val_loss: 4.9315e-05 - val_mape: 1.3690\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6872e-04 - mape: 8248.8154 - val_loss: 7.1456e-05 - val_mape: 1.6793\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3929e-04 - mape: 10835.5479 - val_loss: 1.3658e-05 - val_mape: 0.6280\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6651e-04 - mape: 14259.6084 - val_loss: 2.5101e-05 - val_mape: 0.9109\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1807e-04 - mape: 6755.7573 - val_loss: 1.8667e-05 - val_mape: 0.7108\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2047e-04 - mape: 12732.9336 - val_loss: 1.6094e-05 - val_mape: 0.6829\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1039e-04 - mape: 9223.4492 - val_loss: 1.5594e-05 - val_mape: 0.6809\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5134e-04 - mape: 17551.1289 - val_loss: 3.5089e-05 - val_mape: 1.1304\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0739e-04 - mape: 7362.3452 - val_loss: 5.3380e-05 - val_mape: 1.3423\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6849e-04 - mape: 4955.8818 - val_loss: 1.1418e-04 - val_mape: 2.0054\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6774e-04 - mape: 42581.0000 - val_loss: 1.7857e-05 - val_mape: 0.7323\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7798e-04 - mape: 16104.4609 - val_loss: 2.1286e-05 - val_mape: 0.7762\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3333e-04 - mape: 6501.6431 - val_loss: 5.4604e-05 - val_mape: 1.3826\n",
      "--- 22/51 Training model for NVDA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6380e-04 - mape: 47799.5703 - val_loss: 3.1476e-04 - val_mape: 2.2868\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4480e-04 - mape: 4571.0391 - val_loss: 5.4767e-05 - val_mape: 0.7735\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6458e-04 - mape: 17938.4141 - val_loss: 2.4317e-04 - val_mape: 1.8140\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3844e-04 - mape: 7701.4507 - val_loss: 7.5510e-05 - val_mape: 0.8881\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2471e-04 - mape: 23154.6211 - val_loss: 1.3293e-04 - val_mape: 1.2968\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1511e-04 - mape: 1631.8336 - val_loss: 1.1768e-04 - val_mape: 1.1431\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1522e-04 - mape: 35115.5703 - val_loss: 7.3384e-05 - val_mape: 0.8829\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1493e-04 - mape: 58252.3164 - val_loss: 1.4687e-04 - val_mape: 1.3577\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0664e-04 - mape: 74444.6797 - val_loss: 1.2115e-04 - val_mape: 1.1874\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9643e-04 - mape: 29929.6641 - val_loss: 1.5835e-04 - val_mape: 1.3536\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0514e-04 - mape: 6900.9121 - val_loss: 7.9627e-05 - val_mape: 0.8958\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8475e-04 - mape: 34933.3359 - val_loss: 1.3215e-04 - val_mape: 1.2786\n",
      "--- 23/51 Training model for CPRT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9270e-04 - mape: 50.1167 - val_loss: 5.2508e-05 - val_mape: 0.6661\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7148e-04 - mape: 60.3173 - val_loss: 3.0088e-04 - val_mape: 1.8029\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2916e-04 - mape: 82.7099 - val_loss: 8.7601e-05 - val_mape: 0.8219\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0615e-04 - mape: 69.5197 - val_loss: 5.2431e-05 - val_mape: 0.6884\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2239e-04 - mape: 51.5681 - val_loss: 6.8148e-05 - val_mape: 0.7387\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3987e-04 - mape: 86.9095 - val_loss: 3.2165e-04 - val_mape: 1.7852\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1051e-04 - mape: 45.0424 - val_loss: 9.1393e-05 - val_mape: 0.8305\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8626e-04 - mape: 43.5559 - val_loss: 2.1793e-04 - val_mape: 1.5189\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1541e-04 - mape: 88.6848 - val_loss: 3.3455e-04 - val_mape: 1.9210\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7534e-04 - mape: 56.3312 - val_loss: 5.9356e-05 - val_mape: 0.6721\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8446e-04 - mape: 53.1969 - val_loss: 2.5894e-04 - val_mape: 1.7056\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3347e-04 - mape: 59.2893 - val_loss: 4.8734e-05 - val_mape: 0.6172\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4720e-04 - mape: 79.2727 - val_loss: 6.3733e-04 - val_mape: 2.6551\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1204e-04 - mape: 85.3394 - val_loss: 2.7930e-04 - val_mape: 1.6751\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3351e-04 - mape: 60.3719 - val_loss: 2.1801e-04 - val_mape: 1.5298\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3261e-04 - mape: 137.1371 - val_loss: 3.9351e-04 - val_mape: 2.0635\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6477e-04 - mape: 61.9543 - val_loss: 1.1857e-04 - val_mape: 0.9989\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6935e-04 - mape: 52.7614 - val_loss: 3.7442e-05 - val_mape: 0.5199\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1866e-04 - mape: 56.0956 - val_loss: 2.9013e-04 - val_mape: 1.8272\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9305e-04 - mape: 54.9704 - val_loss: 7.4946e-05 - val_mape: 0.8188\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5248e-04 - mape: 62.7724 - val_loss: 2.3099e-04 - val_mape: 1.5293\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1186e-04 - mape: 71.8120 - val_loss: 8.5833e-05 - val_mape: 0.8905\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3971e-04 - mape: 59.9031 - val_loss: 8.3016e-04 - val_mape: 3.1229\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3064e-04 - mape: 70.0518 - val_loss: 4.8425e-05 - val_mape: 0.6292\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5133e-04 - mape: 78.6165 - val_loss: 6.7131e-05 - val_mape: 0.7833\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6957e-04 - mape: 64.4752 - val_loss: 5.6544e-05 - val_mape: 0.6913\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1598e-04 - mape: 62.7100 - val_loss: 3.2993e-04 - val_mape: 1.9297\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3335e-04 - mape: 54.0241 - val_loss: 9.2425e-04 - val_mape: 3.3566\n",
      "--- 24/51 Training model for ORLY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6429e-04 - mape: 69230.4688 - val_loss: 1.1844e-04 - val_mape: 1.0442\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1378e-04 - mape: 29530.5723 - val_loss: 9.6274e-05 - val_mape: 0.8856\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6615e-04 - mape: 7277.5005 - val_loss: 6.1167e-05 - val_mape: 0.6600\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9238e-04 - mape: 46099.5195 - val_loss: 7.9283e-05 - val_mape: 0.8186\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4150e-04 - mape: 3407.5481 - val_loss: 6.5204e-05 - val_mape: 0.7331\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3428e-04 - mape: 23044.1523 - val_loss: 8.1160e-05 - val_mape: 0.8385\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5904e-04 - mape: 39817.3555 - val_loss: 4.9419e-05 - val_mape: 0.5582\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8811e-04 - mape: 11571.6924 - val_loss: 4.8437e-05 - val_mape: 0.5476\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9594e-04 - mape: 349.7910 - val_loss: 1.2375e-04 - val_mape: 1.1175\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4306e-04 - mape: 25725.1211 - val_loss: 4.1895e-05 - val_mape: 0.5382\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7011e-04 - mape: 8575.6621 - val_loss: 5.2867e-05 - val_mape: 0.6412\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9895e-04 - mape: 56453.6680 - val_loss: 3.6991e-05 - val_mape: 0.4975\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2148e-04 - mape: 39993.2852 - val_loss: 1.4304e-04 - val_mape: 1.1865\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0373e-04 - mape: 23312.0215 - val_loss: 5.2431e-05 - val_mape: 0.6037\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6538e-04 - mape: 86762.3672 - val_loss: 4.5962e-05 - val_mape: 0.5654\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2333e-04 - mape: 87827.6875 - val_loss: 4.6173e-05 - val_mape: 0.5421\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6502e-04 - mape: 19089.7969 - val_loss: 2.8387e-04 - val_mape: 1.7111\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0778e-04 - mape: 51479.1562 - val_loss: 5.5672e-05 - val_mape: 0.5884\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5288e-04 - mape: 29914.1152 - val_loss: 8.4571e-05 - val_mape: 0.7649\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5390e-04 - mape: 26006.9668 - val_loss: 1.3688e-04 - val_mape: 1.1585\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8192e-04 - mape: 17267.2715 - val_loss: 1.8707e-04 - val_mape: 1.3708\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3627e-04 - mape: 21487.3125 - val_loss: 9.5067e-05 - val_mape: 0.9285\n",
      "--- 25/51 Training model for CSGP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0596e-04 - mape: 28.7020 - val_loss: 1.1306e-04 - val_mape: 1.1727\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3874e-04 - mape: 28.3855 - val_loss: 2.2524e-04 - val_mape: 1.7032\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6302e-04 - mape: 14.0413 - val_loss: 1.3621e-04 - val_mape: 1.1556\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2741e-04 - mape: 35.9636 - val_loss: 1.8169e-04 - val_mape: 1.4209\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0646e-04 - mape: 29.1504 - val_loss: 4.2858e-05 - val_mape: 0.5957\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5829e-04 - mape: 17.6177 - val_loss: 2.0551e-05 - val_mape: 0.3854\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9673e-04 - mape: 14.4673 - val_loss: 7.6339e-05 - val_mape: 0.8880\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6701e-04 - mape: 11.4200 - val_loss: 1.5925e-04 - val_mape: 1.3741\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6768e-04 - mape: 13.2677 - val_loss: 2.9801e-05 - val_mape: 0.4873\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5879e-04 - mape: 12.6276 - val_loss: 2.6954e-05 - val_mape: 0.5144\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1875e-04 - mape: 14.4847 - val_loss: 4.7574e-05 - val_mape: 0.6244\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3030e-04 - mape: 16.2177 - val_loss: 4.6625e-05 - val_mape: 0.7718\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9534e-04 - mape: 14.0378 - val_loss: 2.1290e-05 - val_mape: 0.4728\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7602e-04 - mape: 12.3235 - val_loss: 1.7270e-05 - val_mape: 0.3753\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3351e-04 - mape: 16.6848 - val_loss: 2.8097e-05 - val_mape: 0.5478\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6563e-04 - mape: 12.6152 - val_loss: 1.9705e-04 - val_mape: 1.6585\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8644e-04 - mape: 24.2353 - val_loss: 3.0893e-05 - val_mape: 0.5863\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6332e-04 - mape: 21.4692 - val_loss: 1.8654e-05 - val_mape: 0.3985\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2029e-04 - mape: 23.6637 - val_loss: 1.2399e-05 - val_mape: 0.3175\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9421e-04 - mape: 11.9297 - val_loss: 2.1538e-05 - val_mape: 0.4551\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0481e-04 - mape: 23.9086 - val_loss: 2.0372e-05 - val_mape: 0.4145\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7988e-04 - mape: 14.5415 - val_loss: 2.1191e-05 - val_mape: 0.4206\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6468e-04 - mape: 13.4994 - val_loss: 3.7691e-05 - val_mape: 0.6154\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5958e-04 - mape: 13.1523 - val_loss: 1.5229e-05 - val_mape: 0.3657\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5118e-04 - mape: 13.7983 - val_loss: 2.0134e-05 - val_mape: 0.4239\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9947e-04 - mape: 15.7803 - val_loss: 6.0728e-05 - val_mape: 0.8043\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3440e-04 - mape: 16.9501 - val_loss: 3.1170e-05 - val_mape: 0.5673\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3401e-04 - mape: 25.0882 - val_loss: 1.3201e-04 - val_mape: 1.3267\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2345e-04 - mape: 27.0766 - val_loss: 1.9360e-05 - val_mape: 0.4155\n",
      "--- 26/51 Training model for PDD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3473e-04 - mape: 11791.0967 - val_loss: 2.5635e-04 - val_mape: 2.1909\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8446e-04 - mape: 6390.8921 - val_loss: 3.2674e-05 - val_mape: 0.7467\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9486e-04 - mape: 50195.7812 - val_loss: 2.8521e-05 - val_mape: 0.6576\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9464e-04 - mape: 11859.7197 - val_loss: 2.9992e-05 - val_mape: 0.6833\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9780e-04 - mape: 22124.9785 - val_loss: 3.0589e-05 - val_mape: 0.6859\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5882e-04 - mape: 78251.2344 - val_loss: 5.0982e-05 - val_mape: 0.9484\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1082e-04 - mape: 93626.6016 - val_loss: 4.7106e-05 - val_mape: 0.9128\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9998e-04 - mape: 56731.3867 - val_loss: 9.4484e-05 - val_mape: 1.2775\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0319e-04 - mape: 2426.5505 - val_loss: 1.0942e-04 - val_mape: 1.3531\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 121391.5859 - val_loss: 3.7628e-04 - val_mape: 2.5893\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - mape: 126064.8047 - val_loss: 4.7527e-04 - val_mape: 2.8218\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mape: 38547.5547 - val_loss: 6.1673e-04 - val_mape: 3.4128\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mape: 175617.2031 - val_loss: 3.4683e-04 - val_mape: 2.3162\n",
      "--- 27/51 Training model for HON ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4658e-04 - mape: 10.2577 - val_loss: 2.5170e-05 - val_mape: 0.4650\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0915e-04 - mape: 14.5239 - val_loss: 1.2099e-04 - val_mape: 1.2248\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2786e-04 - mape: 7.5212 - val_loss: 4.6879e-05 - val_mape: 0.7016\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1600e-04 - mape: 7.8587 - val_loss: 2.1912e-05 - val_mape: 0.4529\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5479e-04 - mape: 11.0031 - val_loss: 2.5956e-05 - val_mape: 0.5034\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4136e-04 - mape: 8.3005 - val_loss: 2.2773e-05 - val_mape: 0.4569\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1459e-04 - mape: 7.8369 - val_loss: 1.9475e-05 - val_mape: 0.4091\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5045e-04 - mape: 9.7621 - val_loss: 4.9699e-05 - val_mape: 0.7442\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2535e-04 - mape: 9.0321 - val_loss: 1.7972e-05 - val_mape: 0.4046\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6115e-04 - mape: 9.0611 - val_loss: 1.4820e-05 - val_mape: 0.3706\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6919e-04 - mape: 9.1174 - val_loss: 3.3861e-05 - val_mape: 0.5969\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7238e-04 - mape: 9.0287 - val_loss: 7.4018e-05 - val_mape: 0.9548\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2169e-04 - mape: 7.5263 - val_loss: 1.0672e-04 - val_mape: 1.1657\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3634e-04 - mape: 8.9529 - val_loss: 3.9476e-05 - val_mape: 0.6520\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2521e-04 - mape: 9.4358 - val_loss: 1.1326e-04 - val_mape: 1.1934\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3763e-04 - mape: 8.5597 - val_loss: 1.2922e-05 - val_mape: 0.3269\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1716e-04 - mape: 8.0151 - val_loss: 2.6867e-05 - val_mape: 0.5135\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3249e-04 - mape: 9.6281 - val_loss: 2.8879e-05 - val_mape: 0.5419\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3482e-04 - mape: 8.0553 - val_loss: 3.3820e-05 - val_mape: 0.5861\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7907e-04 - mape: 12.0454 - val_loss: 1.3613e-05 - val_mape: 0.3343\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4598e-04 - mape: 9.1407 - val_loss: 2.6201e-05 - val_mape: 0.5048\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5059e-04 - mape: 8.8324 - val_loss: 1.9606e-05 - val_mape: 0.4184\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9454e-04 - mape: 9.6353 - val_loss: 2.7430e-05 - val_mape: 0.4945\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6255e-04 - mape: 10.6131 - val_loss: 1.2675e-04 - val_mape: 1.1827\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1562e-04 - mape: 11.7504 - val_loss: 4.3200e-05 - val_mape: 0.6207\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2912e-04 - mape: 12.6971 - val_loss: 2.0557e-04 - val_mape: 1.6346\n",
      "--- 28/51 Training model for ADI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0164e-04 - mape: 18.7326 - val_loss: 7.7802e-05 - val_mape: 0.8465\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9079e-04 - mape: 29.1924 - val_loss: 1.0484e-04 - val_mape: 1.0731\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0458e-04 - mape: 23.5522 - val_loss: 6.2322e-05 - val_mape: 0.7072\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8652e-04 - mape: 23.8838 - val_loss: 1.0473e-04 - val_mape: 1.1074\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8780e-04 - mape: 23.1687 - val_loss: 6.5572e-05 - val_mape: 0.8959\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9755e-04 - mape: 19.4704 - val_loss: 1.1189e-04 - val_mape: 1.1653\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9636e-04 - mape: 20.0202 - val_loss: 5.6909e-05 - val_mape: 0.6758\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8013e-04 - mape: 19.7863 - val_loss: 9.1676e-05 - val_mape: 1.0396\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3311e-04 - mape: 16.7415 - val_loss: 4.1743e-05 - val_mape: 0.5592\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0407e-04 - mape: 19.5326 - val_loss: 6.0903e-05 - val_mape: 0.8135\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5689e-04 - mape: 18.1477 - val_loss: 3.7258e-05 - val_mape: 0.5629\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3789e-04 - mape: 17.5492 - val_loss: 2.8603e-05 - val_mape: 0.4724\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4923e-04 - mape: 17.9366 - val_loss: 4.3110e-05 - val_mape: 0.6502\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1668e-04 - mape: 16.0786 - val_loss: 3.5175e-05 - val_mape: 0.5384\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4193e-04 - mape: 17.1150 - val_loss: 5.2445e-05 - val_mape: 0.7100\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1267e-04 - mape: 15.7592 - val_loss: 9.9143e-05 - val_mape: 1.0987\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4985e-04 - mape: 17.8906 - val_loss: 4.0068e-05 - val_mape: 0.6322\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5832e-04 - mape: 17.9321 - val_loss: 4.8465e-05 - val_mape: 0.7222\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9607e-04 - mape: 19.5637 - val_loss: 1.4985e-04 - val_mape: 1.4025\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4829e-04 - mape: 17.4703 - val_loss: 2.7944e-05 - val_mape: 0.4781\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3928e-04 - mape: 17.3997 - val_loss: 3.3855e-05 - val_mape: 0.5081\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6008e-04 - mape: 18.5104 - val_loss: 5.5530e-05 - val_mape: 0.7455\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5114e-04 - mape: 17.9145 - val_loss: 5.2064e-05 - val_mape: 0.7396\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4800e-04 - mape: 17.9658 - val_loss: 2.5346e-05 - val_mape: 0.4450\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0701e-04 - mape: 16.1031 - val_loss: 3.1044e-05 - val_mape: 0.5150\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5026e-04 - mape: 18.1113 - val_loss: 4.4928e-05 - val_mape: 0.6262\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0085e-04 - mape: 15.5698 - val_loss: 3.5735e-05 - val_mape: 0.5290\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1886e-04 - mape: 16.0033 - val_loss: 9.5132e-05 - val_mape: 1.0737\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1794e-04 - mape: 16.6623 - val_loss: 5.7517e-05 - val_mape: 0.6975\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8905e-04 - mape: 19.0879 - val_loss: 4.5926e-05 - val_mape: 0.6810\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4564e-04 - mape: 17.9245 - val_loss: 4.5148e-05 - val_mape: 0.6422\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1078e-04 - mape: 15.3986 - val_loss: 2.8961e-05 - val_mape: 0.4798\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5473e-04 - mape: 17.3457 - val_loss: 3.8562e-05 - val_mape: 0.6550\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9612e-04 - mape: 18.9930 - val_loss: 8.8507e-05 - val_mape: 1.0261\n",
      "--- 29/51 Training model for EA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8248e-04 - mape: 7077.4390 - val_loss: 1.2623e-05 - val_mape: 0.3477\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9539e-04 - mape: 14279.7939 - val_loss: 1.2364e-04 - val_mape: 1.2084\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4975e-04 - mape: 18809.6309 - val_loss: 4.6189e-05 - val_mape: 0.7862\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9153e-04 - mape: 7014.2622 - val_loss: 4.6957e-05 - val_mape: 0.7922\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1090e-04 - mape: 31231.7656 - val_loss: 5.8020e-05 - val_mape: 0.8427\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8708e-04 - mape: 10333.0664 - val_loss: 8.8375e-05 - val_mape: 0.9818\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2718e-04 - mape: 13609.0596 - val_loss: 1.0780e-05 - val_mape: 0.3255\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8849e-04 - mape: 18042.4531 - val_loss: 1.6102e-05 - val_mape: 0.4303\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6725e-04 - mape: 16227.5781 - val_loss: 2.5461e-05 - val_mape: 0.5475\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7970e-04 - mape: 19674.9473 - val_loss: 1.5039e-05 - val_mape: 0.3543\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7333e-04 - mape: 16708.7910 - val_loss: 6.2770e-06 - val_mape: 0.2349\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8753e-04 - mape: 32846.0625 - val_loss: 5.9294e-05 - val_mape: 0.8501\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3831e-04 - mape: 6129.6436 - val_loss: 8.5848e-06 - val_mape: 0.2768\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3953e-04 - mape: 21591.3633 - val_loss: 1.9965e-05 - val_mape: 0.4371\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3011e-04 - mape: 24837.8516 - val_loss: 1.1321e-05 - val_mape: 0.3244\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7781e-04 - mape: 42481.8086 - val_loss: 5.3120e-05 - val_mape: 0.8336\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5906e-04 - mape: 15207.2021 - val_loss: 7.5759e-06 - val_mape: 0.2616\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5746e-04 - mape: 11820.4023 - val_loss: 7.1190e-06 - val_mape: 0.2642\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7025e-04 - mape: 17897.9844 - val_loss: 9.1455e-05 - val_mape: 0.9839\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4881e-04 - mape: 27623.0117 - val_loss: 3.2309e-05 - val_mape: 0.5445\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7933e-04 - mape: 42390.2383 - val_loss: 2.3320e-05 - val_mape: 0.4924\n",
      "--- 30/51 Training model for KHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4370e-04 - mape: 1014.0380 - val_loss: 3.8116e-06 - val_mape: 0.4522\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5644e-04 - mape: 2905.4353 - val_loss: 3.2265e-06 - val_mape: 0.4279\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4302e-04 - mape: 8476.0869 - val_loss: 1.3344e-05 - val_mape: 0.9584\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3127e-04 - mape: 13164.5488 - val_loss: 3.2305e-05 - val_mape: 1.5635\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7278e-04 - mape: 10856.0703 - val_loss: 3.6681e-05 - val_mape: 1.6704\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0461e-04 - mape: 10431.5352 - val_loss: 5.7378e-05 - val_mape: 2.0780\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - mape: 2807.8850 - val_loss: 2.9543e-05 - val_mape: 1.3418\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mape: 3829.4272 - val_loss: 4.5589e-05 - val_mape: 1.5762\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - mape: 3470.7688 - val_loss: 3.4938e-05 - val_mape: 1.4236\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - mape: 16408.2207 - val_loss: 3.3383e-05 - val_mape: 1.3876\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - mape: 13671.5020 - val_loss: 5.1205e-05 - val_mape: 1.6509\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - mape: 23712.4922 - val_loss: 4.5261e-05 - val_mape: 1.5330\n",
      "--- 31/51 Training model for WBD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4454e-04 - mape: 4.1002 - val_loss: 5.0051e-06 - val_mape: 3216.5806\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8112e-05 - mape: 3.3419 - val_loss: 5.7175e-06 - val_mape: 12408.3496\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0205e-05 - mape: 3.2127 - val_loss: 4.2995e-06 - val_mape: 10859.4551\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9225e-05 - mape: 3.2563 - val_loss: 3.6891e-06 - val_mape: 790.0319\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3707e-05 - mape: 3.2360 - val_loss: 5.5028e-06 - val_mape: 15152.7705\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7667e-05 - mape: 3.3296 - val_loss: 2.2999e-05 - val_mape: 38268.2578\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7071e-05 - mape: 3.1712 - val_loss: 3.8078e-06 - val_mape: 9366.2090\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5778e-05 - mape: 3.1374 - val_loss: 8.4917e-06 - val_mape: 26369.6641\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2385e-05 - mape: 3.1275 - val_loss: 7.3980e-06 - val_mape: 24648.3379\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5771e-05 - mape: 2.9627 - val_loss: 2.7302e-05 - val_mape: 8809.7754\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2786e-05 - mape: 3.1102 - val_loss: 3.9187e-06 - val_mape: 22247.7148\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4313e-05 - mape: 2.8620 - val_loss: 2.8097e-06 - val_mape: 11152.2314\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1589e-05 - mape: 3.0819 - val_loss: 1.7437e-06 - val_mape: 13200.7549\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8905e-05 - mape: 2.9348 - val_loss: 2.5102e-06 - val_mape: 8555.4951\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1560e-05 - mape: 2.8634 - val_loss: 1.0855e-05 - val_mape: 32585.6172\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4988e-05 - mape: 2.8776 - val_loss: 2.5665e-06 - val_mape: 21039.1836\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7991e-05 - mape: 2.8035 - val_loss: 9.5967e-06 - val_mape: 32181.1562\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6772e-05 - mape: 2.7686 - val_loss: 2.9299e-06 - val_mape: 15266.9932\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8734e-05 - mape: 3.0206 - val_loss: 1.4473e-05 - val_mape: 33767.8555\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8072e-05 - mape: 2.7330 - val_loss: 1.0809e-05 - val_mape: 2641.2649\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8097e-05 - mape: 2.8069 - val_loss: 1.6166e-05 - val_mape: 37943.9102\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8756e-05 - mape: 2.7700 - val_loss: 9.0846e-06 - val_mape: 29128.2090\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8700e-05 - mape: 2.7059 - val_loss: 2.1335e-06 - val_mape: 20176.4727\n",
      "--- 32/51 Training model for ROP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9521e-04 - mape: 8.9737 - val_loss: 3.0587e-05 - val_mape: 0.4155\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9669e-04 - mape: 8.9010 - val_loss: 2.9494e-05 - val_mape: 0.3786\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7439e-04 - mape: 7.7570 - val_loss: 1.7219e-04 - val_mape: 1.3660\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4306e-04 - mape: 10.8778 - val_loss: 3.2516e-05 - val_mape: 0.4227\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9376e-04 - mape: 17.0098 - val_loss: 5.6022e-05 - val_mape: 0.6691\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5072e-04 - mape: 15.8833 - val_loss: 1.2843e-04 - val_mape: 1.1071\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1348e-04 - mape: 21.2303 - val_loss: 2.7440e-05 - val_mape: 0.3575\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6769e-04 - mape: 16.2849 - val_loss: 7.0760e-05 - val_mape: 0.7694\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5786e-04 - mape: 17.7479 - val_loss: 3.3537e-05 - val_mape: 0.4238\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1346e-04 - mape: 17.6543 - val_loss: 1.6838e-04 - val_mape: 1.2936\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 27.0882 - val_loss: 3.8148e-05 - val_mape: 0.4238\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2238e-04 - mape: 19.6738 - val_loss: 1.7917e-04 - val_mape: 1.3447\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7677e-04 - mape: 26.1382 - val_loss: 3.4400e-05 - val_mape: 0.4096\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8967e-04 - mape: 20.1772 - val_loss: 3.5601e-04 - val_mape: 1.9772\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 27.3592 - val_loss: 1.1540e-04 - val_mape: 0.9889\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6192e-04 - mape: 23.4258 - val_loss: 6.6371e-04 - val_mape: 2.7308\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mape: 35.6713 - val_loss: 1.3142e-04 - val_mape: 1.0562\n",
      "--- 33/51 Training model for BKR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2258e-04 - mape: 17882.1367 - val_loss: 3.2298e-05 - val_mape: 0.5794\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7408e-04 - mape: 8838.9668 - val_loss: 1.3177e-05 - val_mape: 0.3638\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7898e-04 - mape: 9576.9932 - val_loss: 4.0681e-05 - val_mape: 0.7236\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7493e-04 - mape: 2825.6917 - val_loss: 2.0056e-05 - val_mape: 0.4681\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1015e-04 - mape: 5381.4692 - val_loss: 3.5143e-05 - val_mape: 0.6264\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8553e-04 - mape: 7317.2534 - val_loss: 1.1131e-05 - val_mape: 0.3350\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6397e-04 - mape: 17276.7930 - val_loss: 8.0423e-05 - val_mape: 1.0242\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3074e-04 - mape: 16043.3652 - val_loss: 8.7385e-06 - val_mape: 0.2912\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8999e-04 - mape: 320.6148 - val_loss: 1.0168e-04 - val_mape: 1.1924\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0296e-04 - mape: 3564.0640 - val_loss: 2.2847e-05 - val_mape: 0.4961\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5553e-04 - mape: 5414.5488 - val_loss: 2.3106e-05 - val_mape: 0.4988\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7770e-04 - mape: 4200.4043 - val_loss: 7.1081e-06 - val_mape: 0.2607\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4638e-04 - mape: 2443.5579 - val_loss: 8.3771e-06 - val_mape: 0.2882\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6914e-04 - mape: 7669.1699 - val_loss: 1.3430e-05 - val_mape: 0.3625\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9215e-04 - mape: 569.5117 - val_loss: 7.7904e-06 - val_mape: 0.2767\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7895e-04 - mape: 21457.1973 - val_loss: 7.5587e-06 - val_mape: 0.2596\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9775e-04 - mape: 17007.4375 - val_loss: 9.1616e-05 - val_mape: 1.1561\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7518e-04 - mape: 2713.3237 - val_loss: 1.3071e-05 - val_mape: 0.3675\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0079e-04 - mape: 3567.9790 - val_loss: 1.1360e-05 - val_mape: 0.3253\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4953e-04 - mape: 2473.3438 - val_loss: 6.4099e-05 - val_mape: 0.9334\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0958e-04 - mape: 1905.8351 - val_loss: 3.4865e-05 - val_mape: 0.6302\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8213e-04 - mape: 10464.4629 - val_loss: 1.0187e-05 - val_mape: 0.3192\n",
      "--- 34/51 Training model for COST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1743e-04 - mape: 43731.3867 - val_loss: 3.1443e-05 - val_mape: 0.5133\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7965e-04 - mape: 29237.5469 - val_loss: 7.8461e-05 - val_mape: 0.9383\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4635e-04 - mape: 6918.0659 - val_loss: 3.6637e-05 - val_mape: 0.5457\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4636e-04 - mape: 148.4055 - val_loss: 9.4326e-05 - val_mape: 1.0588\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2759e-04 - mape: 5079.7778 - val_loss: 5.3809e-05 - val_mape: 0.6869\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6420e-04 - mape: 31058.6191 - val_loss: 1.0062e-04 - val_mape: 1.0880\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7932e-04 - mape: 34862.5117 - val_loss: 3.0099e-05 - val_mape: 0.4812\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5085e-04 - mape: 55585.5625 - val_loss: 2.6028e-05 - val_mape: 0.4596\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1291e-04 - mape: 40972.7656 - val_loss: 5.5374e-05 - val_mape: 0.7801\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2397e-04 - mape: 7518.1074 - val_loss: 3.9733e-05 - val_mape: 0.6177\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7390e-04 - mape: 39094.8750 - val_loss: 9.5340e-05 - val_mape: 0.9575\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9915e-04 - mape: 21862.0996 - val_loss: 1.3412e-04 - val_mape: 1.2898\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6827e-04 - mape: 56420.4023 - val_loss: 2.8234e-05 - val_mape: 0.4779\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3909e-04 - mape: 42013.8203 - val_loss: 2.1205e-05 - val_mape: 0.4099\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9580e-04 - mape: 50438.7852 - val_loss: 3.3966e-05 - val_mape: 0.5968\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9046e-04 - mape: 65539.4453 - val_loss: 1.1806e-04 - val_mape: 1.1979\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5078e-04 - mape: 43825.1445 - val_loss: 2.8389e-05 - val_mape: 0.4676\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0205e-04 - mape: 15347.6377 - val_loss: 3.1994e-05 - val_mape: 0.5335\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6550e-04 - mape: 77245.1406 - val_loss: 4.8911e-05 - val_mape: 0.6256\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6603e-04 - mape: 34412.1992 - val_loss: 3.7673e-05 - val_mape: 0.5471\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6167e-04 - mape: 94896.7266 - val_loss: 5.7297e-05 - val_mape: 0.7901\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6215e-04 - mape: 53570.8359 - val_loss: 2.6435e-05 - val_mape: 0.4784\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9491e-04 - mape: 38286.7695 - val_loss: 3.5960e-05 - val_mape: 0.5506\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7388e-04 - mape: 1166.1678 - val_loss: 3.6093e-05 - val_mape: 0.5283\n",
      "--- 35/51 Training model for AZN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5142e-04 - mape: 15.2090 - val_loss: 2.3527e-05 - val_mape: 0.4663\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3796e-04 - mape: 14.3701 - val_loss: 2.0820e-05 - val_mape: 0.4639\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1768e-04 - mape: 12.6079 - val_loss: 4.0939e-04 - val_mape: 2.5687\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2089e-04 - mape: 12.5258 - val_loss: 2.9114e-05 - val_mape: 0.5432\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2375e-04 - mape: 17.2637 - val_loss: 3.2160e-05 - val_mape: 0.6049\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1073e-04 - mape: 14.6474 - val_loss: 3.9595e-05 - val_mape: 0.6875\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0935e-04 - mape: 14.5035 - val_loss: 1.1715e-04 - val_mape: 1.2784\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8801e-04 - mape: 11.1591 - val_loss: 2.6584e-05 - val_mape: 0.5937\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2634e-04 - mape: 14.0633 - val_loss: 2.0007e-04 - val_mape: 1.7134\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9666e-04 - mape: 13.8237 - val_loss: 2.5876e-05 - val_mape: 0.5404\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2069e-04 - mape: 14.0865 - val_loss: 2.0235e-04 - val_mape: 1.4620\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0518e-04 - mape: 21.9773 - val_loss: 1.1160e-04 - val_mape: 1.1607\n",
      "--- 36/51 Training model for LRCX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2075e-04 - mape: 36.9700 - val_loss: 4.5610e-05 - val_mape: 0.7441\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4121e-04 - mape: 49.9567 - val_loss: 1.4582e-04 - val_mape: 1.4017\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 91.8177 - val_loss: 0.0060 - val_mape: 9.5523\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mape: 124.1760 - val_loss: 1.6363e-04 - val_mape: 1.4379\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6035e-04 - mape: 48.7899 - val_loss: 0.0112 - val_mape: 13.0597\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mape: 116.5080 - val_loss: 8.3225e-05 - val_mape: 0.8906\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1335e-04 - mape: 41.0898 - val_loss: 7.5500e-05 - val_mape: 0.8221\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7781e-04 - mape: 36.7054 - val_loss: 8.8621e-05 - val_mape: 0.9072\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6127e-04 - mape: 31.6663 - val_loss: 7.5606e-05 - val_mape: 0.8321\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9438e-04 - mape: 37.4175 - val_loss: 8.0705e-05 - val_mape: 0.8553\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4660e-04 - mape: 32.0000 - val_loss: 7.7845e-05 - val_mape: 0.8526\n",
      "--- 37/51 Training model for MELI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8795e-04 - mape: 30.0514 - val_loss: 1.5341e-05 - val_mape: 0.3978\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9805e-04 - mape: 20.0791 - val_loss: 1.6216e-05 - val_mape: 0.4089\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1515e-04 - mape: 21.9564 - val_loss: 1.4613e-05 - val_mape: 0.3868\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2205e-04 - mape: 21.7092 - val_loss: 3.2006e-05 - val_mape: 0.5607\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7218e-04 - mape: 37.1969 - val_loss: 3.7876e-05 - val_mape: 0.6560\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9646e-04 - mape: 44.7350 - val_loss: 0.0017 - val_mape: 5.0630\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - mape: 92.7082 - val_loss: 0.0103 - val_mape: 12.4719\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - mape: 123.6094 - val_loss: 1.2048e-04 - val_mape: 1.1435\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4988e-04 - mape: 22.8832 - val_loss: 2.7937e-05 - val_mape: 0.5354\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3595e-04 - mape: 26.8133 - val_loss: 5.9047e-05 - val_mape: 0.8234\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0552e-04 - mape: 20.1407 - val_loss: 2.8558e-05 - val_mape: 0.5228\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5825e-04 - mape: 23.0970 - val_loss: 1.3247e-04 - val_mape: 1.3069\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4410e-04 - mape: 21.6887 - val_loss: 2.8378e-04 - val_mape: 2.0481\n",
      "--- 38/51 Training model for CDW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6682e-04 - mape: 19.4978 - val_loss: 1.6378e-04 - val_mape: 1.2230\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6009e-04 - mape: 26.4088 - val_loss: 8.1784e-05 - val_mape: 0.9166\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9132e-04 - mape: 20.1508 - val_loss: 4.6560e-05 - val_mape: 0.6256\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4982e-04 - mape: 18.1228 - val_loss: 4.4023e-04 - val_mape: 2.3692\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7126e-04 - mape: 25.1565 - val_loss: 3.4410e-05 - val_mape: 0.4745\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7487e-04 - mape: 22.1168 - val_loss: 9.4138e-05 - val_mape: 1.0348\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9173e-04 - mape: 21.9758 - val_loss: 3.3945e-05 - val_mape: 0.4292\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9150e-04 - mape: 21.5505 - val_loss: 1.4175e-04 - val_mape: 1.2959\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7884e-04 - mape: 27.0911 - val_loss: 3.6147e-05 - val_mape: 0.5306\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8001e-04 - mape: 20.4405 - val_loss: 3.4459e-05 - val_mape: 0.5253\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4458e-04 - mape: 19.8496 - val_loss: 6.8330e-05 - val_mape: 0.8648\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2977e-04 - mape: 19.4834 - val_loss: 8.9442e-05 - val_mape: 1.0205\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2864e-04 - mape: 18.1767 - val_loss: 2.9034e-05 - val_mape: 0.4984\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4638e-04 - mape: 19.6922 - val_loss: 2.1512e-05 - val_mape: 0.3632\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6262e-04 - mape: 20.1486 - val_loss: 1.6336e-05 - val_mape: 0.3223\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3164e-04 - mape: 19.8488 - val_loss: 3.0367e-05 - val_mape: 0.5118\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2830e-04 - mape: 19.7522 - val_loss: 6.4159e-05 - val_mape: 0.8308\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3532e-04 - mape: 19.2658 - val_loss: 1.7456e-05 - val_mape: 0.3305\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4283e-04 - mape: 20.1022 - val_loss: 6.8716e-05 - val_mape: 0.8749\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2712e-04 - mape: 17.6478 - val_loss: 1.9241e-05 - val_mape: 0.3295\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3621e-04 - mape: 19.6234 - val_loss: 1.9302e-05 - val_mape: 0.3655\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2923e-04 - mape: 18.8423 - val_loss: 2.0747e-05 - val_mape: 0.4130\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1487e-04 - mape: 18.8331 - val_loss: 1.7774e-05 - val_mape: 0.3184\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4610e-04 - mape: 18.8865 - val_loss: 1.6904e-05 - val_mape: 0.3136\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0529e-04 - mape: 15.8913 - val_loss: 2.5885e-05 - val_mape: 0.4518\n",
      "--- 39/51 Training model for FANG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1227e-05 - mape: 1277.3286 - val_loss: 4.0498e-05 - val_mape: 0.6707\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3355e-05 - mape: 13455.0205 - val_loss: 1.2808e-05 - val_mape: 0.3216\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0842e-05 - mape: 9874.2305 - val_loss: 1.9440e-05 - val_mape: 0.4045\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1934e-05 - mape: 5346.5044 - val_loss: 1.8636e-05 - val_mape: 0.3925\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1399e-05 - mape: 9668.1895 - val_loss: 4.5081e-05 - val_mape: 0.6603\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6741e-05 - mape: 6106.5332 - val_loss: 1.3555e-05 - val_mape: 0.3108\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3211e-05 - mape: 5461.2114 - val_loss: 4.5364e-05 - val_mape: 0.5964\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6359e-05 - mape: 16182.8389 - val_loss: 3.6912e-04 - val_mape: 1.9851\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7833e-04 - mape: 3860.7271 - val_loss: 1.1198e-04 - val_mape: 0.9665\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1963e-05 - mape: 6873.4258 - val_loss: 1.6343e-05 - val_mape: 0.3633\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6967e-05 - mape: 7624.1396 - val_loss: 7.2846e-05 - val_mape: 0.7919\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1120e-04 - mape: 577.8804 - val_loss: 1.0239e-04 - val_mape: 0.8960\n",
      "--- 40/51 Training model for ZS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6146e-04 - mape: 48667.3125 - val_loss: 2.7071e-05 - val_mape: 0.7980\n",
      "Epoch 2/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0656e-04 - mape: 78231.3672 - val_loss: 2.1550e-05 - val_mape: 0.7665\n",
      "Epoch 3/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0375e-04 - mape: 181718.2812 - val_loss: 0.0012 - val_mape: 6.5496\n",
      "Epoch 4/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 104391.7969 - val_loss: 1.5443e-04 - val_mape: 2.1813\n",
      "Epoch 5/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mape: 136097.9688 - val_loss: 0.0072 - val_mape: 16.1667\n",
      "Epoch 6/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - mape: 217518.5000 - val_loss: 6.7260e-04 - val_mape: 5.0179\n",
      "Epoch 7/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7648e-04 - mape: 82509.0781 - val_loss: 7.2088e-05 - val_mape: 1.1853\n",
      "Epoch 8/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1634e-04 - mape: 62638.7578 - val_loss: 8.6972e-04 - val_mape: 5.7891\n",
      "Epoch 9/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7241e-04 - mape: 20266.7793 - val_loss: 1.6128e-04 - val_mape: 2.4704\n",
      "Epoch 10/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4806e-04 - mape: 17642.7441 - val_loss: 2.2884e-04 - val_mape: 2.9430\n",
      "Epoch 11/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6150e-04 - mape: 49801.6016 - val_loss: 1.1644e-04 - val_mape: 2.0626\n",
      "Epoch 12/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4575e-04 - mape: 38573.6094 - val_loss: 1.5953e-04 - val_mape: 2.4730\n",
      "--- 41/51 Training model for ADBE ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1594e-04 - mape: 13.5064 - val_loss: 1.9519e-05 - val_mape: 0.5199\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9780e-04 - mape: 14.3593 - val_loss: 1.7832e-05 - val_mape: 0.4335\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0988e-04 - mape: 16.2179 - val_loss: 0.0023 - val_mape: 5.8915\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - mape: 49.5555 - val_loss: 3.9558e-04 - val_mape: 2.4172\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3349e-04 - mape: 30.7184 - val_loss: 9.8559e-04 - val_mape: 3.7822\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6260e-04 - mape: 19.7707 - val_loss: 5.2225e-04 - val_mape: 2.9976\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mape: 40.5861 - val_loss: 0.0026 - val_mape: 6.4917\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2159e-04 - mape: 27.7603 - val_loss: 2.3962e-04 - val_mape: 1.8854\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mape: 39.7191 - val_loss: 0.0023 - val_mape: 6.0671\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0650e-04 - mape: 31.7396 - val_loss: 3.4767e-05 - val_mape: 0.5870\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4151e-04 - mape: 20.6152 - val_loss: 5.7149e-04 - val_mape: 3.0573\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0840e-04 - mape: 16.5478 - val_loss: 9.4176e-05 - val_mape: 1.1115\n",
      "--- 42/51 Training model for GOOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6907e-04 - mape: 31.4122 - val_loss: 0.0013 - val_mape: 4.2520\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3577e-04 - mape: 30.3737 - val_loss: 3.7470e-04 - val_mape: 2.2478\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9179e-04 - mape: 27.8256 - val_loss: 2.0595e-04 - val_mape: 1.6225\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4349e-04 - mape: 25.0939 - val_loss: 2.1322e-04 - val_mape: 1.6869\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7008e-04 - mape: 26.4731 - val_loss: 3.5702e-04 - val_mape: 2.2317\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6675e-04 - mape: 33.5104 - val_loss: 2.8802e-04 - val_mape: 1.9870\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5467e-04 - mape: 30.8273 - val_loss: 4.5634e-04 - val_mape: 2.5555\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2342e-04 - mape: 35.1835 - val_loss: 3.2075e-04 - val_mape: 2.0473\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2709e-04 - mape: 36.2381 - val_loss: 2.4907e-04 - val_mape: 1.7600\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7564e-04 - mape: 37.0521 - val_loss: 4.5858e-04 - val_mape: 2.4981\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7164e-04 - mape: 44.0157 - val_loss: 7.2720e-04 - val_mape: 3.1939\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5292e-04 - mape: 45.8185 - val_loss: 8.4057e-04 - val_mape: 3.4150\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6914e-04 - mape: 56.8008 - val_loss: 8.2103e-04 - val_mape: 3.3493\n",
      "--- 43/51 Training model for AMAT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6048e-04 - mape: 11323.9316 - val_loss: 0.0033 - val_mape: 7.1741\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4631e-04 - mape: 21254.7109 - val_loss: 1.9308e-04 - val_mape: 1.6071\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6757e-04 - mape: 21171.0332 - val_loss: 3.5310e-04 - val_mape: 2.2629\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8933e-04 - mape: 7961.1045 - val_loss: 1.5059e-04 - val_mape: 1.4099\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5217e-04 - mape: 1954.3138 - val_loss: 1.4813e-04 - val_mape: 1.3991\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0136e-04 - mape: 12924.0439 - val_loss: 1.1644e-04 - val_mape: 1.2107\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1621e-04 - mape: 9518.2402 - val_loss: 9.1761e-05 - val_mape: 1.0583\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8324e-04 - mape: 36081.8672 - val_loss: 4.9940e-05 - val_mape: 0.6954\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4555e-04 - mape: 14914.7578 - val_loss: 5.9603e-05 - val_mape: 0.8027\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4866e-04 - mape: 253.4126 - val_loss: 3.8713e-05 - val_mape: 0.5960\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4100e-04 - mape: 3071.9412 - val_loss: 8.5830e-05 - val_mape: 1.0540\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5216e-04 - mape: 34247.6016 - val_loss: 4.3636e-05 - val_mape: 0.6435\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5328e-04 - mape: 23209.0020 - val_loss: 6.0052e-05 - val_mape: 0.8358\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5952e-04 - mape: 7466.1597 - val_loss: 4.0916e-05 - val_mape: 0.5770\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4589e-04 - mape: 19829.6738 - val_loss: 4.5180e-05 - val_mape: 0.6360\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6647e-04 - mape: 10032.4170 - val_loss: 2.5477e-04 - val_mape: 1.9533\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7284e-04 - mape: 35539.6641 - val_loss: 3.7616e-05 - val_mape: 0.5333\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7356e-04 - mape: 8051.3975 - val_loss: 4.2718e-05 - val_mape: 0.6410\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2734e-04 - mape: 18033.8398 - val_loss: 6.4613e-05 - val_mape: 0.8845\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4967e-04 - mape: 12792.5928 - val_loss: 7.9499e-05 - val_mape: 1.0098\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5001e-04 - mape: 12329.2002 - val_loss: 3.8449e-05 - val_mape: 0.5412\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3431e-04 - mape: 27610.0703 - val_loss: 3.7684e-05 - val_mape: 0.5364\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3204e-04 - mape: 14187.0400 - val_loss: 9.5910e-05 - val_mape: 1.1401\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1144e-04 - mape: 1046.3516 - val_loss: 4.3722e-05 - val_mape: 0.5867\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3902e-04 - mape: 15232.9150 - val_loss: 4.3912e-05 - val_mape: 0.5676\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5748e-04 - mape: 37263.8242 - val_loss: 4.1691e-05 - val_mape: 0.6213\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9983e-04 - mape: 20226.4180 - val_loss: 4.5729e-05 - val_mape: 0.5832\n",
      "--- 44/51 Training model for ADP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2633e-04 - mape: 24311.0938 - val_loss: 1.5779e-05 - val_mape: 0.3875\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1769e-04 - mape: 45799.5156 - val_loss: 2.3098e-04 - val_mape: 1.7614\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9693e-04 - mape: 84698.5312 - val_loss: 8.9758e-05 - val_mape: 1.0228\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7074e-04 - mape: 8066.1074 - val_loss: 2.0267e-05 - val_mape: 0.4636\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0225e-04 - mape: 50392.5273 - val_loss: 3.8672e-05 - val_mape: 0.6282\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7355e-04 - mape: 16824.3809 - val_loss: 5.7619e-05 - val_mape: 0.8472\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0084e-04 - mape: 37950.2930 - val_loss: 2.4451e-05 - val_mape: 0.4968\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0994e-04 - mape: 9032.5205 - val_loss: 4.2387e-05 - val_mape: 0.6887\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2809e-04 - mape: 75747.7266 - val_loss: 1.3327e-04 - val_mape: 1.3286\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3701e-04 - mape: 90478.4453 - val_loss: 1.2225e-05 - val_mape: 0.3264\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7629e-04 - mape: 80770.6562 - val_loss: 5.4525e-05 - val_mape: 0.8023\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9388e-04 - mape: 119166.7578 - val_loss: 1.2905e-04 - val_mape: 1.2861\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0992e-04 - mape: 57554.0078 - val_loss: 8.1867e-05 - val_mape: 1.0042\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0578e-04 - mape: 15316.5508 - val_loss: 2.3010e-05 - val_mape: 0.4643\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7953e-04 - mape: 92763.8125 - val_loss: 7.1835e-05 - val_mape: 0.9219\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9017e-04 - mape: 46788.1914 - val_loss: 9.3890e-06 - val_mape: 0.2849\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1956e-04 - mape: 17471.2500 - val_loss: 1.9176e-05 - val_mape: 0.4091\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3416e-04 - mape: 8105.0972 - val_loss: 1.5506e-04 - val_mape: 1.3782\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1553e-04 - mape: 13943.8301 - val_loss: 7.7027e-05 - val_mape: 0.8844\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0501e-04 - mape: 35130.3906 - val_loss: 1.7100e-05 - val_mape: 0.3831\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4497e-04 - mape: 16271.7520 - val_loss: 4.0656e-05 - val_mape: 0.6765\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6441e-04 - mape: 98840.9219 - val_loss: 1.5884e-05 - val_mape: 0.3597\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4377e-04 - mape: 47819.9492 - val_loss: 9.5310e-06 - val_mape: 0.2713\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6815e-04 - mape: 109579.1172 - val_loss: 1.0392e-05 - val_mape: 0.3249\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4384e-04 - mape: 76271.9141 - val_loss: 6.1993e-05 - val_mape: 0.8727\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1164e-04 - mape: 57913.1289 - val_loss: 1.9792e-05 - val_mape: 0.4236\n",
      "--- 45/51 Training model for SBUX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4737e-04 - mape: 3179.4353 - val_loss: 4.1318e-05 - val_mape: 0.9649\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2848e-04 - mape: 26982.7129 - val_loss: 2.4667e-05 - val_mape: 0.5112\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9297e-04 - mape: 2722.4094 - val_loss: 4.5789e-05 - val_mape: 1.0899\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8399e-04 - mape: 5491.5356 - val_loss: 2.1526e-05 - val_mape: 0.4765\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2998e-04 - mape: 7375.6118 - val_loss: 3.3887e-05 - val_mape: 0.6712\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9247e-04 - mape: 18545.6914 - val_loss: 6.3305e-05 - val_mape: 1.0715\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7803e-04 - mape: 11272.6875 - val_loss: 5.8167e-05 - val_mape: 0.9822\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3018e-04 - mape: 23760.0449 - val_loss: 4.1957e-05 - val_mape: 0.8882\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3000e-04 - mape: 12968.7666 - val_loss: 3.1642e-05 - val_mape: 0.7694\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0006e-04 - mape: 7918.3105 - val_loss: 1.5669e-04 - val_mape: 2.2048\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9021e-04 - mape: 1631.2437 - val_loss: 6.2250e-05 - val_mape: 1.2863\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6387e-04 - mape: 4153.8960 - val_loss: 4.0769e-04 - val_mape: 3.5495\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9764e-04 - mape: 7816.5312 - val_loss: 3.9123e-04 - val_mape: 3.4733\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1881e-04 - mape: 16553.2988 - val_loss: 3.6381e-04 - val_mape: 3.3263\n",
      "--- 46/51 Training model for TTWO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2144e-04 - mape: 7.1706 - val_loss: 7.7097e-06 - val_mape: 0.2985\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5947e-04 - mape: 5.0926 - val_loss: 2.5515e-05 - val_mape: 0.7014\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9138e-04 - mape: 6.4791 - val_loss: 1.0462e-05 - val_mape: 0.3672\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1447e-04 - mape: 9.5294 - val_loss: 2.3084e-04 - val_mape: 2.2893\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8737e-04 - mape: 14.0356 - val_loss: 6.7373e-05 - val_mape: 1.1501\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7908e-04 - mape: 11.3207 - val_loss: 9.1169e-04 - val_mape: 4.5397\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - mape: 26.2767 - val_loss: 2.0546e-04 - val_mape: 2.1241\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 18.3966 - val_loss: 0.0031 - val_mape: 8.4158\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - mape: 35.3300 - val_loss: 3.6452e-04 - val_mape: 2.8685\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4351e-04 - mape: 14.5234 - val_loss: 0.0014 - val_mape: 5.6354\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3531e-04 - mape: 20.4985 - val_loss: 1.5186e-04 - val_mape: 1.8069\n",
      "--- 47/51 Training model for TMUS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7790e-04 - mape: 35999.7031 - val_loss: 5.0026e-05 - val_mape: 0.7613\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3436e-04 - mape: 19890.2812 - val_loss: 1.9111e-05 - val_mape: 0.4292\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0490e-04 - mape: 25727.7402 - val_loss: 1.5431e-05 - val_mape: 0.3683\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7782e-04 - mape: 14875.9482 - val_loss: 2.8022e-05 - val_mape: 0.5677\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6887e-04 - mape: 28612.8281 - val_loss: 1.1359e-05 - val_mape: 0.3078\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6341e-04 - mape: 45769.5469 - val_loss: 1.7477e-05 - val_mape: 0.4029\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1307e-04 - mape: 11328.7773 - val_loss: 1.5592e-05 - val_mape: 0.3636\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6602e-04 - mape: 10336.3457 - val_loss: 1.2299e-05 - val_mape: 0.3295\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6926e-04 - mape: 33582.6641 - val_loss: 1.8945e-05 - val_mape: 0.4404\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8334e-04 - mape: 8247.0664 - val_loss: 1.9205e-05 - val_mape: 0.4730\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6464e-04 - mape: 20433.9121 - val_loss: 1.2447e-05 - val_mape: 0.3553\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7020e-04 - mape: 17154.4297 - val_loss: 1.3526e-05 - val_mape: 0.3471\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7760e-04 - mape: 26725.0137 - val_loss: 8.7100e-06 - val_mape: 0.2875\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5233e-04 - mape: 8131.0674 - val_loss: 1.1525e-05 - val_mape: 0.3738\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4478e-04 - mape: 13178.4512 - val_loss: 8.8859e-06 - val_mape: 0.2766\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6808e-04 - mape: 6182.1543 - val_loss: 1.2662e-05 - val_mape: 0.3369\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7545e-04 - mape: 618.5141 - val_loss: 1.0492e-05 - val_mape: 0.3272\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7773e-04 - mape: 11478.2314 - val_loss: 1.8812e-05 - val_mape: 0.4827\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4649e-04 - mape: 17138.7168 - val_loss: 1.1545e-05 - val_mape: 0.3216\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6671e-04 - mape: 10015.5615 - val_loss: 5.1348e-05 - val_mape: 0.8879\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9426e-04 - mape: 23054.4727 - val_loss: 1.0580e-05 - val_mape: 0.3471\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5707e-04 - mape: 10599.3506 - val_loss: 7.7995e-06 - val_mape: 0.2882\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5874e-04 - mape: 12579.9102 - val_loss: 1.1090e-05 - val_mape: 0.3542\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5648e-04 - mape: 36906.5859 - val_loss: 7.6916e-06 - val_mape: 0.2594\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5568e-04 - mape: 1525.9088 - val_loss: 3.4850e-05 - val_mape: 0.7186\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3144e-04 - mape: 15086.4092 - val_loss: 1.9206e-05 - val_mape: 0.4752\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4822e-04 - mape: 2131.8225 - val_loss: 1.8126e-05 - val_mape: 0.4419\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3752e-04 - mape: 18420.0078 - val_loss: 9.2849e-05 - val_mape: 1.1830\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0284e-04 - mape: 4097.5688 - val_loss: 9.5316e-06 - val_mape: 0.3091\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9578e-04 - mape: 64875.3477 - val_loss: 1.6902e-05 - val_mape: 0.4289\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0649e-04 - mape: 10786.0703 - val_loss: 3.4673e-05 - val_mape: 0.6516\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7383e-04 - mape: 25351.1211 - val_loss: 3.2822e-05 - val_mape: 0.6548\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2381e-04 - mape: 10751.9404 - val_loss: 8.7791e-06 - val_mape: 0.3206\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5395e-04 - mape: 16521.3340 - val_loss: 1.4404e-05 - val_mape: 0.4154\n",
      "--- 48/51 Training model for WDAY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0068e-04 - mape: 5.9099 - val_loss: 3.3916e-05 - val_mape: 0.5678\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8132e-04 - mape: 5.4317 - val_loss: 2.1465e-05 - val_mape: 0.4421\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1288e-04 - mape: 6.0843 - val_loss: 3.9958e-05 - val_mape: 0.6410\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9629e-04 - mape: 5.9756 - val_loss: 2.2257e-05 - val_mape: 0.4358\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1538e-04 - mape: 6.6922 - val_loss: 2.1843e-05 - val_mape: 0.4313\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9299e-04 - mape: 5.8861 - val_loss: 4.2307e-05 - val_mape: 0.6069\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1220e-04 - mape: 6.5113 - val_loss: 5.6174e-05 - val_mape: 0.7436\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0045e-04 - mape: 6.2736 - val_loss: 7.5049e-05 - val_mape: 0.9382\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2385e-04 - mape: 6.5254 - val_loss: 1.3907e-04 - val_mape: 1.3287\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1774e-04 - mape: 6.5261 - val_loss: 3.0246e-05 - val_mape: 0.4744\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4207e-04 - mape: 8.6903 - val_loss: 2.2239e-04 - val_mape: 1.5214\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2785e-04 - mape: 7.0928 - val_loss: 1.8717e-04 - val_mape: 1.3808\n",
      "--- 49/51 Training model for CRWD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1273e-04 - mape: 6617.1729 - val_loss: 5.6409e-05 - val_mape: 0.7766\n",
      "Epoch 2/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5813e-04 - mape: 75677.3203 - val_loss: 0.0015 - val_mape: 4.5422\n",
      "Epoch 3/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mape: 22226.4395 - val_loss: 3.5205e-04 - val_mape: 1.8274\n",
      "Epoch 4/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - mape: 105847.8906 - val_loss: 0.0397 - val_mape: 23.6517\n",
      "Epoch 5/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mape: 76781.3516 - val_loss: 4.6046e-04 - val_mape: 2.2372\n",
      "Epoch 6/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3445e-04 - mape: 9567.0352 - val_loss: 3.8329e-04 - val_mape: 1.9658\n",
      "Epoch 7/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1655e-04 - mape: 22760.5918 - val_loss: 1.4098e-04 - val_mape: 1.0086\n",
      "Epoch 8/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4857e-04 - mape: 36308.4062 - val_loss: 2.1868e-04 - val_mape: 1.3122\n",
      "Epoch 9/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4520e-04 - mape: 31857.0254 - val_loss: 2.6000e-04 - val_mape: 1.4631\n",
      "Epoch 10/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1439e-04 - mape: 24776.8730 - val_loss: 1.4616e-04 - val_mape: 0.9816\n",
      "Epoch 11/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1215e-04 - mape: 18432.7168 - val_loss: 1.9112e-04 - val_mape: 1.1658\n",
      "--- 50/51 Training model for DDOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8447e-04 - mape: 29938.0000 - val_loss: 8.4318e-06 - val_mape: 0.4038\n",
      "Epoch 2/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3493e-04 - mape: 100833.0703 - val_loss: 6.9622e-06 - val_mape: 0.3621\n",
      "Epoch 3/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6887e-04 - mape: 19955.5684 - val_loss: 1.5726e-05 - val_mape: 0.6423\n",
      "Epoch 4/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4429e-04 - mape: 148690.8750 - val_loss: 1.8542e-05 - val_mape: 0.7013\n",
      "Epoch 5/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1458e-04 - mape: 20569.7461 - val_loss: 2.5727e-05 - val_mape: 0.8496\n",
      "Epoch 6/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1868e-04 - mape: 80756.5312 - val_loss: 5.5960e-06 - val_mape: 0.3405\n",
      "Epoch 7/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2941e-04 - mape: 48900.4453 - val_loss: 7.1681e-06 - val_mape: 0.3902\n",
      "Epoch 8/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2759e-04 - mape: 7447.5327 - val_loss: 8.0522e-06 - val_mape: 0.4152\n",
      "Epoch 9/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7613e-04 - mape: 90118.1562 - val_loss: 1.0792e-05 - val_mape: 0.4716\n",
      "Epoch 10/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5005e-04 - mape: 40684.8633 - val_loss: 9.3604e-06 - val_mape: 0.4580\n",
      "Epoch 11/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1628e-04 - mape: 13820.7725 - val_loss: 5.9098e-06 - val_mape: 0.3580\n",
      "Epoch 12/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0137e-04 - mape: 18744.3223 - val_loss: 8.4331e-06 - val_mape: 0.4282\n",
      "Epoch 13/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2820e-04 - mape: 19144.4277 - val_loss: 1.5372e-05 - val_mape: 0.6206\n",
      "Epoch 14/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9770e-04 - mape: 8218.7666 - val_loss: 7.4832e-06 - val_mape: 0.3882\n",
      "Epoch 15/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4377e-04 - mape: 81069.1016 - val_loss: 5.7275e-05 - val_mape: 1.3334\n",
      "Epoch 16/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1130e-04 - mape: 76785.3125 - val_loss: 8.0770e-06 - val_mape: 0.4210\n",
      "--- 51/51 Training model for PCAR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1088e-04 - mape: 41599.1797 - val_loss: 4.4744e-05 - val_mape: 0.6189\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5853e-04 - mape: 54454.1562 - val_loss: 1.2839e-04 - val_mape: 1.1164\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3839e-04 - mape: 4821.8076 - val_loss: 6.4658e-05 - val_mape: 0.7885\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8620e-04 - mape: 29463.8594 - val_loss: 1.5293e-04 - val_mape: 1.2512\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4391e-04 - mape: 6884.0864 - val_loss: 3.7723e-05 - val_mape: 0.5693\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9546e-04 - mape: 32522.1562 - val_loss: 1.0396e-04 - val_mape: 0.9750\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6636e-04 - mape: 28047.5137 - val_loss: 6.5624e-05 - val_mape: 0.7943\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0928e-04 - mape: 18455.4199 - val_loss: 9.6861e-05 - val_mape: 0.9526\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9335e-04 - mape: 7048.4868 - val_loss: 2.1096e-04 - val_mape: 1.5377\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8195e-04 - mape: 10157.8926 - val_loss: 1.6169e-04 - val_mape: 1.2588\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6547e-04 - mape: 9723.9062 - val_loss: 4.9553e-04 - val_mape: 2.5033\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3290e-04 - mape: 17484.7324 - val_loss: 1.8615e-04 - val_mape: 1.3711\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8278e-04 - mape: 30373.6699 - val_loss: 6.9463e-04 - val_mape: 3.0221\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1496e-04 - mape: 27604.4141 - val_loss: 1.2493e-04 - val_mape: 1.1262\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0599e-04 - mape: 13873.4434 - val_loss: 0.0010 - val_mape: 3.7127\n",
      "Saving model in trainings/2024-09-06_06-59-26/...\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.00587509e+02  1.00510886e+02  6.41100000e+05  4.21512009e-01\n",
      " -3.46326863e+01  6.28783557e+00 -2.56055821e+01 -6.51870855e+00]\n",
      "Feature max [4.87242432e+02 4.87132730e+02 1.50315000e+07 2.87933181e+01\n",
      " 3.25800617e+01 1.00000000e+02 1.20422968e+01 6.14184654e+00]\n",
      "Target min [99.81550117]\n",
      "Target max [487.13273043]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [99.81550117]\n",
      "Target max [487.13273043]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Loss: 34.0468 MAPE: 0.0248 R2: 0.9965\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.84646683e+01  6.87845982e+01  7.84815000e+05  5.31412082e-01\n",
      " -1.44093642e+01  2.39690794e+00 -6.57340984e+00 -2.54316181e+00]\n",
      "Feature max [1.67384308e+02 1.67306696e+02 6.04367500e+07 1.52577443e+01\n",
      " 9.25013360e+00 1.00000000e+02 6.57805424e+00 2.69238435e+00]\n",
      "Target min [68.78459817]\n",
      "Target max [167.30669635]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [68.78459817]\n",
      "Target max [167.30669635]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 2.1936 MAPE: 0.0127 R2: 0.9954\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.89599991e+01  7.74000015e+01  1.39900000e+05  4.10003662e-01\n",
      " -2.32099915e+01  4.70614757e+00 -1.31184115e+01 -4.10646090e+00]\n",
      "Feature max [2.55929993e+02 2.56329987e+02 6.83100000e+06 2.37600098e+01\n",
      " 1.91999969e+01 1.00000000e+02 8.18264471e+00 3.93665646e+00]\n",
      "Target min [76.48999786]\n",
      "Target max [256.32998657]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [76.48999786]\n",
      "Target max [256.32998657]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Loss: 2.9363 MAPE: 0.0097 R2: 0.9983\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.03273277e+02  1.03359152e+02  2.19500000e+05  6.57821463e-01\n",
      " -4.38739193e+01  4.44829086e+00 -1.22180140e+01 -7.92088217e+00]\n",
      "Feature max [6.29575256e+02 6.30034691e+02 2.50157000e+07 4.17466241e+01\n",
      " 1.73741639e+01 1.00000000e+02 1.36934893e+01 4.62922057e+00]\n",
      "Target min [103.35915196]\n",
      "Target max [630.03469105]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [103.35915196]\n",
      "Target max [630.03469105]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 90.1196 MAPE: 0.0547 R2: 0.9952\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.79337668e+00  3.79337668e+00  8.68400000e+05  9.98260733e-02\n",
      " -8.36539457e+00  3.51909206e+00 -6.51743216e+00 -3.04277233e+00]\n",
      "Feature max [7.08782501e+01 7.07692960e+01 3.53648800e+08 1.01822223e+01\n",
      " 7.45697933e+00 1.00000000e+02 1.71357740e+00 9.75614791e-01]\n",
      "Target min [3.79337668]\n",
      "Target max [70.76929598]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [3.79337668]\n",
      "Target max [70.76929598]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 1.7594 MAPE: 0.0921 R2: 0.9946\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.33600006e+01  5.29900017e+01  2.38700000e+05  4.90005493e-01\n",
      " -1.83730011e+01  4.38651475e+00 -8.75867425e+00 -3.18077212e+00]\n",
      "Feature max [1.99539993e+02 2.00759995e+02 1.06914000e+07 1.43699951e+01\n",
      " 1.22200012e+01 1.00000000e+02 7.30335474e+00 2.54529581e+00]\n",
      "Target min [52.99000168]\n",
      "Target max [200.75999451]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [52.99000168]\n",
      "Target max [200.75999451]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 7.1415 MAPE: 0.0288 R2: 0.9944\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.23795509e+01  6.15237302e+01  8.22000000e+04  3.54674502e-01\n",
      " -1.17018185e+01  8.39125236e+00 -8.91028210e+00 -2.63484327e+00]\n",
      "Feature max [2.28601547e+02 2.28611505e+02 3.01870000e+06 1.69518814e+01\n",
      " 8.42177947e+00 1.00000000e+02 8.00024996e+00 2.51434700e+00]\n",
      "Target min [61.52373019]\n",
      "Target max [228.6115053]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [61.52373019]\n",
      "Target max [228.6115053]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 6.3815 MAPE: 0.0204 R2: 0.9971\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.16192017e+01  8.13259098e+01  6.67000000e+04  4.21621371e-01\n",
      " -1.51196933e+01  5.69429260e+00 -6.65930233e+00 -3.00966572e+00]\n",
      "Feature max [2.05854782e+02 2.06839810e+02 1.93736000e+07 2.24616661e+01\n",
      " 1.33489264e+01 1.00000000e+02 7.44653178e+00 2.79295859e+00]\n",
      "Target min [81.32590976]\n",
      "Target max [206.83981003]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [81.32590976]\n",
      "Target max [206.83981003]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 4.3365 MAPE: 0.0147 R2: 0.9942\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.01289558  9.09955952  0.          0.         -4.63533746  2.6315563\n",
      " -1.32948641 -0.40327783]\n",
      "Feature max [2.89070969e+01 2.88131247e+01 1.12357800e+08 3.68139972e+00\n",
      " 2.10903787e+00 1.00000000e+02 1.43406379e+00 6.44883059e-01]\n",
      "Target min [9.09955952]\n",
      "Target max [28.81312469]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [9.09955952]\n",
      "Target max [28.81312469]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 0.0954 MAPE: 0.0185 R2: 0.9959\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.86599998e+01  5.87000008e+01  1.10600000e+05  8.30001831e-01\n",
      " -2.82599945e+01  5.24060526e+00 -1.69730343e+01 -5.52897415e+00]\n",
      "Feature max [2.84820007e+02 2.85049988e+02 1.09346000e+07 2.32900009e+01\n",
      " 2.64600067e+01 1.00000000e+02 1.14030842e+01 4.16758318e+00]\n",
      "Target min [58.70000076]\n",
      "Target max [285.04998779]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [58.70000076]\n",
      "Target max [285.04998779]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Loss: 16.0690 MAPE: 0.0305 R2: 0.9947\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35201817e+01  2.45084237e+01  2.43900000e+05  2.45655719e-01\n",
      " -1.10061164e+01  4.04803851e+00 -8.12727362e+00 -3.54222862e+00]\n",
      "Feature max [2.83329590e+02 2.86768374e+02 1.06073000e+07 1.71780370e+01\n",
      " 1.79800110e+01 1.00000000e+02 1.03013808e+01 3.31758305e+00]\n",
      "Target min [24.50842375]\n",
      "Target max [286.7683739]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [24.50842375]\n",
      "Target max [286.7683739]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 58.5392 MAPE: 0.1465 R2: 0.9882\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.68519058e+01  2.86381957e+01  5.59800000e+05  3.74405096e-01\n",
      " -5.67166719e+00  0.00000000e+00 -9.48503913e+00 -4.05116875e+00]\n",
      "Feature max [1.80924591e+02 1.80569421e+02 1.92116000e+07 1.42451174e+01\n",
      " 5.73534258e+00 9.86533369e+01 8.72129514e+00 2.03984071e+00]\n",
      "Target min [28.63819567]\n",
      "Target max [180.56942106]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [28.63819567]\n",
      "Target max [180.56942106]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 11.9572 MAPE: 0.0501 R2: 0.9892\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.02659988e+00  5.08260012e+00  3.37000000e+06  5.71999550e-02\n",
      " -5.07999802e+00  3.23186104e+00 -3.08725790e+00 -7.83855153e-01]\n",
      "Feature max [6.85522003e+01 6.89115982e+01 4.99555000e+08 5.15159988e+00\n",
      " 2.76320267e+00 1.00000000e+02 2.10694421e+00 7.26105232e-01]\n",
      "Target min [5.08260012]\n",
      "Target max [68.91159821]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [5.08260012]\n",
      "Target max [68.91159821]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 1.4241 MAPE: 0.0877 R2: 0.9936\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95926189e+00  7.16416874e+00  1.15980000e+06  2.09904718e-01\n",
      " -4.84139700e+00  5.10099423e+00 -4.35187305e+00 -1.55006635e+00]\n",
      "Feature max [7.40698471e+01 7.65555366e+01 6.16363700e+07 7.39870080e+00\n",
      " 6.74024753e+00 1.00000000e+02 2.95551163e+00 1.18274095e+00]\n",
      "Target min [7.16416874]\n",
      "Target max [76.55553663]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [7.16416874]\n",
      "Target max [76.55553663]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 3.4963 MAPE: 0.0746 R2: 0.9821\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.98299999e+01  3.00799999e+01  2.98200000e+05  2.39997864e-01\n",
      " -9.97999954e+00  7.84311966e+00 -7.08362288e+00 -2.12317125e+00]\n",
      "Feature max [1.17029999e+02 1.17489998e+02 6.70750000e+06 7.91999817e+00\n",
      " 5.76999664e+00 1.00000000e+02 5.92131160e+00 1.75286597e+00]\n",
      "Target min [30.07999992]\n",
      "Target max [117.48999786]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [30.07999992]\n",
      "Target max [117.48999786]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 2.4450 MAPE: 0.0277 R2: 0.9948\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.02654762e+01  1.98761124e+01  6.05500000e+05  1.23819948e-01\n",
      " -7.42467827e+00  9.58324988e+00 -4.89729421e+00 -2.90583217e+00]\n",
      "Feature max [1.42790634e+02 1.42759995e+02 1.17349100e+08 1.33589092e+01\n",
      " 6.04395929e+00 1.00000000e+02 6.69362973e+00 3.03392175e+00]\n",
      "Target min [19.17870974]\n",
      "Target max [142.75999451]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [19.17870974]\n",
      "Target max [142.75999451]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 3.7061 MAPE: 0.0470 R2: 0.9972\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.07085114e+01  6.83493098e+01  2.48900000e+05  5.70679196e-01\n",
      " -2.22916831e+01  7.93943341e+00 -1.78745394e+01 -5.85751159e+00]\n",
      "Feature max [2.13555008e+02 2.13545258e+02 1.34271000e+07 2.41424978e+01\n",
      " 1.51757817e+01 1.00000000e+02 6.38882936e+00 3.61722651e+00]\n",
      "Target min [67.66280998]\n",
      "Target max [213.54525773]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [67.66280998]\n",
      "Target max [213.54525773]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 1.4020 MAPE: 0.0088 R2: 0.9988\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.14519989e+02  4.14980011e+02  3.47000000e+04  2.55001831e+00\n",
      " -6.41400146e+01  4.41096860e+00 -4.73016549e+01 -2.22094798e+01]\n",
      "Feature max [1.70253003e+03 1.70640002e+03 6.81500000e+05 1.27150024e+02\n",
      " 1.02010010e+02 1.00000000e+02 7.18827661e+01 3.37504808e+01]\n",
      "Target min [414.98001099]\n",
      "Target max [1706.40002441]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [414.98001099]\n",
      "Target max [1706.40002441]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 976.0467 MAPE: 0.0375 R2: 0.9922\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.57583466e+01  2.58523274e+01  5.67300000e+05  1.60580914e-01\n",
      " -2.65545371e+00  3.54113859e+00 -1.79134519e+00 -6.34803538e-01]\n",
      "Feature max [5.13342400e+01 5.12780426e+01 1.46589000e+07 5.34807954e+00\n",
      " 3.86255561e+00 1.00000000e+02 1.43424864e+00 6.57552507e-01]\n",
      "Target min [25.8523274]\n",
      "Target max [51.27804256]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [25.8523274]\n",
      "Target max [51.27804256]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 0.2962 MAPE: 0.0144 R2: 0.9919\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.99200001e+01  1.96700001e+01  7.71100000e+05  3.70002747e-01\n",
      " -7.29999924e+00  5.76415573e+00 -1.33147296e+01 -2.92846117e+00]\n",
      "Feature max [9.66999969e+01 9.76699982e+01 1.42812800e+08 1.11700001e+01\n",
      " 9.85000229e+00 1.00000000e+02 4.17876062e+00 2.48433072e+00]\n",
      "Target min [19.67000008]\n",
      "Target max [97.66999817]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [19.67000008]\n",
      "Target max [97.66999817]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 2.0437 MAPE: 0.0280 R2: 0.9943\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.03573082e+02  1.01108149e+02  2.53700000e+05  6.41811081e-01\n",
      " -3.57379450e+01  2.16925939e+00 -2.20757254e+01 -6.73650517e+00]\n",
      "Feature max [5.13239990e+02 5.09649994e+02 9.77040000e+06 3.40230260e+01\n",
      " 1.62938184e+01 1.00000000e+02 1.35507062e+01 7.04866468e+00]\n",
      "Target min [100.83840083]\n",
      "Target max [509.6499939]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [100.83840083]\n",
      "Target max [509.6499939]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 20.6722 MAPE: 0.0182 R2: 0.9981\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15962696e+00  8.21640163e+00  9.86200000e+05  5.55134505e-02\n",
      " -1.98936922e+00  0.00000000e+00 -2.06166849e+00 -5.96182018e-01]\n",
      "Feature max [2.75114403e+01 2.79907994e+01 3.46278000e+07 2.64090620e+00\n",
      " 1.74404113e+00 9.84009496e+01 1.40984670e+00 3.92311143e-01]\n",
      "Target min [8.21640163]\n",
      "Target max [27.99079937]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [8.21640163]\n",
      "Target max [27.99079937]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 0.1896 MAPE: 0.0310 R2: 0.9933\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.95333328e+01  7.88552198e+01  3.42000000e+05  4.33020670e-01\n",
      " -1.02552027e+01  8.15371481e+00 -5.07887573e+00 -2.11600620e+00]\n",
      "Feature max [1.44660004e+02 1.45250000e+02 8.34070000e+06 1.49990093e+01\n",
      " 9.94068691e+00 1.00000000e+02 3.76455949e+00 1.68444528e+00]\n",
      "Target min [78.85521977]\n",
      "Target max [145.25]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [78.85521977]\n",
      "Target max [145.25]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 0.9892 MAPE: 0.0083 R2: 0.9954\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.41631927e+01  5.41419621e+01  1.75053000e+05  2.66199891e-01\n",
      " -1.00821830e+01  8.51326133e-01 -1.11093203e+01 -3.06042471e+00]\n",
      "Feature max [1.90951141e+02 1.90253102e+02 6.22503500e+06 1.27350436e+01\n",
      " 6.66500031e+00 1.00000000e+02 4.95429492e+00 2.29543464e+00]\n",
      "Target min [54.00748834]\n",
      "Target max [190.25310162]\n",
      "Predict with X shape: (1907, 20, 8)\n",
      "Target min [54.00748834]\n",
      "Target max [190.25310162]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 4.3179 MAPE: 0.0206 R2: 0.9969\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.48199997e+01  1.59600000e+01  3.38000000e+06  3.88000488e-01\n",
      " -5.93000031e+00  0.00000000e+00 -4.75278946e+00 -1.74995602e+00]\n",
      "Feature max [8.13899994e+01 8.19400024e+01 3.64231800e+08 6.11000061e+00\n",
      " 5.61000061e+00 9.76519081e+01 3.84552953e+00 1.42446777e+00]\n",
      "Target min [15.96000004]\n",
      "Target max [81.94000244]\n",
      "Predict with X shape: (1316, 20, 8)\n",
      "Target min [15.96000004]\n",
      "Target max [81.94000244]\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss: 2.4474 MAPE: 0.0418 R2: 0.9880\n",
      "{'MA': {'loss': 34.04683776647206, 'mape': 0.024759737112329757, 'r2': 0.9965156039934034}, 'MMM': {'loss': 2.1935845623123718, 'mape': 0.012694435902105167, 'r2': 0.9954322668342186}, 'VRSN': {'loss': 2.9363207233497435, 'mape': 0.009725501788728377, 'r2': 0.9982543030546143}, 'MCK': {'loss': 90.11962870614623, 'mape': 0.05467259689639067, 'r2': 0.9952172423591698}, 'PCG': {'loss': 1.7593779934486764, 'mape': 0.09210417056973957, 'r2': 0.9946215390995712}, 'QRVO': {'loss': 7.141531611711523, 'mape': 0.028779740034821713, 'r2': 0.9943509454849374}, 'AVY': {'loss': 6.381464559815489, 'mape': 0.020412949010591614, 'r2': 0.9971398004010578}, 'JKHY': {'loss': 4.336507469866751, 'mape': 0.014709652788422865, 'r2': 0.994199625485637}, 'GEN': {'loss': 0.09537173299577253, 'mape': 0.018535719186351857, 'r2': 0.995883755828284}, 'MHK': {'loss': 16.06898929502908, 'mape': 0.0304771266104452, 'r2': 0.9946746711313337}, 'PWR': {'loss': 58.53919323637436, 'mape': 0.14647781083501674, 'r2': 0.9882211571121715}, 'VLO': {'loss': 11.957230678466187, 'mape': 0.05010823796223776, 'r2': 0.9892403211007025}, 'CMG': {'loss': 1.4240723269278517, 'mape': 0.08774301672070718, 'r2': 0.9935521981030861}, 'BBWI': {'loss': 3.4962986101187026, 'mape': 0.07457540521102354, 'r2': 0.982104481534185}, 'CBRE': {'loss': 2.4450034153596025, 'mape': 0.02768684342053614, 'r2': 0.9947709839665857}, 'BX': {'loss': 3.7060833728941356, 'mape': 0.04704107352752366, 'r2': 0.9972154074669111}, 'GPN': {'loss': 1.4019572447497748, 'mape': 0.008765178433054022, 'r2': 0.998759189350116}, 'MTD': {'loss': 976.0467427941654, 'mape': 0.037505828940716045, 'r2': 0.9921712390768077}, 'HRL': {'loss': 0.2962347149671792, 'mape': 0.014374704301550049, 'r2': 0.991941244239947}, 'UAL': {'loss': 2.043745279713136, 'mape': 0.027998094175292487, 'r2': 0.9942657514553904}, 'SPGI': {'loss': 20.672216501288304, 'mape': 0.01815586848165075, 'r2': 0.9980887557789703}, 'AES': {'loss': 0.18963989860402614, 'mape': 0.03099401875351929, 'r2': 0.9933081192046148}, 'KMB': {'loss': 0.9891632473564185, 'mape': 0.008258727573731311, 'r2': 0.9953965888430186}, 'DOV': {'loss': 4.317882375847226, 'mape': 0.020573940012599552, 'r2': 0.9968751587037321}, 'UBER': {'loss': 2.44740120717339, 'mape': 0.04181817632162802, 'r2': 0.9879706958907054}}\n",
      "{'loss': 50.20209917300613, 'mape': 0.03795794218282853, 'r2': 0.9940068418199668}\n",
      "XXXXXXXXXXXXXXXX Running 1 256 layers XXXXXXXXXXXXXXXXXXXX\n",
      "Initializing model:\n",
      " - Window size: 20\n",
      " - Features: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
      " - Target: Open\n",
      "--- Preparing ^IXIC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.47700000e+03  5.44091016e+03  8.72110000e+08  1.43798828e+01\n",
      " -1.06362988e+03  1.16226960e+01 -6.03732918e+02 -1.85963467e+02]\n",
      "Feature max [1.86474492e+04 1.86592500e+04 1.19326000e+10 8.98230469e+02\n",
      " 5.16000000e+02 1.00000000e+02 3.79729000e+02 1.68559430e+02]\n",
      "Target min [5425.62011719]\n",
      "Target max [18659.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRTX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.70500031e+01  7.52200012e+01  3.00500000e+05  9.29992676e-01\n",
      " -4.39099884e+01  6.98832867e+00 -1.61057278e+01 -6.35634960e+00]\n",
      "Feature max [5.05779999e+02 5.07040009e+02 1.74930000e+07 3.32000122e+01\n",
      " 2.96399994e+01 1.00000000e+02 1.72224200e+01 7.01903411e+00]\n",
      "Target min [74.43000031]\n",
      "Target max [507.04000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PYPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93100014e+01  3.94000015e+01  1.68000000e+06  2.79998779e-01\n",
      " -3.59100037e+01  5.36242303e+00 -1.82619484e+01 -6.83508729e+00]\n",
      "Feature max [3.08529999e+02 3.09660004e+02 1.36264000e+08 2.25299988e+01\n",
      " 1.48899994e+01 1.00000000e+02 1.63896973e+01 4.70789452e+00]\n",
      "Target min [39.40000153]\n",
      "Target max [309.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GILD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.83768921e+01  4.84647841e+01  1.93100000e+06  3.33687013e-01\n",
      " -6.63972958e+00  5.76429643e+00 -2.31350264e+00 -8.99640092e-01]\n",
      "Feature max [8.53581619e+01 8.44682978e+01 9.43485000e+07 8.04050698e+00\n",
      " 7.22807397e+00 1.00000000e+02 4.20840186e+00 1.25684670e+00]\n",
      "Target min [48.46478409]\n",
      "Target max [84.46829781]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.10076237e+01  1.08333294e+01  2.58690000e+06  1.03459220e-01\n",
      " -2.80620499e+00  6.42020381e+00 -2.09796529e+00 -6.88387246e-01]\n",
      "Feature max [3.81064873e+01 3.81660578e+01 2.95518300e+08 2.47469078e+00\n",
      " 2.03002009e+00 1.00000000e+02 1.17294696e+00 5.41764687e-01]\n",
      "Target min [10.83332938]\n",
      "Target max [38.16605779]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing IDXX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.15949997e+02  1.15989998e+02  6.95000000e+04  1.01998901e+00\n",
      " -5.39599915e+01  0.00000000e+00 -4.51944855e+01 -1.18420530e+01]\n",
      "Feature max [7.05760010e+02 6.98869995e+02 2.06065000e+07 4.94200134e+01\n",
      " 2.44899902e+01 9.87477702e+01 2.80133056e+01 9.19398448e+00]\n",
      "Target min [115.98999786]\n",
      "Target max [698.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.72258072e+01  4.72942329e+01  4.40100000e+05  2.32199924e-01\n",
      " -6.70203006e+00  0.00000000e+00 -5.58792171e+00 -1.85080567e+00]\n",
      "Feature max [1.00876343e+02 1.03304346e+02 2.24557000e+07 1.05535592e+01\n",
      " 3.30011799e+00 1.00000000e+02 2.91608734e+00 1.39528234e+00]\n",
      "Target min [47.29423289]\n",
      "Target max [103.30434621]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TEAM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.47199993e+01  2.47299995e+01  2.10900000e+05  2.16999054e-01\n",
      " -4.31699982e+01  1.07833899e+01 -2.66488051e+01 -8.97255197e+00]\n",
      "Feature max [4.58130005e+02 4.55200012e+02 1.74562000e+07 4.22299805e+01\n",
      " 4.32099915e+01 1.00000000e+02 2.40637139e+01 8.94966359e+00]\n",
      "Target min [24.31999969]\n",
      "Target max [455.20001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PANW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.60033340e+01  3.61399994e+01  1.02260000e+06  3.56666565e-01\n",
      " -9.08899841e+01  3.81140920e+00 -1.38470391e+01 -1.22788064e+01]\n",
      "Feature max [3.76899994e+02 3.75450012e+02 6.53592000e+07 2.73699951e+01\n",
      " 2.68099976e+01 1.00000000e+02 1.51691964e+01 4.87990591e+00]\n",
      "Target min [36.13999939]\n",
      "Target max [375.45001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AVGO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.37303324e+01  1.37248174e+01  4.12300000e+06  1.24250219e-01\n",
      " -1.42100067e+01  0.00000000e+00 -5.06872189e+00 -3.00550723e+00]\n",
      "Feature max [1.82308105e+02 1.83376725e+02 4.35083000e+08 1.69199982e+01\n",
      " 2.13810994e+01 9.28312266e+01 1.05782566e+01 4.55284581e+00]\n",
      "Target min [13.72481739]\n",
      "Target max [183.37672469]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CEG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.08016357e+01  3.98784499e+01  2.35000000e+04  6.26233823e-01\n",
      " -1.08198405e+01  1.27016955e+01 -1.06308757e+01 -3.92755151e+00]\n",
      "Feature max [2.30487686e+02 2.31952715e+02 2.38609000e+07 2.15543358e+01\n",
      " 2.45442808e+01 1.00000000e+02 1.44754867e+01 4.38796659e+00]\n",
      "Target min [37.00563649]\n",
      "Target max [231.9527148]\n",
      "X_train shape: (637, 20, 8)\n",
      "Train_dates: 2022-01-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MSFT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.65738716e+01  5.64739814e+01  7.42560000e+06  2.90591318e-01\n",
      " -1.92852005e+01  0.00000000e+00 -1.18035322e+01 -4.62579684e+00]\n",
      "Feature max [4.66718781e+02 4.66159796e+02 1.11242100e+08 2.43750285e+01\n",
      " 2.10308765e+01 9.87205903e+01 1.16126197e+01 3.05457761e+00]\n",
      "Target min [56.4739814]\n",
      "Target max [466.15979612]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EXC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.82024384e+01  1.85263383e+01  2.00850500e+06  1.22239479e-01\n",
      " -1.93681767e+00  5.27401978e+00 -2.56103502e+00 -9.27310413e-01]\n",
      "Feature max [4.59507675e+01 4.58593246e+01 3.88453000e+07 4.14685444e+00\n",
      " 1.20619631e+00 1.00000000e+02 1.62739185e+00 5.65170278e-01]\n",
      "Target min [18.52633834]\n",
      "Target max [45.8593246]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DXCM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.11149998e+01  1.10325003e+01  8.61200000e+05  1.64999962e-01\n",
      " -4.18499985e+01  4.43708879e+00 -1.21858259e+01 -5.03116733e+00]\n",
      "Feature max [1.62815002e+02 1.64257507e+02 1.23168400e+08 1.88925018e+01\n",
      " 1.24700012e+01 1.00000000e+02 8.60785647e+00 2.40813081e+00]\n",
      "Target min [11.03250027]\n",
      "Target max [164.25750732]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FAST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65418415e+01  1.66370276e+01  7.04500000e+05  1.46829925e-01\n",
      " -3.17296730e+00  2.73472132e+00 -1.96586911e+00 -1.08293915e+00]\n",
      "Feature max [7.75266724e+01 7.77145119e+01 5.26096000e+07 4.66000366e+00\n",
      " 3.55978900e+00 1.00000000e+02 1.87048215e+00 8.56669819e-01]\n",
      "Target min [16.63702755]\n",
      "Target max [77.71451195]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ABNB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.24899979e+01  8.29700012e+01  1.72560000e+06  1.01499939e+00\n",
      " -1.80299988e+01  0.00000000e+00 -1.29513658e+01 -4.57280582e+00]\n",
      "Feature max [2.16839996e+02 2.16240005e+02 7.47864000e+07 3.05000000e+01\n",
      " 1.21199951e+01 9.29350181e+01 1.31150691e+01 3.98198040e+00]\n",
      "Target min [82.97000122]\n",
      "Target max [216.24000549]\n",
      "X_train shape: (915, 20, 8)\n",
      "Train_dates: 2020-12-11 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SNPS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.95699997e+01  5.93699989e+01  2.00200000e+05  2.60002136e-01\n",
      " -3.66699829e+01  7.61484664e+00 -2.46719247e+01 -8.22743530e+00]\n",
      "Feature max [6.21299988e+02 6.22929993e+02 3.02946000e+07 5.02700195e+01\n",
      " 4.64199829e+01 1.00000000e+02 2.12557667e+01 8.46134558e+00]\n",
      "Target min [59.27000046]\n",
      "Target max [622.92999268]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BIIB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [187.53999329 190.55999756   0.           0.         -98.07998657\n",
      "   4.79436191 -25.57434546 -11.64517675]\n",
      "Feature max [4.14709991e+02 4.23329987e+02 2.18431000e+07 1.82549988e+02\n",
      " 8.64900055e+01 1.00000000e+02 3.49582846e+01 1.62224245e+01]\n",
      "Target min [190.55999756]\n",
      "Target max [423.32998657]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing REGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.73459991e+02  2.74350006e+02  1.71600000e+05  2.76998901e+00\n",
      " -4.76300049e+01  6.11531109e+00 -2.90962700e+01 -1.14012185e+01]\n",
      "Feature max [1.20176001e+03 1.20471997e+03 7.86950000e+06 8.12899780e+01\n",
      " 9.05499878e+01 1.00000000e+02 3.48632110e+01 1.33649620e+01]\n",
      "Target min [274.3500061]\n",
      "Target max [1204.7199707]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.40612183e+01  7.38682278e+01  1.45000000e+05  3.47388758e-01\n",
      " -1.39151339e+01  7.46563833e+00 -1.02972301e+01 -4.01614363e+00]\n",
      "Feature max [2.85989990e+02 2.85000000e+02 4.24820000e+06 1.72982830e+01\n",
      " 1.09380049e+01 1.00000000e+02 7.65713957e+00 3.71764210e+00]\n",
      "Target min [73.8682278]\n",
      "Target max [285.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TSLA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.19313326e+01  1.20733328e+01  2.94018000e+07  1.66667938e-01\n",
      " -2.41000061e+01  6.91932630e+00 -2.52713333e+01 -7.67848148e+00]\n",
      "Feature max [4.09970001e+02 4.11470001e+02 9.14082000e+08 5.43266602e+01\n",
      " 3.25100098e+01 1.00000000e+02 3.80679297e+01 1.02961745e+01]\n",
      "Target min [12.07333279]\n",
      "Target max [411.47000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NVDA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35561490e+00  2.36844215e+00  9.78840000e+07  3.05890986e-02\n",
      " -1.52099991e+01  8.18788925e+00 -5.16786769e+00 -2.56494372e+00]\n",
      "Feature max [1.35580002e+02 1.39800003e+02 3.69292800e+09 1.33500061e+01\n",
      " 9.16999817e+00 1.00000000e+02 9.77617753e+00 2.89363431e+00]\n",
      "Target min [2.36844215]\n",
      "Target max [139.80000305]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CPRT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95749998e+00  6.97499990e+00  1.16560000e+06  4.75001335e-02\n",
      " -2.40999985e+00  1.07028555e+01 -2.08288713e+00 -5.95224464e-01]\n",
      "Feature max [5.80699997e+01 5.81300011e+01 2.13690400e+08 3.43000031e+00\n",
      " 1.91999817e+00 1.00000000e+02 1.68053820e+00 5.29970520e-01]\n",
      "Target min [6.94750023]\n",
      "Target max [58.13000107]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ORLY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.72850006e+02  1.72839996e+02  9.76000000e+04  1.75000000e+00\n",
      " -7.26999512e+01  9.93704967e+00 -3.18757122e+01 -1.55376421e+01]\n",
      "Feature max [1.16753003e+03 1.16473999e+03 1.28304000e+07 6.14700928e+01\n",
      " 3.95399780e+01 1.00000000e+02 2.94044788e+01 1.46112531e+01]\n",
      "Target min [172.83999634]\n",
      "Target max [1164.73999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSGP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.90799999e+01  1.86439991e+01  4.31000000e+05  1.32999420e-01\n",
      " -1.35200005e+01  3.82196899e+00 -3.91839760e+00 -1.70338203e+00]\n",
      "Feature max [9.97399979e+01 9.96600037e+01 5.40349000e+07 1.53570023e+01\n",
      " 2.22259979e+01 1.00000000e+02 3.78952594e+00 1.64810768e+00]\n",
      "Target min [18.6439991]\n",
      "Target max [99.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PDD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.71499996e+01  1.72000008e+01  1.21070000e+06  3.10001373e-01\n",
      " -2.96699982e+01  0.00000000e+00 -1.20781712e+01 -6.25067404e+00]\n",
      "Feature max [2.02820007e+02 2.11600006e+02 1.03174600e+08 2.12799988e+01\n",
      " 2.67000046e+01 9.22446129e+01 1.43527401e+01 4.73466591e+00]\n",
      "Target min [17.20000076]\n",
      "Target max [211.6000061]\n",
      "X_train shape: (1514, 20, 8)\n",
      "Train_dates: 2018-07-27 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing HON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.46234360e+01  9.52324076e+01  6.25500000e+05  4.19023052e-01\n",
      " -1.95059016e+01  4.75278607e+00 -1.40929698e+01 -4.45800843e+00]\n",
      "Feature max [2.19502502e+02 2.19940296e+02 2.82371000e+07 2.09818749e+01\n",
      " 1.90410089e+01 1.00000000e+02 8.86861072e+00 3.23137307e+00]\n",
      "Target min [95.2324076]\n",
      "Target max [219.94029556]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.14207611e+01  6.16446746e+01  4.66400000e+05  4.04764990e-01\n",
      " -1.59855186e+01  0.00000000e+00 -6.96255526e+00 -3.47483258e+00]\n",
      "Feature max [2.42376740e+02 2.39537898e+02 1.91564000e+07 1.54971600e+01\n",
      " 1.14345345e+01 9.47163396e+01 9.37402072e+00 2.80709341e+00]\n",
      "Target min [61.64467465]\n",
      "Target max [239.53789776]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.30818100e+01  7.35512493e+01  5.83900000e+05  5.47719845e-01\n",
      " -1.30866480e+01  5.85108252e+00 -5.68716510e+00 -2.63117508e+00]\n",
      "Feature max [1.51820007e+02 1.50807724e+02 3.87045000e+07 1.23726545e+01\n",
      " 1.06121148e+01 1.00000000e+02 4.99350087e+00 2.11381268e+00]\n",
      "Target min [73.55124929]\n",
      "Target max [150.80772389]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.64580727e+01  1.71472504e+01  1.14310000e+06  1.73414616e-01\n",
      " -9.42169789e+00  0.00000000e+00 -3.04021934e+00 -1.40459929e+00]\n",
      "Feature max [6.87902832e+01 6.75091317e+01 1.35204800e+08 4.21353693e+00\n",
      " 3.35944971e+00 9.56385384e+01 1.17085491e+00 5.30558464e-01]\n",
      "Target min [17.14725043]\n",
      "Target max [67.50913169]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WBD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.71000004e+00  6.67000008e+00  7.96300000e+05  1.29999638e-01\n",
      " -4.63999939e+00  7.36432776e+00 -5.62270475e+00 -4.52551421e+00]\n",
      "Feature max [7.72699966e+01 7.79800034e+01 1.58082500e+08 2.36100006e+01\n",
      " 3.59000015e+00 1.00000000e+02 7.78521295e+00 1.10191292e+00]\n",
      "Target min [6.67000008]\n",
      "Target max [77.98000336]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.77167328e+02  1.76918230e+02  1.00700000e+05  1.05556125e+00\n",
      " -7.16817807e+01  1.01359214e+01 -2.43843415e+01 -7.21921351e+00]\n",
      "Feature max [5.76549988e+02 5.77500000e+02 8.03490000e+06 6.23608649e+01\n",
      " 3.51599731e+01 1.00000000e+02 1.65133374e+01 6.23603615e+00]\n",
      "Target min [176.71795625]\n",
      "Target max [577.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15072441  8.44775229  0.          0.         -2.64121934  0.\n",
      " -2.42761184 -0.84240932]\n",
      "Feature max [3.84843826e+01 3.84346839e+01 7.90905000e+07 3.35121803e+00\n",
      " 2.26196184e+00 9.66592825e+01 2.24860583e+00 6.65253741e-01]\n",
      "Target min [8.44775229]\n",
      "Target max [38.43468386]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing COST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.34840027e+02  1.34848979e+02  5.43600000e+05  6.44244141e-01\n",
      " -2.94507776e+01  7.85629341e+00 -3.22091486e+01 -9.48258088e+00]\n",
      "Feature max [9.08900024e+02 9.10960022e+02 2.42330000e+07 4.41770966e+01\n",
      " 1.44716264e+01 1.00000000e+02 2.40226275e+01 6.93894978e+00]\n",
      "Target min [134.84897936]\n",
      "Target max [910.96002197]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.09898186e+01  2.08327099e+01  7.55800000e+05  1.13624071e-01\n",
      " -4.94520049e+00  1.11788092e+01 -2.60963603e+00 -8.58607909e-01]\n",
      "Feature max [8.76200027e+01 8.73300018e+01 6.55402000e+07 7.22391984e+00\n",
      " 4.14095187e+00 1.00000000e+02 2.45854722e+00 7.89947576e-01]\n",
      "Target min [20.83270988]\n",
      "Target max [87.33000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LRCX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.58611450e+01  9.56820789e+01  3.00600000e+05  6.44566123e-01\n",
      " -6.64899902e+01  8.02011760e+00 -6.76982729e+01 -2.23238752e+01]\n",
      "Feature max [1.12730005e+03 1.12977002e+03 1.34214000e+07 7.38499756e+01\n",
      " 3.86400146e+01 1.00000000e+02 3.73546198e+01 1.44478835e+01]\n",
      "Target min [95.50305089]\n",
      "Target max [1129.77001953]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MELI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65434570e+02  1.61862890e+02  1.09000000e+05  1.65614527e+00\n",
      " -1.47979980e+02  6.42065563e+00 -1.26762239e+02 -4.86753050e+01]\n",
      "Feature max [2.06165991e+03 2.03525000e+03 4.29950000e+06 1.80000000e+02\n",
      " 1.14010010e+02 1.00000000e+02 9.65798543e+01 4.12565588e+01]\n",
      "Target min [158.54064047]\n",
      "Target max [2035.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.67368202e+01  4.67459702e+01  1.82100000e+05  3.48899250e-01\n",
      " -2.61501151e+01  1.10567815e+01 -1.16427000e+01 -2.77844166e+00]\n",
      "Feature max [2.56499237e+02 2.59970663e+02 2.45494000e+07 1.57643685e+01\n",
      " 1.15215616e+01 1.00000000e+02 6.29487366e+00 2.94088535e+00]\n",
      "Target min [46.74597021]\n",
      "Target max [259.97066279]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FANG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.26427393e+01  1.29027437e+01  2.62100000e+05  7.69125581e-01\n",
      " -1.58440536e+01  1.03147586e+00 -1.19967650e+01 -3.84871246e+00]\n",
      "Feature max [2.08427399e+02 2.08555865e+02 3.30497000e+07 1.22028993e+01\n",
      " 7.94710827e+00 1.00000000e+02 7.18674571e+00 2.89178313e+00]\n",
      "Target min [12.90274369]\n",
      "Target max [208.55586459]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ZS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.49500008e+01  2.50000000e+01  1.97200000e+05  3.79999161e-01\n",
      " -3.88899994e+01  0.00000000e+00 -2.36812080e+01 -8.89085502e+00]\n",
      "Feature max [3.68779999e+02 3.72500000e+02 2.68458000e+07 5.90399780e+01\n",
      " 2.63500061e+01 9.43483988e+01 1.81146072e+01 6.76156951e+00]\n",
      "Target min [25.]\n",
      "Target max [372.5]\n",
      "X_train shape: (1605, 20, 8)\n",
      "Train_dates: 2018-03-19 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADBE data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.04139999e+02  1.03739998e+02  5.89200000e+05  6.49993896e-01\n",
      " -7.08099976e+01  1.41851355e+00 -3.26176172e+01 -1.20971259e+01]\n",
      "Feature max [6.88369995e+02 6.96280029e+02 2.78402000e+07 5.77900391e+01\n",
      " 7.15100098e+01 1.00000000e+02 3.08100807e+01 9.11981859e+00]\n",
      "Target min [103.43000031]\n",
      "Target max [696.2800293]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93002777e+01  3.92593243e+01  6.93600000e+06  1.63815054e-01\n",
      " -1.10299988e+01  1.33774083e+01 -5.19036880e+00 -2.41195015e+00]\n",
      "Feature max [1.92660004e+02 1.91750000e+02 1.24140000e+08 9.33999634e+00\n",
      " 1.80194956e+01 1.00000000e+02 5.21262163e+00 1.68897131e+00]\n",
      "Target min [38.8962372]\n",
      "Target max [191.75]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMAT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.72328167e+01  2.75991753e+01  1.40920000e+06  2.48054590e-01\n",
      " -1.45720706e+01  1.10477914e+01 -1.30488603e+01 -4.80425105e+00]\n",
      "Feature max [2.54482300e+02 2.55081164e+02 5.25842000e+07 1.67279368e+01\n",
      " 1.42822510e+01 1.00000000e+02 1.06164147e+01 3.45275434e+00]\n",
      "Target min [27.59917534]\n",
      "Target max [255.0811642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.12595749e+01  8.12424824e+01  3.50200000e+05  3.94597419e-01\n",
      " -1.50322602e+01  3.70819088e+00 -1.35625543e+01 -3.90767243e+00]\n",
      "Feature max [2.75910004e+02 2.75790009e+02 2.98376000e+07 1.78119307e+01\n",
      " 1.03888203e+01 1.00000000e+02 1.01973409e+01 2.87688222e+00]\n",
      "Target min [81.24248244]\n",
      "Target max [275.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SBUX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.25571442e+01  4.21538439e+01  1.84780000e+06  2.41612853e-01\n",
      " -1.24990574e+01  3.06340275e+00 -6.61673815e+00 -1.77160421e+00]\n",
      "Feature max [1.17301460e+02 1.17320081e+02 1.57215500e+08 8.91208038e+00\n",
      " 1.39059501e+01 1.00000000e+02 5.32951402e+00 2.47897411e+00]\n",
      "Target min [42.15384393]\n",
      "Target max [117.32008083]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTWO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.93600006e+01  4.94000015e+01  2.11600000e+05  3.89999390e-01\n",
      " -1.71000061e+01  5.25756554e+00 -1.00961129e+01 -3.59837456e+00]\n",
      "Feature max [2.13339996e+02 2.10479996e+02 2.53857000e+07 1.86999969e+01\n",
      " 1.62300034e+01 1.00000000e+02 8.60457497e+00 3.04146889e+00]\n",
      "Target min [49.34999847]\n",
      "Target max [210.47999573]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TMUS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.45139275e+01  5.45139255e+01  4.70100000e+05  2.26488207e-01\n",
      " -9.75855268e+00  9.14573089e+00 -4.12801837e+00 -2.00070086e+00]\n",
      "Feature max [2.03367172e+02 2.04613114e+02 6.69031000e+07 1.24074312e+01\n",
      " 1.02607535e+01 1.00000000e+02 5.13087004e+00 2.60923757e+00]\n",
      "Target min [54.51392553]\n",
      "Target max [204.61311436]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WDAY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.13600006e+01  6.86699982e+01  3.69100000e+05  7.19993591e-01\n",
      " -2.87099915e+01  9.22365714e+00 -1.61351526e+01 -5.44748712e+00]\n",
      "Feature max [3.07209991e+02 3.09100006e+02 1.56112000e+07 2.13899994e+01\n",
      " 3.39099884e+01 1.00000000e+02 1.38299273e+01 6.22001392e+00]\n",
      "Target min [66.75]\n",
      "Target max [309.1000061]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CRWD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.30099983e+01  3.39300003e+01  8.04900000e+05  1.25000000e+00\n",
      " -4.85399780e+01  5.38771656e+00 -3.82154109e+01 -1.52669393e+01]\n",
      "Feature max [3.92149994e+02 3.92510010e+02 5.40774000e+07 4.09899902e+01\n",
      " 6.24899902e+01 1.00000000e+02 1.92436948e+01 8.51986054e+00]\n",
      "Target min [33.93000031]\n",
      "Target max [392.51000977]\n",
      "X_train shape: (1294, 20, 8)\n",
      "Train_dates: 2019-06-13 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DDOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.80400009e+01  2.78999996e+01  5.74800000e+05  7.30003357e-01\n",
      " -2.19200058e+01  0.00000000e+00 -1.14620833e+01 -4.12330397e+00]\n",
      "Feature max [1.96559998e+02 1.97695999e+02 2.91348000e+07 2.36900024e+01\n",
      " 2.69400024e+01 9.94039849e+01 1.14713512e+01 4.87120929e+00]\n",
      "Target min [27.89999962]\n",
      "Target max [197.69599915]\n",
      "X_train shape: (1225, 20, 8)\n",
      "Train_dates: 2019-09-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PCAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.86600723e+01  2.83693944e+01  4.95450000e+05  1.76137070e-01\n",
      " -1.04065623e+01  7.26975186e+00 -3.26233711e+00 -1.44177860e+00]\n",
      "Feature max [1.23713150e+02 1.24249916e+02 1.21321500e+07 7.01745891e+00\n",
      " 3.03884635e+00 1.00000000e+02 4.25862738e+00 1.04586866e+00]\n",
      "Target min [28.36939438]\n",
      "Target max [124.24991579]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">271,360</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m271,360\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,617</span> (1.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m271,617\u001b[0m (1.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,617</span> (1.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m271,617\u001b[0m (1.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/51 Training model for ^IXIC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0096 - mape: 103.0791 - val_loss: 0.0074 - val_mape: 9.2440\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0329 - mape: 266.8864 - val_loss: 0.0038 - val_mape: 6.0797\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0149 - mape: 173.3322 - val_loss: 0.0025 - val_mape: 4.9173\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0044 - mape: 83.9906 - val_loss: 5.7904e-04 - val_mape: 2.1393\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.2356e-04 - mape: 24.3235 - val_loss: 2.5343e-04 - val_mape: 1.4149\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - mape: 49.7705 - val_loss: 2.8566e-04 - val_mape: 1.5617\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.4801e-04 - mape: 19.6926 - val_loss: 3.0443e-04 - val_mape: 1.6746\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.9148e-04 - mape: 26.3390 - val_loss: 3.5393e-04 - val_mape: 1.8820\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3958e-04 - mape: 13.5962 - val_loss: 1.5131e-04 - val_mape: 1.0784\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.9908e-04 - mape: 16.9615 - val_loss: 1.4280e-04 - val_mape: 1.0626\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4391e-04 - mape: 16.9885 - val_loss: 1.2908e-04 - val_mape: 1.0079\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.0550e-04 - mape: 11.7860 - val_loss: 1.3872e-04 - val_mape: 1.1170\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.4380e-04 - mape: 21.2254 - val_loss: 1.0679e-04 - val_mape: 0.8832\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8137e-04 - mape: 10.7034 - val_loss: 9.5647e-04 - val_mape: 3.5496\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4268e-04 - mape: 14.5407 - val_loss: 1.5530e-04 - val_mape: 1.1040\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.0571e-04 - mape: 27.8846 - val_loss: 2.0864e-04 - val_mape: 1.5293\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1216e-04 - mape: 21.2639 - val_loss: 1.3420e-04 - val_mape: 1.0422\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.2255e-04 - mape: 16.6208 - val_loss: 9.0914e-05 - val_mape: 0.8532\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5152e-04 - mape: 9.9792 - val_loss: 1.1240e-04 - val_mape: 0.9502\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4516e-04 - mape: 10.5069 - val_loss: 3.6617e-04 - val_mape: 2.1543\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1449e-04 - mape: 21.9526 - val_loss: 1.4270e-04 - val_mape: 1.0631\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.5990e-04 - mape: 21.8028 - val_loss: 4.1418e-04 - val_mape: 2.2747\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5762e-04 - mape: 9.5296 - val_loss: 1.9580e-04 - val_mape: 1.2925\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.5360e-04 - mape: 36.9845 - val_loss: 8.8550e-04 - val_mape: 3.4803\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.4270e-04 - mape: 34.2260 - val_loss: 3.0344e-04 - val_mape: 1.9111\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.2940e-04 - mape: 13.9378 - val_loss: 8.3100e-05 - val_mape: 0.8068\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.9950e-04 - mape: 32.5096 - val_loss: 4.4367e-04 - val_mape: 2.4027\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.2652e-04 - mape: 22.3814 - val_loss: 2.6776e-04 - val_mape: 1.7932\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4137e-04 - mape: 17.6740 - val_loss: 2.6743e-04 - val_mape: 1.6627\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.7404e-04 - mape: 33.4561 - val_loss: 2.3157e-04 - val_mape: 1.6194\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2307e-04 - mape: 9.7592 - val_loss: 2.0217e-04 - val_mape: 1.5255\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0522e-04 - mape: 8.4886 - val_loss: 7.5856e-05 - val_mape: 0.7246\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.1246e-04 - mape: 14.1858 - val_loss: 8.3168e-05 - val_mape: 0.8152\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3240e-04 - mape: 18.8817 - val_loss: 2.0506e-04 - val_mape: 1.5457\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1700e-04 - mape: 10.7215 - val_loss: 1.1533e-04 - val_mape: 1.0958\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9589e-04 - mape: 8.2329 - val_loss: 1.4095e-04 - val_mape: 1.1390\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.5651e-04 - mape: 18.9792 - val_loss: 7.4620e-05 - val_mape: 0.8103\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8934e-04 - mape: 8.5260 - val_loss: 1.5465e-04 - val_mape: 1.3345\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0700e-04 - mape: 8.5202 - val_loss: 8.3675e-05 - val_mape: 0.8543\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.6044e-04 - mape: 20.1594 - val_loss: 1.5308e-04 - val_mape: 1.1648\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8756e-04 - mape: 15.5352 - val_loss: 1.1426e-04 - val_mape: 1.1287\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3840e-04 - mape: 20.5360 - val_loss: 1.7380e-04 - val_mape: 1.3525\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3300e-04 - mape: 19.5094 - val_loss: 2.3749e-04 - val_mape: 1.5084\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9911e-04 - mape: 10.8371 - val_loss: 2.2297e-04 - val_mape: 1.3908\n",
      "Epoch 45/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0966e-04 - mape: 11.2718 - val_loss: 1.2794e-04 - val_mape: 1.0499\n",
      "Epoch 46/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4078e-04 - mape: 15.3282 - val_loss: 3.7049e-04 - val_mape: 1.8548\n",
      "Epoch 47/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6881e-04 - mape: 8.8487 - val_loss: 3.0291e-04 - val_mape: 1.6245\n",
      "--- 2/51 Training model for VRTX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6966e-04 - mape: 5.7883 - val_loss: 2.4843e-04 - val_mape: 1.5874\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.4355e-04 - mape: 16.9411 - val_loss: 1.6730e-04 - val_mape: 1.2659\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.8597e-04 - mape: 22.4440 - val_loss: 1.0556e-04 - val_mape: 0.9975\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7841e-04 - mape: 15.3491 - val_loss: 2.7140e-04 - val_mape: 1.6636\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4382e-04 - mape: 5.3728 - val_loss: 3.5760e-04 - val_mape: 1.9515\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0633e-04 - mape: 9.2857 - val_loss: 1.3591e-04 - val_mape: 1.1315\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.9801e-04 - mape: 18.5600 - val_loss: 3.5061e-04 - val_mape: 1.8459\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1639e-04 - mape: 9.6262 - val_loss: 1.0342e-04 - val_mape: 0.9729\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8321e-04 - mape: 15.9864 - val_loss: 4.2239e-04 - val_mape: 2.1844\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5592e-04 - mape: 7.1291 - val_loss: 1.8610e-04 - val_mape: 1.2970\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2720e-04 - mape: 4.7132 - val_loss: 1.1640e-04 - val_mape: 1.0717\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8703e-04 - mape: 9.0362 - val_loss: 8.4948e-05 - val_mape: 0.8434\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6177e-04 - mape: 7.7610 - val_loss: 4.7905e-04 - val_mape: 2.3620\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.9801e-04 - mape: 12.3106 - val_loss: 1.5849e-04 - val_mape: 1.2254\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - mape: 28.7743 - val_loss: 1.7477e-04 - val_mape: 1.4101\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.4160e-04 - mape: 14.4248 - val_loss: 2.6066e-04 - val_mape: 1.5459\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8225e-04 - mape: 8.6003 - val_loss: 7.6810e-04 - val_mape: 3.0949\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1242e-04 - mape: 9.9660 - val_loss: 1.6266e-04 - val_mape: 1.2312\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - mape: 31.7151 - val_loss: 1.4816e-04 - val_mape: 1.1772\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.1469e-04 - mape: 24.0283 - val_loss: 1.0753e-04 - val_mape: 0.9224\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4750e-04 - mape: 7.0264 - val_loss: 1.9593e-04 - val_mape: 1.3377\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1869e-04 - mape: 13.9161 - val_loss: 6.3774e-05 - val_mape: 0.7251\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7782e-04 - mape: 9.2415 - val_loss: 1.1277e-04 - val_mape: 1.0017\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2295e-04 - mape: 6.0455 - val_loss: 6.2658e-05 - val_mape: 0.7372\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2833e-04 - mape: 5.0116 - val_loss: 1.2031e-04 - val_mape: 1.0218\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.3663e-04 - mape: 18.0263 - val_loss: 6.2173e-05 - val_mape: 0.7152\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0321e-04 - mape: 4.3632 - val_loss: 7.7119e-05 - val_mape: 0.8087\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1183e-04 - mape: 4.7257 - val_loss: 7.6620e-05 - val_mape: 0.8049\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7424e-04 - mape: 8.8201 - val_loss: 1.5817e-04 - val_mape: 1.2445\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0928e-04 - mape: 5.2856 - val_loss: 1.1006e-04 - val_mape: 1.0449\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6381e-04 - mape: 7.6992 - val_loss: 1.7939e-04 - val_mape: 1.2391\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.1724e-04 - mape: 26.0306 - val_loss: 2.7744e-04 - val_mape: 1.6153\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - mape: 46.3790 - val_loss: 1.3618e-04 - val_mape: 1.1091\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9916e-04 - mape: 15.0185 - val_loss: 6.2589e-05 - val_mape: 0.7161\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0169e-04 - mape: 4.7502 - val_loss: 7.4668e-05 - val_mape: 0.7846\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4251e-04 - mape: 8.0101 - val_loss: 1.0131e-04 - val_mape: 1.0487\n",
      "--- 3/51 Training model for PYPL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5361e-04 - mape: 29478.1367 - val_loss: 3.0944e-05 - val_mape: 5.8556\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5256e-04 - mape: 360.6422 - val_loss: 6.8068e-06 - val_mape: 2.3701\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5088e-04 - mape: 420.4296 - val_loss: 7.4796e-05 - val_mape: 9.9188\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.3493e-04 - mape: 25919.3301 - val_loss: 6.5550e-06 - val_mape: 2.3750\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1511e-04 - mape: 2484.9316 - val_loss: 4.4589e-05 - val_mape: 7.5312\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4947e-04 - mape: 3288.5198 - val_loss: 6.6451e-05 - val_mape: 9.2884\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.1729e-04 - mape: 14589.0322 - val_loss: 9.5323e-05 - val_mape: 11.1727\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.2851e-04 - mape: 40453.0938 - val_loss: 1.1969e-04 - val_mape: 12.1876\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.5702e-04 - mape: 23431.5977 - val_loss: 2.2374e-04 - val_mape: 17.2392\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6993e-04 - mape: 8492.3027 - val_loss: 7.7209e-06 - val_mape: 2.6245\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4240e-04 - mape: 31351.8203 - val_loss: 7.9507e-06 - val_mape: 2.5907\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7291e-04 - mape: 37339.4414 - val_loss: 2.7258e-05 - val_mape: 5.5482\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8687e-04 - mape: 101687.2422 - val_loss: 6.9039e-05 - val_mape: 9.2001\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5513e-04 - mape: 63948.4141 - val_loss: 6.8917e-06 - val_mape: 2.4910\n",
      "--- 4/51 Training model for GILD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.8905e-04 - mape: 7481.6646 - val_loss: 5.0875e-04 - val_mape: 2.8339\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.9368e-04 - mape: 32337.3477 - val_loss: 0.0012 - val_mape: 4.3305\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0020 - mape: 37031.0664 - val_loss: 4.2906e-04 - val_mape: 2.3809\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.9086e-04 - mape: 31473.0703 - val_loss: 2.6371e-04 - val_mape: 1.8897\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.2050e-04 - mape: 16597.0430 - val_loss: 5.9153e-04 - val_mape: 2.9649\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4382e-04 - mape: 27216.2246 - val_loss: 3.1369e-04 - val_mape: 2.1181\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5073e-04 - mape: 14212.6172 - val_loss: 0.0012 - val_mape: 4.8825\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1758e-04 - mape: 28447.1367 - val_loss: 1.7686e-04 - val_mape: 1.6290\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3966e-04 - mape: 20431.3320 - val_loss: 2.4979e-04 - val_mape: 1.9939\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.8480e-04 - mape: 30305.3418 - val_loss: 3.0471e-04 - val_mape: 2.2153\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4301e-04 - mape: 20043.3848 - val_loss: 7.6792e-04 - val_mape: 3.7740\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1154e-04 - mape: 22829.2305 - val_loss: 2.3491e-04 - val_mape: 1.8727\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5417e-04 - mape: 15265.8428 - val_loss: 3.3954e-04 - val_mape: 2.3455\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2057e-04 - mape: 20205.2305 - val_loss: 4.8816e-04 - val_mape: 2.9185\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5967e-04 - mape: 21708.6836 - val_loss: 7.7682e-04 - val_mape: 3.7669\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.9825e-04 - mape: 25378.2539 - val_loss: 1.8645e-04 - val_mape: 1.6624\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4492e-04 - mape: 13599.4463 - val_loss: 3.7464e-04 - val_mape: 2.5154\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1040e-04 - mape: 17715.9043 - val_loss: 3.9218e-04 - val_mape: 2.5835\n",
      "--- 5/51 Training model for CSX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3815e-04 - mape: 5.1841 - val_loss: 5.0844e-05 - val_mape: 0.6576\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.4375e-04 - mape: 8.1271 - val_loss: 8.0241e-05 - val_mape: 0.8388\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - mape: 13.0304 - val_loss: 1.4544e-04 - val_mape: 1.1376\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - mape: 19.0519 - val_loss: 5.1895e-04 - val_mape: 2.2453\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0045 - mape: 26.7896 - val_loss: 4.6881e-04 - val_mape: 2.1248\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0034 - mape: 23.3180 - val_loss: 1.3126e-04 - val_mape: 1.0208\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - mape: 13.0305 - val_loss: 1.0059e-04 - val_mape: 0.8603\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.8101e-04 - mape: 5.1348 - val_loss: 4.4944e-04 - val_mape: 2.3332\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.4802e-04 - mape: 11.0613 - val_loss: 4.9649e-05 - val_mape: 0.6235\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.3576e-04 - mape: 4.0123 - val_loss: 5.0434e-05 - val_mape: 0.6134\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1147e-04 - mape: 3.5165 - val_loss: 5.8896e-05 - val_mape: 0.6777\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0740e-04 - mape: 3.3271 - val_loss: 3.1164e-04 - val_mape: 1.8768\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0870e-04 - mape: 3.4529 - val_loss: 1.5092e-04 - val_mape: 1.1942\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0324e-04 - mape: 3.2863 - val_loss: 7.3028e-05 - val_mape: 0.8041\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0872e-04 - mape: 3.5172 - val_loss: 7.3469e-05 - val_mape: 0.8015\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6102e-04 - mape: 4.6676 - val_loss: 3.5003e-05 - val_mape: 0.5251\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2361e-04 - mape: 3.7515 - val_loss: 1.5502e-04 - val_mape: 1.2926\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4280e-04 - mape: 4.2750 - val_loss: 5.9600e-05 - val_mape: 0.7249\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0686e-04 - mape: 3.4488 - val_loss: 6.1595e-05 - val_mape: 0.7463\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0347e-04 - mape: 3.3149 - val_loss: 3.0707e-05 - val_mape: 0.4884\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7552e-04 - mape: 5.0158 - val_loss: 1.1166e-04 - val_mape: 1.0425\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0369e-04 - mape: 3.5122 - val_loss: 1.6538e-04 - val_mape: 1.3369\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0385e-04 - mape: 3.4247 - val_loss: 1.0300e-04 - val_mape: 1.0413\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0306e-04 - mape: 3.1673 - val_loss: 4.3133e-05 - val_mape: 0.6048\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9898e-04 - mape: 3.3261 - val_loss: 7.3654e-05 - val_mape: 0.8317\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.6246e-04 - mape: 4.4590 - val_loss: 2.7119e-05 - val_mape: 0.4680\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.6397e-04 - mape: 6.2897 - val_loss: 3.1611e-05 - val_mape: 0.5149\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8636e-04 - mape: 6.6583 - val_loss: 7.0770e-05 - val_mape: 0.8307\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8680e-04 - mape: 6.4116 - val_loss: 1.1796e-04 - val_mape: 1.1234\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.3136e-04 - mape: 7.4159 - val_loss: 7.2293e-05 - val_mape: 0.8490\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5953e-04 - mape: 4.8813 - val_loss: 4.3434e-05 - val_mape: 0.6358\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4672e-04 - mape: 4.2049 - val_loss: 5.1175e-05 - val_mape: 0.6645\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6708e-04 - mape: 7.8397 - val_loss: 1.8037e-04 - val_mape: 1.3978\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.5718e-04 - mape: 6.5779 - val_loss: 2.2726e-05 - val_mape: 0.4362\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5519e-04 - mape: 4.6171 - val_loss: 1.5827e-04 - val_mape: 1.3401\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.5090e-04 - mape: 6.2614 - val_loss: 6.2284e-05 - val_mape: 0.7840\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3233e-04 - mape: 4.3974 - val_loss: 3.0477e-05 - val_mape: 0.5030\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4162e-04 - mape: 4.7228 - val_loss: 1.2502e-04 - val_mape: 1.1228\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2199e-04 - mape: 4.0461 - val_loss: 2.6161e-05 - val_mape: 0.4717\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6936e-04 - mape: 5.1895 - val_loss: 3.5283e-05 - val_mape: 0.5333\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1081e-04 - mape: 4.2249 - val_loss: 2.1932e-04 - val_mape: 1.5584\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0665e-04 - mape: 3.3394 - val_loss: 1.3794e-04 - val_mape: 1.1969\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.7561e-04 - mape: 10.0186 - val_loss: 5.1436e-05 - val_mape: 0.6375\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7740e-04 - mape: 6.8237 - val_loss: 3.4355e-04 - val_mape: 2.0407\n",
      "--- 6/51 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5366e-04 - mape: 12.3550 - val_loss: 2.7366e-05 - val_mape: 0.5988\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4898e-04 - mape: 5.9098 - val_loss: 3.3630e-05 - val_mape: 0.6555\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5599e-04 - mape: 7.0042 - val_loss: 3.7845e-05 - val_mape: 0.7556\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1576e-04 - mape: 8.6931 - val_loss: 2.1435e-04 - val_mape: 1.9974\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.8471e-04 - mape: 26.2870 - val_loss: 0.0015 - val_mape: 5.6628\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0028 - mape: 52.2085 - val_loss: 0.0023 - val_mape: 7.0033\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0033 - mape: 56.4391 - val_loss: 0.0020 - val_mape: 6.5040\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0020 - mape: 43.2829 - val_loss: 3.0986e-04 - val_mape: 2.3827\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.0372e-04 - mape: 16.4017 - val_loss: 2.8196e-04 - val_mape: 2.2957\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6365e-04 - mape: 7.7515 - val_loss: 4.2416e-05 - val_mape: 0.7406\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2694e-04 - mape: 10.5355 - val_loss: 7.2936e-05 - val_mape: 1.0560\n",
      "--- 7/51 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5092e-04 - mape: 5.3984 - val_loss: 1.8442e-04 - val_mape: 1.4524\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3640e-04 - mape: 5.9907 - val_loss: 7.3062e-05 - val_mape: 0.7813\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3442e-04 - mape: 5.8287 - val_loss: 1.6277e-04 - val_mape: 1.3303\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5346e-04 - mape: 6.6633 - val_loss: 6.9866e-05 - val_mape: 0.7643\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6947e-04 - mape: 7.9567 - val_loss: 7.1689e-05 - val_mape: 0.9941\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5486e-04 - mape: 7.6792 - val_loss: 1.3801e-04 - val_mape: 1.5626\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8060e-04 - mape: 8.5706 - val_loss: 1.8267e-04 - val_mape: 1.2421\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5828e-04 - mape: 7.1328 - val_loss: 1.4523e-04 - val_mape: 1.0982\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6833e-04 - mape: 7.9438 - val_loss: 5.3848e-04 - val_mape: 2.6251\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9064e-04 - mape: 8.3501 - val_loss: 2.3413e-04 - val_mape: 1.4201\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.0030e-04 - mape: 13.3769 - val_loss: 3.0948e-04 - val_mape: 1.7564\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7639e-04 - mape: 8.6380 - val_loss: 1.6066e-04 - val_mape: 1.1675\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9589e-04 - mape: 9.3811 - val_loss: 1.9555e-04 - val_mape: 1.2712\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8570e-04 - mape: 8.8100 - val_loss: 1.2992e-04 - val_mape: 1.0566\n",
      "--- 8/51 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3973e-04 - mape: 21.5843 - val_loss: 3.1982e-05 - val_mape: 1.1642\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1138e-04 - mape: 50.1525 - val_loss: 2.2353e-05 - val_mape: 1.0530\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5136e-04 - mape: 26.2772 - val_loss: 4.3935e-05 - val_mape: 1.4108\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0810e-04 - mape: 36.0057 - val_loss: 1.3063e-05 - val_mape: 0.7399\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1455e-04 - mape: 22.1075 - val_loss: 1.8184e-05 - val_mape: 0.8812\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2013e-04 - mape: 21.8335 - val_loss: 5.2243e-05 - val_mape: 1.7043\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0715e-04 - mape: 19.1328 - val_loss: 3.2577e-05 - val_mape: 1.1531\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6606e-04 - mape: 29.2811 - val_loss: 2.7349e-05 - val_mape: 1.0817\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7018e-04 - mape: 30.3708 - val_loss: 3.8893e-05 - val_mape: 1.3846\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.7796e-04 - mape: 44.9765 - val_loss: 6.9141e-05 - val_mape: 1.6205\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.7488e-04 - mape: 67.0557 - val_loss: 1.4151e-05 - val_mape: 0.7876\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6577e-04 - mape: 26.5697 - val_loss: 3.8861e-05 - val_mape: 1.3623\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7636e-04 - mape: 32.0030 - val_loss: 2.6427e-05 - val_mape: 1.0712\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0567e-04 - mape: 34.9574 - val_loss: 6.6554e-05 - val_mape: 1.6199\n",
      "--- 9/51 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0766e-04 - mape: 35854.4062 - val_loss: 2.9170e-04 - val_mape: 1.8206\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7130e-05 - mape: 30110.3594 - val_loss: 9.9638e-05 - val_mape: 0.8085\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.2621e-05 - mape: 22348.4473 - val_loss: 3.9768e-04 - val_mape: 2.2018\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3165e-04 - mape: 50731.9570 - val_loss: 1.5744e-04 - val_mape: 1.2354\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1654e-04 - mape: 89505.1719 - val_loss: 3.3456e-04 - val_mape: 2.0174\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5195e-04 - mape: 37271.8281 - val_loss: 8.3505e-05 - val_mape: 0.7558\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1329e-04 - mape: 4524.1929 - val_loss: 9.1604e-05 - val_mape: 0.7932\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.5084e-05 - mape: 60241.2852 - val_loss: 8.7602e-05 - val_mape: 0.6637\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5020e-04 - mape: 51295.8125 - val_loss: 3.5293e-04 - val_mape: 2.0790\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.4538e-04 - mape: 36009.4961 - val_loss: 1.4989e-04 - val_mape: 1.1913\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9527e-04 - mape: 27861.8027 - val_loss: 7.7775e-05 - val_mape: 0.6789\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2744e-04 - mape: 35395.6992 - val_loss: 7.7390e-05 - val_mape: 0.6607\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.1008e-04 - mape: 23442.9883 - val_loss: 1.6459e-04 - val_mape: 1.3152\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.0772e-05 - mape: 6830.4565 - val_loss: 8.5558e-05 - val_mape: 0.7418\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0603e-04 - mape: 25545.2383 - val_loss: 8.3399e-05 - val_mape: 0.6488\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.5323e-05 - mape: 22444.8848 - val_loss: 1.0901e-04 - val_mape: 0.8711\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1474e-04 - mape: 6584.0776 - val_loss: 2.0094e-04 - val_mape: 1.4242\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4010e-04 - mape: 5078.2354 - val_loss: 1.8403e-04 - val_mape: 1.3570\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.2959e-05 - mape: 1771.1316 - val_loss: 1.6054e-04 - val_mape: 1.2286\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.4873e-05 - mape: 6336.7290 - val_loss: 2.0063e-04 - val_mape: 1.4712\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2662e-04 - mape: 44899.3359 - val_loss: 4.1083e-04 - val_mape: 2.2819\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.5762e-05 - mape: 21646.4648 - val_loss: 8.5050e-05 - val_mape: 0.6877\n",
      "--- 10/51 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.9967e-05 - mape: 22.8826 - val_loss: 3.5816e-04 - val_mape: 2.3046\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3215e-04 - mape: 47.6502 - val_loss: 4.6191e-04 - val_mape: 2.0956\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.2286e-04 - mape: 61.6017 - val_loss: 5.1910e-04 - val_mape: 2.9726\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.1854e-04 - mape: 60.3028 - val_loss: 8.0549e-04 - val_mape: 2.9333\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.2321e-04 - mape: 60.7149 - val_loss: 9.6334e-04 - val_mape: 4.2749\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.0167e-04 - mape: 64.5142 - val_loss: 0.0013 - val_mape: 3.9325\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.1187e-04 - mape: 66.6961 - val_loss: 2.0492e-04 - val_mape: 1.6104\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8730e-04 - mape: 44.0346 - val_loss: 0.0016 - val_mape: 4.7524\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.7966e-04 - mape: 71.7402 - val_loss: 9.4661e-05 - val_mape: 0.9139\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0344e-04 - mape: 24.4441 - val_loss: 3.9369e-04 - val_mape: 2.1200\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9058e-04 - mape: 46.0338 - val_loss: 1.4675e-04 - val_mape: 1.1174\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9896e-04 - mape: 37.4591 - val_loss: 0.0013 - val_mape: 4.1241\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.5930e-04 - mape: 71.1488 - val_loss: 1.2212e-04 - val_mape: 1.1020\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6066e-04 - mape: 31.4944 - val_loss: 9.6837e-04 - val_mape: 3.5740\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.2643e-04 - mape: 62.5772 - val_loss: 1.5003e-04 - val_mape: 1.1550\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9874e-04 - mape: 36.2862 - val_loss: 0.0021 - val_mape: 5.3452\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.0465e-04 - mape: 83.3544 - val_loss: 2.1568e-04 - val_mape: 1.4766\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.6267e-05 - mape: 23.3566 - val_loss: 5.1226e-04 - val_mape: 2.4830\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1896e-04 - mape: 56.5425 - val_loss: 2.0049e-04 - val_mape: 1.3491\n",
      "--- 11/51 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4481e-04 - mape: 14.6242 - val_loss: 6.6398e-04 - val_mape: 2.7883\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - mape: 40.7958 - val_loss: 0.0018 - val_mape: 4.8926\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0010 - mape: 26.7017 - val_loss: 0.0028 - val_mape: 6.2218\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0038 - mape: 54.1874 - val_loss: 0.0014 - val_mape: 4.1537\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.1572e-04 - mape: 26.5089 - val_loss: 3.6374e-04 - val_mape: 1.9365\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6182e-04 - mape: 12.5866 - val_loss: 7.7149e-04 - val_mape: 3.0313\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1574e-04 - mape: 11.5928 - val_loss: 0.0016 - val_mape: 4.6847\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - mape: 61.2449 - val_loss: 0.0017 - val_mape: 4.5867\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0017 - mape: 30.1746 - val_loss: 0.0161 - val_mape: 15.0986\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0235 - mape: 146.8980 - val_loss: 3.0538e-04 - val_mape: 1.4229\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - mape: 27.3218 - val_loss: 9.9966e-04 - val_mape: 3.0252\n",
      "Epoch 12/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - mape: 17.7097 - val_loss: 0.0034 - val_mape: 5.6669\n",
      "Epoch 13/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0021 - mape: 39.5574 - val_loss: 7.3525e-04 - val_mape: 2.8193\n",
      "Epoch 14/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4519e-04 - mape: 15.0248 - val_loss: 9.4676e-04 - val_mape: 3.0477\n",
      "Epoch 15/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011 - mape: 29.4152 - val_loss: 3.4573e-04 - val_mape: 1.6917\n",
      "Epoch 16/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3240e-04 - mape: 11.1355 - val_loss: 3.0516e-04 - val_mape: 1.4965\n",
      "Epoch 17/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3564e-04 - mape: 10.0195 - val_loss: 6.6409e-04 - val_mape: 2.5730\n",
      "Epoch 18/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4293e-04 - mape: 14.0482 - val_loss: 3.0723e-04 - val_mape: 1.4562\n",
      "Epoch 19/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5861e-04 - mape: 12.3718 - val_loss: 3.0418e-04 - val_mape: 1.3828\n",
      "Epoch 20/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2506e-04 - mape: 8.0859 - val_loss: 3.6228e-04 - val_mape: 1.6551\n",
      "Epoch 21/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3367e-04 - mape: 7.1652 - val_loss: 2.5897e-04 - val_mape: 1.1900\n",
      "Epoch 22/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0347e-04 - mape: 12.5395 - val_loss: 3.9005e-04 - val_mape: 1.7131\n",
      "Epoch 23/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.8305e-04 - mape: 15.2446 - val_loss: 2.4919e-04 - val_mape: 1.0990\n",
      "Epoch 24/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4714e-04 - mape: 14.6902 - val_loss: 3.0404e-04 - val_mape: 1.3608\n",
      "Epoch 25/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1130e-04 - mape: 7.1644 - val_loss: 4.0803e-04 - val_mape: 1.8528\n",
      "Epoch 26/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.8026e-05 - mape: 5.8690 - val_loss: 2.6722e-04 - val_mape: 1.1463\n",
      "Epoch 27/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1519e-04 - mape: 7.5401 - val_loss: 3.0434e-04 - val_mape: 1.3842\n",
      "Epoch 28/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.9600e-05 - mape: 5.0225 - val_loss: 2.6561e-04 - val_mape: 1.1401\n",
      "Epoch 29/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.4328e-05 - mape: 6.2316 - val_loss: 2.6721e-04 - val_mape: 1.1456\n",
      "Epoch 30/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.8797e-05 - mape: 6.9527 - val_loss: 2.8460e-04 - val_mape: 1.2625\n",
      "Epoch 31/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1559e-04 - mape: 6.7927 - val_loss: 2.5241e-04 - val_mape: 1.1345\n",
      "Epoch 32/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8604e-04 - mape: 9.5115 - val_loss: 2.9724e-04 - val_mape: 1.3034\n",
      "Epoch 33/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9236e-04 - mape: 13.4835 - val_loss: 2.4539e-04 - val_mape: 1.0863\n",
      "Epoch 34/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6847e-04 - mape: 13.1854 - val_loss: 2.6694e-04 - val_mape: 1.1462\n",
      "Epoch 35/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2938e-04 - mape: 8.3889 - val_loss: 2.8344e-04 - val_mape: 1.3177\n",
      "Epoch 36/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0388e-04 - mape: 6.7254 - val_loss: 2.7023e-04 - val_mape: 1.1594\n",
      "Epoch 37/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5387e-05 - mape: 6.3405 - val_loss: 2.6726e-04 - val_mape: 1.1965\n",
      "Epoch 38/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4680e-05 - mape: 6.8515 - val_loss: 2.7656e-04 - val_mape: 1.2404\n",
      "Epoch 39/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.8629e-05 - mape: 5.2533 - val_loss: 2.8303e-04 - val_mape: 1.2845\n",
      "Epoch 40/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7670e-05 - mape: 5.5020 - val_loss: 2.7290e-04 - val_mape: 1.2314\n",
      "Epoch 41/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.4265e-05 - mape: 5.2426 - val_loss: 2.6236e-04 - val_mape: 1.1549\n",
      "Epoch 42/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9140e-05 - mape: 5.5924 - val_loss: 2.6364e-04 - val_mape: 1.1551\n",
      "Epoch 43/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9966e-05 - mape: 5.0090 - val_loss: 2.5607e-04 - val_mape: 1.1512\n",
      "--- 12/51 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.8172e-04 - mape: 81.3892 - val_loss: 4.8391e-04 - val_mape: 2.0122\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2014e-04 - mape: 28.8232 - val_loss: 5.2808e-04 - val_mape: 2.0907\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3686e-04 - mape: 87.5356 - val_loss: 2.0480e-04 - val_mape: 1.2931\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - mape: 206.9497 - val_loss: 5.5324e-04 - val_mape: 2.0950\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - mape: 232.0193 - val_loss: 0.0028 - val_mape: 5.8645\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0032 - mape: 321.1162 - val_loss: 4.0601e-04 - val_mape: 1.7938\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.7978e-04 - mape: 127.4159 - val_loss: 3.6949e-04 - val_mape: 1.8454\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - mape: 183.6747 - val_loss: 7.4174e-04 - val_mape: 2.5827\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.6819e-04 - mape: 127.2372 - val_loss: 4.8519e-04 - val_mape: 2.2168\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - mape: 183.5376 - val_loss: 4.7584e-04 - val_mape: 2.0025\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.7509e-04 - mape: 139.4228 - val_loss: 9.3851e-04 - val_mape: 3.2641\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - mape: 200.2602 - val_loss: 2.8603e-04 - val_mape: 1.5093\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.9634e-04 - mape: 103.2562 - val_loss: 3.6964e-04 - val_mape: 1.9114\n",
      "--- 13/51 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - mape: 70685.8125 - val_loss: 4.9417e-04 - val_mape: 3.1519\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.4016e-04 - mape: 100171.1797 - val_loss: 2.7152e-04 - val_mape: 2.4032\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.2086e-04 - mape: 78439.8906 - val_loss: 1.2670e-04 - val_mape: 1.3355\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.8238e-04 - mape: 67024.5938 - val_loss: 1.0406e-04 - val_mape: 1.3529\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3032e-04 - mape: 58247.3555 - val_loss: 1.4280e-04 - val_mape: 1.4390\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.2031e-04 - mape: 23321.7012 - val_loss: 1.1154e-04 - val_mape: 1.4287\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.5700e-04 - mape: 32949.6836 - val_loss: 2.0964e-04 - val_mape: 1.8716\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1259e-04 - mape: 57228.9727 - val_loss: 7.0088e-05 - val_mape: 1.0202\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.5494e-04 - mape: 52297.8086 - val_loss: 1.4102e-04 - val_mape: 1.4509\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.2769e-04 - mape: 37232.8203 - val_loss: 1.0658e-04 - val_mape: 1.4154\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.4674e-04 - mape: 50082.1211 - val_loss: 5.6028e-05 - val_mape: 0.8501\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2317e-04 - mape: 43364.5430 - val_loss: 1.1755e-04 - val_mape: 1.5243\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0621e-04 - mape: 36284.6367 - val_loss: 2.7532e-04 - val_mape: 2.3346\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.3848e-04 - mape: 49901.2148 - val_loss: 1.0447e-04 - val_mape: 1.4277\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5252e-04 - mape: 40409.0312 - val_loss: 1.3119e-04 - val_mape: 1.4780\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5022e-04 - mape: 33864.8438 - val_loss: 5.8662e-05 - val_mape: 1.0095\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0774e-04 - mape: 4057.7097 - val_loss: 1.0194e-04 - val_mape: 1.3932\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1873e-04 - mape: 113.7556 - val_loss: 1.5013e-04 - val_mape: 1.6397\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1971e-04 - mape: 8223.3740 - val_loss: 5.3195e-05 - val_mape: 0.9497\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3919e-04 - mape: 34925.1992 - val_loss: 4.4311e-05 - val_mape: 0.7875\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1458e-04 - mape: 21410.6797 - val_loss: 8.4926e-05 - val_mape: 1.2441\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4557e-04 - mape: 26026.5059 - val_loss: 4.3098e-05 - val_mape: 0.7201\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1854e-04 - mape: 17730.6680 - val_loss: 4.6645e-05 - val_mape: 0.7567\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3444e-04 - mape: 3935.3228 - val_loss: 3.9290e-05 - val_mape: 0.7333\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4750e-04 - mape: 20641.3320 - val_loss: 6.1026e-05 - val_mape: 0.9337\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8893e-04 - mape: 16386.1992 - val_loss: 4.7794e-05 - val_mape: 0.8000\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.0365e-04 - mape: 9590.2314 - val_loss: 2.3093e-04 - val_mape: 2.1598\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8070e-04 - mape: 24001.0332 - val_loss: 1.6353e-04 - val_mape: 1.6409\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0074e-04 - mape: 57107.9141 - val_loss: 4.8897e-05 - val_mape: 0.7874\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5608e-04 - mape: 24262.4004 - val_loss: 1.3710e-04 - val_mape: 1.6740\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7664e-04 - mape: 70186.4844 - val_loss: 2.6129e-04 - val_mape: 2.4329\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4271e-04 - mape: 14085.4365 - val_loss: 4.2322e-05 - val_mape: 0.7092\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6847e-04 - mape: 3485.4185 - val_loss: 5.4731e-05 - val_mape: 0.9080\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8948e-04 - mape: 33457.0078 - val_loss: 9.8542e-05 - val_mape: 1.2339\n",
      "--- 14/51 Training model for DXCM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.5863e-04 - mape: 1987.5006 - val_loss: 3.2394e-05 - val_mape: 0.7046\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2207e-04 - mape: 252.3640 - val_loss: 8.6144e-05 - val_mape: 1.2349\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4045e-04 - mape: 3586.5244 - val_loss: 1.8373e-04 - val_mape: 1.7754\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4495e-04 - mape: 30237.9102 - val_loss: 6.3708e-04 - val_mape: 3.2408\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7294e-04 - mape: 4276.5630 - val_loss: 2.0019e-04 - val_mape: 2.0552\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6113e-04 - mape: 5326.9277 - val_loss: 3.2840e-05 - val_mape: 0.7032\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2222e-04 - mape: 11379.3828 - val_loss: 1.2138e-04 - val_mape: 1.3953\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8216e-04 - mape: 10235.7041 - val_loss: 1.4330e-04 - val_mape: 1.6321\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5576e-04 - mape: 32388.7734 - val_loss: 1.0327e-04 - val_mape: 1.2483\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2379e-04 - mape: 28647.7500 - val_loss: 3.0467e-05 - val_mape: 0.6539\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5258e-04 - mape: 6787.7856 - val_loss: 2.0143e-04 - val_mape: 1.8741\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4688e-04 - mape: 3732.0220 - val_loss: 7.5579e-05 - val_mape: 1.0942\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1536e-04 - mape: 3245.8115 - val_loss: 9.3449e-05 - val_mape: 1.3141\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1362e-04 - mape: 5063.1582 - val_loss: 1.2097e-04 - val_mape: 1.4698\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7604e-04 - mape: 6727.1748 - val_loss: 8.3313e-05 - val_mape: 1.1381\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6276e-04 - mape: 20207.6836 - val_loss: 1.3800e-04 - val_mape: 1.5793\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3820e-04 - mape: 3118.5923 - val_loss: 2.7349e-04 - val_mape: 2.1432\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5780e-04 - mape: 27613.7988 - val_loss: 1.7103e-04 - val_mape: 1.7938\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5338e-04 - mape: 4951.1406 - val_loss: 1.5047e-04 - val_mape: 1.5827\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2897e-04 - mape: 13685.6904 - val_loss: 1.5389e-05 - val_mape: 0.4814\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2856e-04 - mape: 21553.4180 - val_loss: 4.2020e-05 - val_mape: 0.8392\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1817e-04 - mape: 7426.2852 - val_loss: 2.9421e-05 - val_mape: 0.6526\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4207e-04 - mape: 26484.7324 - val_loss: 2.0820e-04 - val_mape: 1.9032\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.3580e-04 - mape: 17659.9863 - val_loss: 3.8741e-04 - val_mape: 2.5461\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.4017e-04 - mape: 17228.4902 - val_loss: 5.3003e-04 - val_mape: 3.3004\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.9848e-04 - mape: 3183.4229 - val_loss: 6.5419e-04 - val_mape: 3.3177\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.0352e-04 - mape: 14544.9873 - val_loss: 4.6922e-04 - val_mape: 3.3171\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7352e-04 - mape: 18436.9395 - val_loss: 2.7572e-04 - val_mape: 2.1968\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7946e-04 - mape: 11208.5244 - val_loss: 1.4418e-04 - val_mape: 1.7143\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3802e-04 - mape: 12120.2607 - val_loss: 1.7721e-05 - val_mape: 0.5021\n",
      "--- 15/51 Training model for FAST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8060e-04 - mape: 6555.9492 - val_loss: 2.0205e-04 - val_mape: 1.3971\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5220e-04 - mape: 26704.5020 - val_loss: 2.0200e-04 - val_mape: 1.2906\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3978e-04 - mape: 48973.0000 - val_loss: 9.7464e-05 - val_mape: 0.7967\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4532e-04 - mape: 11159.2383 - val_loss: 1.3004e-04 - val_mape: 0.9385\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.2869e-04 - mape: 14559.3770 - val_loss: 1.5079e-04 - val_mape: 1.0932\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.4558e-04 - mape: 29702.9844 - val_loss: 1.1469e-04 - val_mape: 0.8607\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1754e-04 - mape: 512.6022 - val_loss: 1.2638e-04 - val_mape: 0.9627\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2220e-04 - mape: 28374.2070 - val_loss: 1.2098e-04 - val_mape: 0.9130\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8822e-04 - mape: 17065.4863 - val_loss: 1.0896e-04 - val_mape: 0.8957\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.6155e-04 - mape: 12235.0166 - val_loss: 1.6140e-04 - val_mape: 1.1173\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6679e-04 - mape: 15956.3232 - val_loss: 2.5560e-04 - val_mape: 1.6035\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6181e-04 - mape: 31072.8535 - val_loss: 1.1631e-04 - val_mape: 0.9202\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7450e-04 - mape: 18563.4902 - val_loss: 9.8065e-05 - val_mape: 0.8455\n",
      "--- 16/51 Training model for ABNB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.2599e-04 - mape: 18080.5879 - val_loss: 7.6058e-05 - val_mape: 1.7342\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.4865e-04 - mape: 11123.6953 - val_loss: 4.7145e-05 - val_mape: 1.3181\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0109e-04 - mape: 15058.3955 - val_loss: 3.5896e-05 - val_mape: 1.1433\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9332e-04 - mape: 2448.4656 - val_loss: 4.2251e-05 - val_mape: 1.3480\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9302e-04 - mape: 12436.3662 - val_loss: 4.0554e-05 - val_mape: 1.2706\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3799e-04 - mape: 6745.8901 - val_loss: 4.7309e-05 - val_mape: 1.4082\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0197e-04 - mape: 13516.8916 - val_loss: 4.6876e-05 - val_mape: 1.2669\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.2579e-04 - mape: 13271.2285 - val_loss: 4.1737e-05 - val_mape: 1.1971\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1445e-04 - mape: 1317.6483 - val_loss: 3.4067e-05 - val_mape: 1.1412\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0171e-04 - mape: 3180.4724 - val_loss: 4.3509e-05 - val_mape: 1.3913\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.6296e-04 - mape: 1617.4120 - val_loss: 5.9485e-05 - val_mape: 1.4190\n",
      "Epoch 12/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0024e-04 - mape: 10238.3965 - val_loss: 4.6575e-05 - val_mape: 1.2650\n",
      "Epoch 13/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.6641e-04 - mape: 11471.8398 - val_loss: 3.9206e-05 - val_mape: 1.2012\n",
      "Epoch 14/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1834e-04 - mape: 3480.5769 - val_loss: 2.9425e-05 - val_mape: 1.0513\n",
      "Epoch 15/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.6744e-04 - mape: 1226.7157 - val_loss: 4.7077e-05 - val_mape: 1.4491\n",
      "Epoch 16/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7052e-04 - mape: 10311.4619 - val_loss: 3.4170e-05 - val_mape: 1.0827\n",
      "Epoch 17/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6174e-04 - mape: 13216.5830 - val_loss: 3.2346e-05 - val_mape: 1.0351\n",
      "Epoch 18/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8143e-04 - mape: 6314.0444 - val_loss: 3.1579e-05 - val_mape: 1.0390\n",
      "Epoch 19/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3050e-04 - mape: 8169.4546 - val_loss: 3.2977e-05 - val_mape: 1.0919\n",
      "Epoch 20/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8361e-04 - mape: 3546.1958 - val_loss: 3.5405e-05 - val_mape: 1.1037\n",
      "Epoch 21/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8974e-04 - mape: 9882.5898 - val_loss: 4.2321e-05 - val_mape: 1.2057\n",
      "Epoch 22/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1999e-04 - mape: 16393.9512 - val_loss: 2.0964e-05 - val_mape: 0.9155\n",
      "Epoch 23/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3853e-04 - mape: 1240.9092 - val_loss: 2.3772e-05 - val_mape: 0.9439\n",
      "Epoch 24/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9748e-04 - mape: 387.1274 - val_loss: 2.3112e-05 - val_mape: 0.9636\n",
      "Epoch 25/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.9331e-04 - mape: 12609.1543 - val_loss: 6.4890e-05 - val_mape: 1.7383\n",
      "Epoch 26/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.4382e-04 - mape: 14384.7305 - val_loss: 7.5602e-05 - val_mape: 1.7598\n",
      "Epoch 27/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5394e-04 - mape: 16928.5195 - val_loss: 6.0096e-05 - val_mape: 1.6417\n",
      "Epoch 28/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0327e-04 - mape: 25363.8223 - val_loss: 3.4249e-05 - val_mape: 1.1152\n",
      "Epoch 29/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0251e-04 - mape: 7597.6440 - val_loss: 2.2318e-05 - val_mape: 1.0047\n",
      "Epoch 30/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7237e-04 - mape: 1970.0845 - val_loss: 2.6349e-05 - val_mape: 1.0818\n",
      "Epoch 31/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2222e-04 - mape: 7889.1841 - val_loss: 3.4147e-05 - val_mape: 1.1495\n",
      "Epoch 32/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1275e-04 - mape: 5113.8135 - val_loss: 4.7377e-05 - val_mape: 1.4093\n",
      "--- 17/51 Training model for SNPS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0937e-04 - mape: 18.7709 - val_loss: 2.2295e-04 - val_mape: 1.2642\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.4533e-04 - mape: 53.0989 - val_loss: 1.5422e-04 - val_mape: 1.0315\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0188e-04 - mape: 21.2005 - val_loss: 1.4948e-04 - val_mape: 1.0283\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5076e-04 - mape: 27.0167 - val_loss: 1.5221e-04 - val_mape: 1.0179\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.7262e-05 - mape: 18.7004 - val_loss: 2.0890e-04 - val_mape: 1.2723\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4964e-04 - mape: 37.0997 - val_loss: 1.2747e-04 - val_mape: 0.9172\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2932e-04 - mape: 22.7033 - val_loss: 1.4201e-04 - val_mape: 0.9923\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1834e-04 - mape: 22.7248 - val_loss: 1.2290e-04 - val_mape: 0.9080\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.8434e-05 - mape: 18.7650 - val_loss: 1.2118e-04 - val_mape: 0.8858\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1360e-04 - mape: 22.4296 - val_loss: 1.1798e-04 - val_mape: 0.8751\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.5739e-05 - mape: 18.9341 - val_loss: 8.7462e-05 - val_mape: 0.7481\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.4602e-04 - mape: 53.5943 - val_loss: 1.7159e-04 - val_mape: 1.2238\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.6611e-04 - mape: 46.5042 - val_loss: 1.9761e-04 - val_mape: 1.1806\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.5029e-04 - mape: 64.7079 - val_loss: 1.4150e-04 - val_mape: 1.0236\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.4975e-05 - mape: 18.1272 - val_loss: 9.5904e-05 - val_mape: 0.7790\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4894e-04 - mape: 47.0693 - val_loss: 1.6115e-04 - val_mape: 1.1187\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0253e-04 - mape: 32.9587 - val_loss: 1.7080e-04 - val_mape: 1.0675\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.7747e-04 - mape: 54.9706 - val_loss: 1.5574e-04 - val_mape: 1.0568\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2966e-04 - mape: 24.5584 - val_loss: 1.9591e-04 - val_mape: 1.2257\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5864e-04 - mape: 28.7333 - val_loss: 1.3854e-04 - val_mape: 0.9905\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7758e-04 - mape: 30.1881 - val_loss: 1.2518e-04 - val_mape: 0.9472\n",
      "--- 18/51 Training model for BIIB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6729e-04 - mape: 1643.5850 - val_loss: 1.2234e-04 - val_mape: 24.6201\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7679e-04 - mape: 700.4742 - val_loss: 1.8053e-05 - val_mape: 6.3359\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5391e-04 - mape: 1055.5724 - val_loss: 4.5017e-05 - val_mape: 10.2555\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7210e-04 - mape: 1772.2935 - val_loss: 1.9856e-04 - val_mape: 21.3337\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2458e-04 - mape: 2488.6206 - val_loss: 6.7198e-04 - val_mape: 51.9948\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9801e-04 - mape: 1050.2148 - val_loss: 7.5784e-05 - val_mape: 13.0859\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8083e-04 - mape: 1171.4961 - val_loss: 1.3917e-04 - val_mape: 26.0254\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4261e-04 - mape: 583.9063 - val_loss: 2.3295e-04 - val_mape: 29.2758\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8527e-04 - mape: 733.6091 - val_loss: 9.7718e-05 - val_mape: 17.5512\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4406e-04 - mape: 2018.6794 - val_loss: 1.3576e-05 - val_mape: 5.2461\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4230e-04 - mape: 715.0222 - val_loss: 1.1178e-04 - val_mape: 23.7994\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4933e-04 - mape: 1429.4081 - val_loss: 1.1476e-04 - val_mape: 23.1632\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6250e-04 - mape: 3189.0247 - val_loss: 1.5841e-05 - val_mape: 8.9316\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3480e-04 - mape: 4067.4622 - val_loss: 5.7356e-05 - val_mape: 11.8074\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5230e-04 - mape: 764.9105 - val_loss: 2.3178e-04 - val_mape: 27.7891\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9712e-04 - mape: 4062.4802 - val_loss: 5.8221e-04 - val_mape: 43.9386\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8355e-04 - mape: 3264.2207 - val_loss: 4.1192e-04 - val_mape: 39.5697\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8820e-04 - mape: 2434.8064 - val_loss: 6.5276e-04 - val_mape: 52.1779\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3398e-04 - mape: 3668.0796 - val_loss: 3.3524e-05 - val_mape: 8.8615\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3894e-04 - mape: 218.4745 - val_loss: 6.3091e-05 - val_mape: 14.7636\n",
      "--- 19/51 Training model for REGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.9900e-05 - mape: 2771.1143 - val_loss: 6.3918e-05 - val_mape: 0.8383\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.4271e-05 - mape: 6124.2085 - val_loss: 4.3672e-05 - val_mape: 0.7077\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.8881e-05 - mape: 116.0425 - val_loss: 3.8696e-05 - val_mape: 0.6720\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.1727e-05 - mape: 10663.6660 - val_loss: 3.1969e-05 - val_mape: 0.6095\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.8947e-05 - mape: 535.6459 - val_loss: 3.5679e-05 - val_mape: 0.6177\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.8661e-05 - mape: 6699.8481 - val_loss: 7.8081e-05 - val_mape: 0.9412\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.8235e-05 - mape: 3633.4104 - val_loss: 3.0213e-05 - val_mape: 0.5799\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.2566e-05 - mape: 362.1457 - val_loss: 2.9435e-05 - val_mape: 0.5776\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.1920e-05 - mape: 1603.8203 - val_loss: 2.7915e-05 - val_mape: 0.5622\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.6968e-05 - mape: 2011.0038 - val_loss: 3.6062e-05 - val_mape: 0.6360\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.3792e-05 - mape: 6658.2065 - val_loss: 6.2338e-05 - val_mape: 0.8226\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.0800e-05 - mape: 10819.5283 - val_loss: 3.3044e-05 - val_mape: 0.6073\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.9038e-05 - mape: 919.5869 - val_loss: 3.2460e-05 - val_mape: 0.6144\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.5683e-05 - mape: 2086.8374 - val_loss: 4.5109e-05 - val_mape: 0.7388\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.5417e-05 - mape: 4416.0273 - val_loss: 3.1821e-05 - val_mape: 0.6200\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.4287e-05 - mape: 8730.3193 - val_loss: 4.5845e-05 - val_mape: 0.6709\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.4538e-05 - mape: 1881.3356 - val_loss: 6.6667e-05 - val_mape: 0.8621\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.2858e-05 - mape: 3825.4285 - val_loss: 3.2404e-05 - val_mape: 0.5612\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.0364e-05 - mape: 6563.8711 - val_loss: 3.1522e-05 - val_mape: 0.5443\n",
      "--- 20/51 Training model for VRSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8166e-04 - mape: 34827.3672 - val_loss: 1.1035e-04 - val_mape: 1.0571\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8612e-04 - mape: 90335.7266 - val_loss: 7.8153e-04 - val_mape: 3.2551\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.7901e-04 - mape: 42370.3906 - val_loss: 5.8831e-05 - val_mape: 0.6276\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7276e-04 - mape: 68803.3359 - val_loss: 1.5420e-04 - val_mape: 1.2307\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1649e-04 - mape: 18500.5254 - val_loss: 5.3553e-05 - val_mape: 0.5710\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4260e-04 - mape: 17686.2793 - val_loss: 8.3645e-05 - val_mape: 0.8473\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2370e-04 - mape: 37120.8945 - val_loss: 8.9171e-05 - val_mape: 0.9451\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9594e-04 - mape: 56420.2969 - val_loss: 5.5759e-05 - val_mape: 0.6569\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1916e-04 - mape: 16035.5498 - val_loss: 1.0776e-04 - val_mape: 1.0815\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5257e-04 - mape: 28206.2598 - val_loss: 3.7992e-05 - val_mape: 0.4963\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4599e-04 - mape: 82912.0000 - val_loss: 2.9493e-04 - val_mape: 1.9137\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8313e-04 - mape: 39110.1719 - val_loss: 6.4033e-05 - val_mape: 0.6922\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.7545e-05 - mape: 14196.1357 - val_loss: 9.3805e-05 - val_mape: 0.9432\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3066e-04 - mape: 29403.2285 - val_loss: 5.5887e-05 - val_mape: 0.6403\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2168e-04 - mape: 24121.5234 - val_loss: 5.3386e-05 - val_mape: 0.6391\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2698e-04 - mape: 26692.5391 - val_loss: 5.0432e-04 - val_mape: 2.5831\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2689e-04 - mape: 22742.9941 - val_loss: 3.3779e-05 - val_mape: 0.4529\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0654e-04 - mape: 75593.3438 - val_loss: 6.1187e-05 - val_mape: 0.7398\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1092e-04 - mape: 29777.3242 - val_loss: 3.6683e-05 - val_mape: 0.4886\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1389e-04 - mape: 49072.9258 - val_loss: 3.4987e-05 - val_mape: 0.4762\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0998e-04 - mape: 79383.9844 - val_loss: 6.3906e-05 - val_mape: 0.7551\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0061e-04 - mape: 36581.2383 - val_loss: 6.5501e-05 - val_mape: 0.7645\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5419e-04 - mape: 1858.5146 - val_loss: 4.0655e-04 - val_mape: 2.3471\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0129e-04 - mape: 15279.3535 - val_loss: 5.6640e-05 - val_mape: 0.6317\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1299e-04 - mape: 19718.6055 - val_loss: 1.7915e-04 - val_mape: 1.5023\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0572e-04 - mape: 28718.6758 - val_loss: 2.8124e-05 - val_mape: 0.4221\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1904e-04 - mape: 57273.9219 - val_loss: 1.3333e-04 - val_mape: 1.2539\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2552e-04 - mape: 65333.8867 - val_loss: 7.3457e-05 - val_mape: 0.8803\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3443e-04 - mape: 4134.5820 - val_loss: 3.6571e-05 - val_mape: 0.5573\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5415e-04 - mape: 80449.2891 - val_loss: 3.4207e-05 - val_mape: 0.4847\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3462e-04 - mape: 22650.2988 - val_loss: 5.5326e-05 - val_mape: 0.7077\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9418e-04 - mape: 82186.7344 - val_loss: 3.4219e-05 - val_mape: 0.4644\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3908e-04 - mape: 14912.8125 - val_loss: 8.8221e-05 - val_mape: 0.9767\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2245e-04 - mape: 6761.1113 - val_loss: 1.7850e-04 - val_mape: 1.4603\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2656e-04 - mape: 13385.5088 - val_loss: 7.3490e-05 - val_mape: 0.8501\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0001e-04 - mape: 26894.4160 - val_loss: 6.0840e-05 - val_mape: 0.7814\n",
      "--- 21/51 Training model for TSLA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8503e-04 - mape: 921.1710 - val_loss: 8.7659e-05 - val_mape: 1.8497\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.8020e-04 - mape: 4934.5479 - val_loss: 6.9006e-05 - val_mape: 1.2169\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.4448e-04 - mape: 9325.5039 - val_loss: 1.5683e-04 - val_mape: 2.4466\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - mape: 17163.1875 - val_loss: 1.0312e-04 - val_mape: 2.0182\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9228e-04 - mape: 1020.5601 - val_loss: 2.9480e-05 - val_mape: 1.0062\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.7187e-04 - mape: 4555.2729 - val_loss: 3.2103e-05 - val_mape: 0.9581\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.9607e-04 - mape: 6268.8047 - val_loss: 1.6954e-05 - val_mape: 0.7111\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8693e-04 - mape: 5391.3208 - val_loss: 2.2750e-05 - val_mape: 0.8063\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3691e-04 - mape: 17407.0137 - val_loss: 1.4840e-05 - val_mape: 0.6573\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2600e-04 - mape: 8872.3750 - val_loss: 2.4408e-05 - val_mape: 0.8396\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.7008e-04 - mape: 8563.8682 - val_loss: 3.3433e-05 - val_mape: 0.9007\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0869e-04 - mape: 5054.8481 - val_loss: 1.1764e-05 - val_mape: 0.5855\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2271e-04 - mape: 2016.1044 - val_loss: 1.7383e-05 - val_mape: 0.7351\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8272e-04 - mape: 597.9616 - val_loss: 1.9195e-05 - val_mape: 0.7721\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9120e-04 - mape: 7865.5083 - val_loss: 1.6365e-05 - val_mape: 0.6706\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6520e-04 - mape: 5381.3276 - val_loss: 1.8481e-05 - val_mape: 0.7549\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5432e-04 - mape: 4079.6860 - val_loss: 2.6321e-05 - val_mape: 0.8235\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.6380e-04 - mape: 2724.2334 - val_loss: 1.7162e-05 - val_mape: 0.6724\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8281e-04 - mape: 8879.8818 - val_loss: 2.8123e-05 - val_mape: 0.9772\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8438e-04 - mape: 1634.6649 - val_loss: 1.6483e-05 - val_mape: 0.7236\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6702e-04 - mape: 8437.0645 - val_loss: 2.8208e-05 - val_mape: 0.9965\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0797e-04 - mape: 4353.5518 - val_loss: 3.5618e-05 - val_mape: 1.1045\n",
      "--- 22/51 Training model for NVDA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6891e-04 - mape: 53924.4727 - val_loss: 1.9409e-04 - val_mape: 1.5417\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1522e-04 - mape: 25203.9004 - val_loss: 3.0538e-04 - val_mape: 2.1704\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3445e-04 - mape: 16898.7832 - val_loss: 4.6624e-05 - val_mape: 0.6116\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3332e-04 - mape: 32912.5625 - val_loss: 1.6319e-04 - val_mape: 1.4363\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3729e-04 - mape: 46256.3789 - val_loss: 7.7915e-05 - val_mape: 0.8955\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1701e-04 - mape: 8226.8604 - val_loss: 9.9869e-05 - val_mape: 1.0286\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1940e-04 - mape: 2514.1382 - val_loss: 1.4959e-04 - val_mape: 1.3736\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0572e-04 - mape: 15872.0928 - val_loss: 1.3080e-04 - val_mape: 1.2020\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1692e-04 - mape: 2074.4841 - val_loss: 7.6110e-05 - val_mape: 0.8494\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1372e-04 - mape: 14160.4971 - val_loss: 1.0951e-04 - val_mape: 1.1403\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1318e-04 - mape: 12061.0967 - val_loss: 1.2552e-04 - val_mape: 1.2454\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0516e-04 - mape: 1068.9417 - val_loss: 1.4093e-04 - val_mape: 1.3259\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1303e-04 - mape: 7113.7715 - val_loss: 6.3321e-05 - val_mape: 0.7231\n",
      "--- 23/51 Training model for CPRT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.3528e-05 - mape: 31.7160 - val_loss: 8.9471e-05 - val_mape: 0.8674\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0038e-04 - mape: 35.9053 - val_loss: 7.7357e-05 - val_mape: 0.7871\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5272e-04 - mape: 40.0394 - val_loss: 3.0801e-04 - val_mape: 1.7241\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3090e-04 - mape: 89.4884 - val_loss: 1.2863e-04 - val_mape: 1.0358\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0956e-04 - mape: 37.0490 - val_loss: 1.5669e-04 - val_mape: 1.1930\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3169e-04 - mape: 46.3562 - val_loss: 5.5447e-05 - val_mape: 0.6371\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6021e-04 - mape: 55.0207 - val_loss: 1.2865e-04 - val_mape: 1.0775\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.1322e-05 - mape: 34.5744 - val_loss: 5.0225e-05 - val_mape: 0.6237\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1383e-04 - mape: 45.0684 - val_loss: 9.0460e-05 - val_mape: 0.8361\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4271e-04 - mape: 61.3409 - val_loss: 3.2074e-04 - val_mape: 1.7941\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9979e-04 - mape: 49.1522 - val_loss: 2.4400e-04 - val_mape: 1.5268\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0617e-04 - mape: 30.9670 - val_loss: 5.1292e-05 - val_mape: 0.6261\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7543e-04 - mape: 66.9470 - val_loss: 3.3882e-04 - val_mape: 1.9439\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1911e-04 - mape: 66.9395 - val_loss: 2.3805e-04 - val_mape: 1.5134\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3959e-04 - mape: 72.1583 - val_loss: 1.9576e-04 - val_mape: 1.3348\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1891e-04 - mape: 62.4457 - val_loss: 3.8396e-04 - val_mape: 2.0451\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0581e-04 - mape: 37.0004 - val_loss: 5.7562e-05 - val_mape: 0.6600\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3077e-04 - mape: 48.9092 - val_loss: 1.5669e-04 - val_mape: 1.2290\n",
      "--- 24/51 Training model for ORLY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.8748e-05 - mape: 14343.2959 - val_loss: 3.5501e-05 - val_mape: 0.4628\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0731e-04 - mape: 53850.1406 - val_loss: 1.4669e-04 - val_mape: 1.2220\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3536e-04 - mape: 5335.3501 - val_loss: 1.5700e-04 - val_mape: 1.3005\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1433e-04 - mape: 44344.9336 - val_loss: 3.8469e-05 - val_mape: 0.5190\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1031e-04 - mape: 39514.6406 - val_loss: 6.0893e-05 - val_mape: 0.6964\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.1368e-04 - mape: 12794.2959 - val_loss: 1.4956e-04 - val_mape: 1.1642\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.9592e-04 - mape: 17321.2637 - val_loss: 5.4108e-05 - val_mape: 0.6702\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.4267e-04 - mape: 18085.1602 - val_loss: 1.6602e-04 - val_mape: 1.2354\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.5208e-04 - mape: 19965.6289 - val_loss: 6.4010e-05 - val_mape: 0.6647\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8077e-04 - mape: 81923.2031 - val_loss: 6.9693e-05 - val_mape: 0.6484\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9227e-04 - mape: 81336.5000 - val_loss: 6.2745e-05 - val_mape: 0.6079\n",
      "--- 25/51 Training model for CSGP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8061e-04 - mape: 9.7439 - val_loss: 2.4261e-05 - val_mape: 0.4596\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0995e-04 - mape: 12.6253 - val_loss: 3.5646e-05 - val_mape: 0.5578\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7692e-04 - mape: 8.7155 - val_loss: 3.4108e-05 - val_mape: 0.6508\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8351e-04 - mape: 10.0415 - val_loss: 2.1825e-04 - val_mape: 1.7283\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6482e-04 - mape: 8.4206 - val_loss: 6.5269e-05 - val_mape: 0.8721\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8892e-04 - mape: 10.6162 - val_loss: 2.8400e-04 - val_mape: 1.9906\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0771e-04 - mape: 12.6784 - val_loss: 8.2875e-05 - val_mape: 0.9623\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9911e-04 - mape: 11.3764 - val_loss: 3.5861e-05 - val_mape: 0.5263\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3864e-04 - mape: 15.4462 - val_loss: 7.6526e-05 - val_mape: 0.9336\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5028e-04 - mape: 7.8370 - val_loss: 2.0981e-05 - val_mape: 0.4072\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8604e-04 - mape: 9.4078 - val_loss: 5.6458e-05 - val_mape: 0.8736\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.0950e-04 - mape: 18.0547 - val_loss: 1.9923e-05 - val_mape: 0.4531\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4270e-04 - mape: 15.4512 - val_loss: 1.3673e-05 - val_mape: 0.2753\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6565e-04 - mape: 9.9412 - val_loss: 1.5478e-05 - val_mape: 0.3222\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8908e-04 - mape: 11.2087 - val_loss: 1.4923e-05 - val_mape: 0.3525\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2215e-04 - mape: 13.1416 - val_loss: 6.4280e-05 - val_mape: 0.7653\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.9439e-04 - mape: 24.4633 - val_loss: 3.1304e-05 - val_mape: 0.4706\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0412e-04 - mape: 12.3152 - val_loss: 2.2499e-05 - val_mape: 0.4447\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6982e-04 - mape: 10.2362 - val_loss: 1.1806e-04 - val_mape: 1.2605\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6564e-04 - mape: 15.3663 - val_loss: 1.6903e-04 - val_mape: 1.5319\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.0477e-04 - mape: 23.4968 - val_loss: 5.2760e-05 - val_mape: 0.7770\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5416e-04 - mape: 9.2745 - val_loss: 2.2196e-05 - val_mape: 0.4487\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6628e-04 - mape: 9.9817 - val_loss: 2.6715e-05 - val_mape: 0.5082\n",
      "--- 26/51 Training model for PDD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6788e-04 - mape: 73593.7344 - val_loss: 1.5550e-04 - val_mape: 1.6363\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3341e-04 - mape: 51722.1914 - val_loss: 7.8874e-05 - val_mape: 1.1358\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9252e-04 - mape: 18942.7539 - val_loss: 6.1853e-05 - val_mape: 1.0420\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8634e-04 - mape: 2449.0847 - val_loss: 2.6369e-05 - val_mape: 0.6188\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5966e-04 - mape: 48194.2773 - val_loss: 1.4915e-05 - val_mape: 0.5016\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8494e-04 - mape: 44161.5820 - val_loss: 2.3849e-05 - val_mape: 0.6068\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0518e-04 - mape: 16019.7949 - val_loss: 3.2152e-05 - val_mape: 0.7907\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7641e-04 - mape: 61236.5625 - val_loss: 3.0551e-05 - val_mape: 0.7255\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5011e-04 - mape: 47501.7891 - val_loss: 2.4164e-05 - val_mape: 0.6000\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1565e-04 - mape: 17775.0840 - val_loss: 1.5832e-05 - val_mape: 0.5108\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6124e-04 - mape: 22646.6953 - val_loss: 2.1611e-05 - val_mape: 0.5434\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6141e-04 - mape: 52741.1992 - val_loss: 3.6975e-05 - val_mape: 0.8428\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3345e-04 - mape: 24834.9492 - val_loss: 3.0324e-05 - val_mape: 0.7721\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.0543e-04 - mape: 40089.9102 - val_loss: 5.0552e-05 - val_mape: 0.9669\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2261e-04 - mape: 49465.3008 - val_loss: 4.3437e-05 - val_mape: 0.9150\n",
      "--- 27/51 Training model for HON ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.8151e-04 - mape: 9.4104 - val_loss: 5.5721e-05 - val_mape: 0.8291\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7324e-04 - mape: 6.8125 - val_loss: 3.7704e-04 - val_mape: 2.2394\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4035e-04 - mape: 10.5610 - val_loss: 1.7431e-05 - val_mape: 0.3699\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5439e-04 - mape: 6.7010 - val_loss: 3.7543e-04 - val_mape: 2.2493\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5544e-04 - mape: 6.1457 - val_loss: 1.4716e-05 - val_mape: 0.3535\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7249e-04 - mape: 8.2778 - val_loss: 1.8039e-05 - val_mape: 0.3668\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6813e-04 - mape: 6.6664 - val_loss: 1.4366e-05 - val_mape: 0.3495\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7339e-04 - mape: 6.9282 - val_loss: 7.2193e-05 - val_mape: 0.9310\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4181e-04 - mape: 5.8663 - val_loss: 1.4163e-04 - val_mape: 1.3248\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9140e-04 - mape: 8.4055 - val_loss: 3.4638e-04 - val_mape: 2.1373\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0846e-04 - mape: 7.7931 - val_loss: 1.2982e-04 - val_mape: 1.2357\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7134e-04 - mape: 6.1412 - val_loss: 4.1212e-04 - val_mape: 2.2978\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0048e-04 - mape: 7.6405 - val_loss: 3.9280e-04 - val_mape: 2.2049\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9983e-04 - mape: 7.5907 - val_loss: 4.0629e-04 - val_mape: 2.2204\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7086e-04 - mape: 8.2054 - val_loss: 3.3241e-04 - val_mape: 1.9486\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8191e-04 - mape: 8.8602 - val_loss: 7.7693e-05 - val_mape: 0.7790\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.7093e-04 - mape: 14.8010 - val_loss: 5.0939e-04 - val_mape: 2.5245\n",
      "--- 28/51 Training model for ADI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6305e-04 - mape: 12.6812 - val_loss: 1.2398e-04 - val_mape: 1.1249\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.9070e-04 - mape: 31.1395 - val_loss: 9.6206e-05 - val_mape: 0.8761\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7720e-04 - mape: 15.3983 - val_loss: 1.3646e-04 - val_mape: 1.1319\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5224e-04 - mape: 13.7059 - val_loss: 6.9568e-05 - val_mape: 0.7168\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.8899e-05 - mape: 10.2267 - val_loss: 9.0710e-05 - val_mape: 0.8524\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0472e-04 - mape: 11.6030 - val_loss: 6.7791e-05 - val_mape: 0.6898\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.7277e-05 - mape: 11.0643 - val_loss: 6.9491e-05 - val_mape: 0.7059\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1899e-04 - mape: 11.8084 - val_loss: 6.7490e-05 - val_mape: 0.6862\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0942e-04 - mape: 10.8308 - val_loss: 1.1385e-04 - val_mape: 1.0838\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7124e-04 - mape: 15.2311 - val_loss: 5.8942e-05 - val_mape: 0.6634\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0602e-04 - mape: 11.6755 - val_loss: 9.5258e-05 - val_mape: 0.9332\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0118e-04 - mape: 10.3453 - val_loss: 5.9531e-05 - val_mape: 0.7091\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1102e-04 - mape: 11.0692 - val_loss: 1.1485e-04 - val_mape: 1.1024\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7998e-04 - mape: 15.3453 - val_loss: 8.7794e-05 - val_mape: 0.9358\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2589e-04 - mape: 11.8768 - val_loss: 8.3464e-05 - val_mape: 0.8765\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.3639e-05 - mape: 10.4440 - val_loss: 4.7863e-05 - val_mape: 0.6031\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0819e-04 - mape: 10.9308 - val_loss: 7.6098e-05 - val_mape: 0.8190\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0193e-04 - mape: 10.5866 - val_loss: 7.3466e-05 - val_mape: 0.8435\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.8884e-05 - mape: 10.8461 - val_loss: 9.1531e-05 - val_mape: 0.9844\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1695e-04 - mape: 11.7288 - val_loss: 3.8687e-05 - val_mape: 0.5348\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0919e-04 - mape: 11.8165 - val_loss: 8.3093e-05 - val_mape: 0.8558\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0513e-04 - mape: 10.5832 - val_loss: 7.6408e-05 - val_mape: 0.9236\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6500e-04 - mape: 14.5141 - val_loss: 7.1615e-05 - val_mape: 0.8806\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4210e-04 - mape: 13.4578 - val_loss: 4.8179e-05 - val_mape: 0.5900\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0526e-04 - mape: 10.6653 - val_loss: 6.9117e-05 - val_mape: 0.8084\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5182e-04 - mape: 14.3555 - val_loss: 9.0258e-05 - val_mape: 1.0056\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4065e-04 - mape: 18.5228 - val_loss: 5.4116e-05 - val_mape: 0.7134\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2277e-04 - mape: 12.5730 - val_loss: 5.3380e-05 - val_mape: 0.6876\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3877e-04 - mape: 12.8750 - val_loss: 9.0042e-05 - val_mape: 1.0103\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3228e-04 - mape: 12.9490 - val_loss: 8.1859e-05 - val_mape: 0.7925\n",
      "--- 29/51 Training model for EA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6636e-04 - mape: 4606.5693 - val_loss: 8.9493e-05 - val_mape: 1.1102\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7295e-04 - mape: 645.0979 - val_loss: 2.0626e-05 - val_mape: 0.4210\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4642e-04 - mape: 25971.8789 - val_loss: 2.8355e-05 - val_mape: 0.5069\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.7018e-04 - mape: 40493.2344 - val_loss: 7.4745e-06 - val_mape: 0.2791\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8967e-04 - mape: 12588.4609 - val_loss: 4.5238e-05 - val_mape: 0.7302\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5809e-04 - mape: 12412.9150 - val_loss: 7.7092e-06 - val_mape: 0.2547\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5974e-04 - mape: 20706.3633 - val_loss: 1.1379e-04 - val_mape: 1.2755\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7230e-04 - mape: 17559.4961 - val_loss: 5.5239e-05 - val_mape: 0.8303\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1245e-04 - mape: 13034.5439 - val_loss: 9.4883e-06 - val_mape: 0.2751\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0557e-04 - mape: 12835.4609 - val_loss: 4.6188e-06 - val_mape: 0.2088\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7733e-04 - mape: 4749.7734 - val_loss: 7.9574e-06 - val_mape: 0.2617\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8835e-04 - mape: 28795.6035 - val_loss: 6.5233e-05 - val_mape: 0.9523\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2006e-04 - mape: 23626.7324 - val_loss: 4.0204e-06 - val_mape: 0.1869\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8339e-04 - mape: 11771.9746 - val_loss: 2.0364e-05 - val_mape: 0.5056\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8100e-04 - mape: 1756.9205 - val_loss: 1.6572e-05 - val_mape: 0.4144\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8496e-04 - mape: 12155.3330 - val_loss: 9.3531e-05 - val_mape: 1.1362\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5996e-04 - mape: 8801.6426 - val_loss: 9.6077e-05 - val_mape: 1.1820\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5029e-04 - mape: 22016.1973 - val_loss: 1.8238e-05 - val_mape: 0.4726\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6996e-04 - mape: 11232.8398 - val_loss: 6.7210e-06 - val_mape: 0.2418\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4732e-04 - mape: 1264.0081 - val_loss: 4.4107e-05 - val_mape: 0.7520\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4357e-04 - mape: 8432.9355 - val_loss: 6.2084e-06 - val_mape: 0.2384\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5349e-04 - mape: 23229.4473 - val_loss: 9.6592e-06 - val_mape: 0.3049\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5834e-04 - mape: 2530.3022 - val_loss: 5.6673e-06 - val_mape: 0.2358\n",
      "--- 30/51 Training model for KHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.0435e-04 - mape: 5650.8823 - val_loss: 5.2228e-06 - val_mape: 0.4956\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.9886e-04 - mape: 2565.6145 - val_loss: 3.2025e-06 - val_mape: 0.3992\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.2443e-04 - mape: 1484.7013 - val_loss: 2.2182e-06 - val_mape: 0.3353\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.2341e-04 - mape: 1569.3500 - val_loss: 2.4422e-06 - val_mape: 0.3610\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1684e-04 - mape: 13092.7930 - val_loss: 1.7392e-06 - val_mape: 0.2932\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3905e-04 - mape: 7373.6851 - val_loss: 2.6899e-06 - val_mape: 0.3555\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.5172e-04 - mape: 12991.5664 - val_loss: 1.8578e-06 - val_mape: 0.3054\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4979e-04 - mape: 5017.0586 - val_loss: 2.9484e-06 - val_mape: 0.3959\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6809e-04 - mape: 2763.6282 - val_loss: 1.9468e-06 - val_mape: 0.3145\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.8414e-04 - mape: 6582.3906 - val_loss: 2.4086e-06 - val_mape: 0.3472\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.8530e-04 - mape: 9166.7393 - val_loss: 2.3356e-06 - val_mape: 0.3392\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4773e-04 - mape: 4687.3784 - val_loss: 2.4520e-06 - val_mape: 0.3450\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9954e-04 - mape: 890.6260 - val_loss: 4.8495e-06 - val_mape: 0.5303\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.1192e-04 - mape: 18987.3398 - val_loss: 1.4662e-06 - val_mape: 0.2718\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.2812e-04 - mape: 2173.7312 - val_loss: 4.2296e-06 - val_mape: 0.4747\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4492e-04 - mape: 3633.8855 - val_loss: 2.1817e-06 - val_mape: 0.3272\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3272e-04 - mape: 1724.4749 - val_loss: 3.2392e-06 - val_mape: 0.4124\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.1852e-04 - mape: 8533.4346 - val_loss: 2.1324e-06 - val_mape: 0.3170\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9311e-04 - mape: 21875.3691 - val_loss: 3.6796e-06 - val_mape: 0.4359\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.6637e-04 - mape: 3812.5847 - val_loss: 3.0484e-06 - val_mape: 0.3954\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.7213e-04 - mape: 12739.0059 - val_loss: 2.9884e-06 - val_mape: 0.3873\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.0329e-04 - mape: 98.3873 - val_loss: 2.7105e-06 - val_mape: 0.3842\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1994e-04 - mape: 3781.1189 - val_loss: 5.4942e-06 - val_mape: 0.5750\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.5792e-04 - mape: 4373.4946 - val_loss: 6.3238e-06 - val_mape: 0.6111\n",
      "--- 31/51 Training model for WBD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.4728e-05 - mape: 2.3693 - val_loss: 1.8339e-05 - val_mape: 13533.5693\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.1125e-05 - mape: 2.1734 - val_loss: 5.6657e-06 - val_mape: 8493.3506\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6122e-05 - mape: 2.2662 - val_loss: 3.3770e-05 - val_mape: 34247.2305\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6093e-05 - mape: 2.2609 - val_loss: 2.4643e-05 - val_mape: 41757.4219\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.8408e-05 - mape: 3.1928 - val_loss: 1.1499e-04 - val_mape: 58060.9258\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.8391e-05 - mape: 2.4066 - val_loss: 8.0503e-06 - val_mape: 24413.4180\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.1745e-05 - mape: 2.1817 - val_loss: 7.4335e-05 - val_mape: 41396.5273\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.6537e-05 - mape: 2.6801 - val_loss: 7.9526e-05 - val_mape: 61506.2969\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.6422e-05 - mape: 3.2171 - val_loss: 2.0976e-04 - val_mape: 83627.2344\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3909e-04 - mape: 4.0516 - val_loss: 6.8008e-05 - val_mape: 66455.8750\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0889e-04 - mape: 3.5430 - val_loss: 7.6280e-05 - val_mape: 50985.2148\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1869e-04 - mape: 3.7276 - val_loss: 1.7598e-05 - val_mape: 41630.5508\n",
      "--- 32/51 Training model for ROP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1562e-04 - mape: 6.6946 - val_loss: 8.0919e-05 - val_mape: 0.8326\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.9870e-05 - mape: 6.1288 - val_loss: 5.0455e-05 - val_mape: 0.5716\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2847e-04 - mape: 6.4544 - val_loss: 3.5744e-05 - val_mape: 0.4708\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2761e-04 - mape: 7.0695 - val_loss: 7.9892e-05 - val_mape: 0.8445\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3261e-04 - mape: 8.0182 - val_loss: 2.9501e-05 - val_mape: 0.3980\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9977e-04 - mape: 10.4453 - val_loss: 4.6661e-05 - val_mape: 0.5731\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0203e-04 - mape: 6.3227 - val_loss: 5.8536e-05 - val_mape: 0.6685\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4878e-04 - mape: 7.8996 - val_loss: 9.2268e-05 - val_mape: 0.9427\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1638e-04 - mape: 7.2360 - val_loss: 1.2257e-04 - val_mape: 1.1119\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.8542e-05 - mape: 6.1040 - val_loss: 7.1200e-05 - val_mape: 0.7757\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7668e-04 - mape: 9.1152 - val_loss: 2.7279e-05 - val_mape: 0.3818\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.5559e-05 - mape: 6.8448 - val_loss: 2.7469e-05 - val_mape: 0.3714\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0818e-04 - mape: 6.1422 - val_loss: 2.6934e-05 - val_mape: 0.3668\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0380e-04 - mape: 7.2164 - val_loss: 4.3843e-05 - val_mape: 0.5541\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1153e-04 - mape: 6.9828 - val_loss: 4.6769e-05 - val_mape: 0.6116\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3422e-04 - mape: 7.6477 - val_loss: 6.4181e-05 - val_mape: 0.7194\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0559e-04 - mape: 6.2192 - val_loss: 3.1968e-05 - val_mape: 0.3699\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1770e-04 - mape: 7.2459 - val_loss: 5.2070e-05 - val_mape: 0.6463\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1149e-04 - mape: 6.9246 - val_loss: 3.1111e-05 - val_mape: 0.4303\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0445e-04 - mape: 6.3197 - val_loss: 4.0052e-05 - val_mape: 0.5419\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.8197e-05 - mape: 6.6000 - val_loss: 5.0982e-05 - val_mape: 0.6392\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.7069e-05 - mape: 6.2829 - val_loss: 3.3962e-05 - val_mape: 0.4463\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2827e-04 - mape: 6.8908 - val_loss: 1.2208e-04 - val_mape: 1.1227\n",
      "--- 33/51 Training model for BKR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8867e-04 - mape: 12785.2021 - val_loss: 5.7666e-05 - val_mape: 0.8391\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0659e-04 - mape: 1716.3596 - val_loss: 2.2077e-04 - val_mape: 1.7380\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5680e-04 - mape: 5517.0161 - val_loss: 5.9392e-05 - val_mape: 0.8312\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3330e-04 - mape: 13438.1846 - val_loss: 3.7578e-05 - val_mape: 0.6703\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9604e-04 - mape: 3547.1213 - val_loss: 1.9324e-05 - val_mape: 0.4828\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7764e-04 - mape: 1294.4482 - val_loss: 1.6243e-04 - val_mape: 1.5290\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0457e-04 - mape: 6788.8359 - val_loss: 1.1730e-04 - val_mape: 1.2599\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9887e-04 - mape: 10420.3955 - val_loss: 6.0522e-05 - val_mape: 0.9104\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9930e-04 - mape: 5936.8506 - val_loss: 6.5241e-06 - val_mape: 0.2402\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6472e-04 - mape: 29787.2266 - val_loss: 1.4342e-04 - val_mape: 1.4200\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6860e-04 - mape: 5679.9634 - val_loss: 7.1962e-05 - val_mape: 1.0003\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8835e-04 - mape: 12961.9785 - val_loss: 1.4888e-05 - val_mape: 0.3687\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9367e-04 - mape: 5423.9849 - val_loss: 5.0504e-04 - val_mape: 2.6988\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5139e-04 - mape: 13593.1133 - val_loss: 1.5634e-04 - val_mape: 1.5096\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5698e-04 - mape: 11385.9551 - val_loss: 1.6668e-04 - val_mape: 1.5070\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6104e-04 - mape: 4663.8091 - val_loss: 1.6100e-04 - val_mape: 1.4722\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1852e-04 - mape: 19898.6289 - val_loss: 2.4998e-04 - val_mape: 1.8485\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4673e-04 - mape: 3511.1221 - val_loss: 1.7913e-04 - val_mape: 1.5545\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4521e-04 - mape: 2047.1884 - val_loss: 1.1363e-04 - val_mape: 1.1404\n",
      "--- 34/51 Training model for COST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.2071e-04 - mape: 7546.8379 - val_loss: 6.1046e-04 - val_mape: 2.4778\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - mape: 31034.7109 - val_loss: 0.0040 - val_mape: 7.4290\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - mape: 10298.3643 - val_loss: 3.3608e-04 - val_mape: 2.0496\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6258e-04 - mape: 14482.7412 - val_loss: 1.0916e-04 - val_mape: 1.0242\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4597e-04 - mape: 22334.6328 - val_loss: 1.1647e-04 - val_mape: 0.9482\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8754e-04 - mape: 9339.7832 - val_loss: 6.9825e-05 - val_mape: 0.7668\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5526e-04 - mape: 6222.6938 - val_loss: 1.0718e-04 - val_mape: 0.8956\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5771e-04 - mape: 7467.7881 - val_loss: 1.0279e-04 - val_mape: 1.0336\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9333e-04 - mape: 38602.3594 - val_loss: 5.5477e-05 - val_mape: 0.6504\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6844e-04 - mape: 14938.9951 - val_loss: 5.0194e-05 - val_mape: 0.6225\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5202e-04 - mape: 8229.7520 - val_loss: 5.0578e-05 - val_mape: 0.5979\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6648e-04 - mape: 6142.5522 - val_loss: 4.8425e-05 - val_mape: 0.5880\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5609e-04 - mape: 20533.0234 - val_loss: 5.1191e-05 - val_mape: 0.6171\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5907e-04 - mape: 3981.7827 - val_loss: 4.8917e-05 - val_mape: 0.5910\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7242e-04 - mape: 15914.6348 - val_loss: 4.7970e-05 - val_mape: 0.5898\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4470e-04 - mape: 17231.4492 - val_loss: 5.4068e-05 - val_mape: 0.6136\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6545e-04 - mape: 20517.0625 - val_loss: 4.6192e-05 - val_mape: 0.5758\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6043e-04 - mape: 5871.7983 - val_loss: 8.7825e-05 - val_mape: 0.8122\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9289e-04 - mape: 4223.7041 - val_loss: 1.3624e-04 - val_mape: 1.1779\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3797e-04 - mape: 11134.0293 - val_loss: 1.5235e-04 - val_mape: 1.1219\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4935e-04 - mape: 16570.5605 - val_loss: 4.1268e-04 - val_mape: 2.2730\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9388e-04 - mape: 16712.0000 - val_loss: 1.9732e-04 - val_mape: 1.3301\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2356e-04 - mape: 1260.4519 - val_loss: 1.5569e-04 - val_mape: 1.2837\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1735e-04 - mape: 704.2057 - val_loss: 8.4216e-05 - val_mape: 0.7655\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6138e-04 - mape: 28803.3066 - val_loss: 3.1847e-04 - val_mape: 1.9491\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6419e-04 - mape: 1712.4584 - val_loss: 1.9275e-04 - val_mape: 1.2662\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.9180e-04 - mape: 27193.5254 - val_loss: 0.0013 - val_mape: 4.1685\n",
      "--- 35/51 Training model for AZN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3749e-04 - mape: 10.8222 - val_loss: 4.0619e-04 - val_mape: 2.5637\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.5034e-04 - mape: 19.0432 - val_loss: 2.1787e-05 - val_mape: 0.4473\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1875e-04 - mape: 11.4600 - val_loss: 1.8687e-05 - val_mape: 0.4201\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1402e-04 - mape: 9.7884 - val_loss: 2.4522e-05 - val_mape: 0.5131\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1019e-04 - mape: 9.4972 - val_loss: 3.6359e-05 - val_mape: 0.6909\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2205e-04 - mape: 10.1943 - val_loss: 1.0897e-04 - val_mape: 1.2702\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2537e-04 - mape: 10.6934 - val_loss: 1.7106e-04 - val_mape: 1.6241\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2712e-04 - mape: 10.4413 - val_loss: 4.4949e-05 - val_mape: 0.6610\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9782e-04 - mape: 14.5911 - val_loss: 2.5942e-05 - val_mape: 0.5444\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2009e-04 - mape: 11.0820 - val_loss: 6.6310e-05 - val_mape: 0.9630\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1968e-04 - mape: 11.1176 - val_loss: 2.1738e-05 - val_mape: 0.5176\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4173e-04 - mape: 16.3395 - val_loss: 7.5858e-05 - val_mape: 1.0098\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.8792e-05 - mape: 8.9802 - val_loss: 6.4896e-05 - val_mape: 0.9189\n",
      "--- 36/51 Training model for LRCX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7018e-04 - mape: 30.2955 - val_loss: 3.1300e-05 - val_mape: 0.5222\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5554e-04 - mape: 27.2284 - val_loss: 3.8856e-05 - val_mape: 0.6040\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9276e-04 - mape: 33.0761 - val_loss: 5.9184e-05 - val_mape: 0.8501\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4228e-04 - mape: 46.0204 - val_loss: 2.6984e-04 - val_mape: 1.8003\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - mape: 143.7294 - val_loss: 0.0071 - val_mape: 10.3811\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - mape: 144.5437 - val_loss: 1.7084e-04 - val_mape: 1.1685\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3411e-04 - mape: 34.1325 - val_loss: 0.0053 - val_mape: 8.9438\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.0547e-04 - mape: 77.7690 - val_loss: 3.6151e-04 - val_mape: 1.9644\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.7888e-04 - mape: 37.5915 - val_loss: 9.7243e-04 - val_mape: 3.7478\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5886e-04 - mape: 41.8306 - val_loss: 3.1268e-04 - val_mape: 1.8409\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6630e-04 - mape: 31.9992 - val_loss: 3.5804e-04 - val_mape: 2.1958\n",
      "--- 37/51 Training model for MELI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9880e-04 - mape: 15.6730 - val_loss: 1.6708e-04 - val_mape: 1.5441\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.5340e-04 - mape: 43.4281 - val_loss: 5.9517e-04 - val_mape: 2.8353\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0019 - mape: 66.5435 - val_loss: 0.0011 - val_mape: 3.8560\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0044 - mape: 107.9882 - val_loss: 0.0083 - val_mape: 11.1486\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0044 - mape: 116.4687 - val_loss: 3.4393e-05 - val_mape: 0.5497\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0888e-04 - mape: 17.2153 - val_loss: 4.3234e-05 - val_mape: 0.6540\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.8489e-04 - mape: 16.4496 - val_loss: 4.2541e-05 - val_mape: 0.6606\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7130e-04 - mape: 15.8938 - val_loss: 2.1633e-05 - val_mape: 0.3919\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7804e-04 - mape: 16.3046 - val_loss: 6.4243e-05 - val_mape: 0.8874\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6360e-04 - mape: 15.5857 - val_loss: 2.4115e-05 - val_mape: 0.4371\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6770e-04 - mape: 15.5821 - val_loss: 3.1340e-05 - val_mape: 0.5436\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5805e-04 - mape: 14.9965 - val_loss: 2.8451e-05 - val_mape: 0.4745\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4054e-04 - mape: 13.7906 - val_loss: 2.1352e-05 - val_mape: 0.3933\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6101e-04 - mape: 14.3243 - val_loss: 3.3332e-05 - val_mape: 0.5721\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6046e-04 - mape: 15.5497 - val_loss: 3.1435e-05 - val_mape: 0.5384\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.7377e-04 - mape: 15.5334 - val_loss: 4.3659e-05 - val_mape: 0.7014\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2756e-04 - mape: 18.4691 - val_loss: 1.7055e-04 - val_mape: 1.5571\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3965e-04 - mape: 19.4714 - val_loss: 6.5367e-05 - val_mape: 0.8549\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6684e-04 - mape: 28.8958 - val_loss: 9.3015e-04 - val_mape: 3.7125\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.1010e-04 - mape: 40.2645 - val_loss: 8.4708e-05 - val_mape: 0.9685\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - mape: 43.5561 - val_loss: 0.0026 - val_mape: 6.2613\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.9647e-04 - mape: 45.4851 - val_loss: 1.0464e-04 - val_mape: 1.1448\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7583e-04 - mape: 24.5701 - val_loss: 6.2809e-04 - val_mape: 3.0619\n",
      "--- 38/51 Training model for CDW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5260e-04 - mape: 13.4693 - val_loss: 4.8207e-04 - val_mape: 2.1587\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.5561e-04 - mape: 31.1557 - val_loss: 1.2933e-04 - val_mape: 1.0460\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.9617e-04 - mape: 19.9534 - val_loss: 1.1352e-04 - val_mape: 0.8190\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.2255e-04 - mape: 19.9948 - val_loss: 1.4401e-04 - val_mape: 1.1688\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5635e-04 - mape: 23.5621 - val_loss: 1.1316e-04 - val_mape: 0.8062\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3947e-04 - mape: 21.6724 - val_loss: 1.9114e-04 - val_mape: 1.4100\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4426e-04 - mape: 22.9246 - val_loss: 7.2615e-05 - val_mape: 0.6261\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4784e-04 - mape: 16.2841 - val_loss: 1.0657e-04 - val_mape: 0.9645\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5495e-04 - mape: 16.3097 - val_loss: 7.0482e-05 - val_mape: 0.6130\n",
      "Epoch 10/150\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6708e-04 - mape: 17.6669"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.data.make_dataset import load_list, get_stock_data\n",
    "from src.models.StockModel import StockModel\n",
    "window_size = 20\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2024-09-01'\n",
    "feature_columns = ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
    "target = \"Open\"\n",
    "\n",
    "# Load symbols\n",
    "nasdaq_symbols = load_list(\"NASDAQ\")\n",
    "sp500_symbols = load_list(\"SP500\")\n",
    "\n",
    "# Test tickers, sp500 symbols not also in nasdaq\n",
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:25]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC']\n",
    "train_tickers = ['^IXIC'] + nasdaq_symbols\n",
    "train_tickers = train_tickers[:51]\n",
    "\n",
    "# Download data\n",
    "combined_data = get_stock_data(train_tickers, \"1d\", start_date, end_date)\n",
    "combined_data.info()\n",
    "# Test data\n",
    "test_data = get_stock_data(test_tickers, \"1d\", start_date, end_date)\n",
    "\n",
    "layer_config = [(1,128),(1,256),(1,512),(1,1024),(2,128),(2,256),(2,512),(2,768),(3,128),(3,256),(3,512)]\n",
    "for i in layer_config:\n",
    "    print(f\"XXXXXXXXXXXXXXXX Running {i[0]} {i[1]} layers XXXXXXXXXXXXXXXXXXXX\")\n",
    "    # Create and train model\n",
    "    stock_model = StockModel(window_size=window_size, feature_columns=feature_columns, target_name=target, export=True)\n",
    "    \n",
    "    stock_model.train(combined_data, patience=10, epochs=150, graph=False, layers=i[0], units_per_layer=i[1])\n",
    "    metrics_dict, mean_metrics = stock_model.evaluate_many(test_data, graph=False)\n",
    "    print(metrics_dict)\n",
    "    print(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:5]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC', '^DJI']\n",
    "# Test data\n",
    "test_data = get_stock_data([\"^GSPC\", \"^DJI\"], \"1d\", start_date, end_date)\n",
    "\n",
    "metrics_dict, mean_metrics = stock_model.evaluate_many(test_data, graph=True)\n",
    "print(metrics_dict)\n",
    "print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo transcurrido: 00:00:02\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "inicio = time.time()\n",
    "for i in range(100000000):\n",
    "    pass\n",
    "fin = time.time()\n",
    "tiempo = fin-inicio\n",
    "# Convertimos el tiempo a horas, minutos y segundos\n",
    "horas = int(tiempo // 3600)\n",
    "minutos = int((tiempo % 3600) // 60)\n",
    "segundos = int(tiempo % 60)\n",
    "\n",
    "# Imprimimos el tiempo en formato hh:mm:ss\n",
    "print(f\"Tiempo transcurrido: {horas:02d}:{minutos:02d}:{segundos:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
