{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 186328 entries, 2017-01-03 00:00:00-05:00 to 2024-08-30 00:00:00-04:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Open          186328 non-null  float64\n",
      " 1   High          186328 non-null  float64\n",
      " 2   Low           186328 non-null  float64\n",
      " 3   Close         186328 non-null  float64\n",
      " 4   Volume        186328 non-null  int64  \n",
      " 5   Dividends     186328 non-null  float64\n",
      " 6   Stock Splits  186328 non-null  float64\n",
      " 7   Ticker        186328 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 12.8+ MB\n",
      "XXXXXXXXXXXXXXXX Running 1 32 layers XXXXXXXXXXXXXXXXXXXX\n",
      "Initializing model:\n",
      " - Window size: 20\n",
      " - Features: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
      " - Target: Open\n",
      "--- Preparing ^IXIC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.47700000e+03  5.44091016e+03  8.72110000e+08  1.43798828e+01\n",
      " -1.06362988e+03  1.16226960e+01 -6.03732918e+02 -1.85963467e+02]\n",
      "Feature max [1.86474492e+04 1.86592500e+04 1.19326000e+10 8.98230469e+02\n",
      " 5.16000000e+02 1.00000000e+02 3.79729000e+02 1.68559430e+02]\n",
      "Target min [5425.62011719]\n",
      "Target max [18659.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRTX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.70500031e+01  7.52200012e+01  3.00500000e+05  9.29992676e-01\n",
      " -4.39099884e+01  6.98832867e+00 -1.61057278e+01 -6.35634960e+00]\n",
      "Feature max [5.05779999e+02 5.07040009e+02 1.74930000e+07 3.32000122e+01\n",
      " 2.96399994e+01 1.00000000e+02 1.72224200e+01 7.01903411e+00]\n",
      "Target min [74.43000031]\n",
      "Target max [507.04000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PYPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93100014e+01  3.94000015e+01  1.68000000e+06  2.79998779e-01\n",
      " -3.59100037e+01  5.36242303e+00 -1.82619484e+01 -6.83508729e+00]\n",
      "Feature max [3.08529999e+02 3.09660004e+02 1.36264000e+08 2.25299988e+01\n",
      " 1.48899994e+01 1.00000000e+02 1.63896973e+01 4.70789452e+00]\n",
      "Target min [39.40000153]\n",
      "Target max [309.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GILD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.83768845e+01  4.84647914e+01  1.93100000e+06  3.33686987e-01\n",
      " -6.63972958e+00  5.76443697e+00 -2.31350268e+00 -8.99640056e-01]\n",
      "Feature max [8.53581619e+01 8.44682978e+01 9.43485000e+07 8.04050604e+00\n",
      " 7.22805086e+00 1.00000000e+02 4.20840086e+00 1.25684682e+00]\n",
      "Target min [48.46479141]\n",
      "Target max [84.46829781]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.10076246e+01  1.08333303e+01  2.58690000e+06  1.03459211e-01\n",
      " -2.80620499e+00  6.42036899e+00 -2.09796538e+00 -6.88386974e-01]\n",
      "Feature max [3.81064873e+01 3.81660578e+01 2.95518300e+08 2.47469130e+00\n",
      " 2.03001627e+00 1.00000000e+02 1.17294668e+00 5.41764630e-01]\n",
      "Target min [10.83333032]\n",
      "Target max [38.16605779]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing IDXX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.15949997e+02  1.15989998e+02  6.95000000e+04  1.01998901e+00\n",
      " -5.39599915e+01  0.00000000e+00 -4.51944855e+01 -1.18420530e+01]\n",
      "Feature max [7.05760010e+02 6.98869995e+02 2.06065000e+07 4.94200134e+01\n",
      " 2.44899902e+01 9.87477702e+01 2.80133056e+01 9.19398448e+00]\n",
      "Target min [115.98999786]\n",
      "Target max [698.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.72258110e+01  4.72942291e+01  4.40100000e+05  2.32199924e-01\n",
      " -6.70203798e+00  0.00000000e+00 -5.58791944e+00 -1.85080468e+00]\n",
      "Feature max [1.00876343e+02 1.03304346e+02 2.24557000e+07 1.05535592e+01\n",
      " 3.30013324e+00 1.00000000e+02 2.91608734e+00 1.39528265e+00]\n",
      "Target min [47.29422913]\n",
      "Target max [103.30434621]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TEAM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.47199993e+01  2.47299995e+01  2.10900000e+05  2.16999054e-01\n",
      " -4.31699982e+01  1.07833899e+01 -2.66488051e+01 -8.97255197e+00]\n",
      "Feature max [4.58130005e+02 4.55200012e+02 1.74562000e+07 4.22299805e+01\n",
      " 4.32099915e+01 1.00000000e+02 2.40637139e+01 8.94966359e+00]\n",
      "Target min [24.31999969]\n",
      "Target max [455.20001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PANW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.60033340e+01  3.61399994e+01  1.02260000e+06  3.56666565e-01\n",
      " -9.08899841e+01  3.81140920e+00 -1.38470391e+01 -1.22788064e+01]\n",
      "Feature max [3.76899994e+02 3.75450012e+02 6.53592000e+07 2.73699951e+01\n",
      " 2.68099976e+01 1.00000000e+02 1.51691964e+01 4.87990591e+00]\n",
      "Target min [36.13999939]\n",
      "Target max [375.45001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AVGO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.37303305e+01  1.37248155e+01  4.12300000e+06  1.24250191e-01\n",
      " -1.42100067e+01  0.00000000e+00 -5.06872189e+00 -3.00550723e+00]\n",
      "Feature max [1.82308105e+02 1.83376725e+02 4.35083000e+08 1.69199982e+01\n",
      " 2.13810994e+01 9.28312234e+01 1.05782566e+01 4.55284581e+00]\n",
      "Target min [13.72481551]\n",
      "Target max [183.37672469]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CEG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.08016357e+01  3.98784499e+01  2.35000000e+04  6.26233823e-01\n",
      " -1.08198405e+01  1.27016955e+01 -1.06308757e+01 -3.92755151e+00]\n",
      "Feature max [2.30487686e+02 2.31952715e+02 2.38609000e+07 2.15543379e+01\n",
      " 2.45442808e+01 1.00000000e+02 1.44754881e+01 4.38796715e+00]\n",
      "Target min [37.00564339]\n",
      "Target max [231.9527148]\n",
      "X_train shape: (637, 20, 8)\n",
      "Train_dates: 2022-01-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MSFT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.65738869e+01  5.64739966e+01  7.42560000e+06  2.90591394e-01\n",
      " -1.92852005e+01  0.00000000e+00 -1.18035322e+01 -4.62579685e+00]\n",
      "Feature max [4.66718781e+02 4.66159796e+02 1.11242100e+08 2.43750285e+01\n",
      " 2.10308765e+01 9.87200755e+01 1.16126213e+01 3.05457850e+00]\n",
      "Target min [56.47399663]\n",
      "Target max [466.15979612]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EXC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.82024384e+01  1.85263402e+01  2.00850500e+06  1.22239479e-01\n",
      " -1.93681369e+00  5.27394596e+00 -2.56103547e+00 -9.27310674e-01]\n",
      "Feature max [4.59507713e+01 4.58593284e+01 3.88453000e+07 4.14685299e+00\n",
      " 1.20620394e+00 1.00000000e+02 1.62739270e+00 5.65170244e-01]\n",
      "Target min [18.52634024]\n",
      "Target max [45.85932841]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DXCM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.11149998e+01  1.10325003e+01  8.61200000e+05  1.64999962e-01\n",
      " -4.18499985e+01  4.43708879e+00 -1.21858259e+01 -5.03116733e+00]\n",
      "Feature max [1.62815002e+02 1.64257507e+02 1.23168400e+08 1.88925018e+01\n",
      " 1.24700012e+01 1.00000000e+02 8.60785647e+00 2.40813081e+00]\n",
      "Target min [11.03250027]\n",
      "Target max [164.25750732]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FAST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65418453e+01  1.66370294e+01  7.04500000e+05  1.46829898e-01\n",
      " -3.17297478e+00  2.73468077e+00 -1.96586911e+00 -1.08293915e+00]\n",
      "Feature max [7.75266724e+01 7.77145119e+01 5.26096000e+07 4.66000366e+00\n",
      " 3.55978900e+00 1.00000000e+02 1.87048216e+00 8.56669819e-01]\n",
      "Target min [16.63702941]\n",
      "Target max [77.71451195]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ABNB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.24899979e+01  8.29700012e+01  1.72560000e+06  1.01499939e+00\n",
      " -1.80299988e+01  0.00000000e+00 -1.29513658e+01 -4.57280582e+00]\n",
      "Feature max [2.16839996e+02 2.16240005e+02 7.47864000e+07 3.05000000e+01\n",
      " 1.21199951e+01 9.29350181e+01 1.31150691e+01 3.98198040e+00]\n",
      "Target min [82.97000122]\n",
      "Target max [216.24000549]\n",
      "X_train shape: (915, 20, 8)\n",
      "Train_dates: 2020-12-11 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SNPS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.95699997e+01  5.93699989e+01  2.00200000e+05  2.60002136e-01\n",
      " -3.66699829e+01  7.61484664e+00 -2.46719247e+01 -8.22743530e+00]\n",
      "Feature max [6.21299988e+02 6.22929993e+02 3.02946000e+07 5.02700195e+01\n",
      " 4.64199829e+01 1.00000000e+02 2.12557667e+01 8.46134558e+00]\n",
      "Target min [59.27000046]\n",
      "Target max [622.92999268]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BIIB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [187.53999329 190.55999756   0.           0.         -98.07998657\n",
      "   4.79436191 -25.57434546 -11.64517675]\n",
      "Feature max [4.14709991e+02 4.23329987e+02 2.18431000e+07 1.82549988e+02\n",
      " 8.64900055e+01 1.00000000e+02 3.49582846e+01 1.62224245e+01]\n",
      "Target min [190.55999756]\n",
      "Target max [423.32998657]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing REGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.73459991e+02  2.74350006e+02  1.71600000e+05  2.76998901e+00\n",
      " -4.76300049e+01  6.11531109e+00 -2.90962700e+01 -1.14012185e+01]\n",
      "Feature max [1.20176001e+03 1.20471997e+03 7.86950000e+06 8.12899780e+01\n",
      " 9.05499878e+01 1.00000000e+02 3.48632110e+01 1.33649620e+01]\n",
      "Target min [274.3500061]\n",
      "Target max [1204.7199707]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.40612106e+01  7.38682202e+01  1.45000000e+05  3.47388758e-01\n",
      " -1.39151193e+01  7.46573940e+00 -1.02972303e+01 -4.01614549e+00]\n",
      "Feature max [2.85989990e+02 2.85000000e+02 4.24820000e+06 1.72982793e+01\n",
      " 1.09380049e+01 1.00000000e+02 7.65714210e+00 3.71764103e+00]\n",
      "Target min [73.86822019]\n",
      "Target max [285.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TSLA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.19313326e+01  1.20733328e+01  2.94018000e+07  1.66667938e-01\n",
      " -2.41000061e+01  6.91932630e+00 -2.52713333e+01 -7.67848148e+00]\n",
      "Feature max [4.09970001e+02 4.11470001e+02 9.14082000e+08 5.43266602e+01\n",
      " 3.25100098e+01 1.00000000e+02 3.80679297e+01 1.02961745e+01]\n",
      "Target min [12.07333279]\n",
      "Target max [411.47000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NVDA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35561371e+00  2.36844215e+00  9.78840000e+07  3.05890931e-02\n",
      " -1.52099991e+01  8.18788925e+00 -5.16786769e+00 -2.56494372e+00]\n",
      "Feature max [1.35580002e+02 1.39800003e+02 3.69292800e+09 1.33500061e+01\n",
      " 9.16999817e+00 1.00000000e+02 9.77617754e+00 2.89363431e+00]\n",
      "Target min [2.36844215]\n",
      "Target max [139.80000305]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CPRT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95749998e+00  6.97499990e+00  1.16560000e+06  4.75001335e-02\n",
      " -2.40999985e+00  1.07028555e+01 -2.08288713e+00 -5.95224464e-01]\n",
      "Feature max [5.80699997e+01 5.81300011e+01 2.13690400e+08 3.43000031e+00\n",
      " 1.91999817e+00 1.00000000e+02 1.68053820e+00 5.29970520e-01]\n",
      "Target min [6.94750023]\n",
      "Target max [58.13000107]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ORLY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.72850006e+02  1.72839996e+02  9.76000000e+04  1.75000000e+00\n",
      " -7.26999512e+01  9.93704967e+00 -3.18757122e+01 -1.55376421e+01]\n",
      "Feature max [1.16753003e+03 1.16473999e+03 1.28304000e+07 6.14700928e+01\n",
      " 3.95399780e+01 1.00000000e+02 2.94044788e+01 1.46112531e+01]\n",
      "Target min [172.83999634]\n",
      "Target max [1164.73999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSGP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.90799999e+01  1.86439991e+01  4.31000000e+05  1.32999420e-01\n",
      " -1.35200005e+01  3.82196899e+00 -3.91839760e+00 -1.70338203e+00]\n",
      "Feature max [9.97399979e+01 9.96600037e+01 5.40349000e+07 1.53570023e+01\n",
      " 2.22259979e+01 1.00000000e+02 3.78952594e+00 1.64810768e+00]\n",
      "Target min [18.6439991]\n",
      "Target max [99.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PDD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.71499996e+01  1.72000008e+01  1.21070000e+06  3.10001373e-01\n",
      " -2.96699982e+01  0.00000000e+00 -1.20781712e+01 -6.25067404e+00]\n",
      "Feature max [2.02820007e+02 2.11600006e+02 1.03174600e+08 2.12799988e+01\n",
      " 2.67000046e+01 9.22446129e+01 1.43527401e+01 4.73466591e+00]\n",
      "Target min [17.20000076]\n",
      "Target max [211.6000061]\n",
      "X_train shape: (1514, 20, 8)\n",
      "Train_dates: 2018-07-27 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing HON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.46234283e+01  9.52323924e+01  6.25500000e+05  4.19023023e-01\n",
      " -1.95059691e+01  4.75191361e+00 -1.40929686e+01 -4.45800722e+00]\n",
      "Feature max [2.19502518e+02 2.19940326e+02 2.82371000e+07 2.09818764e+01\n",
      " 1.90409461e+01 1.00000000e+02 8.86860871e+00 3.23137198e+00]\n",
      "Target min [95.23239237]\n",
      "Target max [219.94032644]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.14207764e+01  6.16446975e+01  4.66400000e+05  4.04764895e-01\n",
      " -1.59855186e+01  0.00000000e+00 -6.96255730e+00 -3.47483258e+00]\n",
      "Feature max [2.42376740e+02 2.39537898e+02 1.91564000e+07 1.54971600e+01\n",
      " 1.14345648e+01 9.47163396e+01 9.37402072e+00 2.80709341e+00]\n",
      "Target min [61.64469753]\n",
      "Target max [239.53789776]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.30817719e+01  7.35512640e+01  5.83900000e+05  5.47719753e-01\n",
      " -1.30866556e+01  5.85068100e+00 -5.68716369e+00 -2.63117505e+00]\n",
      "Feature max [1.51820007e+02 1.50807724e+02 3.87045000e+07 1.23726565e+01\n",
      " 1.06121300e+01 1.00000000e+02 4.99350023e+00 2.11381073e+00]\n",
      "Target min [73.55126402]\n",
      "Target max [150.80772389]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.64580708e+01  1.71472468e+01  1.14310000e+06  1.73414642e-01\n",
      " -9.42169202e+00  0.00000000e+00 -3.04021906e+00 -1.40459868e+00]\n",
      "Feature max [6.87902756e+01 6.75091239e+01 1.35204800e+08 4.21353646e+00\n",
      " 3.35943863e+00 9.56385384e+01 1.17085641e+00 5.30558159e-01]\n",
      "Target min [17.14724681]\n",
      "Target max [67.50912394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WBD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.71000004e+00  6.67000008e+00  7.96300000e+05  1.29999638e-01\n",
      " -4.63999939e+00  7.36432776e+00 -5.62270475e+00 -4.52551421e+00]\n",
      "Feature max [7.72699966e+01 7.79800034e+01 1.58082500e+08 2.36100006e+01\n",
      " 3.59000015e+00 1.00000000e+02 7.78521295e+00 1.10191292e+00]\n",
      "Target min [6.67000008]\n",
      "Target max [77.98000336]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.77167313e+02  1.76918230e+02  1.00700000e+05  1.05556133e+00\n",
      " -7.16818278e+01  1.01359955e+01 -2.43843433e+01 -7.21921725e+00]\n",
      "Feature max [5.76549988e+02 5.77500000e+02 8.03490000e+06 6.23608442e+01\n",
      " 3.51599731e+01 1.00000000e+02 1.65133356e+01 6.23603896e+00]\n",
      "Target min [176.71792575]\n",
      "Target max [577.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15072441  8.44775065  0.          0.         -2.64121934  0.\n",
      " -2.42761186 -0.8424089 ]\n",
      "Feature max [3.84843826e+01 3.84346839e+01 7.90905000e+07 3.35121765e+00\n",
      " 2.26195980e+00 9.66592743e+01 2.24860646e+00 6.65254204e-01]\n",
      "Target min [8.44775065]\n",
      "Target max [38.43468386]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing COST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.34840012e+02  1.34848979e+02  5.43600000e+05  6.44244340e-01\n",
      " -2.94507165e+01  7.85628126e+00 -3.22091495e+01 -9.48258100e+00]\n",
      "Feature max [9.08900024e+02 9.10960022e+02 2.42330000e+07 4.41770966e+01\n",
      " 1.44717175e+01 1.00000000e+02 2.40226275e+01 6.93894982e+00]\n",
      "Target min [134.84897936]\n",
      "Target max [910.96002197]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.09898205e+01  2.08327117e+01  7.55800000e+05  1.13624078e-01\n",
      " -4.94519677e+00  1.11789303e+01 -2.60963623e+00 -8.58607195e-01]\n",
      "Feature max [8.76200027e+01 8.73300018e+01 6.55402000e+07 7.22391984e+00\n",
      " 4.14094037e+00 1.00000000e+02 2.45854722e+00 7.89947017e-01]\n",
      "Target min [20.83271174]\n",
      "Target max [87.33000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LRCX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.58611450e+01  9.56820940e+01  3.00600000e+05  6.44566075e-01\n",
      " -6.64899902e+01  8.02008893e+00 -6.76982729e+01 -2.23238752e+01]\n",
      "Feature max [1.12730005e+03 1.12977002e+03 1.34214000e+07 7.38499756e+01\n",
      " 3.86400146e+01 1.00000000e+02 3.73546174e+01 1.44478835e+01]\n",
      "Target min [95.50305089]\n",
      "Target max [1129.77001953]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MELI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65434586e+02  1.61862905e+02  1.09000000e+05  1.65614514e+00\n",
      " -1.47979980e+02  6.42065563e+00 -1.26762239e+02 -4.86753050e+01]\n",
      "Feature max [2.06165991e+03 2.03525000e+03 4.29950000e+06 1.80000000e+02\n",
      " 1.14010010e+02 1.00000000e+02 9.65798543e+01 4.12565588e+01]\n",
      "Target min [158.54062541]\n",
      "Target max [2035.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.67368240e+01  4.67459853e+01  1.82100000e+05  3.48899225e-01\n",
      " -2.61500847e+01  1.10566618e+01 -1.16426956e+01 -2.77844168e+00]\n",
      "Feature max [2.56499237e+02 2.59970663e+02 2.45494000e+07 1.57643685e+01\n",
      " 1.15215616e+01 1.00000000e+02 6.29487146e+00 2.94088481e+00]\n",
      "Target min [46.74598533]\n",
      "Target max [259.97066279]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FANG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.26427402e+01  1.29027445e+01  2.62100000e+05  7.69125709e-01\n",
      " -1.58440519e+01  1.03119802e+00 -1.19967650e+01 -3.84871264e+00]\n",
      "Feature max [2.08427399e+02 2.08555865e+02 3.30497000e+07 1.22028993e+01\n",
      " 7.94710772e+00 1.00000000e+02 7.18674461e+00 2.89178241e+00]\n",
      "Target min [12.9027445]\n",
      "Target max [208.55586459]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ZS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.49500008e+01  2.50000000e+01  1.97200000e+05  3.79999161e-01\n",
      " -3.88899994e+01  0.00000000e+00 -2.36812080e+01 -8.89085502e+00]\n",
      "Feature max [3.68779999e+02 3.72500000e+02 2.68458000e+07 5.90399780e+01\n",
      " 2.63500061e+01 9.43483988e+01 1.81146072e+01 6.76156951e+00]\n",
      "Target min [25.]\n",
      "Target max [372.5]\n",
      "X_train shape: (1605, 20, 8)\n",
      "Train_dates: 2018-03-19 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADBE data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.04139999e+02  1.03739998e+02  5.89200000e+05  6.49993896e-01\n",
      " -7.08099976e+01  1.41851355e+00 -3.26176172e+01 -1.20971259e+01]\n",
      "Feature max [6.88369995e+02 6.96280029e+02 2.78402000e+07 5.77900391e+01\n",
      " 7.15100098e+01 1.00000000e+02 3.08100807e+01 9.11981859e+00]\n",
      "Target min [103.43000031]\n",
      "Target max [696.2800293]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93002777e+01  3.92593243e+01  6.93600000e+06  1.63815054e-01\n",
      " -1.10299988e+01  1.33774083e+01 -5.19036880e+00 -2.41195015e+00]\n",
      "Feature max [1.92660004e+02 1.91750000e+02 1.24140000e+08 9.33999634e+00\n",
      " 1.80194956e+01 1.00000000e+02 5.21262163e+00 1.68897131e+00]\n",
      "Target min [38.8962372]\n",
      "Target max [191.75]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMAT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.72328167e+01  2.75991735e+01  1.40920000e+06  2.48054563e-01\n",
      " -1.45720706e+01  1.10478638e+01 -1.30488603e+01 -4.80425104e+00]\n",
      "Feature max [2.54482300e+02 2.55081164e+02 5.25842000e+07 1.67279368e+01\n",
      " 1.42822510e+01 1.00000000e+02 1.06164158e+01 3.45275434e+00]\n",
      "Target min [27.59917352]\n",
      "Target max [255.0811642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.12595596e+01  8.12424975e+01  3.50200000e+05  3.94597454e-01\n",
      " -1.50322602e+01  3.70815748e+00 -1.35625544e+01 -3.90767423e+00]\n",
      "Feature max [2.75910004e+02 2.75790009e+02 2.98376000e+07 1.78119307e+01\n",
      " 1.03888054e+01 1.00000000e+02 1.01973412e+01 2.87688200e+00]\n",
      "Target min [81.24249753]\n",
      "Target max [275.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SBUX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.25571518e+01  4.21538514e+01  1.84780000e+06  2.41612834e-01\n",
      " -1.24990574e+01  3.06340275e+00 -6.61673915e+00 -1.77160465e+00]\n",
      "Feature max [1.17301468e+02 1.17320081e+02 1.57215500e+08 8.91207977e+00\n",
      " 1.39059501e+01 1.00000000e+02 5.32951402e+00 2.47897411e+00]\n",
      "Target min [42.15385144]\n",
      "Target max [117.32008083]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTWO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.93600006e+01  4.94000015e+01  2.11600000e+05  3.89999390e-01\n",
      " -1.71000061e+01  5.25756554e+00 -1.00961129e+01 -3.59837456e+00]\n",
      "Feature max [2.13339996e+02 2.10479996e+02 2.53857000e+07 1.86999969e+01\n",
      " 1.62300034e+01 1.00000000e+02 8.60457497e+00 3.04146889e+00]\n",
      "Target min [49.34999847]\n",
      "Target max [210.47999573]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TMUS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.45139313e+01  5.45139293e+01  4.70100000e+05  2.26488207e-01\n",
      " -9.75855268e+00  9.14566324e+00 -4.12801695e+00 -2.00070151e+00]\n",
      "Feature max [2.03367172e+02 2.04613114e+02 6.69031000e+07 1.24074312e+01\n",
      " 1.02607535e+01 1.00000000e+02 5.13087001e+00 2.60923852e+00]\n",
      "Target min [54.51392929]\n",
      "Target max [204.61311436]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WDAY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.13600006e+01  6.86699982e+01  3.69100000e+05  7.19993591e-01\n",
      " -2.87099915e+01  9.22365714e+00 -1.61351526e+01 -5.44748712e+00]\n",
      "Feature max [3.07209991e+02 3.09100006e+02 1.56112000e+07 2.13899994e+01\n",
      " 3.39099884e+01 1.00000000e+02 1.38299273e+01 6.22001392e+00]\n",
      "Target min [66.75]\n",
      "Target max [309.1000061]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CRWD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.30099983e+01  3.39300003e+01  8.04900000e+05  1.25000000e+00\n",
      " -4.85399780e+01  5.38771656e+00 -3.82154109e+01 -1.52669393e+01]\n",
      "Feature max [3.92149994e+02 3.92510010e+02 5.40774000e+07 4.09899902e+01\n",
      " 6.24899902e+01 1.00000000e+02 1.92436948e+01 8.51986054e+00]\n",
      "Target min [33.93000031]\n",
      "Target max [392.51000977]\n",
      "X_train shape: (1294, 20, 8)\n",
      "Train_dates: 2019-06-13 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DDOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.80400009e+01  2.78999996e+01  5.74800000e+05  7.30003357e-01\n",
      " -2.19200058e+01  0.00000000e+00 -1.14620833e+01 -4.12330397e+00]\n",
      "Feature max [1.96559998e+02 1.97695999e+02 2.91348000e+07 2.36900024e+01\n",
      " 2.69400024e+01 9.94039849e+01 1.14713512e+01 4.87120929e+00]\n",
      "Target min [27.89999962]\n",
      "Target max [197.69599915]\n",
      "X_train shape: (1225, 20, 8)\n",
      "Train_dates: 2019-09-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PCAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.86600780e+01  2.83693981e+01  4.95450000e+05  1.76137089e-01\n",
      " -1.04065623e+01  7.26950133e+00 -3.26233711e+00 -1.44177806e+00]\n",
      "Feature max [1.23713150e+02 1.24249916e+02 1.21321500e+07 7.01745891e+00\n",
      " 3.03883490e+00 1.00000000e+02 4.25862637e+00 1.04586865e+00]\n",
      "Target min [28.36939812]\n",
      "Target max [124.24991579]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRNA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.22600002e+01  1.22600002e+01  2.72800000e+05  2.99999237e-01\n",
      " -5.01100159e+01  6.23065240e+00 -3.31765627e+01 -1.53366601e+01]\n",
      "Feature max [4.84470001e+02 4.85500000e+02 1.25130400e+08 8.40969849e+01\n",
      " 4.59499817e+01 1.00000000e+02 5.26756442e+01 1.60440938e+01]\n",
      "Target min [12.26000023]\n",
      "Target max [485.5]\n",
      "X_train shape: (1421, 20, 8)\n",
      "Train_dates: 2018-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing META data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.87276764e+01  8.98952753e+01  5.46750000e+06  5.18937895e-01\n",
      " -7.81893309e+01  9.76807860e+00 -2.89867457e+01 -9.55160653e+00]\n",
      "Feature max [5.39909973e+02 5.42349976e+02 2.32316600e+08 3.50699768e+01\n",
      " 6.46870778e+01 1.00000000e+02 2.92185297e+01 7.48696378e+00]\n",
      "Target min [89.89527525]\n",
      "Target max [542.34997559]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MNST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.07199993e+01  2.07049999e+01  9.22800000e+05  1.65000916e-01\n",
      " -5.64999771e+00  7.54052007e+00 -2.06519425e+00 -6.53749929e-01]\n",
      "Feature max [6.08499985e+01 6.10000000e+01 3.67095000e+07 4.27999878e+00\n",
      " 4.58000183e+00 1.00000000e+02 1.81693996e+00 9.25280916e-01]\n",
      "Target min [20.70499992]\n",
      "Target max [61.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.52999973e+00  9.07999992e+00  1.10358000e+07  1.19999886e-01\n",
      " -1.03399963e+01  0.00000000e+00 -9.13773987e+00 -3.97167693e+00]\n",
      "Feature max [2.11380005e+02 2.13410004e+02 3.25058400e+08 2.16999969e+01\n",
      " 1.31100006e+01 9.59459396e+01 1.14017298e+01 3.51085324e+00]\n",
      "Target min [9.07999992]\n",
      "Target max [213.41000366]\n",
      "X_train shape: (1906, 20, 8)\n",
      "Train_dates: 2017-01-05 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing QCOM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.10863304e+01  4.13346323e+01  2.12020000e+06  2.21164971e-01\n",
      " -1.19638954e+01  7.39827819e+00 -1.13783823e+01 -3.46840781e+00]\n",
      "Feature max [2.25922470e+02 2.25653869e+02 1.56019300e+08 1.56075693e+01\n",
      " 1.67030158e+01 1.00000000e+02 1.22270489e+01 3.97922020e+00]\n",
      "Target min [41.33463229]\n",
      "Target max [225.65386916]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CCEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55083256e+01  2.55731054e+01  2.18600000e+05  1.48332760e-01\n",
      " -5.48859495e+00  7.67561705e+00 -5.38139225e+00 -1.98555559e+00]\n",
      "Feature max [8.04899979e+01 8.02600021e+01 3.00719000e+07 5.47105868e+00\n",
      " 5.02390093e+00 1.00000000e+02 2.10718525e+00 1.58574569e+00]\n",
      "Target min [25.23299509]\n",
      "Target max [80.26000214]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PAYX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.40656738e+01  4.43662845e+01  4.22500000e+05  2.53874812e-01\n",
      " -6.98216638e+00  6.37119496e+00 -7.06664430e+00 -2.03882489e+00]\n",
      "Feature max [1.31301483e+02 1.30869995e+02 1.68049000e+07 1.40609656e+01\n",
      " 5.64424831e+00 1.00000000e+02 4.66590735e+00 1.34585565e+00]\n",
      "Target min [44.36628453]\n",
      "Target max [130.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CHTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.54610001e+02  2.38960007e+02  2.42700000e+05  1.79000854e+00\n",
      " -4.96099854e+01  1.00045832e+01 -3.55786821e+01 -1.27762515e+01]\n",
      "Feature max [8.21010010e+02 8.23080017e+02 1.55224000e+07 4.71099854e+01\n",
      " 4.25099792e+01 1.00000000e+02 2.18537876e+01 9.81964050e+00]\n",
      "Target min [238.96000671]\n",
      "Target max [823.08001709]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTAS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.05113632e+02  1.05187604e+02  1.12200000e+05  5.64083578e-01\n",
      " -4.39267993e+01  1.00216936e+01 -2.82557842e+01 -9.58054397e+00]\n",
      "Feature max [8.05119995e+02 8.04500000e+02 2.72700000e+06 4.61448665e+01\n",
      " 4.98478169e+01 1.00000000e+02 1.69135603e+01 6.24244827e+00]\n",
      "Target min [105.18760444]\n",
      "Target max [804.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GEHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.58701439e+01  5.28771002e+01  2.22000000e+04  4.48496557e-01\n",
      " -7.89708004e+00  0.00000000e+00 -2.75575517e+00 -9.40396651e-01]\n",
      "Feature max [9.38021851e+01 9.37422203e+01 3.33385000e+07 1.07550019e+01\n",
      " 3.51607095e+00 8.71251436e+01 4.22888858e+00 9.98581047e-01]\n",
      "Target min [52.87710024]\n",
      "Target max [93.74222026]\n",
      "X_train shape: (408, 20, 8)\n",
      "Train_dates: 2022-12-16 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRVL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.31523428e+01  1.32089097e+01  1.60940000e+06  9.52960595e-02\n",
      " -5.81999969e+00  1.28620499e+01 -4.44552075e+00 -2.03029601e+00]\n",
      "Feature max [9.03993835e+01 9.02215755e+01 9.43073000e+07 9.40218170e+00\n",
      " 1.46796437e+01 1.00000000e+02 5.29263865e+00 2.28143624e+00]\n",
      "Target min [13.13348379]\n",
      "Target max [90.22157553]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NXPI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.02686577e+01  6.05207032e+01  4.80500000e+05  1.27887277e-01\n",
      " -2.30199890e+01  8.16542295e+00 -1.30447499e+01 -4.12573737e+00]\n",
      "Feature max [2.90779999e+02 2.85390015e+02 5.31022000e+07 2.01099854e+01\n",
      " 1.25948901e+01 1.00000000e+02 9.68135871e+00 3.81693584e+00]\n",
      "Target min [60.5207032]\n",
      "Target max [285.39001465]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.71000004e+00  2.69000006e+00  6.31000000e+05  5.90000153e-02\n",
      " -1.51449966e+01  1.02722976e+01 -7.73271712e+00 -2.83294696e+00]\n",
      "Feature max [1.11639999e+02 1.11089996e+02 1.27624000e+08 1.49599991e+01\n",
      " 1.57500000e+01 1.00000000e+02 8.65914541e+00 3.44913976e+00]\n",
      "Target min [2.69000006]\n",
      "Target max [111.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKNG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.14665942e+03  1.16132802e+03  7.94000000e+04  6.03070832e+00\n",
      " -3.52589844e+02  6.38670853e+00 -1.75862484e+02 -7.18094172e+01]\n",
      "Feature max [4.11908984e+03 4.11700000e+03 3.32510000e+06 2.15700222e+02\n",
      " 3.13563739e+02 1.00000000e+02 1.22086329e+02 4.95826730e+01]\n",
      "Target min [1161.32802486]\n",
      "Target max [4117.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KDP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.17389641e+01  1.13540082e+01  3.12600000e+05  5.19934914e-02\n",
      " -2.16673458e+00  5.47452680e+00 -1.84060856e+00 -7.08470451e-01]\n",
      "Feature max [3.81241417e+01 3.81621806e+01 1.43326600e+08 4.27929837e+00\n",
      " 4.32504079e+00 1.00000000e+02 1.24850177e+00 5.03788950e-01]\n",
      "Target min [11.3540082]\n",
      "Target max [38.16218065]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ODFL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.60743752e+01  2.62781747e+01  2.93800000e+05  2.29686435e-01\n",
      " -1.23647591e+01  9.60346788e+00 -9.47054035e+00 -4.03113180e+00]\n",
      "Feature max [2.24051163e+02 2.25128094e+02 4.64676000e+07 2.78705293e+01\n",
      " 9.12877978e+00 1.00000000e+02 9.61462501e+00 3.12346450e+00]\n",
      "Target min [26.27817474]\n",
      "Target max [225.12809388]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ISRG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.99433365e+01  7.00211105e+01  4.89900000e+05  4.15557861e-01\n",
      " -1.95700073e+01  0.00000000e+00 -2.11512520e+01 -7.04575693e+00]\n",
      "Feature max [4.92630005e+02 4.92619995e+02 1.12668000e+07 2.48000031e+01\n",
      " 3.32899780e+01 9.95441593e+01 1.42319395e+01 6.40623327e+00]\n",
      "Target min [70.02111053]\n",
      "Target max [492.61999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TXN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.90602150e+01  5.90278329e+01  1.04440000e+06  2.77122029e-01\n",
      " -1.04008109e+01  0.00000000e+00 -6.09191206e+00 -2.17086585e+00]\n",
      "Feature max [2.14339996e+02 2.12580002e+02 2.51217000e+07 1.31599884e+01\n",
      " 1.25867588e+01 9.74574577e+01 7.69273172e+00 2.34828512e+00]\n",
      "Target min [59.02783295]\n",
      "Target max [212.58000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ARM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.78699989e+01  4.72200012e+01  2.26890000e+06  1.22000122e+00\n",
      " -2.08500061e+01  0.00000000e+00 -1.27820527e+01 -6.74110994e+00]\n",
      "Feature max [1.86460007e+02 1.86839996e+02 1.11349700e+08 4.53099976e+01\n",
      " 1.74000015e+01 9.62229824e+01 1.65008639e+01 6.88049836e+00]\n",
      "Target min [47.22000122]\n",
      "Target max [186.83999634]\n",
      "X_train shape: (222, 20, 8)\n",
      "Train_dates: 2023-09-15 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.95189934e+01  4.98084740e+01  5.35700000e+05  4.09831436e-01\n",
      " -2.21022813e+01  7.32256125e+00 -1.31744938e+01 -4.43503068e+00]\n",
      "Feature max [1.55210007e+02 1.63559998e+02 3.45755000e+07 1.30095116e+01\n",
      " 1.65455338e+01 1.00000000e+02 7.20230600e+00 2.52539233e+00]\n",
      "Target min [49.808474]\n",
      "Target max [163.55999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDLZ data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.26199265e+01  3.25591386e+01  1.83380000e+06  1.95484721e-01\n",
      " -4.06838384e+00  0.00000000e+00 -3.04621952e+00 -1.02893348e+00]\n",
      "Feature max [7.60628128e+01 7.61016380e+01 2.91974000e+07 4.50139843e+00\n",
      " 3.43486217e+00 9.24407526e+01 2.31448896e+00 8.04107706e-01]\n",
      "Target min [32.55913859]\n",
      "Target max [76.10163795]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LIN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01270164e+02  1.01313959e+02  2.76400000e+05  5.60332217e-01\n",
      " -2.60359056e+01  0.00000000e+00 -1.35822668e+01 -4.32009475e+00]\n",
      "Feature max [4.76847687e+02 4.73647108e+02 5.73756000e+07 2.50221268e+01\n",
      " 1.73251100e+01 9.79872343e+01 1.39092182e+01 4.41989505e+00]\n",
      "Target min [101.31395871]\n",
      "Target max [473.64710757]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSCO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.37586079e+01  2.37744503e+01  5.72050000e+06  1.35897090e-01\n",
      " -5.72839768e+00  0.00000000e+00 -2.51348457e+00 -7.94817961e-01]\n",
      "Feature max [5.87176704e+01 5.87911218e+01 1.06928300e+08 3.98683297e+00\n",
      " 3.31000137e+00 9.41031589e+01 1.74181746e+00 6.52277355e-01]\n",
      "Target min [23.77445027]\n",
      "Target max [58.79112185]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.08447884e+02  1.05853958e+02  4.17100000e+05  4.74368466e-01\n",
      " -4.12029187e+01  4.31332021e+00 -2.91569420e+01 -1.00687248e+01]\n",
      "Feature max [6.82518738e+02 7.03358157e+02 6.66440000e+06 4.95999756e+01\n",
      " 8.54107082e+01 1.00000000e+02 2.48427116e+01 9.59889358e+00]\n",
      "Target min [105.85395772]\n",
      "Target max [703.35815692]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.01410446e+01  8.03660673e+01  8.83300000e+05  2.61090826e-01\n",
      " -1.13063004e+01  5.70031306e+00 -6.88044533e+00 -2.29319818e+00]\n",
      "Feature max [1.88991516e+02 1.89425174e+02 2.75597000e+07 1.50898174e+01\n",
      " 5.84070749e+00 1.00000000e+02 3.42618620e+00 2.29382247e+00]\n",
      "Target min [80.36606728]\n",
      "Target max [189.42517439]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ANSS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.32399979e+01  9.30100021e+01  1.40800000e+05  5.89996338e-01\n",
      " -3.09700012e+01  8.81775088e+00 -1.95951198e+01 -9.68954390e+00]\n",
      "Feature max [4.11220001e+02 4.13220001e+02 1.76134000e+07 5.81499939e+01\n",
      " 5.98500061e+01 1.00000000e+02 1.77876080e+01 8.00055630e+00]\n",
      "Target min [93.01000214]\n",
      "Target max [413.22000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SMCI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [  11.64999962   11.55000019 1300.            0.         -112.07000732\n",
      "    3.06121694  -80.8459551   -37.07896777]\n",
      "Feature max [1.18806995e+03 1.21200000e+03 3.69735000e+07 2.76719971e+02\n",
      " 1.33520020e+02 1.00000000e+02 1.39404960e+02 3.27849310e+01]\n",
      "Target min [11.55000019]\n",
      "Target max [1212.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MCHP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.59165325e+01  2.58235891e+01  9.03800000e+05  2.06648672e-01\n",
      " -4.89303413e+00  0.00000000e+00 -5.27414129e+00 -1.76700590e+00]\n",
      "Feature max [9.89445496e+01 9.94815944e+01 6.08822000e+07 6.51408535e+00\n",
      " 6.70936116e+00 9.91723404e+01 3.41370794e+00 1.65715979e+00]\n",
      "Target min [25.82358912]\n",
      "Target max [99.48159441]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DASH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.30600014e+01  4.40000000e+01  6.73000000e+05  1.04000092e+00\n",
      " -1.43899994e+01  0.00000000e+00 -1.42424126e+01 -6.22931087e+00]\n",
      "Feature max [2.45970001e+02 2.47520004e+02 4.74057000e+07 6.56900024e+01\n",
      " 3.15700073e+01 8.94834273e+01 1.00982520e+01 7.89917563e+00]\n",
      "Target min [44.]\n",
      "Target max [247.52000427]\n",
      "X_train shape: (916, 20, 8)\n",
      "Train_dates: 2020-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LULU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.79099998e+01  4.80200005e+01  3.97400000e+05  5.40000916e-01\n",
      " -6.25899963e+01  5.58157336e+00 -2.90394509e+01 -9.98076840e+00]\n",
      "Feature max [5.11290009e+02 5.13239990e+02 4.96203000e+07 4.49899902e+01\n",
      " 5.28800049e+01 1.00000000e+02 2.51784526e+01 8.66763261e+00]\n",
      "Target min [48.02000046]\n",
      "Target max [513.23999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.20500984e+02  1.20691455e+02  6.12800000e+05  8.28945522e-01\n",
      " -1.51888122e+01  4.25188197e+00 -6.90048759e+00 -3.92935252e+00]\n",
      "Feature max [3.33829987e+02 3.35086817e+02 2.39368000e+07 2.95567899e+01\n",
      " 3.45128549e+01 1.00000000e+02 1.11182756e+01 4.56750792e+00]\n",
      "Target min [117.33470545]\n",
      "Target max [335.08681669]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.69300003e+01  7.61900024e+01  2.56200000e+05  5.80001831e-01\n",
      " -4.11199951e+01  8.69419477e+00 -1.48270264e+01 -9.41658874e+00]\n",
      "Feature max [3.42269989e+02 3.42519989e+02 1.94870000e+07 2.90000076e+01\n",
      " 2.02900085e+01 1.00000000e+02 1.45651636e+01 4.69711212e+00]\n",
      "Target min [74.61000061]\n",
      "Target max [342.51998901]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTSH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88846703e+01  3.95294675e+01  6.22600000e+05  2.63455735e-01\n",
      " -7.87767379e+00  3.88436978e+00 -4.96337393e+00 -1.63582222e+00]\n",
      "Feature max [8.93110580e+01 8.89753726e+01 4.05510000e+07 7.35239114e+00\n",
      " 4.92299173e+00 1.00000000e+02 2.87894145e+00 1.48546432e+00]\n",
      "Target min [39.52946751]\n",
      "Target max [88.9753726]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CMCSA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.63607178e+01  2.63434807e+01  3.87530000e+06  1.43293758e-01\n",
      " -4.19077573e+00  4.89599374e+00 -2.20475416e+00 -7.52469262e-01]\n",
      "Feature max [5.69077454e+01 5.66128467e+01 1.05512100e+08 5.02262469e+00\n",
      " 2.79153520e+00 1.00000000e+02 1.64204644e+00 6.64990158e-01]\n",
      "Target min [26.34348075]\n",
      "Target max [56.61284673]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AAPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.68914185e+01  2.68520158e+01  2.40483000e+07  1.39069199e-01\n",
      " -2.07459821e+01  0.00000000e+00 -6.52546418e+00 -2.48303795e+00]\n",
      "Feature max [2.34548523e+02 2.36206595e+02 4.47940000e+08 1.74797677e+01\n",
      " 1.35858198e+01 9.66324640e+01 8.94504543e+00 2.34169434e+00]\n",
      "Target min [26.84042339]\n",
      "Target max [236.20659489]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DLTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.55699997e+01  6.56299973e+01  6.51800000e+05  6.50001526e-01\n",
      " -2.06100006e+01  5.95402131e+00 -8.27013588e+00 -4.05435465e+00]\n",
      "Feature max [1.74080002e+02 1.75119995e+02 2.64414000e+07 1.71399956e+01\n",
      " 2.62200012e+01 1.00000000e+02 1.03700274e+01 2.48843256e+00]\n",
      "Target min [65.62999725]\n",
      "Target max [175.11999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GFS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88100014e+01  3.79099998e+01  4.52100000e+05  4.29996490e-01\n",
      " -4.36000061e+00  7.50238102e+00 -4.23886167e+00 -2.38196636e+00]\n",
      "Feature max [7.89400024e+01 7.86999969e+01 2.59534000e+07 9.84000015e+00\n",
      " 5.52999878e+00 1.00000000e+02 5.44023126e+00 1.92129480e+00]\n",
      "Target min [37.90999985]\n",
      "Target max [78.69999695]\n",
      "X_train shape: (693, 20, 8)\n",
      "Train_dates: 2021-10-29 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.44999981e+00  8.35999966e+00  1.22410000e+06  1.59999847e-01\n",
      " -1.02299957e+01  1.19369510e+01 -7.02511537e+00 -2.54591706e+00]\n",
      "Feature max [1.08089996e+02 1.09739998e+02 9.31809000e+07 8.59999847e+00\n",
      " 5.73000336e+00 1.00000000e+02 5.08121811e+00 1.91962014e+00]\n",
      "Target min [8.35999966]\n",
      "Target max [109.73999786]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOGL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.03422012e+01  4.03287161e+01  9.31200000e+06  2.03764713e-01\n",
      " -1.11600037e+01  0.00000000e+00 -5.26264397e+00 -2.43230043e+00]\n",
      "Feature max [1.91179993e+02 1.90309998e+02 1.33178000e+08 9.50000000e+00\n",
      " 1.83489409e+01 9.87786722e+01 5.22104620e+00 1.70818585e+00]\n",
      "Target min [39.98510758]\n",
      "Target max [190.30999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.13033676e+01  2.10973018e+01  4.34960000e+06  2.94382095e-01\n",
      " -6.56426828e+00  0.00000000e+00 -1.04368766e+01 -2.87377563e+00]\n",
      "Feature max [1.53315903e+02 1.56872784e+02 1.42315800e+08 1.44873285e+01\n",
      " 1.70885413e+01 9.98187592e+01 9.21113765e+00 2.76849472e+00]\n",
      "Target min [21.09730184]\n",
      "Target max [156.87278409]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ILMN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.02626495e+01  9.14591446e+01  2.24207000e+05  1.42024231e+00\n",
      " -5.47957153e+01  1.07051311e+00 -2.98009348e+01 -1.18772369e+01]\n",
      "Feature max [5.10544739e+02 5.08336578e+02 3.66514900e+07 1.00622589e+02\n",
      " 3.87353821e+01 1.00000000e+02 2.65404856e+01 7.18644479e+00]\n",
      "Target min [91.45914459]\n",
      "Target max [508.33657837]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDNS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55699997e+01  2.53400002e+01  3.77200000e+05  1.30001068e-01\n",
      " -1.65799866e+01  6.34196911e+00 -1.44468346e+01 -5.97594400e+00]\n",
      "Feature max [3.26500000e+02 3.28790009e+02 5.72181000e+07 2.09400024e+01\n",
      " 1.50199890e+01 1.00000000e+02 8.60328681e+00 4.15512117e+00]\n",
      "Target min [25.34000015]\n",
      "Target max [328.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FTNT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.08400011e+00  6.03000021e+00  1.55300000e+06  5.60002327e-02\n",
      " -1.53400040e+01  3.96274759e+00 -4.72904041e+00 -2.60667325e+00]\n",
      "Feature max [8.02799988e+01 8.04499969e+01 1.66853000e+08 9.42400360e+00\n",
      " 9.86999893e+00 1.00000000e+02 4.39902634e+00 1.72982386e+00]\n",
      "Target min [6.03000021]\n",
      "Target max [80.44999695]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NFLX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.29179993e+02  1.27489998e+02  1.14400000e+06  8.99993896e-01\n",
      " -1.07820007e+02  2.54085690e+00 -5.92338064e+01 -1.83116588e+01]\n",
      "Feature max [7.01349976e+02 7.00359985e+02 1.33387500e+08 5.69599915e+01\n",
      " 6.36499939e+01 1.00000000e+02 2.49544334e+01 9.64348338e+00]\n",
      "Target min [124.95999908]\n",
      "Target max [700.35998535]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ASML data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01730980e+02  1.01656938e+02  1.91300000e+05  5.09020910e-01\n",
      " -8.94442496e+01  0.00000000e+00 -4.66577753e+01 -2.22673979e+01]\n",
      "Feature max [1.09691748e+03 1.10792721e+03 7.75430000e+06 7.14700317e+01\n",
      " 6.84131669e+01 9.61643651e+01 5.18699482e+01 1.62876849e+01]\n",
      "Target min [101.65693821]\n",
      "Target max [1107.92720614]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.57600002e+01  2.56200008e+01  7.45000000e+04  3.59998703e-01\n",
      " -7.29299927e+01  0.00000000e+00 -4.01420346e+01 -1.51743729e+01]\n",
      "Feature max [5.85030029e+02 5.85030029e+02 1.25421000e+07 6.22800293e+01\n",
      " 9.26100159e+01 9.67312153e+01 3.60296232e+01 1.38232539e+01]\n",
      "Target min [25.62000084]\n",
      "Target max [585.0300293]\n",
      "X_train shape: (1706, 20, 8)\n",
      "Train_dates: 2017-10-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.76626549e+01  5.97122717e+01  4.45200000e+05  3.56549996e-01\n",
      " -1.06970511e+01  0.00000000e+00 -1.68949977e+01 -4.25844733e+00]\n",
      "Feature max [2.57128174e+02 2.54701584e+02 2.58818000e+07 2.13453368e+01\n",
      " 1.87003391e+01 9.38515897e+01 7.41175465e+00 3.17530337e+00]\n",
      "Target min [59.71227172]\n",
      "Target max [254.70158394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.89899998e+01  1.91000004e+01  6.31320000e+06  1.65667071e-01\n",
      " -7.35439988e+00  0.00000000e+00 -3.67962875e+00 -1.56579357e+00]\n",
      "Feature max [6.20833359e+01 6.20287604e+01 3.00895900e+08 7.64107525e+00\n",
      " 5.65918728e+00 9.56313208e+01 2.62854917e+00 1.12867583e+00]\n",
      "Target min [19.10000038]\n",
      "Target max [62.0287604]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KLAC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.84464798e+01  6.86297678e+01  2.57700000e+05  5.09411721e-01\n",
      " -4.98388271e+01  0.00000000e+00 -2.75021476e+01 -1.29123594e+01]\n",
      "Feature max [8.90720154e+02 8.94682933e+02 6.29590000e+06 7.53521125e+01\n",
      " 4.65248886e+01 9.61332471e+01 3.03164111e+01 1.17409375e+01]\n",
      "Target min [68.62976779]\n",
      "Target max [894.68293334]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.78590012e+01  3.79194984e+01  1.76260000e+07  1.59500122e-01\n",
      " -1.73200073e+01  1.14353166e+01 -1.24315006e+01 -3.31749210e+00]\n",
      "Feature max [2.00000000e+02 2.00089996e+02 3.31300000e+08 1.37949982e+01\n",
      " 1.67610016e+01 1.00000000e+02 8.13447345e+00 3.39296647e+00]\n",
      "Target min [37.89599991]\n",
      "Target max [200.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing XEL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [32.11784744 32.15771459  0.          0.         -5.25528431  4.89724286\n",
      " -3.58270555 -1.54356316]\n",
      "Feature max [7.23329010e+01 7.20338820e+01 2.27822000e+07 8.42780017e+00\n",
      " 2.38429559e+00 1.00000000e+02 1.75878041e+00 1.02005387e+00]\n",
      "Target min [32.15771459]\n",
      "Target max [72.03388205]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m5,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,281</span> (20.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,281\u001b[0m (20.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,281</span> (20.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,281\u001b[0m (20.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/102 Training model for ^IXIC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0665 - mape: 318.3037 - val_loss: 0.0785 - val_mape: 31.8834\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0539 - mape: 292.9315 - val_loss: 0.0154 - val_mape: 12.6307\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0552 - mape: 304.8530 - val_loss: 0.0081 - val_mape: 8.9336\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0251 - mape: 201.7200 - val_loss: 0.0068 - val_mape: 8.3179\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mape: 95.5210 - val_loss: 0.0087 - val_mape: 9.9690\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mape: 69.1840 - val_loss: 0.0090 - val_mape: 10.3626\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mape: 57.7157 - val_loss: 0.0082 - val_mape: 9.9164\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mape: 50.8348 - val_loss: 0.0081 - val_mape: 9.9339\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - mape: 52.4887 - val_loss: 0.0052 - val_mape: 7.5568\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mape: 49.1594 - val_loss: 0.0089 - val_mape: 10.4696\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - mape: 50.4024 - val_loss: 0.0094 - val_mape: 10.8497\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mape: 44.6757 - val_loss: 0.0084 - val_mape: 10.1628\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mape: 56.2846 - val_loss: 0.0123 - val_mape: 12.5766\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mape: 58.6425 - val_loss: 0.0132 - val_mape: 13.0456\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - mape: 58.8097 - val_loss: 0.0119 - val_mape: 12.2426\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mape: 68.7438 - val_loss: 0.0110 - val_mape: 11.6568\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mape: 78.7645 - val_loss: 0.0110 - val_mape: 11.7018\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mape: 67.3469 - val_loss: 0.0116 - val_mape: 12.0388\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mape: 77.5838 - val_loss: 0.0114 - val_mape: 11.8695\n",
      "--- 2/102 Training model for VRTX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mape: 30.7895 - val_loss: 0.0045 - val_mape: 7.3387\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mape: 54.5776 - val_loss: 0.0028 - val_mape: 5.7740\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mape: 25.4398 - val_loss: 0.0031 - val_mape: 6.1755\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 23.7461 - val_loss: 0.0017 - val_mape: 4.2472\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 22.2891 - val_loss: 0.0022 - val_mape: 5.0867\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 20.9331 - val_loss: 9.9455e-04 - val_mape: 3.0553\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 20.0750 - val_loss: 0.0020 - val_mape: 4.7730\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 19.6869 - val_loss: 0.0018 - val_mape: 4.5484\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 22.6175 - val_loss: 0.0027 - val_mape: 5.6384\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 18.1103 - val_loss: 0.0021 - val_mape: 4.8464\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 19.0057 - val_loss: 0.0011 - val_mape: 3.2327\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 20.0515 - val_loss: 0.0032 - val_mape: 6.2450\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4972e-04 - mape: 16.3990 - val_loss: 0.0023 - val_mape: 5.0873\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 18.4088 - val_loss: 0.0028 - val_mape: 5.7132\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5087e-04 - mape: 15.3166 - val_loss: 0.0015 - val_mape: 3.9360\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0162e-04 - mape: 15.6273 - val_loss: 0.0030 - val_mape: 5.9376\n",
      "--- 3/102 Training model for PYPL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mape: 142334.6250 - val_loss: 7.2997e-05 - val_mape: 8.7033\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mape: 41883.4414 - val_loss: 8.7566e-04 - val_mape: 34.5861\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mape: 24802.4980 - val_loss: 0.0033 - val_mape: 67.7979\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mape: 220426.1406 - val_loss: 2.4678e-04 - val_mape: 16.6254\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - mape: 59684.4922 - val_loss: 1.0551e-04 - val_mape: 9.7501\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mape: 147036.2812 - val_loss: 6.3190e-04 - val_mape: 27.5548\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mape: 126232.3203 - val_loss: 6.1176e-04 - val_mape: 27.1591\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mape: 141064.1875 - val_loss: 3.0236e-04 - val_mape: 18.0699\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mape: 15666.1143 - val_loss: 4.1835e-04 - val_mape: 22.5251\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 28801.7969 - val_loss: 2.5075e-04 - val_mape: 17.1294\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 34113.5508 - val_loss: 1.4842e-04 - val_mape: 12.9099\n",
      "--- 4/102 Training model for GILD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mape: 39646.8828 - val_loss: 0.0013 - val_mape: 4.3925\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 93243.0781 - val_loss: 9.5839e-04 - val_mape: 3.5748\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 60966.2891 - val_loss: 0.0014 - val_mape: 4.4871\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 36639.1055 - val_loss: 9.5105e-04 - val_mape: 3.6860\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 35649.9023 - val_loss: 9.8606e-04 - val_mape: 3.7344\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 42858.8867 - val_loss: 0.0014 - val_mape: 4.7279\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 13892.1426 - val_loss: 0.0013 - val_mape: 4.5040\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 3065.3274 - val_loss: 7.7631e-04 - val_mape: 3.1319\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 36123.5898 - val_loss: 0.0013 - val_mape: 4.6573\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 31227.3574 - val_loss: 0.0013 - val_mape: 4.4987\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 22508.3770 - val_loss: 0.0012 - val_mape: 4.2413\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 38038.7070 - val_loss: 0.0010 - val_mape: 3.6626\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 20868.5332 - val_loss: 6.6498e-04 - val_mape: 2.9876\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 27338.8438 - val_loss: 5.0432e-04 - val_mape: 2.5117\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 29106.4180 - val_loss: 6.2990e-04 - val_mape: 2.7318\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 51250.0859 - val_loss: 8.6422e-04 - val_mape: 3.3665\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 10076.7393 - val_loss: 0.0012 - val_mape: 4.2007\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 12106.1309 - val_loss: 0.0011 - val_mape: 3.9224\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 12666.3789 - val_loss: 5.9459e-04 - val_mape: 2.7510\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4142e-04 - mape: 18769.5469 - val_loss: 0.0012 - val_mape: 4.4017\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 493.9189 - val_loss: 6.1974e-04 - val_mape: 2.7785\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8188e-04 - mape: 11361.6611 - val_loss: 5.4903e-04 - val_mape: 2.6400\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9370e-04 - mape: 23770.0254 - val_loss: 4.6491e-04 - val_mape: 2.5032\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1301e-04 - mape: 17088.7500 - val_loss: 5.9192e-04 - val_mape: 2.9420\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6786e-04 - mape: 5423.0547 - val_loss: 4.5365e-04 - val_mape: 2.3547\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8942e-04 - mape: 41866.2656 - val_loss: 4.6945e-04 - val_mape: 2.4801\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4538e-04 - mape: 58843.2656 - val_loss: 7.8442e-04 - val_mape: 3.4097\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2071e-04 - mape: 64483.2578 - val_loss: 6.5859e-04 - val_mape: 3.0408\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4503e-04 - mape: 34802.9453 - val_loss: 3.8387e-04 - val_mape: 2.2479\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8598e-04 - mape: 53181.8047 - val_loss: 4.0171e-04 - val_mape: 2.2720\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3313e-04 - mape: 76351.6172 - val_loss: 4.6351e-04 - val_mape: 2.4341\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4874e-04 - mape: 45441.7383 - val_loss: 4.7114e-04 - val_mape: 2.4416\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2274e-04 - mape: 54088.9531 - val_loss: 4.0652e-04 - val_mape: 2.3120\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6563e-04 - mape: 41974.3672 - val_loss: 6.9352e-04 - val_mape: 3.2672\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9519e-04 - mape: 3172.8748 - val_loss: 5.1822e-04 - val_mape: 2.7636\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5174e-04 - mape: 19624.7422 - val_loss: 7.0867e-04 - val_mape: 3.4058\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3245e-04 - mape: 30245.4922 - val_loss: 6.0600e-04 - val_mape: 3.1701\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0538e-04 - mape: 7924.4741 - val_loss: 3.0965e-04 - val_mape: 2.0630\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6118e-04 - mape: 47377.1758 - val_loss: 4.6482e-04 - val_mape: 2.6843\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6509e-04 - mape: 67220.0469 - val_loss: 3.2144e-04 - val_mape: 2.2098\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7643e-04 - mape: 60706.6641 - val_loss: 3.6008e-04 - val_mape: 2.2779\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1293e-04 - mape: 54200.9453 - val_loss: 2.9926e-04 - val_mape: 2.0746\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2398e-04 - mape: 22388.9023 - val_loss: 3.2675e-04 - val_mape: 2.1500\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1281e-04 - mape: 16883.7148 - val_loss: 6.5329e-04 - val_mape: 3.2257\n",
      "Epoch 45/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2028e-04 - mape: 19216.5352 - val_loss: 6.6745e-04 - val_mape: 3.4508\n",
      "Epoch 46/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8230e-04 - mape: 329.2388 - val_loss: 3.9741e-04 - val_mape: 2.5120\n",
      "Epoch 47/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3314e-04 - mape: 52635.3086 - val_loss: 3.2732e-04 - val_mape: 2.1495\n",
      "Epoch 48/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9131e-04 - mape: 52607.3320 - val_loss: 3.5343e-04 - val_mape: 2.3348\n",
      "Epoch 49/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3850e-04 - mape: 41068.8320 - val_loss: 4.0685e-04 - val_mape: 2.5653\n",
      "Epoch 50/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4231e-04 - mape: 50801.4883 - val_loss: 9.2092e-04 - val_mape: 4.1410\n",
      "Epoch 51/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9921e-04 - mape: 22122.0586 - val_loss: 3.7971e-04 - val_mape: 2.5227\n",
      "Epoch 52/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1280e-04 - mape: 26070.2676 - val_loss: 2.6383e-04 - val_mape: 1.9802\n",
      "Epoch 53/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5238e-04 - mape: 43239.9922 - val_loss: 3.7877e-04 - val_mape: 2.4657\n",
      "Epoch 54/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2636e-04 - mape: 94.6837 - val_loss: 3.0301e-04 - val_mape: 2.1834\n",
      "Epoch 55/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6418e-04 - mape: 70480.1562 - val_loss: 3.1105e-04 - val_mape: 2.1634\n",
      "Epoch 56/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1668e-04 - mape: 43267.7539 - val_loss: 2.5748e-04 - val_mape: 1.9662\n",
      "Epoch 57/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5220e-04 - mape: 9253.7441 - val_loss: 3.4549e-04 - val_mape: 2.2308\n",
      "Epoch 58/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2478e-04 - mape: 41334.6484 - val_loss: 8.0419e-04 - val_mape: 3.6413\n",
      "Epoch 59/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6939e-04 - mape: 59619.6680 - val_loss: 5.2512e-04 - val_mape: 2.8359\n",
      "Epoch 60/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8180e-04 - mape: 47761.2422 - val_loss: 4.0228e-04 - val_mape: 2.5903\n",
      "Epoch 61/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2906e-04 - mape: 56294.2227 - val_loss: 4.0878e-04 - val_mape: 2.6019\n",
      "Epoch 62/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7215e-04 - mape: 951.3026 - val_loss: 5.4543e-04 - val_mape: 3.1665\n",
      "Epoch 63/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2247e-04 - mape: 32090.2344 - val_loss: 6.9154e-04 - val_mape: 3.7157\n",
      "Epoch 64/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8451e-04 - mape: 15642.2949 - val_loss: 3.5644e-04 - val_mape: 2.6423\n",
      "Epoch 65/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7781e-04 - mape: 1405.6854 - val_loss: 4.2088e-04 - val_mape: 2.9308\n",
      "Epoch 66/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7176e-04 - mape: 28619.2344 - val_loss: 1.9921e-04 - val_mape: 1.7527\n",
      "Epoch 67/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9516e-04 - mape: 49501.0000 - val_loss: 4.2911e-04 - val_mape: 2.8219\n",
      "Epoch 68/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7121e-04 - mape: 53622.2734 - val_loss: 2.7484e-04 - val_mape: 1.9760\n",
      "Epoch 69/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8183e-04 - mape: 926.4243 - val_loss: 4.7311e-04 - val_mape: 3.0133\n",
      "Epoch 70/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5308e-04 - mape: 10340.4551 - val_loss: 2.1769e-04 - val_mape: 1.8710\n",
      "Epoch 71/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7898e-04 - mape: 4572.3838 - val_loss: 7.6162e-04 - val_mape: 3.8335\n",
      "Epoch 72/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3677e-04 - mape: 11543.4297 - val_loss: 2.4473e-04 - val_mape: 1.9918\n",
      "Epoch 73/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0553e-04 - mape: 14327.2646 - val_loss: 2.0077e-04 - val_mape: 1.7914\n",
      "Epoch 74/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3607e-04 - mape: 9049.6260 - val_loss: 2.2836e-04 - val_mape: 1.8881\n",
      "Epoch 75/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4418e-04 - mape: 5640.5303 - val_loss: 1.8079e-04 - val_mape: 1.7043\n",
      "Epoch 76/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2364e-04 - mape: 8150.2559 - val_loss: 2.0202e-04 - val_mape: 1.7662\n",
      "Epoch 77/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9942e-04 - mape: 49074.4023 - val_loss: 1.9833e-04 - val_mape: 1.8337\n",
      "Epoch 78/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6721e-04 - mape: 34537.4688 - val_loss: 1.9115e-04 - val_mape: 1.7519\n",
      "Epoch 79/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0604e-04 - mape: 21120.5039 - val_loss: 3.2592e-04 - val_mape: 2.2900\n",
      "Epoch 80/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2941e-04 - mape: 38907.0977 - val_loss: 5.3493e-04 - val_mape: 2.8416\n",
      "Epoch 81/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6813e-04 - mape: 27522.6094 - val_loss: 8.2961e-04 - val_mape: 3.8586\n",
      "Epoch 82/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6742e-04 - mape: 30055.4082 - val_loss: 9.7498e-04 - val_mape: 4.4218\n",
      "Epoch 83/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1017e-04 - mape: 57434.7500 - val_loss: 6.9153e-04 - val_mape: 3.5767\n",
      "Epoch 84/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6211e-04 - mape: 18131.9473 - val_loss: 9.1491e-04 - val_mape: 4.2835\n",
      "Epoch 85/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6146e-04 - mape: 45772.6523 - val_loss: 2.1091e-04 - val_mape: 1.9130\n",
      "--- 5/102 Training model for CSX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 9.5742 - val_loss: 2.5571e-04 - val_mape: 1.5016\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 10.6017 - val_loss: 1.6704e-04 - val_mape: 1.1993\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1013e-04 - mape: 9.1082 - val_loss: 1.6574e-04 - val_mape: 1.1948\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0878e-04 - mape: 8.3081 - val_loss: 7.0082e-04 - val_mape: 2.7503\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 10.0299 - val_loss: 5.9774e-04 - val_mape: 2.5459\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2642e-04 - mape: 8.5267 - val_loss: 1.9168e-04 - val_mape: 1.2735\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8313e-04 - mape: 8.3318 - val_loss: 2.3547e-04 - val_mape: 1.4829\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8628e-04 - mape: 8.5465 - val_loss: 3.2329e-04 - val_mape: 1.8285\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5609e-04 - mape: 9.9214 - val_loss: 1.2797e-04 - val_mape: 1.0917\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 11.2596 - val_loss: 9.2626e-05 - val_mape: 0.8452\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 11.2248 - val_loss: 6.7249e-05 - val_mape: 0.7579\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 10.9463 - val_loss: 6.3224e-05 - val_mape: 0.7478\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 14.3577 - val_loss: 5.2614e-05 - val_mape: 0.6511\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 12.9527 - val_loss: 4.1079e-04 - val_mape: 2.1751\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 11.7536 - val_loss: 3.1633e-04 - val_mape: 1.8677\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1688e-04 - mape: 9.3060 - val_loss: 5.9294e-04 - val_mape: 2.6468\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7935e-04 - mape: 8.8151 - val_loss: 2.2255e-04 - val_mape: 1.4922\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3911e-04 - mape: 8.4799 - val_loss: 3.7003e-04 - val_mape: 2.0509\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2477e-04 - mape: 9.1632 - val_loss: 2.8871e-04 - val_mape: 1.7011\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3184e-04 - mape: 10.1082 - val_loss: 2.4846e-04 - val_mape: 1.5642\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1748e-04 - mape: 9.9222 - val_loss: 7.7582e-04 - val_mape: 3.1102\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 11.3328 - val_loss: 4.0783e-04 - val_mape: 2.1182\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1349e-04 - mape: 10.0996 - val_loss: 3.4651e-04 - val_mape: 1.9325\n",
      "--- 6/102 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mape: 38.1742 - val_loss: 1.1061e-04 - val_mape: 1.3221\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 27.6808 - val_loss: 8.2210e-04 - val_mape: 4.0225\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mape: 40.0986 - val_loss: 6.3537e-05 - val_mape: 0.9225\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 34.2239 - val_loss: 2.8404e-04 - val_mape: 2.2303\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 29.2324 - val_loss: 6.0181e-05 - val_mape: 0.9069\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 29.0825 - val_loss: 3.2254e-04 - val_mape: 2.4256\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 30.4838 - val_loss: 1.5404e-04 - val_mape: 1.3909\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mape: 45.5596 - val_loss: 8.9867e-04 - val_mape: 4.2130\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mape: 33.3845 - val_loss: 0.0013 - val_mape: 4.9042\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mape: 50.2123 - val_loss: 3.7595e-04 - val_mape: 2.6206\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 36.1523 - val_loss: 7.5851e-04 - val_mape: 3.8237\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 31.9471 - val_loss: 2.6826e-04 - val_mape: 2.1747\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 27.2250 - val_loss: 6.9468e-04 - val_mape: 3.5633\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 35.3825 - val_loss: 1.1907e-04 - val_mape: 1.3092\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 29.3886 - val_loss: 2.1197e-04 - val_mape: 1.8949\n",
      "--- 7/102 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 24.0309 - val_loss: 1.7209e-04 - val_mape: 1.3647\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2778e-04 - mape: 21.8017 - val_loss: 2.5778e-04 - val_mape: 1.7122\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7744e-04 - mape: 20.2732 - val_loss: 5.1210e-04 - val_mape: 2.4906\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 25.9991 - val_loss: 9.6251e-04 - val_mape: 3.5792\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 31.2640 - val_loss: 0.0012 - val_mape: 3.6595\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mape: 40.9587 - val_loss: 6.2362e-04 - val_mape: 3.0819\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mape: 71.8251 - val_loss: 0.0016 - val_mape: 5.8462\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - mape: 88.0517 - val_loss: 9.2162e-04 - val_mape: 4.4285\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - mape: 63.9486 - val_loss: 9.8518e-04 - val_mape: 4.3168\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mape: 39.4728 - val_loss: 1.6663e-04 - val_mape: 1.4972\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 26.4346 - val_loss: 1.8711e-04 - val_mape: 1.5878\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3786e-04 - mape: 21.9088 - val_loss: 1.3762e-04 - val_mape: 1.3069\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3161e-04 - mape: 21.2809 - val_loss: 1.6756e-04 - val_mape: 1.3752\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5524e-04 - mape: 20.6608 - val_loss: 1.8576e-04 - val_mape: 1.3882\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8695e-04 - mape: 21.3181 - val_loss: 1.3007e-04 - val_mape: 1.2064\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5894e-04 - mape: 20.3168 - val_loss: 1.4767e-04 - val_mape: 1.2496\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6689e-04 - mape: 19.7777 - val_loss: 1.3204e-04 - val_mape: 1.2043\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6901e-04 - mape: 22.7616 - val_loss: 1.5305e-04 - val_mape: 1.2560\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2816e-04 - mape: 20.8168 - val_loss: 1.3196e-04 - val_mape: 1.3739\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8935e-04 - mape: 22.2979 - val_loss: 1.4639e-04 - val_mape: 1.2240\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5064e-04 - mape: 20.7390 - val_loss: 1.7949e-04 - val_mape: 1.7361\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8921e-04 - mape: 20.8456 - val_loss: 1.0785e-04 - val_mape: 1.1647\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4314e-04 - mape: 21.0146 - val_loss: 1.3690e-04 - val_mape: 1.2070\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 25.2196 - val_loss: 1.5786e-04 - val_mape: 1.2745\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 27.0632 - val_loss: 1.2172e-04 - val_mape: 1.2332\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 28.1865 - val_loss: 2.3790e-04 - val_mape: 2.0718\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 33.4923 - val_loss: 1.2164e-04 - val_mape: 1.1981\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 26.6493 - val_loss: 1.7652e-04 - val_mape: 1.4149\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 35.0320 - val_loss: 1.5600e-04 - val_mape: 1.5472\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 30.5796 - val_loss: 1.3064e-04 - val_mape: 1.2625\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 30.3130 - val_loss: 2.1718e-04 - val_mape: 1.9538\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 33.5692 - val_loss: 3.0780e-04 - val_mape: 2.3421\n",
      "--- 8/102 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 110.4680 - val_loss: 4.5422e-05 - val_mape: 1.3366\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 80.0752 - val_loss: 4.1611e-05 - val_mape: 1.2686\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 77.1000 - val_loss: 4.0495e-05 - val_mape: 1.2310\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 85.0722 - val_loss: 4.8260e-05 - val_mape: 1.3740\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 86.6400 - val_loss: 6.4126e-05 - val_mape: 1.5988\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 80.8126 - val_loss: 6.9822e-05 - val_mape: 1.6873\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 95.2507 - val_loss: 2.6021e-04 - val_mape: 3.7499\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 84.2097 - val_loss: 1.6802e-04 - val_mape: 2.7276\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 110.7787 - val_loss: 1.7817e-04 - val_mape: 3.0296\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 102.3625 - val_loss: 1.3365e-04 - val_mape: 2.3148\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mape: 128.5349 - val_loss: 1.7160e-04 - val_mape: 2.6250\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mape: 140.1314 - val_loss: 1.9545e-04 - val_mape: 2.8317\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mape: 157.5150 - val_loss: 1.6626e-04 - val_mape: 2.6429\n",
      "--- 9/102 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 179352.5781 - val_loss: 0.0037 - val_mape: 7.1874\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - mape: 177511.8594 - val_loss: 2.3407e-04 - val_mape: 1.4309\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 175975.5156 - val_loss: 3.1180e-04 - val_mape: 1.8222\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 134248.2812 - val_loss: 3.7044e-04 - val_mape: 2.0863\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 110604.6250 - val_loss: 4.2090e-04 - val_mape: 2.2838\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 117261.3984 - val_loss: 2.1886e-04 - val_mape: 1.4418\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6284e-04 - mape: 33241.0742 - val_loss: 2.3805e-04 - val_mape: 1.5538\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 61686.0156 - val_loss: 1.9085e-04 - val_mape: 1.3047\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 46637.8398 - val_loss: 3.7980e-04 - val_mape: 2.1610\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5438e-04 - mape: 133402.8281 - val_loss: 2.1626e-04 - val_mape: 1.4550\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8475e-04 - mape: 77098.5703 - val_loss: 4.3911e-04 - val_mape: 2.3629\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6600e-04 - mape: 118988.6719 - val_loss: 1.3878e-04 - val_mape: 0.9879\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5611e-04 - mape: 108587.9531 - val_loss: 1.3844e-04 - val_mape: 0.9556\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0511e-04 - mape: 31590.2969 - val_loss: 1.3815e-04 - val_mape: 0.9903\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9421e-04 - mape: 59465.2695 - val_loss: 2.0200e-04 - val_mape: 1.4046\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5347e-04 - mape: 37461.9883 - val_loss: 3.3914e-04 - val_mape: 2.0387\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7365e-04 - mape: 124780.8906 - val_loss: 4.9918e-04 - val_mape: 2.5148\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2074e-04 - mape: 13769.7148 - val_loss: 1.2165e-04 - val_mape: 0.9221\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6352e-04 - mape: 104037.6484 - val_loss: 1.1727e-04 - val_mape: 0.9071\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5750e-04 - mape: 98273.3438 - val_loss: 1.1125e-04 - val_mape: 0.8526\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2724e-04 - mape: 162543.9844 - val_loss: 2.5316e-04 - val_mape: 1.6526\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6153e-04 - mape: 2438.9277 - val_loss: 1.1156e-04 - val_mape: 0.8089\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1365e-04 - mape: 44250.1289 - val_loss: 7.4058e-04 - val_mape: 3.1236\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9284e-04 - mape: 85499.7500 - val_loss: 1.4678e-04 - val_mape: 1.1350\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6590e-04 - mape: 27835.7871 - val_loss: 3.3156e-04 - val_mape: 2.0171\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5438e-04 - mape: 83298.5547 - val_loss: 9.8662e-05 - val_mape: 0.7555\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6427e-04 - mape: 970.2111 - val_loss: 1.7076e-04 - val_mape: 1.3012\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4874e-04 - mape: 66149.8438 - val_loss: 2.8106e-04 - val_mape: 1.7598\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1092e-04 - mape: 2579.1064 - val_loss: 2.3577e-04 - val_mape: 1.6371\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 129594.8516 - val_loss: 0.0023 - val_mape: 5.6055\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mape: 231809.5156 - val_loss: 1.8279e-04 - val_mape: 1.2917\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4776e-04 - mape: 111433.5859 - val_loss: 7.2058e-04 - val_mape: 3.0464\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8151e-04 - mape: 41823.8672 - val_loss: 1.0881e-04 - val_mape: 0.8662\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2988e-04 - mape: 79958.0391 - val_loss: 0.0017 - val_mape: 4.8115\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 55994.7070 - val_loss: 1.1740e-04 - val_mape: 0.8745\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7601e-04 - mape: 4495.3677 - val_loss: 0.0019 - val_mape: 5.0872\n",
      "--- 10/102 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7829e-04 - mape: 72.1770 - val_loss: 0.0012 - val_mape: 4.2464\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 99.0188 - val_loss: 0.0052 - val_mape: 9.2363\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 97.8233 - val_loss: 9.6807e-05 - val_mape: 0.9552\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9200e-04 - mape: 55.3508 - val_loss: 1.9594e-04 - val_mape: 1.5971\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9176e-04 - mape: 56.2759 - val_loss: 3.5263e-04 - val_mape: 2.1923\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3790e-04 - mape: 52.7144 - val_loss: 8.7542e-05 - val_mape: 0.9239\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7990e-04 - mape: 49.4745 - val_loss: 2.7970e-04 - val_mape: 1.8944\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2965e-04 - mape: 53.6112 - val_loss: 9.7797e-05 - val_mape: 0.9975\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0265e-04 - mape: 52.0977 - val_loss: 2.4235e-04 - val_mape: 1.7816\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3189e-04 - mape: 47.4225 - val_loss: 2.0105e-04 - val_mape: 1.6131\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8716e-04 - mape: 44.9415 - val_loss: 1.5423e-04 - val_mape: 1.3293\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0856e-04 - mape: 46.3458 - val_loss: 1.5890e-04 - val_mape: 1.3672\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8379e-04 - mape: 44.4417 - val_loss: 1.3211e-04 - val_mape: 1.2208\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9780e-04 - mape: 44.8150 - val_loss: 6.6251e-04 - val_mape: 3.0697\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6971e-04 - mape: 50.8719 - val_loss: 7.4108e-05 - val_mape: 0.8110\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6097e-04 - mape: 44.3059 - val_loss: 2.0051e-04 - val_mape: 1.5391\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7159e-04 - mape: 45.1490 - val_loss: 1.0591e-04 - val_mape: 1.0735\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2411e-04 - mape: 40.4914 - val_loss: 5.1675e-04 - val_mape: 2.6623\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2507e-04 - mape: 49.7836 - val_loss: 1.2065e-04 - val_mape: 1.1202\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2651e-04 - mape: 40.4552 - val_loss: 1.0725e-04 - val_mape: 1.0749\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1753e-04 - mape: 42.0501 - val_loss: 5.1863e-04 - val_mape: 2.7070\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5620e-04 - mape: 44.5387 - val_loss: 9.4019e-05 - val_mape: 0.9503\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7139e-04 - mape: 39.5958 - val_loss: 1.6092e-04 - val_mape: 1.2930\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0770e-04 - mape: 40.3065 - val_loss: 7.7111e-05 - val_mape: 0.8558\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0596e-04 - mape: 42.3758 - val_loss: 0.0014 - val_mape: 4.5858\n",
      "--- 11/102 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3081e-04 - mape: 11.6959 - val_loss: 0.0020 - val_mape: 5.1357\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3788e-04 - mape: 17.8743 - val_loss: 4.2453e-04 - val_mape: 2.2059\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - mape: 56.2595 - val_loss: 4.4605e-04 - val_mape: 2.1337\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - mape: 63.9354 - val_loss: 0.0110 - val_mape: 12.1051\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mape: 91.4131 - val_loss: 0.0015 - val_mape: 4.4800\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8405e-04 - mape: 18.0727 - val_loss: 4.8578e-04 - val_mape: 2.1412\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mape: 36.1045 - val_loss: 0.0083 - val_mape: 10.5609\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - mape: 62.0474 - val_loss: 0.0011 - val_mape: 3.6058\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3894e-04 - mape: 16.1170 - val_loss: 1.9850e-04 - val_mape: 1.3945\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5364e-04 - mape: 13.6036 - val_loss: 9.0699e-04 - val_mape: 3.3106\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6983e-04 - mape: 21.6817 - val_loss: 2.5805e-04 - val_mape: 1.6017\n",
      "Epoch 12/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0848e-04 - mape: 13.9102 - val_loss: 3.9348e-04 - val_mape: 2.0138\n",
      "Epoch 13/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9541e-04 - mape: 13.5253 - val_loss: 2.0698e-04 - val_mape: 1.4334\n",
      "Epoch 14/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9109e-04 - mape: 11.1644 - val_loss: 2.1786e-04 - val_mape: 1.4859\n",
      "Epoch 15/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6155e-04 - mape: 13.4338 - val_loss: 7.5478e-04 - val_mape: 2.9277\n",
      "Epoch 16/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7395e-04 - mape: 19.2167 - val_loss: 2.5632e-04 - val_mape: 1.5443\n",
      "Epoch 17/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5614e-04 - mape: 16.8130 - val_loss: 3.6786e-04 - val_mape: 1.9046\n",
      "Epoch 18/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4055e-04 - mape: 15.4935 - val_loss: 2.2427e-04 - val_mape: 1.4801\n",
      "Epoch 19/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0227e-04 - mape: 12.6535 - val_loss: 2.5986e-04 - val_mape: 1.5514\n",
      "--- 12/102 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7442e-04 - mape: 82.3042 - val_loss: 9.0082e-05 - val_mape: 0.8418\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7192e-04 - mape: 127.2121 - val_loss: 7.2160e-05 - val_mape: 0.8011\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0040e-04 - mape: 82.2156 - val_loss: 1.9682e-04 - val_mape: 1.4636\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3862e-04 - mape: 115.5516 - val_loss: 3.1553e-04 - val_mape: 1.7340\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2736e-04 - mape: 95.9111 - val_loss: 4.3491e-05 - val_mape: 0.6191\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1433e-04 - mape: 103.6521 - val_loss: 4.0930e-04 - val_mape: 2.0113\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7129e-04 - mape: 85.6286 - val_loss: 5.7720e-04 - val_mape: 2.6640\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 168.3773 - val_loss: 7.0428e-05 - val_mape: 0.8069\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9412e-04 - mape: 100.4929 - val_loss: 2.1878e-04 - val_mape: 1.5519\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 148.4702 - val_loss: 3.2819e-04 - val_mape: 1.8000\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2602e-04 - mape: 94.8225 - val_loss: 2.5561e-04 - val_mape: 1.6986\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9930e-04 - mape: 110.1073 - val_loss: 7.1466e-05 - val_mape: 0.7869\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8882e-04 - mape: 106.8792 - val_loss: 4.5827e-04 - val_mape: 2.3376\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 130.4069 - val_loss: 1.5391e-04 - val_mape: 1.1718\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1039e-04 - mape: 87.9389 - val_loss: 4.2827e-04 - val_mape: 2.2438\n",
      "--- 13/102 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4065e-04 - mape: 2707.8032 - val_loss: 7.3476e-05 - val_mape: 1.0560\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8526e-04 - mape: 7075.1855 - val_loss: 2.6373e-04 - val_mape: 2.4037\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7818e-04 - mape: 153442.0312 - val_loss: 7.5083e-05 - val_mape: 1.0180\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7313e-04 - mape: 85451.5469 - val_loss: 7.5982e-05 - val_mape: 0.9199\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1347e-04 - mape: 16994.3711 - val_loss: 1.5053e-04 - val_mape: 1.4552\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1560e-04 - mape: 105752.7656 - val_loss: 1.1825e-04 - val_mape: 1.3932\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7469e-04 - mape: 56525.4219 - val_loss: 7.0255e-05 - val_mape: 0.9307\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4686e-04 - mape: 15713.6035 - val_loss: 8.4100e-05 - val_mape: 1.0811\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3313e-04 - mape: 6255.6968 - val_loss: 1.7773e-04 - val_mape: 1.8635\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7463e-04 - mape: 13486.2998 - val_loss: 9.4691e-05 - val_mape: 1.0330\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0051e-04 - mape: 117737.8438 - val_loss: 1.3611e-04 - val_mape: 1.3653\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0645e-04 - mape: 46412.9492 - val_loss: 1.0365e-04 - val_mape: 1.2287\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3401e-04 - mape: 44451.5625 - val_loss: 8.9974e-05 - val_mape: 1.1458\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6094e-04 - mape: 11946.4131 - val_loss: 1.8570e-04 - val_mape: 1.8904\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3738e-04 - mape: 17323.8965 - val_loss: 1.2043e-04 - val_mape: 1.2451\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.0443e-04 - mape: 83445.4297 - val_loss: 1.1371e-04 - val_mape: 1.3252\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6351e-04 - mape: 32269.2637 - val_loss: 1.4497e-04 - val_mape: 1.5881\n",
      "--- 14/102 Training model for DXCM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 79272.6719 - val_loss: 1.3493e-04 - val_mape: 1.3454\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 80848.8438 - val_loss: 1.1872e-04 - val_mape: 1.2107\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7808e-04 - mape: 41510.3672 - val_loss: 2.5482e-04 - val_mape: 2.0673\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6160e-04 - mape: 50141.7500 - val_loss: 1.0744e-04 - val_mape: 1.1247\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 36237.3359 - val_loss: 1.2468e-04 - val_mape: 1.2990\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9608e-04 - mape: 48193.5586 - val_loss: 1.4586e-04 - val_mape: 1.4668\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6721e-04 - mape: 22734.5605 - val_loss: 1.3734e-04 - val_mape: 1.3642\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7687e-04 - mape: 101691.3359 - val_loss: 1.3679e-04 - val_mape: 1.3343\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 60459.0234 - val_loss: 1.2580e-04 - val_mape: 1.2149\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 4194.6484 - val_loss: 1.1893e-04 - val_mape: 1.1821\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 85894.4688 - val_loss: 1.0444e-04 - val_mape: 1.0361\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6568e-04 - mape: 12784.7295 - val_loss: 2.9948e-04 - val_mape: 2.2690\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7020e-04 - mape: 71724.6328 - val_loss: 1.1533e-04 - val_mape: 1.1573\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 76388.8594 - val_loss: 2.3075e-04 - val_mape: 1.9847\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1859e-04 - mape: 47599.1094 - val_loss: 9.5290e-05 - val_mape: 0.9775\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9871e-04 - mape: 8782.5098 - val_loss: 1.8659e-04 - val_mape: 1.6871\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 75801.5859 - val_loss: 1.1841e-04 - val_mape: 1.1190\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 35677.8477 - val_loss: 1.3910e-04 - val_mape: 1.3144\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 49464.0586 - val_loss: 1.2269e-04 - val_mape: 1.1463\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 31472.8594 - val_loss: 1.4529e-04 - val_mape: 1.3894\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 51876.4805 - val_loss: 1.4327e-04 - val_mape: 1.3657\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 47753.4883 - val_loss: 9.2043e-05 - val_mape: 0.8986\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 13057.2705 - val_loss: 1.2631e-04 - val_mape: 1.2448\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 2323.6897 - val_loss: 1.2532e-04 - val_mape: 1.1706\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 52454.6289 - val_loss: 1.3963e-04 - val_mape: 1.3599\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 52871.1133 - val_loss: 1.2372e-04 - val_mape: 1.1451\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 44115.0703 - val_loss: 1.4445e-04 - val_mape: 1.3890\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 32477.3613 - val_loss: 9.7111e-05 - val_mape: 0.9309\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 39143.0781 - val_loss: 1.1657e-04 - val_mape: 1.1252\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 32390.6855 - val_loss: 1.2985e-04 - val_mape: 1.1767\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 122899.6250 - val_loss: 1.4206e-04 - val_mape: 1.2772\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 15586.2412 - val_loss: 2.0590e-04 - val_mape: 1.7609\n",
      "--- 15/102 Training model for FAST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6278e-04 - mape: 7376.8120 - val_loss: 1.4567e-04 - val_mape: 1.1589\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 257.6939 - val_loss: 2.3774e-04 - val_mape: 1.4862\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3932e-04 - mape: 3580.0801 - val_loss: 1.2042e-04 - val_mape: 0.9325\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2092e-04 - mape: 36521.9023 - val_loss: 1.8247e-04 - val_mape: 1.2612\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4212e-04 - mape: 10414.1279 - val_loss: 4.6165e-04 - val_mape: 2.3258\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5529e-04 - mape: 72059.1172 - val_loss: 8.8848e-05 - val_mape: 0.7933\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.6392e-04 - mape: 67156.2812 - val_loss: 1.9945e-04 - val_mape: 1.3935\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3170e-04 - mape: 79686.2656 - val_loss: 1.0324e-04 - val_mape: 0.9206\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5247e-04 - mape: 39870.2070 - val_loss: 1.0193e-04 - val_mape: 0.8712\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4857e-04 - mape: 10864.7217 - val_loss: 1.3022e-04 - val_mape: 1.0875\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0317e-04 - mape: 23467.6914 - val_loss: 6.9686e-05 - val_mape: 0.7103\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1662e-04 - mape: 38920.7383 - val_loss: 1.9891e-04 - val_mape: 1.4067\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8160e-04 - mape: 46333.4609 - val_loss: 1.7458e-04 - val_mape: 1.3307\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7687e-04 - mape: 110458.3984 - val_loss: 2.7168e-04 - val_mape: 1.7853\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3713e-04 - mape: 54695.9922 - val_loss: 7.0247e-05 - val_mape: 0.7523\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7060e-04 - mape: 23369.0410 - val_loss: 2.6277e-04 - val_mape: 1.7312\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4779e-04 - mape: 227.7750 - val_loss: 5.5373e-04 - val_mape: 2.6179\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 10159.8721 - val_loss: 1.4749e-04 - val_mape: 1.2106\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7178e-04 - mape: 52847.8555 - val_loss: 2.7834e-04 - val_mape: 1.7696\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7878e-04 - mape: 83433.8594 - val_loss: 6.7601e-05 - val_mape: 0.7208\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 64048.9414 - val_loss: 4.3335e-04 - val_mape: 2.2888\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 31941.5645 - val_loss: 5.1330e-05 - val_mape: 0.6357\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4888e-04 - mape: 3874.0000 - val_loss: 1.3130e-04 - val_mape: 1.1592\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9097e-04 - mape: 54431.3086 - val_loss: 5.8577e-05 - val_mape: 0.6620\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1965e-04 - mape: 10529.6230 - val_loss: 2.2128e-04 - val_mape: 1.5971\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9476e-04 - mape: 72038.9062 - val_loss: 5.0157e-05 - val_mape: 0.6950\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7532e-04 - mape: 78088.4766 - val_loss: 9.8723e-05 - val_mape: 0.9005\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8001e-04 - mape: 31793.2266 - val_loss: 0.0012 - val_mape: 3.8432\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 6148.1396 - val_loss: 6.8867e-05 - val_mape: 0.7136\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3685e-04 - mape: 114263.8828 - val_loss: 9.3094e-04 - val_mape: 3.4196\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 128889.2500 - val_loss: 6.1739e-05 - val_mape: 0.6551\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6443e-04 - mape: 55508.0508 - val_loss: 0.0011 - val_mape: 3.8461\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 829.1695 - val_loss: 5.0864e-05 - val_mape: 0.5834\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1838e-04 - mape: 61521.8633 - val_loss: 4.1652e-05 - val_mape: 0.6141\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2289e-04 - mape: 32916.7383 - val_loss: 1.5529e-04 - val_mape: 1.2632\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1520e-04 - mape: 37153.5781 - val_loss: 2.9248e-04 - val_mape: 1.8582\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3960e-04 - mape: 53876.2734 - val_loss: 1.0749e-04 - val_mape: 1.0170\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5231e-04 - mape: 32268.8574 - val_loss: 1.1970e-04 - val_mape: 1.1932\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7395e-04 - mape: 4999.6885 - val_loss: 1.3483e-04 - val_mape: 1.1827\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7512e-04 - mape: 10979.2510 - val_loss: 1.6458e-04 - val_mape: 1.3514\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1012e-04 - mape: 3681.4365 - val_loss: 4.2161e-04 - val_mape: 2.3139\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2311e-04 - mape: 32279.7715 - val_loss: 3.3277e-04 - val_mape: 2.0262\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6170e-04 - mape: 24289.1387 - val_loss: 4.2895e-05 - val_mape: 0.5461\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8341e-04 - mape: 66211.3359 - val_loss: 2.9342e-04 - val_mape: 1.8900\n",
      "--- 16/102 Training model for ABNB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - mape: 3675.0876 - val_loss: 1.0421e-04 - val_mape: 2.0390\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 47650.1680 - val_loss: 6.7159e-05 - val_mape: 1.5181\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 18565.1230 - val_loss: 9.7326e-05 - val_mape: 2.0094\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 5282.3354 - val_loss: 4.7785e-04 - val_mape: 4.4991\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - mape: 40589.3672 - val_loss: 0.0019 - val_mape: 8.0609\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - mape: 56371.0352 - val_loss: 0.0017 - val_mape: 8.4768\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - mape: 28185.8262 - val_loss: 5.0951e-04 - val_mape: 5.0951\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 13306.5469 - val_loss: 6.1901e-05 - val_mape: 1.6273\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 36313.7422 - val_loss: 4.5832e-05 - val_mape: 1.2978\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 13320.1914 - val_loss: 6.2180e-05 - val_mape: 1.5255\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 8692.8564 - val_loss: 8.5647e-05 - val_mape: 1.7965\n",
      "Epoch 12/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 551.2556 - val_loss: 8.3111e-05 - val_mape: 1.8389\n",
      "Epoch 13/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 12130.7285 - val_loss: 7.9225e-05 - val_mape: 1.7312\n",
      "Epoch 14/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 27916.4629 - val_loss: 5.5199e-05 - val_mape: 1.4618\n",
      "Epoch 15/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 18721.0156 - val_loss: 7.4634e-05 - val_mape: 1.6740\n",
      "Epoch 16/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 17940.2656 - val_loss: 1.5259e-04 - val_mape: 2.4755\n",
      "Epoch 17/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 78381.0156 - val_loss: 8.7070e-05 - val_mape: 1.9624\n",
      "Epoch 18/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 6491.2129 - val_loss: 5.6047e-05 - val_mape: 1.4262\n",
      "Epoch 19/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 22074.3086 - val_loss: 4.7880e-05 - val_mape: 1.4155\n",
      "--- 17/102 Training model for SNPS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 70.0885 - val_loss: 4.0539e-04 - val_mape: 1.9677\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 68.8027 - val_loss: 1.2498e-04 - val_mape: 0.9832\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6045e-04 - mape: 64.2568 - val_loss: 8.6313e-05 - val_mape: 0.8850\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 80.5928 - val_loss: 6.5355e-04 - val_mape: 2.7353\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 80.6011 - val_loss: 7.2501e-05 - val_mape: 0.7986\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 88.8880 - val_loss: 0.0014 - val_mape: 4.1105\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mape: 114.6442 - val_loss: 3.2649e-04 - val_mape: 1.8665\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9562e-04 - mape: 59.6697 - val_loss: 0.0018 - val_mape: 4.7322\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mape: 131.4965 - val_loss: 5.6379e-05 - val_mape: 0.6769\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3932e-04 - mape: 62.1301 - val_loss: 4.3103e-04 - val_mape: 2.2021\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4932e-04 - mape: 58.5170 - val_loss: 2.7567e-04 - val_mape: 1.7183\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9440e-04 - mape: 55.9173 - val_loss: 1.1427e-04 - val_mape: 1.0288\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1079e-04 - mape: 57.3578 - val_loss: 2.1819e-04 - val_mape: 1.5214\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2289e-04 - mape: 58.3208 - val_loss: 5.2743e-04 - val_mape: 2.4845\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3840e-04 - mape: 55.0431 - val_loss: 3.8513e-04 - val_mape: 2.0919\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4262e-04 - mape: 65.1023 - val_loss: 1.1858e-04 - val_mape: 1.0393\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6782e-04 - mape: 64.4242 - val_loss: 3.6737e-04 - val_mape: 2.0483\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5228e-04 - mape: 64.7296 - val_loss: 4.7442e-05 - val_mape: 0.6167\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 89.3890 - val_loss: 0.0015 - val_mape: 4.3287\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mape: 123.6709 - val_loss: 4.6504e-05 - val_mape: 0.6175\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3806e-04 - mape: 65.5057 - val_loss: 7.0988e-04 - val_mape: 2.9272\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 79.3691 - val_loss: 7.5642e-05 - val_mape: 0.8220\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5642e-04 - mape: 59.6780 - val_loss: 7.0130e-05 - val_mape: 0.7831\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1433e-04 - mape: 54.9228 - val_loss: 5.5474e-05 - val_mape: 0.6730\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5466e-04 - mape: 58.7082 - val_loss: 1.9707e-04 - val_mape: 1.4520\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1592e-04 - mape: 58.9521 - val_loss: 9.5675e-05 - val_mape: 0.9337\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3475e-04 - mape: 56.4456 - val_loss: 1.2677e-04 - val_mape: 1.1089\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9139e-04 - mape: 58.8654 - val_loss: 1.0465e-04 - val_mape: 0.9920\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3281e-04 - mape: 55.2736 - val_loss: 8.5610e-05 - val_mape: 0.9091\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.0045e-04 - mape: 51.6415 - val_loss: 5.0996e-05 - val_mape: 0.6473\n",
      "--- 18/102 Training model for BIIB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.0981e-04 - mape: 1641.4816 - val_loss: 4.1856e-05 - val_mape: 5.5177\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2620e-04 - mape: 7511.7993 - val_loss: 4.9186e-05 - val_mape: 8.4619\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0326e-04 - mape: 1360.1451 - val_loss: 7.3933e-05 - val_mape: 12.8325\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9083e-04 - mape: 43.8236 - val_loss: 3.6872e-05 - val_mape: 5.2864\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2562e-04 - mape: 2319.1492 - val_loss: 2.5267e-05 - val_mape: 8.9119\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1447e-04 - mape: 618.0250 - val_loss: 3.7800e-05 - val_mape: 5.5070\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5584e-04 - mape: 5006.0830 - val_loss: 2.2210e-05 - val_mape: 7.4671\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2113e-04 - mape: 4692.8281 - val_loss: 4.7516e-05 - val_mape: 14.9958\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1422e-04 - mape: 8045.1479 - val_loss: 2.2837e-05 - val_mape: 5.1315\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0247e-04 - mape: 1477.1504 - val_loss: 9.0991e-05 - val_mape: 14.5985\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1746e-04 - mape: 2054.0295 - val_loss: 3.6764e-05 - val_mape: 5.5771\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7727e-04 - mape: 4606.9097 - val_loss: 2.1095e-05 - val_mape: 7.8945\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2227e-04 - mape: 2197.7161 - val_loss: 4.6990e-05 - val_mape: 6.7469\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6815e-04 - mape: 1561.1957 - val_loss: 2.2069e-05 - val_mape: 4.8767\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9382e-04 - mape: 1682.0504 - val_loss: 1.0775e-04 - val_mape: 27.4810\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1827e-04 - mape: 6051.4805 - val_loss: 2.1304e-05 - val_mape: 9.9592\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4711e-04 - mape: 5054.3301 - val_loss: 6.2934e-05 - val_mape: 8.4125\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0918e-04 - mape: 11152.2607 - val_loss: 2.2047e-05 - val_mape: 4.0915\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9811e-04 - mape: 467.2428 - val_loss: 5.0304e-05 - val_mape: 6.0714\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3873e-04 - mape: 9741.5137 - val_loss: 2.7417e-04 - val_mape: 40.2570\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4722e-04 - mape: 5719.7988 - val_loss: 1.8997e-05 - val_mape: 9.7076\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6307e-04 - mape: 3951.2439 - val_loss: 7.9280e-05 - val_mape: 21.4549\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4088e-04 - mape: 3052.0447 - val_loss: 2.9247e-05 - val_mape: 4.4083\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5090e-04 - mape: 1325.6088 - val_loss: 7.8090e-05 - val_mape: 12.3912\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3488e-04 - mape: 6714.0371 - val_loss: 2.2652e-05 - val_mape: 10.8833\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4938e-04 - mape: 4550.7207 - val_loss: 1.7546e-05 - val_mape: 4.6620\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0786e-04 - mape: 5561.2202 - val_loss: 1.1134e-04 - val_mape: 25.7431\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0680e-04 - mape: 12198.6738 - val_loss: 6.4359e-05 - val_mape: 19.6275\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0919e-04 - mape: 3575.2126 - val_loss: 2.0087e-05 - val_mape: 3.8752\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1392e-04 - mape: 3281.8259 - val_loss: 2.2330e-05 - val_mape: 11.5911\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5991e-04 - mape: 5636.7158 - val_loss: 9.8557e-05 - val_mape: 25.6889\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7852e-04 - mape: 17820.9922 - val_loss: 4.9648e-04 - val_mape: 49.8253\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8270e-04 - mape: 7837.4121 - val_loss: 1.7351e-04 - val_mape: 30.2264\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6301e-04 - mape: 152.9874 - val_loss: 2.2702e-04 - val_mape: 33.8851\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4893e-04 - mape: 14371.4199 - val_loss: 8.5550e-05 - val_mape: 21.1408\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0342e-04 - mape: 964.5832 - val_loss: 1.9348e-05 - val_mape: 8.8832\n",
      "--- 19/102 Training model for REGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4769e-04 - mape: 12539.5859 - val_loss: 1.3666e-04 - val_mape: 1.3523\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8929e-04 - mape: 5857.0488 - val_loss: 3.8550e-05 - val_mape: 0.6234\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3080e-04 - mape: 3324.2190 - val_loss: 4.4734e-05 - val_mape: 0.7550\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5778e-04 - mape: 1961.4778 - val_loss: 3.5112e-05 - val_mape: 0.6763\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3720e-04 - mape: 27293.7852 - val_loss: 1.4939e-04 - val_mape: 1.4577\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8640e-04 - mape: 15257.6846 - val_loss: 2.8938e-05 - val_mape: 0.5712\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0139e-04 - mape: 8769.8516 - val_loss: 1.3336e-04 - val_mape: 1.3797\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3278e-04 - mape: 27774.5469 - val_loss: 4.8533e-05 - val_mape: 0.7954\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4491e-04 - mape: 3209.5955 - val_loss: 1.8642e-05 - val_mape: 0.4478\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9571e-04 - mape: 18699.2656 - val_loss: 2.7755e-05 - val_mape: 0.6047\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7799e-04 - mape: 8512.0303 - val_loss: 1.2121e-04 - val_mape: 1.3785\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5544e-04 - mape: 27462.3438 - val_loss: 3.3684e-05 - val_mape: 0.6512\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7668e-04 - mape: 9885.6182 - val_loss: 2.2654e-05 - val_mape: 0.5254\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1571e-04 - mape: 15183.7676 - val_loss: 3.0532e-05 - val_mape: 0.6169\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7533e-04 - mape: 3196.6316 - val_loss: 1.5901e-04 - val_mape: 1.5359\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0076e-04 - mape: 3116.6785 - val_loss: 1.7450e-05 - val_mape: 0.4556\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8346e-04 - mape: 20655.0586 - val_loss: 2.0601e-05 - val_mape: 0.5002\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1261e-04 - mape: 9013.6621 - val_loss: 1.5048e-05 - val_mape: 0.3933\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8501e-04 - mape: 45074.8906 - val_loss: 1.3285e-05 - val_mape: 0.3941\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3609e-04 - mape: 12769.2627 - val_loss: 3.1634e-05 - val_mape: 0.6656\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1595e-04 - mape: 31331.6348 - val_loss: 3.5697e-05 - val_mape: 0.6798\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0921e-04 - mape: 40360.7344 - val_loss: 2.3149e-05 - val_mape: 0.5558\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9606e-04 - mape: 1697.7618 - val_loss: 9.5948e-05 - val_mape: 1.2205\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5049e-04 - mape: 9282.3145 - val_loss: 2.7408e-05 - val_mape: 0.5855\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3543e-04 - mape: 12036.5791 - val_loss: 2.1943e-05 - val_mape: 0.5169\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4104e-04 - mape: 36141.7969 - val_loss: 1.9001e-04 - val_mape: 1.7207\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9409e-04 - mape: 22528.6562 - val_loss: 8.0904e-05 - val_mape: 0.9904\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4408e-04 - mape: 1134.3568 - val_loss: 5.8532e-05 - val_mape: 0.8250\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5742e-04 - mape: 43131.3047 - val_loss: 9.2772e-05 - val_mape: 1.0136\n",
      "--- 20/102 Training model for VRSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5194e-04 - mape: 76120.2734 - val_loss: 1.2958e-04 - val_mape: 1.2872\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8254e-04 - mape: 19157.0312 - val_loss: 1.8135e-05 - val_mape: 0.4067\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2686e-04 - mape: 33199.8984 - val_loss: 4.8166e-05 - val_mape: 0.7755\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4380e-04 - mape: 45840.2695 - val_loss: 6.4281e-05 - val_mape: 0.7978\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4063e-04 - mape: 26449.4238 - val_loss: 2.8153e-05 - val_mape: 0.4595\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3017e-04 - mape: 72620.4453 - val_loss: 5.5317e-04 - val_mape: 2.6930\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4381e-04 - mape: 69959.8984 - val_loss: 3.7965e-05 - val_mape: 0.5918\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 224468.9688 - val_loss: 4.8490e-04 - val_mape: 2.5598\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 138876.3125 - val_loss: 8.1928e-05 - val_mape: 0.7837\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 92393.3750 - val_loss: 2.9330e-05 - val_mape: 0.4740\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 188253.8906 - val_loss: 0.0027 - val_mape: 5.7922\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - mape: 284457.0000 - val_loss: 6.9008e-05 - val_mape: 0.7314\n",
      "--- 21/102 Training model for TSLA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 27793.5879 - val_loss: 3.0448e-04 - val_mape: 2.4807\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 16355.7236 - val_loss: 1.9185e-04 - val_mape: 2.0207\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mape: 10370.9961 - val_loss: 7.1181e-05 - val_mape: 1.3284\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 10858.0469 - val_loss: 8.8987e-05 - val_mape: 1.4370\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 17883.7871 - val_loss: 9.0038e-05 - val_mape: 1.4610\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 6013.1587 - val_loss: 1.6719e-04 - val_mape: 2.0415\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 16266.3916 - val_loss: 9.9944e-05 - val_mape: 1.5140\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 6853.7822 - val_loss: 5.4318e-05 - val_mape: 1.1244\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 20349.8164 - val_loss: 9.5277e-05 - val_mape: 1.5768\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 10027.9297 - val_loss: 1.3460e-04 - val_mape: 1.7333\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 48397.7266 - val_loss: 6.6515e-05 - val_mape: 1.2612\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 63216.1875 - val_loss: 9.8535e-05 - val_mape: 1.4933\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 13128.4707 - val_loss: 6.6748e-05 - val_mape: 1.3054\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 28610.8145 - val_loss: 6.5858e-05 - val_mape: 1.2442\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 19310.3516 - val_loss: 8.7933e-05 - val_mape: 1.4229\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 13832.2344 - val_loss: 3.8174e-05 - val_mape: 1.0066\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 5868.4385 - val_loss: 7.1973e-05 - val_mape: 1.2994\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 25113.4570 - val_loss: 5.9961e-05 - val_mape: 1.2300\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 26330.6152 - val_loss: 8.4027e-05 - val_mape: 1.3864\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 20370.4727 - val_loss: 9.0357e-05 - val_mape: 1.4342\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 2284.4722 - val_loss: 7.7865e-05 - val_mape: 1.3471\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 7042.0317 - val_loss: 5.8569e-05 - val_mape: 1.2501\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 3839.5576 - val_loss: 6.3227e-05 - val_mape: 1.2446\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 10523.6152 - val_loss: 4.8072e-05 - val_mape: 1.1758\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 10080.2305 - val_loss: 5.2534e-05 - val_mape: 1.1840\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 34308.2188 - val_loss: 5.5033e-05 - val_mape: 1.2331\n",
      "--- 22/102 Training model for NVDA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 18540.0195 - val_loss: 0.0039 - val_mape: 8.2255\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 44610.7422 - val_loss: 0.0026 - val_mape: 6.7541\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7231e-04 - mape: 35541.6992 - val_loss: 0.0018 - val_mape: 5.4751\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0234e-04 - mape: 43261.8125 - val_loss: 0.0012 - val_mape: 4.3504\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2915e-04 - mape: 14425.1123 - val_loss: 8.4867e-04 - val_mape: 3.5953\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9093e-04 - mape: 46047.8320 - val_loss: 6.2940e-04 - val_mape: 2.9067\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8004e-04 - mape: 60994.7344 - val_loss: 5.5460e-04 - val_mape: 2.7294\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8499e-04 - mape: 45115.9648 - val_loss: 6.0272e-04 - val_mape: 2.8083\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4277e-04 - mape: 94643.0703 - val_loss: 6.5525e-04 - val_mape: 2.9401\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4790e-04 - mape: 8117.4072 - val_loss: 5.0209e-04 - val_mape: 2.5089\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3237e-04 - mape: 88059.2891 - val_loss: 4.0279e-04 - val_mape: 2.1717\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3790e-04 - mape: 29152.2715 - val_loss: 5.5030e-04 - val_mape: 2.6918\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2996e-04 - mape: 21815.5234 - val_loss: 3.8867e-04 - val_mape: 2.1189\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5647e-04 - mape: 8591.0576 - val_loss: 3.7867e-04 - val_mape: 2.1242\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8824e-04 - mape: 25892.6445 - val_loss: 4.9145e-04 - val_mape: 2.4530\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6797e-04 - mape: 24160.6504 - val_loss: 4.9724e-04 - val_mape: 2.5325\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2337e-04 - mape: 29135.5723 - val_loss: 5.0330e-04 - val_mape: 2.5232\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2314e-04 - mape: 37844.2109 - val_loss: 4.0894e-04 - val_mape: 2.2374\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9540e-04 - mape: 56039.1172 - val_loss: 3.2820e-04 - val_mape: 1.9270\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4464e-04 - mape: 21667.9512 - val_loss: 4.8665e-04 - val_mape: 2.4030\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8127e-04 - mape: 44866.5234 - val_loss: 4.2152e-04 - val_mape: 2.2607\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6420e-04 - mape: 67482.3359 - val_loss: 4.8948e-04 - val_mape: 2.4199\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1942e-04 - mape: 14721.4141 - val_loss: 3.1102e-04 - val_mape: 1.9646\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1823e-04 - mape: 48348.2930 - val_loss: 4.6227e-04 - val_mape: 2.3401\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8202e-04 - mape: 39621.7773 - val_loss: 4.1343e-04 - val_mape: 2.1953\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6996e-04 - mape: 7834.3857 - val_loss: 3.2326e-04 - val_mape: 2.0362\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5629e-04 - mape: 43856.5391 - val_loss: 6.3738e-04 - val_mape: 2.9506\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3268e-04 - mape: 9187.5322 - val_loss: 5.6080e-04 - val_mape: 2.6298\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5426e-04 - mape: 22787.7266 - val_loss: 3.6878e-04 - val_mape: 2.1167\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2736e-04 - mape: 123132.7344 - val_loss: 2.7869e-04 - val_mape: 1.8565\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3941e-04 - mape: 39156.5547 - val_loss: 4.0347e-04 - val_mape: 2.2298\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0558e-04 - mape: 36693.3594 - val_loss: 3.0671e-04 - val_mape: 1.9274\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8375e-04 - mape: 19006.4277 - val_loss: 3.0687e-04 - val_mape: 2.0058\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0157e-04 - mape: 34581.3672 - val_loss: 2.9264e-04 - val_mape: 1.9218\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8244e-04 - mape: 52170.8906 - val_loss: 2.6266e-04 - val_mape: 1.8716\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6741e-04 - mape: 4009.1084 - val_loss: 2.4470e-04 - val_mape: 1.7916\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6084e-04 - mape: 45298.7891 - val_loss: 3.2843e-04 - val_mape: 2.0246\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5341e-04 - mape: 35758.8984 - val_loss: 4.6686e-04 - val_mape: 2.4880\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4874e-04 - mape: 18599.4629 - val_loss: 4.1987e-04 - val_mape: 2.2500\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3579e-04 - mape: 18494.1016 - val_loss: 2.2688e-04 - val_mape: 1.7634\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4390e-04 - mape: 23966.9863 - val_loss: 2.5696e-04 - val_mape: 1.8241\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3349e-04 - mape: 10092.4863 - val_loss: 3.3053e-04 - val_mape: 2.1070\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3189e-04 - mape: 23078.7930 - val_loss: 3.5706e-04 - val_mape: 2.1334\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2173e-04 - mape: 12793.9717 - val_loss: 2.6715e-04 - val_mape: 1.7737\n",
      "Epoch 45/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3402e-04 - mape: 19400.0742 - val_loss: 1.7036e-04 - val_mape: 1.5204\n",
      "Epoch 46/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1362e-04 - mape: 20546.6016 - val_loss: 2.2089e-04 - val_mape: 1.6727\n",
      "Epoch 47/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1251e-04 - mape: 49546.5078 - val_loss: 1.8425e-04 - val_mape: 1.5421\n",
      "Epoch 48/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9797e-05 - mape: 2704.9109 - val_loss: 4.9825e-04 - val_mape: 2.5444\n",
      "Epoch 49/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2071e-04 - mape: 78513.6953 - val_loss: 1.2093e-04 - val_mape: 1.2771\n",
      "Epoch 50/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0933e-04 - mape: 31360.5273 - val_loss: 3.2698e-04 - val_mape: 1.8760\n",
      "Epoch 51/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3491e-04 - mape: 8599.9453 - val_loss: 1.3376e-04 - val_mape: 1.3355\n",
      "Epoch 52/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2447e-04 - mape: 6138.7642 - val_loss: 5.2895e-04 - val_mape: 2.8268\n",
      "Epoch 53/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0405e-04 - mape: 24632.2266 - val_loss: 1.1631e-04 - val_mape: 1.3150\n",
      "Epoch 54/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0898e-04 - mape: 2978.9866 - val_loss: 3.7378e-04 - val_mape: 2.3386\n",
      "Epoch 55/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8049e-05 - mape: 39522.8203 - val_loss: 7.6396e-05 - val_mape: 0.9986\n",
      "Epoch 56/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9232e-05 - mape: 35119.1250 - val_loss: 1.6397e-04 - val_mape: 1.4287\n",
      "Epoch 57/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5001e-05 - mape: 29962.4102 - val_loss: 5.9597e-05 - val_mape: 1.0169\n",
      "Epoch 58/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3625e-04 - mape: 34116.7617 - val_loss: 5.9056e-04 - val_mape: 2.7628\n",
      "Epoch 59/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2023e-04 - mape: 71034.4766 - val_loss: 1.4837e-04 - val_mape: 1.5174\n",
      "Epoch 60/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2466e-04 - mape: 67515.0000 - val_loss: 0.0033 - val_mape: 7.5428\n",
      "Epoch 61/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5738e-04 - mape: 73002.9062 - val_loss: 7.2751e-04 - val_mape: 2.9999\n",
      "Epoch 62/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6897e-04 - mape: 8049.1250 - val_loss: 0.0011 - val_mape: 4.4071\n",
      "Epoch 63/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5886e-04 - mape: 42262.7539 - val_loss: 2.1367e-04 - val_mape: 1.6263\n",
      "Epoch 64/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2534e-04 - mape: 13231.1973 - val_loss: 2.2688e-04 - val_mape: 1.9128\n",
      "Epoch 65/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0939e-04 - mape: 32812.2734 - val_loss: 2.6785e-04 - val_mape: 1.7743\n",
      "Epoch 66/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3598e-05 - mape: 19534.5039 - val_loss: 8.4947e-05 - val_mape: 1.3266\n",
      "Epoch 67/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6003e-05 - mape: 8149.5522 - val_loss: 6.0204e-05 - val_mape: 0.9584\n",
      "--- 23/102 Training model for CPRT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2827e-04 - mape: 35.9153 - val_loss: 1.6771e-04 - val_mape: 1.2183\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6866e-04 - mape: 43.0403 - val_loss: 6.5692e-04 - val_mape: 2.6843\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9541e-04 - mape: 92.5780 - val_loss: 2.0474e-04 - val_mape: 1.3822\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 165.5079 - val_loss: 3.2425e-04 - val_mape: 1.7378\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 193.4833 - val_loss: 0.0052 - val_mape: 7.9010\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mape: 251.7827 - val_loss: 9.4908e-04 - val_mape: 3.3103\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mape: 247.8325 - val_loss: 0.0025 - val_mape: 5.5266\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 145.7882 - val_loss: 0.0028 - val_mape: 5.7857\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - mape: 323.9369 - val_loss: 6.3453e-04 - val_mape: 2.7070\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1068e-04 - mape: 80.2322 - val_loss: 6.5974e-05 - val_mape: 0.7393\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0369e-04 - mape: 57.7844 - val_loss: 1.0306e-04 - val_mape: 0.9825\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2380e-04 - mape: 66.8732 - val_loss: 1.0738e-04 - val_mape: 1.0094\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9125e-04 - mape: 71.6452 - val_loss: 0.0014 - val_mape: 4.1509\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5573e-04 - mape: 133.6661 - val_loss: 3.1037e-05 - val_mape: 0.4815\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4333e-04 - mape: 71.2180 - val_loss: 3.6860e-05 - val_mape: 0.5262\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5177e-04 - mape: 70.4141 - val_loss: 3.0695e-04 - val_mape: 1.8189\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0455e-04 - mape: 111.1907 - val_loss: 0.0020 - val_mape: 4.8912\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 173.6312 - val_loss: 9.2056e-05 - val_mape: 0.9350\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5942e-04 - mape: 70.6804 - val_loss: 7.7370e-05 - val_mape: 0.8582\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8905e-04 - mape: 73.1530 - val_loss: 2.7955e-04 - val_mape: 1.7610\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4651e-04 - mape: 84.1147 - val_loss: 3.8380e-05 - val_mape: 0.5356\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0766e-04 - mape: 96.5074 - val_loss: 2.0137e-04 - val_mape: 1.4495\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5905e-04 - mape: 112.9742 - val_loss: 3.7346e-05 - val_mape: 0.5275\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8088e-04 - mape: 95.0339 - val_loss: 0.0014 - val_mape: 4.1424\n",
      "--- 24/102 Training model for ORLY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2730e-04 - mape: 10122.2246 - val_loss: 4.6665e-05 - val_mape: 0.5942\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4382e-04 - mape: 39098.0820 - val_loss: 1.0574e-04 - val_mape: 0.9686\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6551e-04 - mape: 38656.4336 - val_loss: 5.5206e-05 - val_mape: 0.6411\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2610e-04 - mape: 28011.7832 - val_loss: 1.5819e-04 - val_mape: 1.2419\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4946e-04 - mape: 45402.0000 - val_loss: 4.1795e-05 - val_mape: 0.5473\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7609e-04 - mape: 57283.0664 - val_loss: 3.6320e-04 - val_mape: 1.9279\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5477e-04 - mape: 22226.4199 - val_loss: 9.8001e-05 - val_mape: 0.9830\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9028e-04 - mape: 167578.9844 - val_loss: 1.1247e-04 - val_mape: 0.9707\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1784e-04 - mape: 44952.4922 - val_loss: 2.2940e-04 - val_mape: 1.5865\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8616e-04 - mape: 23165.6621 - val_loss: 7.8947e-05 - val_mape: 0.7551\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9916e-04 - mape: 38206.1445 - val_loss: 6.9258e-05 - val_mape: 0.7249\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6288e-04 - mape: 18716.6094 - val_loss: 6.6139e-05 - val_mape: 0.7116\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9104e-04 - mape: 20329.5625 - val_loss: 8.1189e-05 - val_mape: 0.8375\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0391e-04 - mape: 5050.1772 - val_loss: 2.2739e-04 - val_mape: 1.5588\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6932e-04 - mape: 30575.0508 - val_loss: 3.7787e-04 - val_mape: 2.1036\n",
      "--- 25/102 Training model for CSGP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 18.4860 - val_loss: 2.5540e-05 - val_mape: 0.4749\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 23.6428 - val_loss: 7.2011e-04 - val_mape: 3.1871\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5750e-04 - mape: 19.9498 - val_loss: 3.1944e-05 - val_mape: 0.5459\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 27.8610 - val_loss: 4.7791e-05 - val_mape: 0.6467\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 20.8862 - val_loss: 5.1888e-04 - val_mape: 2.5638\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 27.1330 - val_loss: 6.6870e-05 - val_mape: 0.8375\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 42.0217 - val_loss: 4.6704e-05 - val_mape: 0.6880\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9021e-04 - mape: 24.7431 - val_loss: 3.7487e-05 - val_mape: 0.6038\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 26.9345 - val_loss: 3.6872e-05 - val_mape: 0.6204\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6417e-04 - mape: 21.2424 - val_loss: 3.5624e-05 - val_mape: 0.5786\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 25.2002 - val_loss: 2.8967e-04 - val_mape: 1.8867\n",
      "--- 26/102 Training model for PDD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 94013.2422 - val_loss: 1.1046e-04 - val_mape: 1.2338\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3458e-04 - mape: 59051.9453 - val_loss: 6.0479e-05 - val_mape: 0.9567\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1969e-04 - mape: 121400.5547 - val_loss: 1.8729e-04 - val_mape: 1.8860\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7712e-04 - mape: 52958.0703 - val_loss: 1.6166e-04 - val_mape: 1.7061\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3814e-04 - mape: 5915.4229 - val_loss: 1.1696e-04 - val_mape: 1.4052\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0386e-04 - mape: 29199.1797 - val_loss: 1.5758e-04 - val_mape: 1.7502\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3487e-04 - mape: 5445.3223 - val_loss: 1.9074e-04 - val_mape: 1.9973\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9301e-04 - mape: 164851.0938 - val_loss: 1.2678e-04 - val_mape: 1.5044\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7810e-04 - mape: 15741.9355 - val_loss: 1.0107e-04 - val_mape: 1.2552\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9499e-04 - mape: 130899.8984 - val_loss: 1.2976e-04 - val_mape: 1.5286\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0134e-04 - mape: 16256.4336 - val_loss: 1.2756e-04 - val_mape: 1.5285\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7765e-04 - mape: 115820.6719 - val_loss: 1.4067e-04 - val_mape: 1.6320\n",
      "--- 27/102 Training model for HON ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0087e-04 - mape: 13.4707 - val_loss: 1.7184e-04 - val_mape: 1.3974\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0758e-04 - mape: 12.4460 - val_loss: 1.8965e-04 - val_mape: 1.4680\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4191e-04 - mape: 13.6097 - val_loss: 3.9656e-04 - val_mape: 2.2072\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3714e-04 - mape: 13.7154 - val_loss: 3.4468e-05 - val_mape: 0.5650\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4993e-04 - mape: 13.7845 - val_loss: 4.4742e-05 - val_mape: 0.6239\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9255e-04 - mape: 14.7633 - val_loss: 4.0726e-04 - val_mape: 2.2175\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0276e-04 - mape: 15.7891 - val_loss: 1.6655e-04 - val_mape: 1.3132\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2350e-04 - mape: 16.2506 - val_loss: 3.8070e-05 - val_mape: 0.5985\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3168e-04 - mape: 16.5048 - val_loss: 8.3502e-05 - val_mape: 0.8389\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7305e-04 - mape: 17.2272 - val_loss: 4.0730e-04 - val_mape: 2.2279\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9939e-04 - mape: 17.6709 - val_loss: 6.2281e-04 - val_mape: 2.8410\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3007e-04 - mape: 20.1661 - val_loss: 1.9209e-04 - val_mape: 1.4508\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7988e-04 - mape: 17.8056 - val_loss: 3.2112e-05 - val_mape: 0.5426\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9121e-04 - mape: 17.3110 - val_loss: 1.3503e-04 - val_mape: 1.1949\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0129e-04 - mape: 18.8789 - val_loss: 4.7159e-05 - val_mape: 0.6233\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 19.8553 - val_loss: 2.8109e-04 - val_mape: 1.7954\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5384e-04 - mape: 17.5334 - val_loss: 1.9948e-04 - val_mape: 1.5084\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6165e-04 - mape: 19.3051 - val_loss: 6.8290e-04 - val_mape: 2.9918\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9975e-04 - mape: 18.6071 - val_loss: 6.4191e-05 - val_mape: 0.7374\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2227e-04 - mape: 17.6654 - val_loss: 2.0606e-04 - val_mape: 1.5522\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8572e-04 - mape: 18.2396 - val_loss: 1.2493e-04 - val_mape: 1.1055\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 22.6987 - val_loss: 3.6140e-05 - val_mape: 0.5612\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 21.9038 - val_loss: 2.7778e-05 - val_mape: 0.4894\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5029e-04 - mape: 19.4621 - val_loss: 2.1591e-04 - val_mape: 1.6098\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 20.7322 - val_loss: 1.7219e-04 - val_mape: 1.3618\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 22.3614 - val_loss: 3.8757e-05 - val_mape: 0.5783\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9860e-04 - mape: 20.4532 - val_loss: 4.1736e-05 - val_mape: 0.6022\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 21.2862 - val_loss: 4.8296e-05 - val_mape: 0.6464\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 21.5785 - val_loss: 9.3540e-05 - val_mape: 0.9835\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 22.1627 - val_loss: 7.1023e-05 - val_mape: 0.8101\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 24.5543 - val_loss: 3.5215e-05 - val_mape: 0.5540\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 23.8470 - val_loss: 5.5334e-05 - val_mape: 0.7066\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 22.6874 - val_loss: 8.1435e-05 - val_mape: 0.8935\n",
      "--- 28/102 Training model for ADI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 41.9158 - val_loss: 2.1640e-04 - val_mape: 1.3818\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 41.3487 - val_loss: 1.1994e-04 - val_mape: 0.9230\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 39.1717 - val_loss: 1.0641e-04 - val_mape: 0.9246\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 40.3443 - val_loss: 1.5927e-04 - val_mape: 1.0670\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 39.5824 - val_loss: 8.7223e-05 - val_mape: 0.7941\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0491e-04 - mape: 32.5807 - val_loss: 7.0881e-05 - val_mape: 0.7259\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 35.6039 - val_loss: 7.2333e-05 - val_mape: 0.7302\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 34.8959 - val_loss: 1.7624e-04 - val_mape: 1.2906\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 36.5580 - val_loss: 6.3092e-05 - val_mape: 0.6973\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4709e-04 - mape: 34.4028 - val_loss: 1.4259e-04 - val_mape: 1.1143\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1490e-04 - mape: 34.6088 - val_loss: 1.9746e-04 - val_mape: 1.4609\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8020e-04 - mape: 34.9749 - val_loss: 2.1580e-04 - val_mape: 1.4057\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 36.0739 - val_loss: 1.8158e-04 - val_mape: 1.3351\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4069e-04 - mape: 33.7686 - val_loss: 1.5027e-04 - val_mape: 1.2048\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2778e-04 - mape: 31.2545 - val_loss: 1.1493e-04 - val_mape: 0.9188\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3956e-04 - mape: 35.8892 - val_loss: 6.9314e-05 - val_mape: 0.7365\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4333e-04 - mape: 31.0510 - val_loss: 8.1362e-05 - val_mape: 0.7894\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3299e-04 - mape: 32.3295 - val_loss: 8.4686e-05 - val_mape: 0.8062\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8833e-04 - mape: 33.4062 - val_loss: 3.3741e-04 - val_mape: 2.0450\n",
      "--- 29/102 Training model for EA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8173e-04 - mape: 31390.1445 - val_loss: 7.9854e-05 - val_mape: 0.9532\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9173e-04 - mape: 40300.8125 - val_loss: 4.3697e-04 - val_mape: 2.2581\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 41699.7070 - val_loss: 1.0557e-04 - val_mape: 1.0075\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 122695.5234 - val_loss: 0.0013 - val_mape: 3.8862\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 16009.9121 - val_loss: 4.7239e-05 - val_mape: 0.7138\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 62290.4258 - val_loss: 3.1275e-04 - val_mape: 1.9144\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2862e-04 - mape: 894.1649 - val_loss: 4.8780e-05 - val_mape: 0.6067\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6646e-04 - mape: 34049.4570 - val_loss: 1.8632e-04 - val_mape: 1.5102\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6356e-04 - mape: 44764.4805 - val_loss: 1.6643e-04 - val_mape: 1.3748\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8983e-04 - mape: 13954.9678 - val_loss: 8.0641e-05 - val_mape: 0.9356\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5477e-04 - mape: 74277.9453 - val_loss: 1.8252e-04 - val_mape: 1.4219\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9319e-04 - mape: 51129.5586 - val_loss: 2.7706e-04 - val_mape: 1.8003\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4088e-04 - mape: 58676.6914 - val_loss: 3.0900e-05 - val_mape: 0.5681\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7459e-04 - mape: 16435.7734 - val_loss: 2.0613e-04 - val_mape: 1.5472\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8310e-04 - mape: 33114.5312 - val_loss: 7.1752e-05 - val_mape: 0.9023\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7744e-04 - mape: 3961.6072 - val_loss: 2.3333e-04 - val_mape: 1.6341\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2500e-04 - mape: 46956.0312 - val_loss: 3.2156e-04 - val_mape: 1.9448\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7243e-04 - mape: 8200.8018 - val_loss: 4.0633e-05 - val_mape: 0.6070\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1954e-04 - mape: 43368.5859 - val_loss: 3.1866e-04 - val_mape: 1.9628\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1118e-04 - mape: 31810.3672 - val_loss: 2.4331e-05 - val_mape: 0.4597\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7788e-04 - mape: 10084.1240 - val_loss: 1.8425e-04 - val_mape: 1.3896\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7341e-04 - mape: 32573.8594 - val_loss: 2.1899e-04 - val_mape: 1.6564\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5761e-04 - mape: 96885.6172 - val_loss: 1.1632e-04 - val_mape: 1.1459\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1142e-04 - mape: 17829.3887 - val_loss: 8.0348e-05 - val_mape: 0.9686\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2391e-04 - mape: 49070.2188 - val_loss: 1.6924e-04 - val_mape: 1.2936\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3687e-04 - mape: 12043.7441 - val_loss: 4.7800e-05 - val_mape: 0.7396\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8872e-04 - mape: 54643.7617 - val_loss: 3.5559e-04 - val_mape: 2.1114\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5461e-04 - mape: 44162.8672 - val_loss: 2.7646e-05 - val_mape: 0.4989\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5250e-04 - mape: 14611.2061 - val_loss: 6.8629e-05 - val_mape: 0.8468\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8472e-04 - mape: 45211.1523 - val_loss: 8.2638e-05 - val_mape: 0.9614\n",
      "--- 30/102 Training model for KHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 46545.3789 - val_loss: 5.4857e-06 - val_mape: 0.5309\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 23395.0391 - val_loss: 6.3306e-06 - val_mape: 0.5687\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 8226.9521 - val_loss: 1.5468e-05 - val_mape: 1.0083\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 463.7846 - val_loss: 2.1657e-05 - val_mape: 1.2109\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 11081.8096 - val_loss: 5.3783e-06 - val_mape: 0.5251\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 14649.6865 - val_loss: 1.0580e-05 - val_mape: 0.7477\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 17388.3613 - val_loss: 1.3303e-05 - val_mape: 0.8605\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mape: 30833.6094 - val_loss: 8.0929e-06 - val_mape: 0.6313\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 12175.0771 - val_loss: 8.6269e-06 - val_mape: 0.6721\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 12193.5674 - val_loss: 1.0844e-05 - val_mape: 0.8029\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 14381.0820 - val_loss: 8.6098e-06 - val_mape: 0.7049\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 3600.3076 - val_loss: 5.8120e-06 - val_mape: 0.5354\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 41523.8984 - val_loss: 6.0772e-06 - val_mape: 0.5610\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mape: 23064.3613 - val_loss: 2.2293e-05 - val_mape: 1.2349\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 31224.7422 - val_loss: 6.2827e-06 - val_mape: 0.6009\n",
      "--- 31/102 Training model for WBD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5296e-04 - mape: 8.8527 - val_loss: 1.8788e-05 - val_mape: 47428.2578\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8965e-04 - mape: 8.3442 - val_loss: 3.2001e-06 - val_mape: 30331.4082\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3564e-04 - mape: 7.9330 - val_loss: 9.5920e-05 - val_mape: 82400.0625\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8105e-04 - mape: 7.6313 - val_loss: 3.8443e-05 - val_mape: 60982.7227\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8203e-04 - mape: 7.5657 - val_loss: 6.0675e-06 - val_mape: 35743.9414\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9057e-04 - mape: 6.8507 - val_loss: 1.6195e-05 - val_mape: 11786.8076\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8111e-04 - mape: 6.6827 - val_loss: 3.4454e-05 - val_mape: 58201.8164\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3940e-04 - mape: 6.2609 - val_loss: 4.1345e-06 - val_mape: 20968.1172\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0017e-04 - mape: 5.8919 - val_loss: 8.4583e-06 - val_mape: 39144.7773\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9358e-04 - mape: 5.8185 - val_loss: 1.9350e-05 - val_mape: 11104.3428\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9131e-04 - mape: 5.8004 - val_loss: 2.7076e-05 - val_mape: 3190.9597\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9593e-04 - mape: 5.5722 - val_loss: 6.3653e-05 - val_mape: 66002.5234\n",
      "--- 32/102 Training model for ROP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 21.1428 - val_loss: 2.6489e-04 - val_mape: 1.6612\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 22.3233 - val_loss: 1.3933e-04 - val_mape: 1.1739\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3092e-04 - mape: 22.1228 - val_loss: 4.6661e-04 - val_mape: 2.2838\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 25.2925 - val_loss: 1.9761e-04 - val_mape: 1.4403\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9855e-04 - mape: 22.9772 - val_loss: 7.1350e-05 - val_mape: 0.7710\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5285e-04 - mape: 21.4232 - val_loss: 7.6303e-05 - val_mape: 0.7970\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3034e-04 - mape: 20.7223 - val_loss: 3.9469e-05 - val_mape: 0.5308\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3355e-04 - mape: 20.9006 - val_loss: 7.2030e-05 - val_mape: 0.7683\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 25.2796 - val_loss: 4.8480e-05 - val_mape: 0.6125\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8980e-04 - mape: 22.1856 - val_loss: 1.1405e-04 - val_mape: 1.0599\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7181e-04 - mape: 19.9500 - val_loss: 3.9771e-05 - val_mape: 0.4944\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2755e-04 - mape: 21.8649 - val_loss: 3.1449e-04 - val_mape: 1.8552\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 25.3256 - val_loss: 6.6701e-05 - val_mape: 0.7607\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 22.9175 - val_loss: 1.6195e-04 - val_mape: 1.2785\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 21.4086 - val_loss: 1.5727e-04 - val_mape: 1.2476\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 24.9849 - val_loss: 7.0577e-05 - val_mape: 0.7848\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2429e-04 - mape: 19.2205 - val_loss: 1.9792e-04 - val_mape: 1.4507\n",
      "--- 33/102 Training model for BKR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1692e-04 - mape: 14972.0029 - val_loss: 1.8690e-05 - val_mape: 0.4289\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 52582.1836 - val_loss: 1.5540e-04 - val_mape: 1.4663\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4546e-04 - mape: 6481.9976 - val_loss: 1.6912e-05 - val_mape: 0.4029\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3283e-04 - mape: 11340.6787 - val_loss: 7.2417e-05 - val_mape: 0.9266\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2925e-04 - mape: 3748.4482 - val_loss: 1.5305e-05 - val_mape: 0.4004\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9046e-04 - mape: 13258.3877 - val_loss: 1.5595e-04 - val_mape: 1.3930\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1039e-04 - mape: 7065.0410 - val_loss: 9.5849e-05 - val_mape: 1.0760\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8278e-04 - mape: 1428.2269 - val_loss: 7.6744e-05 - val_mape: 0.8951\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1721e-04 - mape: 8054.5884 - val_loss: 1.1212e-04 - val_mape: 1.1671\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0558e-04 - mape: 17551.9648 - val_loss: 8.1099e-05 - val_mape: 1.0070\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2639e-04 - mape: 6652.8877 - val_loss: 1.8535e-05 - val_mape: 0.4104\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8377e-04 - mape: 5760.8525 - val_loss: 9.6909e-05 - val_mape: 1.0540\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5492e-04 - mape: 5443.8252 - val_loss: 1.3646e-04 - val_mape: 1.3215\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4319e-04 - mape: 5653.3408 - val_loss: 2.3482e-05 - val_mape: 0.5354\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3085e-04 - mape: 42152.9844 - val_loss: 2.1788e-04 - val_mape: 1.7294\n",
      "--- 34/102 Training model for COST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mape: 11517.0479 - val_loss: 7.7196e-04 - val_mape: 3.1527\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mape: 50825.5820 - val_loss: 5.7398e-04 - val_mape: 2.5828\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mape: 34133.6367 - val_loss: 7.1926e-04 - val_mape: 2.9844\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 5105.0820 - val_loss: 6.1432e-04 - val_mape: 2.6946\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 44293.8828 - val_loss: 6.2161e-04 - val_mape: 2.7414\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 14789.6709 - val_loss: 6.8410e-04 - val_mape: 2.8296\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 72590.5000 - val_loss: 7.8410e-04 - val_mape: 3.0272\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 87271.0859 - val_loss: 6.2602e-04 - val_mape: 2.6739\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 18918.7852 - val_loss: 4.1039e-04 - val_mape: 2.0153\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 53486.0195 - val_loss: 4.7259e-04 - val_mape: 2.2253\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 7660.1313 - val_loss: 2.1258e-04 - val_mape: 1.3814\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 63991.6836 - val_loss: 2.3422e-04 - val_mape: 1.5108\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 56256.3242 - val_loss: 2.5433e-04 - val_mape: 1.5896\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5229e-04 - mape: 3829.3208 - val_loss: 2.9955e-04 - val_mape: 1.7872\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5759e-04 - mape: 30186.5156 - val_loss: 3.3600e-04 - val_mape: 1.8678\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6464e-04 - mape: 26748.6445 - val_loss: 1.3379e-04 - val_mape: 1.0843\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7173e-04 - mape: 8399.1826 - val_loss: 1.9681e-04 - val_mape: 1.4049\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4462e-04 - mape: 105615.2109 - val_loss: 1.3731e-04 - val_mape: 1.1362\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8617e-04 - mape: 3968.7981 - val_loss: 1.4478e-04 - val_mape: 1.1555\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 6037.5596 - val_loss: 5.1296e-05 - val_mape: 0.7942\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9817e-04 - mape: 56156.4023 - val_loss: 5.4349e-05 - val_mape: 0.7994\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8307e-04 - mape: 84892.9062 - val_loss: 1.1899e-04 - val_mape: 1.0584\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5581e-04 - mape: 11904.7578 - val_loss: 4.0445e-05 - val_mape: 0.7003\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0606e-04 - mape: 48836.0547 - val_loss: 3.8170e-05 - val_mape: 0.6232\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0266e-04 - mape: 59275.5469 - val_loss: 3.9181e-05 - val_mape: 0.5844\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0023e-04 - mape: 47271.2305 - val_loss: 2.3516e-04 - val_mape: 1.6325\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1120e-04 - mape: 21514.2949 - val_loss: 0.0016 - val_mape: 4.5916\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5164e-04 - mape: 65284.3945 - val_loss: 9.8693e-04 - val_mape: 3.5119\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0147e-04 - mape: 32604.6328 - val_loss: 4.6944e-04 - val_mape: 2.2413\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3808e-04 - mape: 3614.8020 - val_loss: 6.1658e-05 - val_mape: 0.7072\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3441e-04 - mape: 37576.5820 - val_loss: 7.3366e-05 - val_mape: 0.7794\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0084e-04 - mape: 37850.6094 - val_loss: 7.9244e-05 - val_mape: 0.9972\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3248e-04 - mape: 109665.7578 - val_loss: 1.5682e-04 - val_mape: 1.2134\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3104e-04 - mape: 361.5546 - val_loss: 2.0264e-04 - val_mape: 1.3924\n",
      "--- 35/102 Training model for AZN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9622e-04 - mape: 19.1654 - val_loss: 2.2082e-05 - val_mape: 0.4534\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1623e-04 - mape: 18.5267 - val_loss: 2.6825e-04 - val_mape: 2.1392\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6268e-04 - mape: 20.0107 - val_loss: 3.4907e-05 - val_mape: 0.6611\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8015e-04 - mape: 21.6544 - val_loss: 9.5920e-05 - val_mape: 1.1845\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1180e-04 - mape: 25.3288 - val_loss: 2.0941e-05 - val_mape: 0.4369\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8625e-04 - mape: 21.2105 - val_loss: 5.8397e-05 - val_mape: 0.6972\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4936e-04 - mape: 24.9175 - val_loss: 1.4196e-04 - val_mape: 1.5350\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5467e-04 - mape: 23.8769 - val_loss: 3.4420e-05 - val_mape: 0.7058\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4703e-04 - mape: 22.7818 - val_loss: 2.0162e-05 - val_mape: 0.4944\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4502e-04 - mape: 22.2892 - val_loss: 8.5508e-05 - val_mape: 0.8861\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8864e-04 - mape: 28.7916 - val_loss: 1.1872e-04 - val_mape: 1.4102\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9541e-04 - mape: 22.3250 - val_loss: 1.9702e-05 - val_mape: 0.4537\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3453e-04 - mape: 23.3154 - val_loss: 3.6081e-05 - val_mape: 0.7345\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8391e-04 - mape: 23.2197 - val_loss: 5.0484e-05 - val_mape: 0.7438\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7058e-04 - mape: 25.7227 - val_loss: 2.0447e-05 - val_mape: 0.4197\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2781e-04 - mape: 23.3243 - val_loss: 3.4528e-05 - val_mape: 0.7091\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4738e-04 - mape: 23.4114 - val_loss: 1.8283e-05 - val_mape: 0.4385\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0955e-04 - mape: 25.9815 - val_loss: 1.7553e-04 - val_mape: 1.7122\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7477e-04 - mape: 25.5779 - val_loss: 1.0525e-04 - val_mape: 1.1716\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9497e-04 - mape: 23.9406 - val_loss: 4.5442e-05 - val_mape: 0.6905\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2301e-04 - mape: 24.7150 - val_loss: 1.9556e-05 - val_mape: 0.5056\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3752e-04 - mape: 22.3187 - val_loss: 1.5832e-04 - val_mape: 1.4280\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3325e-04 - mape: 25.6181 - val_loss: 2.0610e-04 - val_mape: 1.4896\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1043e-04 - mape: 28.8847 - val_loss: 4.4492e-05 - val_mape: 0.6486\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3979e-04 - mape: 26.5586 - val_loss: 3.8230e-05 - val_mape: 0.7046\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1359e-04 - mape: 23.8690 - val_loss: 1.1299e-04 - val_mape: 1.3791\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9338e-04 - mape: 22.8899 - val_loss: 5.6918e-05 - val_mape: 0.7089\n",
      "--- 36/102 Training model for LRCX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1509e-04 - mape: 62.1262 - val_loss: 2.6639e-04 - val_mape: 1.8609\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6996e-04 - mape: 63.3370 - val_loss: 3.8625e-05 - val_mape: 0.6333\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 70.8704 - val_loss: 4.0020e-04 - val_mape: 2.3110\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4493e-04 - mape: 57.0972 - val_loss: 6.1745e-05 - val_mape: 0.9372\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 79.9541 - val_loss: 0.0071 - val_mape: 10.3990\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 114.1585 - val_loss: 1.2604e-04 - val_mape: 1.0808\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 75.1886 - val_loss: 0.0024 - val_mape: 6.0449\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8438e-04 - mape: 73.3538 - val_loss: 8.9770e-05 - val_mape: 0.9250\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2794e-04 - mape: 58.7300 - val_loss: 7.8947e-04 - val_mape: 3.4563\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6221e-04 - mape: 67.7287 - val_loss: 5.7870e-05 - val_mape: 0.7533\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2842e-04 - mape: 59.1140 - val_loss: 2.5468e-04 - val_mape: 1.9007\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6105e-04 - mape: 56.7952 - val_loss: 6.0641e-05 - val_mape: 0.7587\n",
      "--- 37/102 Training model for MELI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6618e-04 - mape: 37.3027 - val_loss: 1.9687e-05 - val_mape: 0.4575\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 37.0193 - val_loss: 5.9519e-05 - val_mape: 0.8380\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mape: 55.9186 - val_loss: 0.0038 - val_mape: 7.5083\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mape: 83.2915 - val_loss: 3.7945e-05 - val_mape: 0.6228\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 52.5566 - val_loss: 0.0019 - val_mape: 5.4188\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 45.0586 - val_loss: 1.0683e-05 - val_mape: 0.3254\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 38.3568 - val_loss: 2.3071e-04 - val_mape: 1.8110\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7873e-04 - mape: 37.4087 - val_loss: 1.1556e-04 - val_mape: 1.2908\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7766e-04 - mape: 37.7342 - val_loss: 2.3114e-04 - val_mape: 1.8685\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 42.2239 - val_loss: 1.3890e-05 - val_mape: 0.3702\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5644e-04 - mape: 38.5826 - val_loss: 9.6915e-05 - val_mape: 1.1746\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 40.3957 - val_loss: 1.2647e-04 - val_mape: 1.3616\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7365e-04 - mape: 36.3467 - val_loss: 7.3516e-05 - val_mape: 0.9950\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 37.4356 - val_loss: 2.4268e-05 - val_mape: 0.5064\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 42.2282 - val_loss: 4.5233e-05 - val_mape: 0.7063\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 43.3081 - val_loss: 5.7086e-04 - val_mape: 2.9242\n",
      "--- 38/102 Training model for CDW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9650e-04 - mape: 36.9296 - val_loss: 2.7174e-04 - val_mape: 1.8101\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 42.4516 - val_loss: 2.8611e-04 - val_mape: 1.9176\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2570e-04 - mape: 41.2525 - val_loss: 1.5146e-05 - val_mape: 0.3292\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5389e-04 - mape: 34.7298 - val_loss: 1.1041e-04 - val_mape: 1.1510\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1413e-04 - mape: 37.0017 - val_loss: 3.8534e-04 - val_mape: 2.2227\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3521e-04 - mape: 39.5779 - val_loss: 1.4700e-05 - val_mape: 0.3337\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0796e-04 - mape: 33.0404 - val_loss: 4.6830e-04 - val_mape: 2.4713\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5671e-04 - mape: 34.7490 - val_loss: 9.6028e-05 - val_mape: 1.0760\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0145e-04 - mape: 30.0045 - val_loss: 2.8376e-04 - val_mape: 1.9040\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5517e-04 - mape: 36.9344 - val_loss: 1.3240e-05 - val_mape: 0.2954\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4028e-04 - mape: 36.7296 - val_loss: 3.5980e-04 - val_mape: 2.1391\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8098e-04 - mape: 38.3457 - val_loss: 1.2656e-04 - val_mape: 1.2372\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5798e-04 - mape: 41.6483 - val_loss: 8.6809e-04 - val_mape: 3.3507\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 42.0565 - val_loss: 2.6310e-04 - val_mape: 1.8196\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3570e-04 - mape: 36.8954 - val_loss: 2.2646e-04 - val_mape: 1.6670\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1084e-04 - mape: 40.6282 - val_loss: 5.8707e-04 - val_mape: 2.7511\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9122e-04 - mape: 38.2099 - val_loss: 2.1612e-04 - val_mape: 1.6387\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1885e-04 - mape: 33.2936 - val_loss: 7.3551e-04 - val_mape: 3.0707\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 41.9750 - val_loss: 1.6595e-04 - val_mape: 1.4001\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6816e-04 - mape: 37.0289 - val_loss: 1.8923e-04 - val_mape: 1.5036\n",
      "--- 39/102 Training model for FANG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6965e-04 - mape: 24925.3301 - val_loss: 5.9435e-05 - val_mape: 0.8110\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7694e-04 - mape: 5049.1943 - val_loss: 1.0965e-04 - val_mape: 1.1080\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6350e-04 - mape: 3899.4985 - val_loss: 1.2641e-04 - val_mape: 1.1788\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8136e-04 - mape: 31371.3203 - val_loss: 4.0556e-05 - val_mape: 0.6549\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7493e-04 - mape: 14010.2871 - val_loss: 1.8546e-04 - val_mape: 1.4999\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8898e-04 - mape: 600.2378 - val_loss: 2.9404e-04 - val_mape: 1.8089\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0856e-04 - mape: 4399.4863 - val_loss: 2.7180e-04 - val_mape: 1.7347\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0574e-04 - mape: 25761.7012 - val_loss: 1.5359e-05 - val_mape: 0.3594\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7542e-04 - mape: 9793.3750 - val_loss: 7.5413e-05 - val_mape: 0.9106\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7101e-04 - mape: 15583.3799 - val_loss: 4.1059e-05 - val_mape: 0.6131\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8832e-04 - mape: 39987.8359 - val_loss: 7.7786e-05 - val_mape: 0.8756\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8497e-04 - mape: 25412.8770 - val_loss: 8.4565e-05 - val_mape: 0.9638\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6975e-04 - mape: 12686.9404 - val_loss: 2.7253e-04 - val_mape: 1.7527\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0424e-04 - mape: 9074.6006 - val_loss: 2.8854e-04 - val_mape: 1.8458\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9979e-04 - mape: 2372.8442 - val_loss: 2.9571e-04 - val_mape: 1.7975\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4270e-04 - mape: 36538.2852 - val_loss: 3.1850e-05 - val_mape: 0.4811\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3100e-04 - mape: 7005.7490 - val_loss: 1.1819e-04 - val_mape: 1.1806\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7867e-04 - mape: 5963.4824 - val_loss: 1.0111e-04 - val_mape: 1.0756\n",
      "--- 40/102 Training model for ZS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 35622.6602 - val_loss: 4.9718e-05 - val_mape: 1.2904\n",
      "Epoch 2/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 76379.7891 - val_loss: 8.0125e-05 - val_mape: 1.7368\n",
      "Epoch 3/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 22756.4375 - val_loss: 1.1965e-04 - val_mape: 2.1259\n",
      "Epoch 4/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6322e-04 - mape: 43517.0117 - val_loss: 2.9525e-04 - val_mape: 3.2541\n",
      "Epoch 5/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 30190.2344 - val_loss: 1.2476e-04 - val_mape: 1.9903\n",
      "Epoch 6/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 28696.9648 - val_loss: 1.2177e-04 - val_mape: 2.1799\n",
      "Epoch 7/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6690e-04 - mape: 178849.0000 - val_loss: 2.1505e-05 - val_mape: 0.8086\n",
      "Epoch 8/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1562e-04 - mape: 135885.1875 - val_loss: 4.7811e-04 - val_mape: 4.3062\n",
      "Epoch 9/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9970e-04 - mape: 159743.4375 - val_loss: 9.8945e-05 - val_mape: 1.9730\n",
      "Epoch 10/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2158e-04 - mape: 228127.8750 - val_loss: 2.9052e-04 - val_mape: 3.2527\n",
      "Epoch 11/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 10247.3467 - val_loss: 3.8855e-04 - val_mape: 3.7951\n",
      "Epoch 12/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 66393.5469 - val_loss: 3.6238e-04 - val_mape: 3.8409\n",
      "Epoch 13/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2658e-04 - mape: 41966.6914 - val_loss: 8.9104e-05 - val_mape: 1.8185\n",
      "Epoch 14/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6459e-04 - mape: 116008.5234 - val_loss: 1.6195e-04 - val_mape: 2.5535\n",
      "Epoch 15/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1390e-04 - mape: 121164.3906 - val_loss: 3.8018e-05 - val_mape: 1.1006\n",
      "Epoch 16/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2904e-04 - mape: 1310.9257 - val_loss: 2.1848e-05 - val_mape: 0.8470\n",
      "Epoch 17/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4881e-04 - mape: 54711.9648 - val_loss: 4.3246e-04 - val_mape: 4.1695\n",
      "--- 41/102 Training model for ADBE ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3842e-04 - mape: 23.3966 - val_loss: 9.4172e-05 - val_mape: 1.1769\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9269e-04 - mape: 21.4420 - val_loss: 7.5679e-05 - val_mape: 1.0530\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4742e-04 - mape: 23.6609 - val_loss: 6.9670e-05 - val_mape: 0.9382\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 34.6437 - val_loss: 0.0053 - val_mape: 9.4439\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mape: 64.3569 - val_loss: 1.8572e-04 - val_mape: 1.4416\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mape: 38.4218 - val_loss: 0.0045 - val_mape: 8.5792\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mape: 70.7280 - val_loss: 0.0011 - val_mape: 4.2613\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 47.5761 - val_loss: 3.3350e-05 - val_mape: 0.6077\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8127e-04 - mape: 25.2719 - val_loss: 2.7279e-05 - val_mape: 0.5424\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4941e-04 - mape: 27.0697 - val_loss: 6.9605e-05 - val_mape: 0.9719\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2573e-04 - mape: 27.0787 - val_loss: 3.5611e-05 - val_mape: 0.6148\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4857e-04 - mape: 28.3170 - val_loss: 2.3016e-05 - val_mape: 0.4715\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5720e-04 - mape: 24.9313 - val_loss: 7.4585e-05 - val_mape: 1.0098\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4959e-04 - mape: 25.9909 - val_loss: 2.1624e-05 - val_mape: 0.5025\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3778e-04 - mape: 28.1755 - val_loss: 3.9118e-05 - val_mape: 0.6372\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7551e-04 - mape: 27.5316 - val_loss: 6.2078e-04 - val_mape: 3.1192\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 34.2891 - val_loss: 6.1676e-05 - val_mape: 0.9453\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2527e-04 - mape: 28.6471 - val_loss: 1.2439e-04 - val_mape: 1.3020\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9208e-04 - mape: 27.4507 - val_loss: 8.3843e-05 - val_mape: 1.1289\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 31.4599 - val_loss: 1.4399e-04 - val_mape: 1.4289\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2590e-04 - mape: 28.7182 - val_loss: 1.3922e-04 - val_mape: 1.4150\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 31.8048 - val_loss: 5.3592e-04 - val_mape: 2.9222\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 33.2831 - val_loss: 2.2887e-05 - val_mape: 0.5128\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4488e-04 - mape: 28.3434 - val_loss: 4.2135e-04 - val_mape: 2.5711\n",
      "--- 42/102 Training model for GOOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 59.2057 - val_loss: 2.6613e-05 - val_mape: 0.4541\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 50.4899 - val_loss: 7.2043e-05 - val_mape: 0.9333\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4101e-04 - mape: 51.9452 - val_loss: 1.5177e-04 - val_mape: 1.4434\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 55.7036 - val_loss: 2.4002e-04 - val_mape: 1.8393\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8737e-04 - mape: 53.9040 - val_loss: 2.6463e-04 - val_mape: 1.8957\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 63.0456 - val_loss: 5.5575e-05 - val_mape: 0.7472\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2253e-04 - mape: 47.7063 - val_loss: 1.3662e-04 - val_mape: 1.3478\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9041e-04 - mape: 53.7779 - val_loss: 2.6002e-04 - val_mape: 1.8810\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 54.7022 - val_loss: 3.0256e-04 - val_mape: 2.0300\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 55.5561 - val_loss: 1.4939e-04 - val_mape: 1.3261\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 58.5208 - val_loss: 3.7592e-04 - val_mape: 2.3009\n",
      "--- 43/102 Training model for AMAT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 2748.0149 - val_loss: 6.3140e-04 - val_mape: 3.0755\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 37656.4727 - val_loss: 1.5987e-04 - val_mape: 1.5079\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 29791.0938 - val_loss: 3.5550e-04 - val_mape: 2.3325\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 77178.0781 - val_loss: 5.2232e-05 - val_mape: 0.7923\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 47376.6914 - val_loss: 1.1435e-04 - val_mape: 1.2834\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6382e-04 - mape: 7502.4497 - val_loss: 8.6051e-05 - val_mape: 1.0362\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2441e-04 - mape: 25865.6191 - val_loss: 4.2753e-05 - val_mape: 0.6908\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2466e-04 - mape: 17070.8379 - val_loss: 3.6941e-05 - val_mape: 0.6118\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2321e-04 - mape: 19577.5488 - val_loss: 1.6839e-04 - val_mape: 1.5261\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7343e-04 - mape: 12656.6045 - val_loss: 1.0573e-04 - val_mape: 1.1590\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6586e-04 - mape: 9731.6230 - val_loss: 1.2462e-04 - val_mape: 1.3108\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4272e-04 - mape: 18553.5176 - val_loss: 1.9328e-04 - val_mape: 1.7103\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0929e-04 - mape: 34163.4258 - val_loss: 9.5196e-05 - val_mape: 1.1178\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2221e-04 - mape: 31952.2090 - val_loss: 5.2127e-05 - val_mape: 0.7929\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5071e-04 - mape: 20752.0176 - val_loss: 6.7173e-05 - val_mape: 0.9113\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7323e-04 - mape: 31595.2852 - val_loss: 1.7655e-04 - val_mape: 1.6325\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4384e-04 - mape: 35255.3086 - val_loss: 6.9764e-05 - val_mape: 0.9699\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6359e-04 - mape: 9499.6748 - val_loss: 1.7895e-04 - val_mape: 1.6384\n",
      "--- 44/102 Training model for ADP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5857e-04 - mape: 44858.3047 - val_loss: 1.2002e-04 - val_mape: 1.2687\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9987e-04 - mape: 96775.5469 - val_loss: 1.0665e-05 - val_mape: 0.3015\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8323e-04 - mape: 16594.4766 - val_loss: 3.2438e-05 - val_mape: 0.5900\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8544e-04 - mape: 65740.9688 - val_loss: 1.2104e-05 - val_mape: 0.3297\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6652e-04 - mape: 156806.5312 - val_loss: 3.5833e-04 - val_mape: 2.1850\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0633e-04 - mape: 181593.1406 - val_loss: 1.5667e-05 - val_mape: 0.3868\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9494e-04 - mape: 64269.0625 - val_loss: 1.1485e-05 - val_mape: 0.3214\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6729e-04 - mape: 139672.6250 - val_loss: 1.7555e-05 - val_mape: 0.4020\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2207e-04 - mape: 208428.2656 - val_loss: 1.8723e-04 - val_mape: 1.5562\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 95472.3828 - val_loss: 1.0297e-04 - val_mape: 1.1477\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 25374.7305 - val_loss: 0.0012 - val_mape: 4.1128\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 178493.9219 - val_loss: 1.2334e-04 - val_mape: 1.2583\n",
      "--- 45/102 Training model for SBUX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6202e-04 - mape: 7221.7876 - val_loss: 2.5995e-05 - val_mape: 0.6865\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4884e-04 - mape: 79814.0938 - val_loss: 1.4066e-04 - val_mape: 2.0366\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9340e-04 - mape: 23929.9766 - val_loss: 2.8217e-05 - val_mape: 0.7138\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0235e-04 - mape: 1164.9539 - val_loss: 3.5552e-05 - val_mape: 0.8274\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7133e-04 - mape: 12441.2852 - val_loss: 4.0861e-05 - val_mape: 0.9816\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6624e-04 - mape: 1302.5035 - val_loss: 2.2659e-05 - val_mape: 0.6404\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 53696.3477 - val_loss: 2.5204e-04 - val_mape: 2.7977\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9340e-04 - mape: 43334.1016 - val_loss: 1.2375e-04 - val_mape: 1.7205\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 25570.7637 - val_loss: 1.1361e-04 - val_mape: 1.8355\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7221e-04 - mape: 45839.6562 - val_loss: 4.6246e-05 - val_mape: 0.9490\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 14067.6611 - val_loss: 7.1073e-05 - val_mape: 1.3727\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 48589.8047 - val_loss: 7.3068e-05 - val_mape: 1.1827\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 1759.5635 - val_loss: 1.4444e-04 - val_mape: 2.0922\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 15938.4863 - val_loss: 2.9202e-05 - val_mape: 0.6998\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 6328.6138 - val_loss: 2.6305e-05 - val_mape: 0.6545\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 33370.3242 - val_loss: 5.8203e-05 - val_mape: 1.0528\n",
      "--- 46/102 Training model for TTWO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4758e-04 - mape: 11.9052 - val_loss: 8.3983e-05 - val_mape: 1.3108\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2222e-04 - mape: 12.1316 - val_loss: 5.4971e-05 - val_mape: 1.0378\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2228e-04 - mape: 9.8943 - val_loss: 1.0764e-05 - val_mape: 0.3860\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9589e-04 - mape: 11.8328 - val_loss: 4.2625e-05 - val_mape: 0.8805\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6895e-04 - mape: 12.5669 - val_loss: 2.7380e-04 - val_mape: 2.4512\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9864e-04 - mape: 13.0815 - val_loss: 1.9948e-05 - val_mape: 0.5297\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8064e-04 - mape: 13.1815 - val_loss: 1.3265e-04 - val_mape: 1.6347\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7986e-04 - mape: 12.7995 - val_loss: 1.1920e-05 - val_mape: 0.4257\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5526e-04 - mape: 12.9370 - val_loss: 2.6947e-05 - val_mape: 0.6256\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0415e-04 - mape: 12.2292 - val_loss: 1.8601e-04 - val_mape: 1.9816\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9880e-04 - mape: 13.5059 - val_loss: 1.9284e-05 - val_mape: 0.5280\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8551e-04 - mape: 11.4280 - val_loss: 3.0562e-05 - val_mape: 0.6995\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1024e-04 - mape: 14.4947 - val_loss: 1.0033e-05 - val_mape: 0.3755\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9995e-04 - mape: 13.1309 - val_loss: 1.0076e-05 - val_mape: 0.3690\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8756e-04 - mape: 14.9387 - val_loss: 9.0827e-05 - val_mape: 1.3783\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9197e-04 - mape: 14.3875 - val_loss: 1.0035e-05 - val_mape: 0.3653\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0261e-04 - mape: 15.4592 - val_loss: 7.3488e-05 - val_mape: 1.2118\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2946e-04 - mape: 16.8062 - val_loss: 1.4723e-05 - val_mape: 0.4578\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5620e-04 - mape: 15.9838 - val_loss: 1.4492e-04 - val_mape: 1.7469\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1193e-04 - mape: 14.0419 - val_loss: 1.1388e-05 - val_mape: 0.3971\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9069e-04 - mape: 13.3769 - val_loss: 1.4656e-04 - val_mape: 1.7517\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2930e-04 - mape: 15.4222 - val_loss: 9.8483e-06 - val_mape: 0.3677\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5500e-04 - mape: 17.7360 - val_loss: 3.9360e-04 - val_mape: 2.9471\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3777e-04 - mape: 13.9793 - val_loss: 3.8288e-05 - val_mape: 0.7993\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 18.9385 - val_loss: 7.1191e-04 - val_mape: 4.0148\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 19.3697 - val_loss: 5.0589e-05 - val_mape: 0.9960\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8680e-04 - mape: 15.6503 - val_loss: 3.7397e-04 - val_mape: 2.8704\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6214e-04 - mape: 17.0277 - val_loss: 3.6075e-05 - val_mape: 0.8225\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1861e-04 - mape: 16.0349 - val_loss: 2.4060e-04 - val_mape: 2.2824\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7582e-04 - mape: 17.2318 - val_loss: 6.0158e-05 - val_mape: 1.0839\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3793e-04 - mape: 17.2470 - val_loss: 1.7427e-04 - val_mape: 1.9305\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4244e-04 - mape: 16.8956 - val_loss: 7.3798e-05 - val_mape: 1.2396\n",
      "--- 47/102 Training model for TMUS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 5402.1694 - val_loss: 2.2298e-05 - val_mape: 0.3845\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 18927.0195 - val_loss: 1.4157e-04 - val_mape: 1.3287\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 5421.9927 - val_loss: 8.7039e-05 - val_mape: 0.9878\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 38537.4727 - val_loss: 1.0726e-04 - val_mape: 1.1479\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 29926.5820 - val_loss: 1.3899e-04 - val_mape: 1.3262\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 67142.0391 - val_loss: 1.5716e-04 - val_mape: 1.5050\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 60333.7812 - val_loss: 2.1666e-04 - val_mape: 1.8661\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 12317.7256 - val_loss: 1.7234e-04 - val_mape: 1.6287\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 50709.9531 - val_loss: 1.2690e-04 - val_mape: 1.3402\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 8618.2236 - val_loss: 8.2381e-05 - val_mape: 1.0164\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 49355.6289 - val_loss: 1.6120e-04 - val_mape: 1.5837\n",
      "--- 48/102 Training model for WDAY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4386e-04 - mape: 15.7783 - val_loss: 3.2106e-05 - val_mape: 0.5838\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6103e-04 - mape: 15.4410 - val_loss: 1.0318e-04 - val_mape: 1.1269\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1531e-04 - mape: 15.1833 - val_loss: 1.1475e-04 - val_mape: 1.2652\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4414e-04 - mape: 14.2692 - val_loss: 1.3618e-04 - val_mape: 1.2713\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1121e-04 - mape: 13.1217 - val_loss: 2.8339e-05 - val_mape: 0.5331\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8166e-04 - mape: 14.5454 - val_loss: 1.3803e-04 - val_mape: 1.2522\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5646e-04 - mape: 13.8416 - val_loss: 1.4482e-04 - val_mape: 1.2223\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5363e-04 - mape: 15.8952 - val_loss: 6.6026e-05 - val_mape: 0.9392\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 16.1440 - val_loss: 6.1532e-04 - val_mape: 2.8005\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 16.1951 - val_loss: 1.5904e-04 - val_mape: 1.3985\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6603e-04 - mape: 15.0514 - val_loss: 9.4363e-05 - val_mape: 1.1026\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4255e-04 - mape: 14.3141 - val_loss: 1.8533e-04 - val_mape: 1.4524\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0805e-04 - mape: 15.3962 - val_loss: 5.7988e-05 - val_mape: 0.8150\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2443e-04 - mape: 14.8397 - val_loss: 1.9311e-04 - val_mape: 1.5268\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1050e-04 - mape: 14.8652 - val_loss: 6.3498e-05 - val_mape: 0.8879\n",
      "--- 49/102 Training model for CRWD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 56754.6602 - val_loss: 0.0020 - val_mape: 5.4486\n",
      "Epoch 2/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 12863.2939 - val_loss: 6.8937e-05 - val_mape: 0.8296\n",
      "Epoch 3/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 33190.5742 - val_loss: 0.0018 - val_mape: 5.1569\n",
      "Epoch 4/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6034e-04 - mape: 185542.7812 - val_loss: 5.5602e-05 - val_mape: 0.7617\n",
      "Epoch 5/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 24824.6699 - val_loss: 9.3022e-04 - val_mape: 3.7886\n",
      "Epoch 6/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 54135.6328 - val_loss: 1.2056e-04 - val_mape: 1.2497\n",
      "Epoch 7/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4910e-04 - mape: 20658.9004 - val_loss: 3.7822e-04 - val_mape: 2.4178\n",
      "Epoch 8/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 45925.4609 - val_loss: 8.4773e-05 - val_mape: 0.9875\n",
      "Epoch 9/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5401e-04 - mape: 11458.7744 - val_loss: 2.5484e-04 - val_mape: 1.9577\n",
      "Epoch 10/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2860e-04 - mape: 39797.0312 - val_loss: 1.2719e-04 - val_mape: 1.2955\n",
      "Epoch 11/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2236e-04 - mape: 40025.2148 - val_loss: 1.0969e-04 - val_mape: 1.1911\n",
      "Epoch 12/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8903e-04 - mape: 4868.1489 - val_loss: 4.1887e-05 - val_mape: 0.6868\n",
      "Epoch 13/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7505e-04 - mape: 111493.4062 - val_loss: 1.5347e-04 - val_mape: 1.4885\n",
      "Epoch 14/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5824e-04 - mape: 99120.7500 - val_loss: 1.4975e-04 - val_mape: 1.4349\n",
      "Epoch 15/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9207e-04 - mape: 128852.3828 - val_loss: 1.0396e-04 - val_mape: 1.1661\n",
      "Epoch 16/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6419e-04 - mape: 25513.8867 - val_loss: 5.2421e-05 - val_mape: 0.7841\n",
      "Epoch 17/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8939e-04 - mape: 9995.6104 - val_loss: 1.3128e-04 - val_mape: 1.3695\n",
      "Epoch 18/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0983e-04 - mape: 72913.8203 - val_loss: 3.2157e-04 - val_mape: 2.2446\n",
      "Epoch 19/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1295e-04 - mape: 107871.0703 - val_loss: 7.4493e-05 - val_mape: 0.8977\n",
      "Epoch 20/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9483e-04 - mape: 17489.6270 - val_loss: 1.9551e-04 - val_mape: 1.7241\n",
      "Epoch 21/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5659e-04 - mape: 10884.0918 - val_loss: 2.4574e-04 - val_mape: 1.9500\n",
      "Epoch 22/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9783e-04 - mape: 18316.7051 - val_loss: 1.1054e-04 - val_mape: 1.2305\n",
      "--- 50/102 Training model for DDOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7724e-04 - mape: 236870.6250 - val_loss: 5.1353e-05 - val_mape: 1.1664\n",
      "Epoch 2/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6463e-04 - mape: 318479.4375 - val_loss: 2.0461e-04 - val_mape: 2.5482\n",
      "Epoch 3/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 6380.2354 - val_loss: 2.0991e-04 - val_mape: 2.4881\n",
      "Epoch 4/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 38225.2656 - val_loss: 2.1927e-05 - val_mape: 0.6889\n",
      "Epoch 5/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 123237.5391 - val_loss: 1.1577e-05 - val_mape: 0.5212\n",
      "Epoch 6/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0064e-04 - mape: 30293.0664 - val_loss: 2.4487e-05 - val_mape: 0.7805\n",
      "Epoch 7/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9655e-04 - mape: 59852.8711 - val_loss: 7.0547e-05 - val_mape: 1.4151\n",
      "Epoch 8/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 149515.0469 - val_loss: 7.7908e-05 - val_mape: 1.4172\n",
      "Epoch 9/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 32432.9629 - val_loss: 3.5880e-05 - val_mape: 0.9769\n",
      "Epoch 10/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 30775.6348 - val_loss: 4.7643e-05 - val_mape: 1.1641\n",
      "Epoch 11/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1224e-04 - mape: 338349.5312 - val_loss: 7.3808e-05 - val_mape: 1.4894\n",
      "Epoch 12/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8894e-04 - mape: 79789.7422 - val_loss: 3.6512e-05 - val_mape: 0.9948\n",
      "Epoch 13/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6066e-04 - mape: 115776.5703 - val_loss: 9.9207e-06 - val_mape: 0.4809\n",
      "Epoch 14/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.6613e-04 - mape: 152782.9531 - val_loss: 5.5818e-05 - val_mape: 1.2653\n",
      "Epoch 15/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5999e-04 - mape: 154614.8594 - val_loss: 3.1876e-05 - val_mape: 0.9101\n",
      "Epoch 16/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6732e-04 - mape: 36545.6602 - val_loss: 1.5825e-05 - val_mape: 0.5911\n",
      "Epoch 17/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2211e-04 - mape: 188466.6406 - val_loss: 1.5664e-05 - val_mape: 0.5836\n",
      "Epoch 18/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 2594.5063 - val_loss: 1.6314e-05 - val_mape: 0.6193\n",
      "Epoch 19/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0367e-04 - mape: 172955.0781 - val_loss: 1.2491e-04 - val_mape: 1.9395\n",
      "Epoch 20/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 185986.5781 - val_loss: 4.2459e-05 - val_mape: 1.0380\n",
      "Epoch 21/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8919e-04 - mape: 148826.3594 - val_loss: 9.4585e-06 - val_mape: 0.4274\n",
      "Epoch 22/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1583e-04 - mape: 156104.5156 - val_loss: 7.8554e-06 - val_mape: 0.4012\n",
      "Epoch 23/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4644e-04 - mape: 155159.0625 - val_loss: 4.1337e-05 - val_mape: 1.0701\n",
      "Epoch 24/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9312e-04 - mape: 325136.1875 - val_loss: 1.4089e-05 - val_mape: 0.5586\n",
      "Epoch 25/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3650e-04 - mape: 148360.6875 - val_loss: 1.3540e-05 - val_mape: 0.5431\n",
      "Epoch 26/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6538e-04 - mape: 261171.3594 - val_loss: 2.0110e-05 - val_mape: 0.6891\n",
      "Epoch 27/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 90120.4922 - val_loss: 7.3433e-05 - val_mape: 1.4942\n",
      "Epoch 28/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.6959e-04 - mape: 233558.8125 - val_loss: 1.5233e-05 - val_mape: 0.6180\n",
      "Epoch 29/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0977e-04 - mape: 53591.5938 - val_loss: 2.0745e-05 - val_mape: 0.7331\n",
      "Epoch 30/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5976e-04 - mape: 142046.8906 - val_loss: 7.9536e-06 - val_mape: 0.3928\n",
      "Epoch 31/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5569e-04 - mape: 53491.1523 - val_loss: 4.1627e-05 - val_mape: 1.0665\n",
      "Epoch 32/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5775e-04 - mape: 117685.7734 - val_loss: 8.2076e-06 - val_mape: 0.3879\n",
      "--- 51/102 Training model for PCAR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 31904.1602 - val_loss: 2.1449e-04 - val_mape: 1.6413\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 38905.0781 - val_loss: 7.1296e-05 - val_mape: 0.8942\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 62908.8594 - val_loss: 2.0310e-04 - val_mape: 1.6334\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5871e-04 - mape: 44201.9492 - val_loss: 2.2112e-04 - val_mape: 1.7000\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 30312.5957 - val_loss: 1.3667e-04 - val_mape: 1.3191\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7666e-04 - mape: 47469.6016 - val_loss: 2.2590e-04 - val_mape: 1.7067\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 54011.9141 - val_loss: 1.2900e-04 - val_mape: 1.2812\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1713e-04 - mape: 6769.1030 - val_loss: 1.8492e-04 - val_mape: 1.5745\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9201e-04 - mape: 4716.8984 - val_loss: 1.7387e-04 - val_mape: 1.5077\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7877e-04 - mape: 20733.2383 - val_loss: 1.1088e-04 - val_mape: 1.2055\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9888e-04 - mape: 27194.6816 - val_loss: 2.0525e-04 - val_mape: 1.6939\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1486e-04 - mape: 12233.1504 - val_loss: 1.2823e-04 - val_mape: 1.3185\n",
      "--- 52/102 Training model for MRNA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 75804.1484 - val_loss: 1.3234e-05 - val_mape: 1.2425\n",
      "Epoch 2/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 32649.0742 - val_loss: 1.1562e-05 - val_mape: 1.1411\n",
      "Epoch 3/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 165895.0938 - val_loss: 1.8799e-05 - val_mape: 1.4981\n",
      "Epoch 4/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 83302.1797 - val_loss: 9.9876e-05 - val_mape: 4.8200\n",
      "Epoch 5/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 224372.1406 - val_loss: 1.7835e-05 - val_mape: 1.8280\n",
      "Epoch 6/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 101140.1953 - val_loss: 1.1235e-05 - val_mape: 1.1717\n",
      "Epoch 7/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 64761.0273 - val_loss: 7.0346e-06 - val_mape: 0.9162\n",
      "Epoch 8/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 73850.6172 - val_loss: 1.4413e-05 - val_mape: 1.2700\n",
      "Epoch 9/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 17380.5000 - val_loss: 6.1599e-05 - val_mape: 3.7211\n",
      "Epoch 10/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 52664.9062 - val_loss: 7.2497e-06 - val_mape: 0.9898\n",
      "Epoch 11/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 27205.3223 - val_loss: 6.1791e-06 - val_mape: 0.9061\n",
      "Epoch 12/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 51745.7227 - val_loss: 2.0842e-05 - val_mape: 2.0965\n",
      "Epoch 13/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9646e-04 - mape: 101064.2969 - val_loss: 8.3169e-05 - val_mape: 4.3428\n",
      "Epoch 14/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8329e-04 - mape: 22421.5820 - val_loss: 1.4715e-05 - val_mape: 1.7333\n",
      "Epoch 15/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8918e-04 - mape: 53141.4375 - val_loss: 2.8471e-05 - val_mape: 2.4822\n",
      "Epoch 16/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1757e-04 - mape: 15660.5127 - val_loss: 3.5631e-05 - val_mape: 2.7579\n",
      "Epoch 17/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 36968.8789 - val_loss: 1.5746e-04 - val_mape: 6.1804\n",
      "Epoch 18/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 40284.8008 - val_loss: 1.2339e-05 - val_mape: 1.2649\n",
      "Epoch 19/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0782e-04 - mape: 12673.3730 - val_loss: 1.0985e-05 - val_mape: 1.2599\n",
      "Epoch 20/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3507e-04 - mape: 9390.2598 - val_loss: 3.1948e-05 - val_mape: 2.6125\n",
      "Epoch 21/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8496e-04 - mape: 42492.2109 - val_loss: 1.5880e-05 - val_mape: 1.6813\n",
      "--- 53/102 Training model for META ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9860e-04 - mape: 3350.2480 - val_loss: 7.8252e-05 - val_mape: 0.8960\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6366e-04 - mape: 1846.3201 - val_loss: 4.8997e-04 - val_mape: 2.3880\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3446e-04 - mape: 1477.8801 - val_loss: 7.7852e-05 - val_mape: 0.8490\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7543e-04 - mape: 3468.3223 - val_loss: 1.9870e-04 - val_mape: 1.4845\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2356e-04 - mape: 3353.9080 - val_loss: 2.3228e-04 - val_mape: 1.6208\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1371e-04 - mape: 4760.0083 - val_loss: 2.4178e-04 - val_mape: 1.6344\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9658e-04 - mape: 1926.5125 - val_loss: 7.0874e-05 - val_mape: 0.8547\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9135e-04 - mape: 11690.9834 - val_loss: 2.2527e-04 - val_mape: 1.5272\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8511e-04 - mape: 2252.6025 - val_loss: 1.0877e-04 - val_mape: 1.1114\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2378e-04 - mape: 1892.3750 - val_loss: 2.3566e-04 - val_mape: 1.6283\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8113e-04 - mape: 143.2551 - val_loss: 9.2519e-04 - val_mape: 3.3579\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2141e-04 - mape: 2542.8416 - val_loss: 1.8434e-04 - val_mape: 1.4188\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4610e-04 - mape: 2583.7190 - val_loss: 3.6583e-05 - val_mape: 0.5037\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0453e-04 - mape: 1049.0499 - val_loss: 9.2090e-04 - val_mape: 3.4100\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8050e-04 - mape: 73.7625 - val_loss: 3.5159e-04 - val_mape: 1.8731\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0902e-04 - mape: 6280.2427 - val_loss: 1.5092e-04 - val_mape: 1.3250\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2524e-04 - mape: 6904.8589 - val_loss: 2.7365e-04 - val_mape: 1.6444\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3393e-04 - mape: 4869.6763 - val_loss: 6.4028e-04 - val_mape: 3.0125\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8221e-04 - mape: 6132.5469 - val_loss: 2.6579e-04 - val_mape: 1.5928\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2458e-04 - mape: 8563.5400 - val_loss: 1.3620e-04 - val_mape: 1.2315\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6173e-04 - mape: 4814.8413 - val_loss: 1.3520e-04 - val_mape: 1.1395\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9881e-04 - mape: 4342.2646 - val_loss: 4.3413e-04 - val_mape: 2.4167\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2191e-04 - mape: 1630.7036 - val_loss: 3.5418e-04 - val_mape: 1.9103\n",
      "--- 54/102 Training model for MNST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5527e-04 - mape: 91915.6328 - val_loss: 1.9125e-04 - val_mape: 1.3122\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0027e-04 - mape: 179017.4844 - val_loss: 6.7617e-05 - val_mape: 0.8452\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 305195.4375 - val_loss: 0.0026 - val_mape: 6.2708\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mape: 179503.7500 - val_loss: 1.9657e-04 - val_mape: 1.5311\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4961e-04 - mape: 65519.3945 - val_loss: 4.4238e-05 - val_mape: 0.6244\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1134e-04 - mape: 139941.4062 - val_loss: 3.4259e-05 - val_mape: 0.5711\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7878e-04 - mape: 10333.0986 - val_loss: 3.8157e-05 - val_mape: 0.6032\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0451e-04 - mape: 201824.7188 - val_loss: 7.3246e-05 - val_mape: 0.9729\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8987e-04 - mape: 42991.4453 - val_loss: 3.5808e-05 - val_mape: 0.5859\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4793e-04 - mape: 1366.0470 - val_loss: 2.4982e-04 - val_mape: 1.7435\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6457e-04 - mape: 69318.6641 - val_loss: 2.7392e-05 - val_mape: 0.5015\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6307e-04 - mape: 125974.5000 - val_loss: 8.7871e-05 - val_mape: 0.9995\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7022e-04 - mape: 114827.1562 - val_loss: 5.6464e-05 - val_mape: 0.7475\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0363e-04 - mape: 32258.4941 - val_loss: 3.7328e-05 - val_mape: 0.6450\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2483e-04 - mape: 170422.8906 - val_loss: 5.5266e-05 - val_mape: 0.7265\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0168e-04 - mape: 113386.0078 - val_loss: 3.3046e-05 - val_mape: 0.5322\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1630e-04 - mape: 117692.7109 - val_loss: 7.2595e-05 - val_mape: 0.8665\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2449e-04 - mape: 167145.7031 - val_loss: 2.1872e-05 - val_mape: 0.4085\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4711e-04 - mape: 171326.2656 - val_loss: 1.8667e-04 - val_mape: 1.5103\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1377e-04 - mape: 45637.5430 - val_loss: 4.7149e-05 - val_mape: 0.6788\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 145206.5156 - val_loss: 2.9727e-05 - val_mape: 0.5508\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1838e-04 - mape: 190558.6094 - val_loss: 3.0029e-05 - val_mape: 0.5480\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9787e-04 - mape: 80438.7344 - val_loss: 8.2207e-05 - val_mape: 0.9497\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5773e-04 - mape: 75103.9844 - val_loss: 2.4810e-05 - val_mape: 0.4520\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8096e-04 - mape: 147539.0625 - val_loss: 2.2307e-05 - val_mape: 0.4039\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2160e-04 - mape: 56848.0000 - val_loss: 3.2626e-05 - val_mape: 0.5084\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6694e-04 - mape: 63675.5273 - val_loss: 3.0909e-04 - val_mape: 2.0056\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5316e-04 - mape: 68385.9609 - val_loss: 9.6353e-05 - val_mape: 1.1027\n",
      "--- 55/102 Training model for AMD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 38643.6367 - val_loss: 0.0012 - val_mape: 4.0256\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 37546.6602 - val_loss: 5.2366e-04 - val_mape: 2.3290\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 59132.4180 - val_loss: 5.9087e-04 - val_mape: 2.5161\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 22987.7598 - val_loss: 6.1406e-04 - val_mape: 2.5795\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 60110.7695 - val_loss: 6.0563e-04 - val_mape: 2.6046\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 7657.0054 - val_loss: 4.0438e-04 - val_mape: 2.0816\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 8173.6650 - val_loss: 8.1313e-04 - val_mape: 3.2008\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 6230.0522 - val_loss: 6.6867e-04 - val_mape: 2.8722\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 40856.7656 - val_loss: 5.2068e-04 - val_mape: 2.5168\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 20250.6426 - val_loss: 6.8939e-04 - val_mape: 2.9914\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 39466.9023 - val_loss: 4.0987e-04 - val_mape: 2.2126\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 27017.3730 - val_loss: 4.5120e-04 - val_mape: 2.3751\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 11047.8389 - val_loss: 2.8430e-04 - val_mape: 1.8185\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 39910.8398 - val_loss: 4.0798e-04 - val_mape: 2.2669\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 57457.7852 - val_loss: 4.9962e-04 - val_mape: 2.5666\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 21447.4414 - val_loss: 6.5661e-04 - val_mape: 3.0043\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 36107.3750 - val_loss: 5.7253e-04 - val_mape: 2.7578\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 19053.8496 - val_loss: 6.4336e-04 - val_mape: 2.9825\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 52094.4570 - val_loss: 7.8539e-04 - val_mape: 3.3356\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 7501.9482 - val_loss: 7.1151e-04 - val_mape: 3.1262\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mape: 12107.5811 - val_loss: 4.5788e-04 - val_mape: 2.3824\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 18174.3223 - val_loss: 6.1936e-04 - val_mape: 2.8792\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 37518.8867 - val_loss: 3.9794e-04 - val_mape: 2.2054\n",
      "--- 56/102 Training model for QCOM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 12559.7852 - val_loss: 4.6055e-04 - val_mape: 2.5300\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9209e-04 - mape: 21791.8633 - val_loss: 8.7050e-04 - val_mape: 3.5931\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 37934.8242 - val_loss: 9.2415e-04 - val_mape: 3.5676\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 75176.6797 - val_loss: 0.0018 - val_mape: 5.3389\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 93869.7500 - val_loss: 0.0027 - val_mape: 6.4485\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 68206.8438 - val_loss: 0.0031 - val_mape: 6.8595\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 32154.2344 - val_loss: 0.0044 - val_mape: 8.1993\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mape: 45004.7344 - val_loss: 0.0040 - val_mape: 7.5585\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mape: 40899.0430 - val_loss: 0.0035 - val_mape: 6.7789\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mape: 103296.7891 - val_loss: 0.0023 - val_mape: 5.3529\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mape: 115765.5859 - val_loss: 0.0019 - val_mape: 4.8887\n",
      "--- 57/102 Training model for CCEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3385e-04 - mape: 13.5619 - val_loss: 5.3583e-05 - val_mape: 0.7129\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5040e-04 - mape: 14.3363 - val_loss: 5.6832e-05 - val_mape: 0.7413\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4098e-04 - mape: 10.5967 - val_loss: 4.5413e-05 - val_mape: 0.6216\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4500e-04 - mape: 11.5238 - val_loss: 4.4804e-05 - val_mape: 0.6186\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7041e-04 - mape: 11.0832 - val_loss: 9.9072e-05 - val_mape: 1.0388\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5141e-04 - mape: 10.1920 - val_loss: 1.0142e-04 - val_mape: 1.0366\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9483e-04 - mape: 11.2409 - val_loss: 1.5684e-04 - val_mape: 1.3594\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2662e-04 - mape: 11.5112 - val_loss: 4.6583e-05 - val_mape: 0.6448\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6487e-04 - mape: 10.5573 - val_loss: 1.1239e-04 - val_mape: 1.1476\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7310e-04 - mape: 10.7549 - val_loss: 4.5902e-05 - val_mape: 0.6561\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8304e-04 - mape: 11.1577 - val_loss: 5.2079e-05 - val_mape: 0.7048\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5574e-04 - mape: 10.6629 - val_loss: 3.0213e-05 - val_mape: 0.4984\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3017e-04 - mape: 12.0350 - val_loss: 5.5343e-05 - val_mape: 0.7261\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1096e-04 - mape: 11.7086 - val_loss: 3.7881e-05 - val_mape: 0.5799\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3099e-04 - mape: 10.3072 - val_loss: 3.3582e-05 - val_mape: 0.5483\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5953e-04 - mape: 10.6319 - val_loss: 2.6267e-05 - val_mape: 0.4558\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0455e-04 - mape: 11.5350 - val_loss: 6.1597e-05 - val_mape: 0.7935\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0450e-04 - mape: 11.3316 - val_loss: 2.8410e-05 - val_mape: 0.4798\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6720e-04 - mape: 10.8176 - val_loss: 2.4391e-05 - val_mape: 0.4348\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1072e-04 - mape: 11.1539 - val_loss: 2.9214e-05 - val_mape: 0.4995\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7161e-04 - mape: 11.2692 - val_loss: 5.2298e-05 - val_mape: 0.7211\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2713e-04 - mape: 11.5951 - val_loss: 2.5989e-05 - val_mape: 0.4655\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8997e-04 - mape: 11.3750 - val_loss: 3.1439e-04 - val_mape: 2.0667\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8585e-04 - mape: 11.1802 - val_loss: 2.2823e-04 - val_mape: 1.7402\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3047e-04 - mape: 11.9702 - val_loss: 2.4884e-05 - val_mape: 0.4470\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5440e-04 - mape: 12.1930 - val_loss: 1.0347e-04 - val_mape: 1.1031\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9507e-04 - mape: 11.7980 - val_loss: 1.0002e-04 - val_mape: 1.0764\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1739e-04 - mape: 11.5537 - val_loss: 2.1098e-04 - val_mape: 1.6559\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5263e-04 - mape: 10.3295 - val_loss: 7.1700e-05 - val_mape: 0.8590\n",
      "--- 58/102 Training model for PAYX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1528e-04 - mape: 38819.6797 - val_loss: 7.5102e-05 - val_mape: 0.8034\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1927e-04 - mape: 113595.2422 - val_loss: 2.4443e-05 - val_mape: 0.4165\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5746e-04 - mape: 44577.0977 - val_loss: 2.6808e-05 - val_mape: 0.4446\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0843e-04 - mape: 96036.5312 - val_loss: 1.3370e-04 - val_mape: 1.2249\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8483e-04 - mape: 5601.8862 - val_loss: 4.2427e-04 - val_mape: 2.2684\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 83841.9766 - val_loss: 1.9049e-05 - val_mape: 0.3779\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 4375.2173 - val_loss: 1.0617e-04 - val_mape: 1.0811\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2943e-04 - mape: 133390.7812 - val_loss: 7.1093e-05 - val_mape: 0.8622\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 12485.1152 - val_loss: 6.3772e-05 - val_mape: 0.8138\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6115e-04 - mape: 11548.7158 - val_loss: 3.2000e-04 - val_mape: 1.9560\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 22931.0898 - val_loss: 1.3632e-05 - val_mape: 0.3325\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6178e-04 - mape: 60969.8984 - val_loss: 6.1363e-05 - val_mape: 0.7873\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 95585.2266 - val_loss: 1.0085e-04 - val_mape: 1.0251\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5458e-04 - mape: 30390.0566 - val_loss: 4.4487e-05 - val_mape: 0.6424\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 3938.0300 - val_loss: 1.8963e-04 - val_mape: 1.4804\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 60567.3945 - val_loss: 3.6635e-05 - val_mape: 0.5944\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7387e-04 - mape: 71304.2344 - val_loss: 4.3474e-04 - val_mape: 2.3004\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 55679.8047 - val_loss: 5.7797e-04 - val_mape: 2.6169\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mape: 103981.3359 - val_loss: 4.6391e-05 - val_mape: 0.6893\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 111887.5234 - val_loss: 0.0010 - val_mape: 3.5980\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 13965.5332 - val_loss: 1.9080e-04 - val_mape: 1.5007\n",
      "--- 59/102 Training model for CHTR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5240e-04 - mape: 12.3000 - val_loss: 1.1440e-05 - val_mape: 52114.3672\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3906e-04 - mape: 11.2587 - val_loss: 3.4401e-05 - val_mape: 6578.6772\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9488e-04 - mape: 12.1388 - val_loss: 1.2274e-05 - val_mape: 44491.3047\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6984e-04 - mape: 11.5165 - val_loss: 1.5775e-05 - val_mape: 22355.6074\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4995e-04 - mape: 12.0414 - val_loss: 2.6823e-05 - val_mape: 1588.3761\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7999e-04 - mape: 11.0180 - val_loss: 1.0988e-05 - val_mape: 24016.8477\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5485e-04 - mape: 11.2030 - val_loss: 1.8701e-05 - val_mape: 49939.0977\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8434e-04 - mape: 11.4918 - val_loss: 3.8540e-05 - val_mape: 70113.3125\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5908e-04 - mape: 11.5073 - val_loss: 2.4968e-05 - val_mape: 32075.3145\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1480e-04 - mape: 11.8872 - val_loss: 5.7018e-05 - val_mape: 11914.3467\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0777e-04 - mape: 11.7979 - val_loss: 2.4517e-05 - val_mape: 62005.4922\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9285e-04 - mape: 11.4696 - val_loss: 7.7358e-05 - val_mape: 35070.8359\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4737e-04 - mape: 12.2767 - val_loss: 9.6921e-05 - val_mape: 21504.5859\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0968e-04 - mape: 12.1811 - val_loss: 1.1247e-04 - val_mape: 28982.2695\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1840e-04 - mape: 12.7168 - val_loss: 1.7306e-04 - val_mape: 4529.7148\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 14.8468 - val_loss: 1.2491e-04 - val_mape: 29009.3906\n",
      "--- 60/102 Training model for CTAS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 131.3757 - val_loss: 0.0011 - val_mape: 3.7389\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 213.3907 - val_loss: 9.2553e-05 - val_mape: 0.9101\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 133.5882 - val_loss: 8.2211e-05 - val_mape: 0.9184\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2106e-04 - mape: 146.7877 - val_loss: 1.7175e-04 - val_mape: 1.4694\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6681e-04 - mape: 130.5262 - val_loss: 3.6587e-04 - val_mape: 2.2243\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6256e-04 - mape: 126.7439 - val_loss: 2.1167e-04 - val_mape: 1.6336\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1195e-04 - mape: 110.0334 - val_loss: 8.5486e-05 - val_mape: 0.9598\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8905e-04 - mape: 133.0229 - val_loss: 2.5979e-04 - val_mape: 1.8540\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2724e-04 - mape: 112.7376 - val_loss: 1.3957e-04 - val_mape: 1.2837\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7917e-04 - mape: 116.4800 - val_loss: 1.5465e-04 - val_mape: 1.3866\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8715e-04 - mape: 107.6314 - val_loss: 1.0309e-04 - val_mape: 1.0549\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1102e-04 - mape: 148.1174 - val_loss: 9.2579e-05 - val_mape: 1.0910\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1865e-04 - mape: 114.8931 - val_loss: 2.5207e-04 - val_mape: 1.8566\n",
      "--- 61/102 Training model for GEHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9729e-04 - mape: 4.3632 - val_loss: 4.9989e-05 - val_mape: 0.8620\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8096e-04 - mape: 3.4697 - val_loss: 2.2082e-05 - val_mape: 0.5499\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7441e-04 - mape: 4.3807 - val_loss: 2.0052e-04 - val_mape: 1.8215\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0800e-04 - mape: 3.5426 - val_loss: 2.9101e-05 - val_mape: 0.6277\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4271e-04 - mape: 4.0043 - val_loss: 1.5144e-04 - val_mape: 1.5874\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1956e-04 - mape: 3.2339 - val_loss: 4.3661e-05 - val_mape: 0.7829\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5747e-04 - mape: 3.6301 - val_loss: 2.9235e-05 - val_mape: 0.6167\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3577e-04 - mape: 3.2834 - val_loss: 1.6305e-05 - val_mape: 0.4297\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7149e-04 - mape: 3.6162 - val_loss: 1.0345e-04 - val_mape: 1.3017\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1887e-04 - mape: 3.2067 - val_loss: 3.2664e-05 - val_mape: 0.7142\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7235e-04 - mape: 3.3773 - val_loss: 1.1326e-04 - val_mape: 1.3665\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8382e-04 - mape: 3.1571 - val_loss: 1.8600e-04 - val_mape: 1.7986\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1118e-04 - mape: 3.0816 - val_loss: 2.8665e-04 - val_mape: 2.2208\n",
      "Epoch 14/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1015e-04 - mape: 3.1636 - val_loss: 7.7352e-05 - val_mape: 1.1619\n",
      "Epoch 15/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8190e-04 - mape: 4.2358 - val_loss: 3.9702e-05 - val_mape: 0.7192\n",
      "Epoch 16/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2916e-04 - mape: 3.0020 - val_loss: 4.7201e-05 - val_mape: 0.7990\n",
      "Epoch 17/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5836e-04 - mape: 3.3349 - val_loss: 2.0355e-05 - val_mape: 0.5631\n",
      "Epoch 18/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0191e-04 - mape: 3.2115 - val_loss: 5.6540e-05 - val_mape: 0.9009\n",
      "--- 62/102 Training model for MRVL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 67.2563 - val_loss: 2.7484e-05 - val_mape: 0.5970\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 55.8881 - val_loss: 2.9924e-05 - val_mape: 0.5897\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 58.1224 - val_loss: 6.1779e-04 - val_mape: 3.3202\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 57.6234 - val_loss: 6.2130e-05 - val_mape: 0.9403\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 65.0848 - val_loss: 7.3042e-05 - val_mape: 1.0423\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5284e-04 - mape: 57.8393 - val_loss: 2.2568e-04 - val_mape: 1.9288\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 65.8701 - val_loss: 2.3062e-04 - val_mape: 1.9740\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 62.0356 - val_loss: 8.5157e-05 - val_mape: 1.1229\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 59.1588 - val_loss: 1.2113e-04 - val_mape: 1.4277\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9897e-04 - mape: 55.0131 - val_loss: 8.4703e-05 - val_mape: 1.1242\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 56.8122 - val_loss: 2.0123e-04 - val_mape: 1.8037\n",
      "--- 63/102 Training model for NXPI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2999e-04 - mape: 33645.4258 - val_loss: 6.1296e-04 - val_mape: 2.7632\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0548e-04 - mape: 17523.0684 - val_loss: 5.6150e-04 - val_mape: 2.6706\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7999e-04 - mape: 40883.7188 - val_loss: 6.2480e-04 - val_mape: 2.8080\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8781e-04 - mape: 17484.9824 - val_loss: 7.1702e-05 - val_mape: 0.8998\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6914e-04 - mape: 130.4694 - val_loss: 2.6771e-04 - val_mape: 1.8342\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6584e-04 - mape: 692.4871 - val_loss: 4.0291e-04 - val_mape: 2.2832\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2018e-04 - mape: 9046.6641 - val_loss: 1.6040e-04 - val_mape: 1.3973\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7591e-04 - mape: 8225.9004 - val_loss: 4.2011e-04 - val_mape: 2.3642\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8123e-04 - mape: 20492.2578 - val_loss: 2.0572e-04 - val_mape: 1.6651\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8722e-04 - mape: 5891.1460 - val_loss: 1.8556e-04 - val_mape: 1.5619\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0215e-04 - mape: 8463.8105 - val_loss: 1.8714e-04 - val_mape: 1.4996\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0087e-04 - mape: 2326.4626 - val_loss: 2.0315e-05 - val_mape: 0.4259\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3652e-04 - mape: 257.6322 - val_loss: 3.7430e-05 - val_mape: 0.5654\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4831e-04 - mape: 27057.3438 - val_loss: 1.8026e-05 - val_mape: 0.4210\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9815e-04 - mape: 16612.0859 - val_loss: 3.9647e-05 - val_mape: 0.6547\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9057e-04 - mape: 5303.2910 - val_loss: 1.6711e-04 - val_mape: 1.4967\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9574e-04 - mape: 4549.1343 - val_loss: 5.5455e-04 - val_mape: 2.6592\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9284e-04 - mape: 32176.1230 - val_loss: 2.9120e-05 - val_mape: 0.5862\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7794e-04 - mape: 19756.5059 - val_loss: 3.6645e-04 - val_mape: 2.2016\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3871e-04 - mape: 4801.3716 - val_loss: 7.1972e-05 - val_mape: 0.9534\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2226e-04 - mape: 2221.0859 - val_loss: 1.6850e-04 - val_mape: 1.4783\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0254e-04 - mape: 9196.9951 - val_loss: 2.0982e-04 - val_mape: 1.6244\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7227e-04 - mape: 21285.1875 - val_loss: 1.6831e-04 - val_mape: 1.4301\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0712e-04 - mape: 5480.7104 - val_loss: 2.8076e-04 - val_mape: 1.8852\n",
      "--- 64/102 Training model for TTD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 143.5736 - val_loss: 9.6291e-06 - val_mape: 0.3087\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 140.9888 - val_loss: 1.1437e-04 - val_mape: 1.2451\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mape: 129.3931 - val_loss: 6.9389e-05 - val_mape: 0.8649\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 167.8206 - val_loss: 1.0502e-04 - val_mape: 1.2725\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 164.0969 - val_loss: 0.0016 - val_mape: 4.7173\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 247.4261 - val_loss: 3.0975e-05 - val_mape: 0.5827\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mape: 160.8464 - val_loss: 0.0013 - val_mape: 4.3829\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mape: 198.1730 - val_loss: 1.0724e-04 - val_mape: 1.1265\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mape: 126.8060 - val_loss: 9.6427e-05 - val_mape: 1.1642\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 146.9645 - val_loss: 2.9339e-04 - val_mape: 2.0772\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 122.4486 - val_loss: 1.9852e-04 - val_mape: 1.6694\n",
      "--- 65/102 Training model for BKNG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2177e-04 - mape: 35723.2734 - val_loss: 1.3927e-05 - val_mape: 0.3407\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1492e-04 - mape: 5117.3369 - val_loss: 1.1923e-05 - val_mape: 0.3065\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9585e-04 - mape: 12458.7998 - val_loss: 1.1019e-05 - val_mape: 0.2939\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1307e-04 - mape: 7498.0898 - val_loss: 1.0551e-05 - val_mape: 0.2850\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0403e-04 - mape: 15614.0654 - val_loss: 1.1476e-05 - val_mape: 0.3086\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0133e-04 - mape: 30030.4258 - val_loss: 8.1279e-06 - val_mape: 0.2516\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7015e-04 - mape: 7816.4038 - val_loss: 1.2406e-05 - val_mape: 0.3314\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8068e-04 - mape: 33930.3477 - val_loss: 1.1071e-04 - val_mape: 1.2187\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9545e-04 - mape: 15717.5059 - val_loss: 1.2295e-04 - val_mape: 1.2735\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5820e-04 - mape: 36586.6484 - val_loss: 2.9898e-05 - val_mape: 0.5729\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4142e-04 - mape: 6102.9653 - val_loss: 1.6923e-05 - val_mape: 0.4002\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5989e-04 - mape: 15388.2930 - val_loss: 4.8360e-05 - val_mape: 0.7741\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8452e-04 - mape: 1419.1768 - val_loss: 1.3987e-04 - val_mape: 1.3547\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6006e-04 - mape: 12505.9199 - val_loss: 4.9291e-05 - val_mape: 0.7743\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8353e-04 - mape: 23794.9023 - val_loss: 1.1698e-04 - val_mape: 1.2456\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4358e-04 - mape: 17152.3379 - val_loss: 4.7082e-05 - val_mape: 0.7559\n",
      "--- 66/102 Training model for KDP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 51662.0352 - val_loss: 4.8403e-04 - val_mape: 2.7382\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 81304.3438 - val_loss: 4.5098e-05 - val_mape: 0.7692\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 3791.4072 - val_loss: 4.6230e-05 - val_mape: 0.7233\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 18531.6016 - val_loss: 1.8881e-05 - val_mape: 0.4640\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 58880.4609 - val_loss: 9.6118e-05 - val_mape: 1.0336\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mape: 111801.0234 - val_loss: 4.0314e-04 - val_mape: 2.3517\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 35781.9961 - val_loss: 1.1567e-04 - val_mape: 1.0812\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mape: 16788.3652 - val_loss: 2.9259e-04 - val_mape: 1.9018\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 1853.8251 - val_loss: 1.8442e-04 - val_mape: 1.4849\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mape: 30923.7461 - val_loss: 6.3145e-05 - val_mape: 0.7962\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 69378.3359 - val_loss: 4.6016e-05 - val_mape: 0.7137\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5896e-04 - mape: 4322.0576 - val_loss: 6.9232e-05 - val_mape: 0.8581\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7986e-04 - mape: 40563.2656 - val_loss: 1.0725e-05 - val_mape: 0.3379\n",
      "--- 30/102 Training model for KHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8229e-04 - mape: 2845.6521 - val_loss: 5.2054e-06 - val_mape: 0.5186\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7121e-04 - mape: 1417.4757 - val_loss: 3.3376e-06 - val_mape: 0.4324\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7037e-04 - mape: 1015.5746 - val_loss: 1.1693e-05 - val_mape: 0.8873\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9075e-04 - mape: 37548.1328 - val_loss: 3.6527e-05 - val_mape: 1.6819\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8824e-04 - mape: 3445.4475 - val_loss: 1.2682e-05 - val_mape: 0.8672\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 24714.7871 - val_loss: 2.7331e-05 - val_mape: 1.4400\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7194e-04 - mape: 9676.9854 - val_loss: 4.7685e-05 - val_mape: 1.9348\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 15895.9248 - val_loss: 1.7435e-05 - val_mape: 1.0005\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 32515.3906 - val_loss: 2.8774e-05 - val_mape: 1.2644\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - mape: 647.3506 - val_loss: 2.1832e-05 - val_mape: 1.1483\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - mape: 12198.5801 - val_loss: 1.4749e-05 - val_mape: 0.9300\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 14273.6650 - val_loss: 1.2760e-05 - val_mape: 0.8327\n",
      "--- 31/102 Training model for WBD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6895e-04 - mape: 6.5958 - val_loss: 4.6346e-05 - val_mape: 39580.6484\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9099e-04 - mape: 5.9001 - val_loss: 2.0004e-05 - val_mape: 23274.4668\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2032e-04 - mape: 6.0704 - val_loss: 6.9439e-06 - val_mape: 13937.8086\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6040e-04 - mape: 5.5449 - val_loss: 5.7572e-05 - val_mape: 51917.9883\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7895e-04 - mape: 5.6724 - val_loss: 3.2801e-06 - val_mape: 391.6189\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5791e-04 - mape: 5.5394 - val_loss: 6.2423e-06 - val_mape: 2818.0176\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5031e-04 - mape: 5.4238 - val_loss: 2.5143e-06 - val_mape: 9634.4082\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3509e-04 - mape: 5.2046 - val_loss: 7.3649e-06 - val_mape: 23381.6934\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4286e-04 - mape: 5.1910 - val_loss: 1.6739e-06 - val_mape: 14764.1611\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2273e-04 - mape: 5.2295 - val_loss: 2.4193e-06 - val_mape: 12073.7910\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3698e-04 - mape: 5.2139 - val_loss: 4.2652e-05 - val_mape: 48179.6133\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7913e-04 - mape: 4.5171 - val_loss: 7.7607e-06 - val_mape: 25420.0664\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1250e-04 - mape: 4.9913 - val_loss: 1.7722e-05 - val_mape: 9443.3955\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9588e-04 - mape: 4.8296 - val_loss: 3.8441e-06 - val_mape: 21591.6250\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5494e-04 - mape: 4.2192 - val_loss: 1.8947e-05 - val_mape: 34574.7109\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5698e-04 - mape: 4.1585 - val_loss: 1.3546e-05 - val_mape: 29089.2383\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5884e-04 - mape: 4.2090 - val_loss: 5.1355e-06 - val_mape: 21627.2051\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6628e-04 - mape: 4.3246 - val_loss: 1.4906e-06 - val_mape: 7454.1743\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6615e-04 - mape: 4.2933 - val_loss: 4.7388e-06 - val_mape: 24846.8789\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7335e-04 - mape: 4.2472 - val_loss: 3.8668e-05 - val_mape: 39850.8281\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5328e-04 - mape: 4.1039 - val_loss: 4.8050e-06 - val_mape: 26894.3594\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8883e-04 - mape: 4.5223 - val_loss: 3.1151e-05 - val_mape: 39745.5117\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3711e-04 - mape: 3.8140 - val_loss: 3.1939e-06 - val_mape: 19484.7988\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4990e-04 - mape: 4.1175 - val_loss: 5.5848e-06 - val_mape: 22885.6855\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0869e-04 - mape: 3.4742 - val_loss: 6.5386e-06 - val_mape: 29398.5312\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4225e-04 - mape: 3.8997 - val_loss: 2.4806e-06 - val_mape: 1735.3326\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1886e-04 - mape: 3.5636 - val_loss: 9.5215e-06 - val_mape: 35278.3125\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7262e-04 - mape: 4.2839 - val_loss: 2.6294e-05 - val_mape: 31062.6621\n",
      "--- 32/102 Training model for ROP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6848e-04 - mape: 12.9092 - val_loss: 1.2165e-04 - val_mape: 1.0926\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5025e-04 - mape: 12.5212 - val_loss: 2.0106e-05 - val_mape: 0.3820\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9972e-04 - mape: 13.9166 - val_loss: 2.8380e-05 - val_mape: 0.4799\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2486e-04 - mape: 20.1204 - val_loss: 4.2520e-05 - val_mape: 0.6440\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1040e-04 - mape: 13.0631 - val_loss: 1.7448e-05 - val_mape: 0.3362\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4555e-04 - mape: 20.0042 - val_loss: 2.3031e-05 - val_mape: 0.4016\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1238e-04 - mape: 23.1551 - val_loss: 7.0326e-05 - val_mape: 0.8031\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 28.0121 - val_loss: 2.4523e-05 - val_mape: 0.4111\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 23.6341 - val_loss: 0.0015 - val_mape: 4.2146\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 44.5464 - val_loss: 3.4594e-05 - val_mape: 0.5132\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 32.6950 - val_loss: 0.0019 - val_mape: 4.7772\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 43.4032 - val_loss: 4.0783e-05 - val_mape: 0.5694\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 34.1655 - val_loss: 0.0024 - val_mape: 5.3130\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 44.6673 - val_loss: 2.9215e-04 - val_mape: 1.7968\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9088e-04 - mape: 25.4334 - val_loss: 3.2686e-04 - val_mape: 1.9104\n",
      "--- 33/102 Training model for BKR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9776e-04 - mape: 40715.8906 - val_loss: 7.1494e-05 - val_mape: 0.8916\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9441e-04 - mape: 25008.6484 - val_loss: 5.2552e-05 - val_mape: 0.7676\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2007e-04 - mape: 10443.0830 - val_loss: 3.9307e-05 - val_mape: 0.6757\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6292e-04 - mape: 20339.8418 - val_loss: 9.7957e-06 - val_mape: 0.2959\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1827e-04 - mape: 23288.5586 - val_loss: 2.0305e-05 - val_mape: 0.5246\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4733e-04 - mape: 15717.9648 - val_loss: 4.8165e-06 - val_mape: 0.2069\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2012e-04 - mape: 2471.3423 - val_loss: 1.0538e-05 - val_mape: 0.3387\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3989e-04 - mape: 21354.8301 - val_loss: 1.1666e-05 - val_mape: 0.3269\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2069e-04 - mape: 8379.1592 - val_loss: 3.3154e-05 - val_mape: 0.6852\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9653e-04 - mape: 10979.6738 - val_loss: 1.0356e-05 - val_mape: 0.3106\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4898e-04 - mape: 14112.3223 - val_loss: 2.0086e-05 - val_mape: 0.5118\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6741e-04 - mape: 11262.3457 - val_loss: 1.4784e-04 - val_mape: 1.4392\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9565e-04 - mape: 2059.6689 - val_loss: 6.5021e-05 - val_mape: 0.9744\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9537e-04 - mape: 14216.5039 - val_loss: 6.5155e-05 - val_mape: 0.8835\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8343e-04 - mape: 7448.6294 - val_loss: 3.5239e-05 - val_mape: 0.6432\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3841e-04 - mape: 45623.1914 - val_loss: 9.5034e-06 - val_mape: 0.3351\n",
      "--- 34/102 Training model for COST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6300e-04 - mape: 21266.8418 - val_loss: 1.6752e-04 - val_mape: 1.4496\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9332e-04 - mape: 20090.7871 - val_loss: 5.2045e-05 - val_mape: 0.7323\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5107e-04 - mape: 35074.5625 - val_loss: 2.7171e-05 - val_mape: 0.4884\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6778e-04 - mape: 150.3457 - val_loss: 3.0100e-05 - val_mape: 0.5226\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1859e-04 - mape: 61836.2773 - val_loss: 4.9987e-05 - val_mape: 0.7097\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3401e-04 - mape: 20161.5703 - val_loss: 9.4324e-05 - val_mape: 1.0394\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3933e-04 - mape: 22589.1504 - val_loss: 4.2574e-05 - val_mape: 0.6315\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6116e-04 - mape: 12080.0518 - val_loss: 2.5707e-05 - val_mape: 0.4842\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1266e-04 - mape: 64047.8633 - val_loss: 1.1392e-04 - val_mape: 1.1599\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3530e-04 - mape: 21998.7598 - val_loss: 5.7308e-05 - val_mape: 0.7718\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6860e-04 - mape: 46176.1250 - val_loss: 2.6494e-05 - val_mape: 0.5000\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2762e-04 - mape: 1690.5842 - val_loss: 3.2541e-04 - val_mape: 2.0289\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5577e-04 - mape: 24158.7988 - val_loss: 2.1985e-05 - val_mape: 0.4358\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1106e-04 - mape: 16051.5645 - val_loss: 2.4645e-04 - val_mape: 1.7747\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2619e-04 - mape: 113046.9766 - val_loss: 5.0341e-05 - val_mape: 0.6943\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3585e-04 - mape: 75195.9375 - val_loss: 1.9088e-05 - val_mape: 0.3993\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8605e-04 - mape: 90611.2812 - val_loss: 1.4648e-04 - val_mape: 1.3089\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4367e-04 - mape: 31365.9180 - val_loss: 2.5924e-05 - val_mape: 0.4964\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3770e-04 - mape: 36291.6289 - val_loss: 1.4016e-04 - val_mape: 1.3055\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3682e-04 - mape: 42720.2344 - val_loss: 9.4327e-05 - val_mape: 1.0386\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1472e-04 - mape: 63259.5547 - val_loss: 7.2379e-04 - val_mape: 3.1286\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3236e-04 - mape: 2292.4734 - val_loss: 1.2751e-04 - val_mape: 1.1627\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6805e-04 - mape: 17801.9727 - val_loss: 3.9687e-05 - val_mape: 0.6699\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5342e-04 - mape: 4544.3237 - val_loss: 1.9857e-04 - val_mape: 1.4847\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6703e-04 - mape: 28874.6914 - val_loss: 2.1223e-05 - val_mape: 0.4092\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3935e-04 - mape: 29544.8008 - val_loss: 4.1323e-04 - val_mape: 2.3685\n",
      "--- 35/102 Training model for AZN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5629e-04 - mape: 16.3040 - val_loss: 2.8702e-05 - val_mape: 0.6056\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5972e-04 - mape: 18.6386 - val_loss: 3.6580e-04 - val_mape: 2.3170\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4873e-04 - mape: 16.1171 - val_loss: 4.4446e-05 - val_mape: 0.8141\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8743e-04 - mape: 21.2813 - val_loss: 2.0291e-04 - val_mape: 1.6118\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1426e-04 - mape: 16.4720 - val_loss: 1.1959e-04 - val_mape: 0.9879\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7546e-04 - mape: 21.8480 - val_loss: 3.4485e-05 - val_mape: 0.5526\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5448e-04 - mape: 15.9308 - val_loss: 2.3768e-05 - val_mape: 0.5509\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7550e-04 - mape: 18.0905 - val_loss: 1.4475e-05 - val_mape: 0.3908\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6214e-04 - mape: 21.6244 - val_loss: 1.4666e-04 - val_mape: 1.1545\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1510e-04 - mape: 18.8694 - val_loss: 1.8362e-05 - val_mape: 0.4720\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5484e-04 - mape: 17.0166 - val_loss: 4.8148e-05 - val_mape: 0.6972\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8505e-04 - mape: 18.7650 - val_loss: 3.0027e-05 - val_mape: 0.5175\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3790e-04 - mape: 15.9977 - val_loss: 2.2670e-04 - val_mape: 1.8051\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1830e-04 - mape: 19.7384 - val_loss: 2.1520e-04 - val_mape: 1.4012\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3380e-04 - mape: 22.4059 - val_loss: 1.3494e-04 - val_mape: 1.0295\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5068e-04 - mape: 20.6663 - val_loss: 6.0235e-05 - val_mape: 0.6924\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3960e-04 - mape: 18.2595 - val_loss: 8.2430e-05 - val_mape: 1.1305\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0216e-04 - mape: 20.6155 - val_loss: 1.1441e-05 - val_mape: 0.3655\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0975e-04 - mape: 21.0596 - val_loss: 2.6665e-05 - val_mape: 0.6166\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4613e-04 - mape: 16.8427 - val_loss: 5.1369e-05 - val_mape: 0.7090\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4069e-04 - mape: 16.6450 - val_loss: 1.6633e-04 - val_mape: 1.6858\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9090e-04 - mape: 18.9808 - val_loss: 1.6005e-05 - val_mape: 0.4497\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4106e-04 - mape: 25.0877 - val_loss: 7.0385e-05 - val_mape: 1.0344\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4774e-04 - mape: 23.4992 - val_loss: 2.4492e-05 - val_mape: 0.5037\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2629e-04 - mape: 22.0078 - val_loss: 2.9898e-05 - val_mape: 0.6721\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4709e-04 - mape: 23.4160 - val_loss: 1.0456e-05 - val_mape: 0.3300\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8611e-04 - mape: 18.0951 - val_loss: 3.0822e-05 - val_mape: 0.6783\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2217e-04 - mape: 17.9479 - val_loss: 8.3301e-06 - val_mape: 0.2821\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8860e-04 - mape: 20.8048 - val_loss: 2.0638e-05 - val_mape: 0.4578\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9514e-04 - mape: 17.7379 - val_loss: 1.9457e-05 - val_mape: 0.4933\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0456e-04 - mape: 19.9339 - val_loss: 1.7282e-05 - val_mape: 0.4847\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9403e-04 - mape: 18.6251 - val_loss: 1.2084e-05 - val_mape: 0.3843\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9184e-04 - mape: 18.0773 - val_loss: 2.5894e-05 - val_mape: 0.4731\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6422e-04 - mape: 17.0961 - val_loss: 2.7135e-05 - val_mape: 0.6427\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7360e-04 - mape: 17.9653 - val_loss: 1.8847e-04 - val_mape: 1.5801\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0933e-04 - mape: 19.3551 - val_loss: 2.2048e-05 - val_mape: 0.4485\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6081e-04 - mape: 16.8974 - val_loss: 9.1946e-05 - val_mape: 0.8346\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4165e-04 - mape: 19.1945 - val_loss: 3.0653e-05 - val_mape: 0.5588\n",
      "--- 36/102 Training model for LRCX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2734e-04 - mape: 51.9642 - val_loss: 4.7678e-05 - val_mape: 0.7505\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5453e-04 - mape: 48.0668 - val_loss: 5.1198e-05 - val_mape: 0.7348\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7207e-04 - mape: 50.2812 - val_loss: 2.0321e-04 - val_mape: 1.7756\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 96.3371 - val_loss: 0.0068 - val_mape: 10.2602\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 105.6880 - val_loss: 2.0277e-04 - val_mape: 1.3725\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9739e-04 - mape: 66.0970 - val_loss: 0.0055 - val_mape: 9.2504\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 101.7174 - val_loss: 1.1133e-04 - val_mape: 0.9732\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0444e-04 - mape: 56.8375 - val_loss: 8.1672e-04 - val_mape: 3.5359\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8541e-04 - mape: 57.9928 - val_loss: 2.6960e-04 - val_mape: 1.6828\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7210e-04 - mape: 47.6285 - val_loss: 5.2072e-04 - val_mape: 2.8252\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3980e-04 - mape: 52.9657 - val_loss: 4.8714e-05 - val_mape: 0.7011\n",
      "--- 37/102 Training model for MELI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8106e-04 - mape: 29.0670 - val_loss: 7.3296e-05 - val_mape: 0.9092\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 41.1103 - val_loss: 0.0011 - val_mape: 4.0194\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - mape: 97.9162 - val_loss: 0.0083 - val_mape: 11.2458\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mape: 86.7126 - val_loss: 7.1445e-05 - val_mape: 0.9911\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6606e-04 - mape: 27.8591 - val_loss: 1.0576e-05 - val_mape: 0.3244\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3769e-04 - mape: 27.3254 - val_loss: 6.0026e-05 - val_mape: 0.8945\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3761e-04 - mape: 28.0309 - val_loss: 1.6772e-05 - val_mape: 0.4225\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9191e-04 - mape: 26.5128 - val_loss: 6.3278e-05 - val_mape: 0.9420\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7033e-04 - mape: 30.2175 - val_loss: 1.1238e-05 - val_mape: 0.3341\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1208e-04 - mape: 27.5447 - val_loss: 2.1240e-05 - val_mape: 0.4524\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3677e-04 - mape: 28.4510 - val_loss: 9.3635e-05 - val_mape: 1.1533\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3568e-04 - mape: 28.7662 - val_loss: 1.6378e-05 - val_mape: 0.3951\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3475e-04 - mape: 35.2464 - val_loss: 4.9909e-04 - val_mape: 2.7336\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0442e-04 - mape: 38.6571 - val_loss: 1.3366e-05 - val_mape: 0.3540\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4058e-04 - mape: 34.3667 - val_loss: 4.4409e-04 - val_mape: 2.5940\n",
      "--- 38/102 Training model for CDW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5759e-04 - mape: 24.6388 - val_loss: 3.6466e-04 - val_mape: 2.1116\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.6749e-04 - mape: 39.2440 - val_loss: 2.3112e-04 - val_mape: 1.6883\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6687e-04 - mape: 32.3140 - val_loss: 2.6434e-05 - val_mape: 0.4298\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6836e-04 - mape: 26.4570 - val_loss: 7.7050e-05 - val_mape: 0.9517\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1451e-04 - mape: 25.6759 - val_loss: 1.0517e-04 - val_mape: 1.1246\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3891e-04 - mape: 25.3949 - val_loss: 4.1849e-05 - val_mape: 0.6690\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1926e-04 - mape: 23.2105 - val_loss: 7.9566e-05 - val_mape: 0.9715\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5171e-04 - mape: 27.1126 - val_loss: 2.7099e-04 - val_mape: 1.8498\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6097e-04 - mape: 31.2607 - val_loss: 3.5659e-05 - val_mape: 0.5941\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1130e-04 - mape: 28.2421 - val_loss: 2.8752e-04 - val_mape: 1.9126\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1591e-04 - mape: 29.2614 - val_loss: 3.6169e-05 - val_mape: 0.6129\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1748e-04 - mape: 26.0934 - val_loss: 3.6111e-05 - val_mape: 0.6029\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2921e-04 - mape: 28.0830 - val_loss: 2.9748e-04 - val_mape: 1.9469\n",
      "--- 39/102 Training model for FANG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1564e-04 - mape: 11544.6797 - val_loss: 1.7127e-05 - val_mape: 0.3695\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5257e-05 - mape: 2955.3149 - val_loss: 3.9486e-05 - val_mape: 0.6058\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0482e-04 - mape: 12374.6133 - val_loss: 1.7563e-04 - val_mape: 1.3086\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2538e-04 - mape: 9026.3154 - val_loss: 4.7679e-05 - val_mape: 0.7212\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0116e-04 - mape: 25138.1641 - val_loss: 2.2549e-05 - val_mape: 0.4005\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0556e-04 - mape: 2161.8684 - val_loss: 3.9813e-05 - val_mape: 0.5961\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0242e-04 - mape: 5856.0151 - val_loss: 2.1920e-05 - val_mape: 0.4316\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9038e-05 - mape: 3961.0474 - val_loss: 3.3526e-05 - val_mape: 0.5597\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0221e-04 - mape: 34257.3203 - val_loss: 2.0381e-05 - val_mape: 0.4468\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0882e-04 - mape: 12963.6963 - val_loss: 1.1443e-04 - val_mape: 1.0094\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5216e-04 - mape: 8121.8218 - val_loss: 6.0301e-05 - val_mape: 0.8561\n",
      "--- 40/102 Training model for ZS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8992e-04 - mape: 8342.2764 - val_loss: 1.0454e-04 - val_mape: 1.8543\n",
      "Epoch 2/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0422e-04 - mape: 69315.0703 - val_loss: 9.8491e-06 - val_mape: 0.4631\n",
      "Epoch 3/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2727e-04 - mape: 31880.2520 - val_loss: 2.3503e-05 - val_mape: 0.8920\n",
      "Epoch 4/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0331e-04 - mape: 23471.6875 - val_loss: 5.8252e-06 - val_mape: 0.3764\n",
      "Epoch 5/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6977e-04 - mape: 37271.0742 - val_loss: 8.8788e-06 - val_mape: 0.4803\n",
      "Epoch 6/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0229e-04 - mape: 65294.7422 - val_loss: 7.9333e-05 - val_mape: 1.6049\n",
      "Epoch 7/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6399e-04 - mape: 76915.6094 - val_loss: 3.3761e-05 - val_mape: 1.1087\n",
      "Epoch 8/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4272e-04 - mape: 43217.5039 - val_loss: 1.6512e-05 - val_mape: 0.6621\n",
      "Epoch 9/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3401e-04 - mape: 38102.2500 - val_loss: 3.4555e-04 - val_mape: 3.4235\n",
      "Epoch 10/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4722e-04 - mape: 82798.6172 - val_loss: 3.9017e-05 - val_mape: 0.8920\n",
      "Epoch 11/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3049e-04 - mape: 43533.4062 - val_loss: 6.5669e-04 - val_mape: 4.8734\n",
      "Epoch 12/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1984e-04 - mape: 159155.5938 - val_loss: 2.2242e-05 - val_mape: 0.7097\n",
      "Epoch 13/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4324e-04 - mape: 98777.2266 - val_loss: 5.2652e-05 - val_mape: 1.3678\n",
      "Epoch 14/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1788e-04 - mape: 11062.4326 - val_loss: 1.3507e-04 - val_mape: 2.1441\n",
      "--- 41/102 Training model for ADBE ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2001e-04 - mape: 18.9349 - val_loss: 7.4074e-05 - val_mape: 1.0217\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3345e-04 - mape: 18.1524 - val_loss: 1.2632e-04 - val_mape: 1.4439\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7827e-04 - mape: 21.3661 - val_loss: 0.0010 - val_mape: 3.9228\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mape: 48.2282 - val_loss: 3.2064e-04 - val_mape: 2.3066\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mape: 30.4667 - val_loss: 0.0089 - val_mape: 11.9651\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - mape: 74.1769 - val_loss: 8.9123e-05 - val_mape: 1.0515\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8409e-04 - mape: 23.5303 - val_loss: 9.8428e-04 - val_mape: 3.9993\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1425e-04 - mape: 24.2136 - val_loss: 3.2047e-05 - val_mape: 0.5628\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4712e-04 - mape: 18.7384 - val_loss: 2.6531e-05 - val_mape: 0.5027\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4319e-04 - mape: 19.0803 - val_loss: 2.4731e-04 - val_mape: 1.9654\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8439e-04 - mape: 21.5252 - val_loss: 2.2297e-05 - val_mape: 0.4614\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7438e-04 - mape: 20.7700 - val_loss: 2.4241e-05 - val_mape: 0.5020\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6470e-04 - mape: 21.0336 - val_loss: 3.7423e-05 - val_mape: 0.6564\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1163e-04 - mape: 18.3381 - val_loss: 5.6631e-05 - val_mape: 0.8444\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8736e-04 - mape: 17.3714 - val_loss: 2.4326e-05 - val_mape: 0.4846\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3532e-04 - mape: 24.7385 - val_loss: 4.4735e-04 - val_mape: 2.7144\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8318e-04 - mape: 21.6707 - val_loss: 2.4401e-05 - val_mape: 0.4883\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5475e-04 - mape: 19.5649 - val_loss: 4.1533e-04 - val_mape: 2.5966\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5496e-04 - mape: 20.2408 - val_loss: 2.1853e-05 - val_mape: 0.4615\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4679e-04 - mape: 20.1579 - val_loss: 4.1975e-05 - val_mape: 0.7019\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9667e-04 - mape: 18.2159 - val_loss: 2.4386e-05 - val_mape: 0.4937\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0529e-04 - mape: 21.1518 - val_loss: 3.4891e-04 - val_mape: 2.3740\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2024e-04 - mape: 20.9361 - val_loss: 1.1039e-04 - val_mape: 1.1215\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4620e-04 - mape: 28.0558 - val_loss: 0.0028 - val_mape: 6.8125\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 36.5479 - val_loss: 6.9884e-05 - val_mape: 0.9006\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8863e-04 - mape: 24.4537 - val_loss: 8.2760e-04 - val_mape: 3.7157\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1279e-04 - mape: 24.7090 - val_loss: 3.4401e-05 - val_mape: 0.6094\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6885e-04 - mape: 20.2287 - val_loss: 3.7221e-04 - val_mape: 2.4556\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8812e-04 - mape: 20.4449 - val_loss: 4.6641e-05 - val_mape: 0.7005\n",
      "--- 42/102 Training model for GOOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0888e-04 - mape: 39.7462 - val_loss: 8.0407e-04 - val_mape: 3.3379\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1284e-04 - mape: 46.5917 - val_loss: 2.5807e-04 - val_mape: 1.7772\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0666e-04 - mape: 39.4312 - val_loss: 3.9206e-04 - val_mape: 2.2531\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3043e-04 - mape: 44.6411 - val_loss: 2.0341e-04 - val_mape: 1.5089\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3387e-04 - mape: 42.2493 - val_loss: 2.5655e-04 - val_mape: 1.7267\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7213e-04 - mape: 41.7400 - val_loss: 3.7881e-04 - val_mape: 2.1564\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1280e-04 - mape: 54.2230 - val_loss: 2.5821e-04 - val_mape: 1.6275\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2176e-04 - mape: 51.0187 - val_loss: 3.1761e-04 - val_mape: 1.8361\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 59.4456 - val_loss: 2.5557e-04 - val_mape: 1.5061\n",
      "Epoch 10/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5866e-04 - mape: 26854.6484 - val_loss: 4.9042e-06 - val_mape: 0.8211\n",
      "Epoch 8/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9379e-04 - mape: 10022.2920 - val_loss: 1.4451e-05 - val_mape: 1.5708\n",
      "Epoch 9/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9223e-04 - mape: 25383.9492 - val_loss: 1.9238e-05 - val_mape: 1.9948\n",
      "Epoch 10/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5443e-04 - mape: 28293.3711 - val_loss: 6.0809e-06 - val_mape: 0.9460\n",
      "Epoch 11/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5521e-04 - mape: 74836.9688 - val_loss: 6.7479e-05 - val_mape: 3.9611\n",
      "Epoch 12/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9670e-04 - mape: 48911.5352 - val_loss: 3.5358e-05 - val_mape: 2.7915\n",
      "Epoch 13/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1415e-04 - mape: 54164.2305 - val_loss: 6.4269e-05 - val_mape: 3.7070\n",
      "Epoch 14/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0225e-04 - mape: 37601.5039 - val_loss: 1.9268e-05 - val_mape: 1.9178\n",
      "Epoch 15/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0868e-04 - mape: 27560.2422 - val_loss: 6.0746e-06 - val_mape: 0.9545\n",
      "Epoch 16/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5115e-04 - mape: 21302.7422 - val_loss: 1.3889e-05 - val_mape: 1.5968\n",
      "Epoch 17/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9491e-04 - mape: 21334.9121 - val_loss: 7.4446e-05 - val_mape: 3.8705\n",
      "--- 53/102 Training model for META ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5250e-04 - mape: 223.0427 - val_loss: 1.1111e-04 - val_mape: 0.9600\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5066e-04 - mape: 3310.0994 - val_loss: 1.3813e-04 - val_mape: 1.2047\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8350e-04 - mape: 90.6423 - val_loss: 8.6665e-05 - val_mape: 0.9753\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3946e-04 - mape: 5027.4023 - val_loss: 2.8293e-05 - val_mape: 0.4692\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3054e-04 - mape: 5276.9351 - val_loss: 9.2855e-05 - val_mape: 1.0464\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3806e-04 - mape: 5523.6377 - val_loss: 3.0454e-05 - val_mape: 0.5168\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3828e-04 - mape: 3492.3550 - val_loss: 7.6472e-05 - val_mape: 0.9404\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6844e-04 - mape: 8158.1895 - val_loss: 3.2304e-05 - val_mape: 0.5453\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4102e-04 - mape: 2712.4429 - val_loss: 6.2893e-05 - val_mape: 0.8285\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9943e-04 - mape: 2697.9470 - val_loss: 4.8872e-05 - val_mape: 0.6254\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8286e-04 - mape: 1703.8029 - val_loss: 5.5259e-05 - val_mape: 0.7228\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6332e-04 - mape: 3283.3503 - val_loss: 4.1167e-05 - val_mape: 0.5407\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5642e-04 - mape: 1012.1228 - val_loss: 6.8595e-05 - val_mape: 0.8108\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7761e-04 - mape: 601.2333 - val_loss: 3.3331e-05 - val_mape: 0.4604\n",
      "--- 54/102 Training model for MNST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2439e-04 - mape: 69736.9531 - val_loss: 5.4375e-04 - val_mape: 2.7340\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9878e-04 - mape: 69466.5781 - val_loss: 3.9786e-05 - val_mape: 0.5819\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6045e-04 - mape: 80337.8125 - val_loss: 7.6027e-05 - val_mape: 0.8768\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4043e-04 - mape: 15847.3037 - val_loss: 1.7967e-05 - val_mape: 0.3631\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9901e-04 - mape: 9482.3613 - val_loss: 2.4507e-05 - val_mape: 0.4555\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0337e-04 - mape: 162205.6875 - val_loss: 2.0191e-04 - val_mape: 1.5839\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0617e-04 - mape: 53588.1211 - val_loss: 4.7887e-05 - val_mape: 0.6449\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8535e-04 - mape: 92436.0547 - val_loss: 4.8182e-05 - val_mape: 0.6712\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0997e-04 - mape: 75098.9375 - val_loss: 4.1903e-04 - val_mape: 2.3224\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8034e-04 - mape: 30940.5117 - val_loss: 1.7419e-04 - val_mape: 1.4079\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9275e-04 - mape: 13942.4248 - val_loss: 6.7165e-05 - val_mape: 0.7988\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9138e-04 - mape: 7964.2920 - val_loss: 2.8721e-05 - val_mape: 0.5035\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2657e-04 - mape: 55219.1680 - val_loss: 3.2791e-05 - val_mape: 0.5340\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5649e-04 - mape: 86082.6328 - val_loss: 1.1209e-04 - val_mape: 1.2052\n",
      "--- 55/102 Training model for AMD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7250e-04 - mape: 30095.3652 - val_loss: 4.7406e-04 - val_mape: 2.2891\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4622e-04 - mape: 7313.6069 - val_loss: 3.5105e-04 - val_mape: 1.9885\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8344e-04 - mape: 12700.3291 - val_loss: 3.4984e-04 - val_mape: 1.9904\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6909e-04 - mape: 26378.4102 - val_loss: 2.2100e-04 - val_mape: 1.5614\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7793e-04 - mape: 57259.5547 - val_loss: 1.8922e-04 - val_mape: 1.4495\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2425e-04 - mape: 11257.4883 - val_loss: 1.9922e-04 - val_mape: 1.4970\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8783e-04 - mape: 38288.3086 - val_loss: 1.7259e-04 - val_mape: 1.3238\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8824e-04 - mape: 10407.4805 - val_loss: 3.3568e-04 - val_mape: 2.0145\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4935e-04 - mape: 44772.4414 - val_loss: 1.7461e-04 - val_mape: 1.3310\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3365e-04 - mape: 23910.8906 - val_loss: 3.6022e-04 - val_mape: 2.1136\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6461e-04 - mape: 3946.7437 - val_loss: 1.8922e-04 - val_mape: 1.3367\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4681e-04 - mape: 15545.4727 - val_loss: 1.9816e-04 - val_mape: 1.3957\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7501e-04 - mape: 16101.2598 - val_loss: 1.9993e-04 - val_mape: 1.3767\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9935e-04 - mape: 18403.8027 - val_loss: 2.2484e-04 - val_mape: 1.4713\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9520e-04 - mape: 18535.7832 - val_loss: 2.3719e-04 - val_mape: 1.4959\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0392e-04 - mape: 13591.9307 - val_loss: 3.6188e-04 - val_mape: 2.0129\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8284e-04 - mape: 7255.7280 - val_loss: 2.4568e-04 - val_mape: 1.5077\n",
      "--- 56/102 Training model for QCOM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2970e-04 - mape: 26586.9785 - val_loss: 3.0088e-04 - val_mape: 1.8872\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8020e-04 - mape: 15388.6182 - val_loss: 1.3489e-04 - val_mape: 1.1362\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7959e-04 - mape: 36732.7539 - val_loss: 1.1390e-04 - val_mape: 1.0246\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2950e-04 - mape: 4121.5479 - val_loss: 8.3863e-05 - val_mape: 0.8600\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9357e-04 - mape: 6538.5093 - val_loss: 8.8360e-05 - val_mape: 0.9634\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7233e-04 - mape: 40825.5430 - val_loss: 7.4757e-05 - val_mape: 0.9416\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5521e-04 - mape: 31172.2246 - val_loss: 9.8001e-05 - val_mape: 1.0248\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0564e-04 - mape: 1604.7106 - val_loss: 1.1077e-04 - val_mape: 1.0566\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0094e-04 - mape: 7287.5083 - val_loss: 5.1459e-05 - val_mape: 0.7446\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4599e-04 - mape: 6643.1226 - val_loss: 4.6278e-04 - val_mape: 2.7283\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0716e-04 - mape: 25682.2969 - val_loss: 1.2439e-04 - val_mape: 1.1185\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1030e-04 - mape: 35497.9531 - val_loss: 3.7421e-04 - val_mape: 2.3924\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2777e-04 - mape: 21420.8809 - val_loss: 2.7610e-04 - val_mape: 1.9640\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9712e-04 - mape: 90437.2188 - val_loss: 3.6619e-04 - val_mape: 2.2805\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8592e-04 - mape: 12884.9795 - val_loss: 6.4245e-04 - val_mape: 3.0094\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9461e-04 - mape: 20399.8770 - val_loss: 7.7032e-04 - val_mape: 3.1794\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9505e-04 - mape: 30799.0312 - val_loss: 3.7683e-04 - val_mape: 2.2003\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9523e-04 - mape: 37497.0938 - val_loss: 3.9772e-04 - val_mape: 2.4771\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7775e-04 - mape: 27823.2109 - val_loss: 5.2006e-04 - val_mape: 2.7720\n",
      "--- 57/102 Training model for CCEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6308e-04 - mape: 6.8531 - val_loss: 1.3939e-04 - val_mape: 1.3757\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6626e-04 - mape: 7.0017 - val_loss: 1.2740e-04 - val_mape: 1.3150\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8433e-04 - mape: 7.4924 - val_loss: 5.4438e-04 - val_mape: 2.8358\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1101e-04 - mape: 7.7930 - val_loss: 1.1805e-04 - val_mape: 1.2560\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9765e-04 - mape: 10.1276 - val_loss: 3.9594e-04 - val_mape: 2.3780\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8189e-04 - mape: 7.1467 - val_loss: 4.1617e-05 - val_mape: 0.6303\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8653e-04 - mape: 7.4855 - val_loss: 2.7080e-05 - val_mape: 0.4728\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1435e-04 - mape: 8.2564 - val_loss: 4.3582e-04 - val_mape: 2.5254\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2062e-04 - mape: 8.5207 - val_loss: 1.2771e-05 - val_mape: 0.2881\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7418e-04 - mape: 7.0569 - val_loss: 2.4198e-05 - val_mape: 0.5247\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9471e-04 - mape: 9.9560 - val_loss: 1.9979e-05 - val_mape: 0.4408\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3470e-04 - mape: 9.0023 - val_loss: 1.7296e-05 - val_mape: 0.3845\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9246e-04 - mape: 7.7753 - val_loss: 2.2350e-05 - val_mape: 0.4275\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7724e-04 - mape: 7.4647 - val_loss: 1.9136e-04 - val_mape: 1.6591\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6905e-04 - mape: 7.1185 - val_loss: 2.9190e-04 - val_mape: 2.0758\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5365e-04 - mape: 9.0482 - val_loss: 2.8251e-05 - val_mape: 0.5140\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3647e-04 - mape: 8.7042 - val_loss: 2.6399e-05 - val_mape: 0.5033\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1013e-04 - mape: 8.4026 - val_loss: 2.8647e-04 - val_mape: 2.0390\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9457e-04 - mape: 7.8239 - val_loss: 1.5407e-05 - val_mape: 0.3351\n",
      "--- 58/102 Training model for PAYX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1509e-04 - mape: 20025.2637 - val_loss: 3.6617e-05 - val_mape: 0.5542\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9317e-04 - mape: 11149.4854 - val_loss: 4.4887e-05 - val_mape: 0.6220\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8467e-04 - mape: 10432.8369 - val_loss: 2.3512e-05 - val_mape: 0.4367\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3716e-04 - mape: 6783.6528 - val_loss: 3.9000e-05 - val_mape: 0.6168\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0480e-04 - mape: 46589.0938 - val_loss: 5.5220e-05 - val_mape: 0.7739\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8203e-04 - mape: 65768.5781 - val_loss: 1.8143e-04 - val_mape: 1.4830\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1281e-04 - mape: 53057.7266 - val_loss: 2.0182e-04 - val_mape: 1.5591\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7013e-04 - mape: 7473.7305 - val_loss: 9.4841e-05 - val_mape: 1.0289\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4759e-04 - mape: 26513.6035 - val_loss: 1.2454e-04 - val_mape: 1.1949\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0136e-04 - mape: 58989.8906 - val_loss: 1.0264e-05 - val_mape: 0.2898\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9735e-04 - mape: 59104.2539 - val_loss: 2.4493e-04 - val_mape: 1.7252\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1166e-04 - mape: 9629.1230 - val_loss: 6.9047e-05 - val_mape: 0.8329\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8112e-04 - mape: 4777.9146 - val_loss: 1.2342e-05 - val_mape: 0.3013\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8244e-04 - mape: 54533.0625 - val_loss: 1.1973e-05 - val_mape: 0.3100\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3408e-04 - mape: 12388.8555 - val_loss: 2.2807e-04 - val_mape: 1.6509\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9684e-04 - mape: 56170.9141 - val_loss: 1.0783e-04 - val_mape: 1.0672\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 11570.0449 - val_loss: 1.8244e-05 - val_mape: 0.4201\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9029e-04 - mape: 78651.7969 - val_loss: 1.2731e-04 - val_mape: 1.2190\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7230e-04 - mape: 30509.5527 - val_loss: 1.8679e-05 - val_mape: 0.4108\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7762e-04 - mape: 22255.8887 - val_loss: 2.0562e-04 - val_mape: 1.5707\n",
      "--- 59/102 Training model for CHTR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7771e-04 - mape: 8.4793 - val_loss: 3.2327e-05 - val_mape: 23679.6719\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3131e-04 - mape: 7.9725 - val_loss: 2.8992e-05 - val_mape: 53058.8281\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2060e-04 - mape: 7.4257 - val_loss: 5.0097e-05 - val_mape: 42529.7852\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8974e-04 - mape: 8.4754 - val_loss: 7.9364e-05 - val_mape: 39700.6875\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4890e-04 - mape: 8.8890 - val_loss: 1.3200e-04 - val_mape: 61976.3398\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4907e-04 - mape: 10.0803 - val_loss: 2.1699e-04 - val_mape: 88467.3438\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 11.9599 - val_loss: 4.0984e-04 - val_mape: 159272.5781\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mape: 14.1648 - val_loss: 7.9510e-04 - val_mape: 187644.3125\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mape: 16.9214 - val_loss: 8.2991e-04 - val_mape: 151124.1094\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 15.7667 - val_loss: 3.0526e-04 - val_mape: 62756.5547\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4402e-04 - mape: 13.3542 - val_loss: 2.5183e-04 - val_mape: 49956.3945\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2592e-04 - mape: 11.6193 - val_loss: 1.3430e-04 - val_mape: 58048.7812\n",
      "--- 60/102 Training model for CTAS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0675e-04 - mape: 97.9414 - val_loss: 5.3472e-04 - val_mape: 2.5737\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3347e-04 - mape: 155.3063 - val_loss: 5.3953e-05 - val_mape: 0.6290\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0412e-04 - mape: 81.3071 - val_loss: 3.4815e-05 - val_mape: 0.4479\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4255e-04 - mape: 105.7940 - val_loss: 8.8691e-05 - val_mape: 0.9571\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0004e-04 - mape: 88.5921 - val_loss: 6.2738e-05 - val_mape: 0.7361\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6680e-04 - mape: 92.6617 - val_loss: 9.4722e-05 - val_mape: 1.0229\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5923e-04 - mape: 87.7839 - val_loss: 4.6292e-05 - val_mape: 0.5831\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6073e-04 - mape: 77.4239 - val_loss: 2.6762e-05 - val_mape: 0.3947\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5286e-04 - mape: 89.1485 - val_loss: 7.0299e-05 - val_mape: 0.8480\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0974e-04 - mape: 86.0696 - val_loss: 1.0826e-04 - val_mape: 1.0637\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5521e-04 - mape: 102.4255 - val_loss: 2.8770e-05 - val_mape: 0.4178\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0600e-04 - mape: 88.3443 - val_loss: 7.0103e-05 - val_mape: 0.8282\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9763e-04 - mape: 85.1462 - val_loss: 4.4794e-05 - val_mape: 0.6125\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8898e-04 - mape: 87.5644 - val_loss: 7.1199e-05 - val_mape: 0.8375\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8628e-04 - mape: 81.5061 - val_loss: 5.8944e-05 - val_mape: 0.7543\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9692e-04 - mape: 78.6720 - val_loss: 4.6478e-05 - val_mape: 0.6657\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3958e-04 - mape: 79.2618 - val_loss: 5.3354e-05 - val_mape: 0.7309\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9139e-04 - mape: 85.4816 - val_loss: 5.4943e-05 - val_mape: 0.7310\n",
      "--- 61/102 Training model for GEHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1973e-04 - mape: 3.3125 - val_loss: 1.2759e-04 - val_mape: 1.5210\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4497e-04 - mape: 3.4055 - val_loss: 1.4103e-05 - val_mape: 0.4279\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3258e-04 - mape: 3.0238 - val_loss: 4.7583e-05 - val_mape: 0.8324\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4366e-04 - mape: 2.9771 - val_loss: 1.0616e-05 - val_mape: 0.3849\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6133e-04 - mape: 3.0812 - val_loss: 5.9523e-05 - val_mape: 0.9698\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7638e-04 - mape: 2.6825 - val_loss: 2.7778e-05 - val_mape: 0.6356\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2232e-04 - mape: 2.6778 - val_loss: 2.5560e-05 - val_mape: 0.6149\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6184e-04 - mape: 2.6732 - val_loss: 7.9640e-05 - val_mape: 1.1400\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1363e-04 - mape: 2.4641 - val_loss: 1.5408e-05 - val_mape: 0.4532\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0360e-04 - mape: 2.8481 - val_loss: 2.1239e-05 - val_mape: 0.5272\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1214e-04 - mape: 2.6432 - val_loss: 1.5669e-05 - val_mape: 0.4318\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8385e-04 - mape: 2.6953 - val_loss: 4.4968e-05 - val_mape: 0.8132\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0714e-04 - mape: 2.4253 - val_loss: 1.9690e-05 - val_mape: 0.5077\n",
      "Epoch 14/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2218e-04 - mape: 2.4711 - val_loss: 2.7570e-05 - val_mape: 0.6148\n",
      "--- 62/102 Training model for MRVL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1046e-04 - mape: 43.3269 - val_loss: 1.2912e-05 - val_mape: 0.4141\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1105e-04 - mape: 46.4076 - val_loss: 2.0829e-04 - val_mape: 1.8486\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9342e-04 - mape: 37.4977 - val_loss: 5.4934e-05 - val_mape: 0.8612\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9157e-04 - mape: 38.0901 - val_loss: 1.1377e-04 - val_mape: 1.2788\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4067e-04 - mape: 42.6462 - val_loss: 4.3592e-05 - val_mape: 0.7255\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4376e-04 - mape: 40.0359 - val_loss: 1.6683e-04 - val_mape: 1.6912\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5780e-04 - mape: 39.2511 - val_loss: 1.2070e-04 - val_mape: 1.3845\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3570e-04 - mape: 42.8045 - val_loss: 1.3365e-04 - val_mape: 1.3964\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5706e-04 - mape: 57.0115 - val_loss: 1.5220e-04 - val_mape: 1.4922\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8285e-04 - mape: 53.8215 - val_loss: 1.1673e-04 - val_mape: 1.2583\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5753e-04 - mape: 65.6396 - val_loss: 8.6568e-05 - val_mape: 1.0206\n",
      "--- 63/102 Training model for NXPI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8623e-04 - mape: 93.3952 - val_loss: 8.4661e-04 - val_mape: 3.3159\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7567e-04 - mape: 17266.6719 - val_loss: 3.7209e-04 - val_mape: 2.1693\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6534e-04 - mape: 14250.3730 - val_loss: 3.4491e-04 - val_mape: 2.1284\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4685e-04 - mape: 4078.4536 - val_loss: 2.0209e-04 - val_mape: 1.5505\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7903e-04 - mape: 640.9374 - val_loss: 1.0956e-04 - val_mape: 1.1441\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4758e-04 - mape: 13883.7373 - val_loss: 7.5572e-05 - val_mape: 0.9503\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3736e-04 - mape: 147.7424 - val_loss: 1.3290e-04 - val_mape: 1.2682\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6964e-04 - mape: 11668.5059 - val_loss: 6.1872e-05 - val_mape: 0.8094\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4315e-04 - mape: 1439.3723 - val_loss: 5.5003e-05 - val_mape: 0.7531\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3466e-04 - mape: 16117.5078 - val_loss: 5.1824e-05 - val_mape: 0.7549\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4990e-04 - mape: 11237.0947 - val_loss: 3.1766e-05 - val_mape: 0.5627\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5020e-04 - mape: 25355.9062 - val_loss: 4.2663e-05 - val_mape: 0.6325\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5886e-04 - mape: 15154.3770 - val_loss: 3.3076e-05 - val_mape: 0.5754\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3175e-04 - mape: 16960.9395 - val_loss: 2.1970e-05 - val_mape: 0.4287\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2530e-04 - mape: 21076.3730 - val_loss: 6.6693e-05 - val_mape: 0.8500\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6414e-04 - mape: 7361.2847 - val_loss: 5.6118e-05 - val_mape: 0.7920\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3741e-04 - mape: 29530.8281 - val_loss: 1.7459e-05 - val_mape: 0.3820\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4651e-04 - mape: 19452.7559 - val_loss: 3.0031e-05 - val_mape: 0.5069\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5324e-04 - mape: 25824.9238 - val_loss: 1.2579e-04 - val_mape: 1.1948\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5416e-04 - mape: 2478.1304 - val_loss: 2.2067e-05 - val_mape: 0.4325\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5022e-04 - mape: 1531.7733 - val_loss: 3.9820e-05 - val_mape: 0.6088\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4578e-04 - mape: 5787.4702 - val_loss: 2.0755e-05 - val_mape: 0.4126\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5503e-04 - mape: 7303.4604 - val_loss: 1.3040e-04 - val_mape: 1.2349\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0792e-04 - mape: 27973.8672 - val_loss: 1.4195e-05 - val_mape: 0.3498\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4701e-04 - mape: 1277.8882 - val_loss: 2.9534e-05 - val_mape: 0.4924\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4112e-04 - mape: 5809.1357 - val_loss: 2.2670e-05 - val_mape: 0.4516\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8148e-04 - mape: 12147.9941 - val_loss: 4.6138e-05 - val_mape: 0.6233\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5810e-04 - mape: 28358.9941 - val_loss: 2.1419e-05 - val_mape: 0.4257\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6044e-04 - mape: 20510.9141 - val_loss: 4.2336e-05 - val_mape: 0.6329\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2919e-04 - mape: 1709.3583 - val_loss: 2.0382e-05 - val_mape: 0.4245\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5469e-04 - mape: 17884.1426 - val_loss: 3.8727e-05 - val_mape: 0.6272\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4859e-04 - mape: 5873.9858 - val_loss: 1.5522e-05 - val_mape: 0.3595\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3533e-04 - mape: 20232.2129 - val_loss: 2.8421e-05 - val_mape: 0.5694\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4939e-04 - mape: 4341.6016 - val_loss: 6.5939e-05 - val_mape: 0.8218\n",
      "--- 64/102 Training model for TTD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0941e-04 - mape: 88.1458 - val_loss: 4.0973e-04 - val_mape: 2.6967\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 154.9756 - val_loss: 0.0011 - val_mape: 3.6714\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mape: 314.1951 - val_loss: 4.1007e-04 - val_mape: 2.2469\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 207.3402 - val_loss: 0.0013 - val_mape: 4.4895\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 158.3805 - val_loss: 6.7644e-04 - val_mape: 3.1583\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1988e-04 - mape: 166.5370 - val_loss: 5.0162e-05 - val_mape: 0.7360\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7701e-04 - mape: 87.3710 - val_loss: 1.4177e-05 - val_mape: 0.3611\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4325e-04 - mape: 102.2115 - val_loss: 1.0122e-05 - val_mape: 0.2887\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3535e-04 - mape: 99.9172 - val_loss: 2.9673e-05 - val_mape: 0.6234\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5486e-04 - mape: 95.3180 - val_loss: 4.5285e-05 - val_mape: 0.7283\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3466e-04 - mape: 95.7962 - val_loss: 1.2176e-05 - val_mape: 0.3203\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5892e-04 - mape: 91.0076 - val_loss: 9.7595e-06 - val_mape: 0.3028\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2780e-04 - mape: 82.6050 - val_loss: 4.6751e-05 - val_mape: 0.7315\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4316e-04 - mape: 86.4875 - val_loss: 1.2293e-05 - val_mape: 0.3340\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1213e-04 - mape: 101.2790 - val_loss: 4.4903e-05 - val_mape: 0.7246\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6346e-04 - mape: 94.7025 - val_loss: 5.0583e-05 - val_mape: 0.8212\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6334e-04 - mape: 84.3071 - val_loss: 1.1708e-04 - val_mape: 1.2825\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5892e-04 - mape: 96.9451 - val_loss: 9.8795e-06 - val_mape: 0.2903\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5052e-04 - mape: 91.2840 - val_loss: 1.0450e-04 - val_mape: 1.2547\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5222e-04 - mape: 95.9149 - val_loss: 1.8661e-04 - val_mape: 1.6030\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2911e-04 - mape: 97.4808 - val_loss: 8.4880e-06 - val_mape: 0.2778\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8195e-04 - mape: 103.8291 - val_loss: 1.0763e-05 - val_mape: 0.3169\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4728e-04 - mape: 95.8159 - val_loss: 3.2400e-05 - val_mape: 0.6292\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7218e-04 - mape: 110.6010 - val_loss: 4.3661e-05 - val_mape: 0.8219\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0435e-04 - mape: 96.3790 - val_loss: 3.3844e-04 - val_mape: 2.2314\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7668e-04 - mape: 95.7246 - val_loss: 1.4576e-05 - val_mape: 0.3772\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4199e-04 - mape: 89.5951 - val_loss: 2.1503e-05 - val_mape: 0.4461\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2858e-04 - mape: 113.9360 - val_loss: 1.7997e-05 - val_mape: 0.4550\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3305e-04 - mape: 90.4013 - val_loss: 3.4258e-05 - val_mape: 0.5732\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9838e-04 - mape: 96.2297 - val_loss: 8.3904e-05 - val_mape: 1.1244\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9155e-04 - mape: 109.2523 - val_loss: 2.0830e-04 - val_mape: 1.7024\n",
      "--- 65/102 Training model for BKNG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3783e-04 - mape: 39981.3984 - val_loss: 8.4706e-05 - val_mape: 0.9793\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0790e-04 - mape: 2678.5442 - val_loss: 2.3705e-05 - val_mape: 0.4135\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4421e-05 - mape: 2771.8271 - val_loss: 2.9383e-05 - val_mape: 0.4870\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1710e-04 - mape: 7518.6499 - val_loss: 2.4002e-05 - val_mape: 0.4171\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7034e-05 - mape: 6173.8232 - val_loss: 1.9702e-05 - val_mape: 0.3687\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1358e-04 - mape: 15095.6680 - val_loss: 2.3513e-05 - val_mape: 0.4302\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7285e-05 - mape: 2957.6814 - val_loss: 2.0990e-05 - val_mape: 0.4119\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1118e-04 - mape: 1404.4214 - val_loss: 4.1252e-05 - val_mape: 0.6834\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0232e-04 - mape: 9786.7197 - val_loss: 2.9063e-05 - val_mape: 0.5388\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6150e-05 - mape: 3461.3220 - val_loss: 1.5484e-05 - val_mape: 0.3483\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0012e-04 - mape: 15127.8838 - val_loss: 6.8393e-05 - val_mape: 0.9167\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0355e-04 - mape: 38.3362 - val_loss: 1.7735e-05 - val_mape: 0.3778\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8739e-05 - mape: 3216.9604 - val_loss: 1.5831e-05 - val_mape: 0.3451\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2452e-05 - mape: 13871.9277 - val_loss: 1.8451e-05 - val_mape: 0.3640\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9460e-05 - mape: 13517.2979 - val_loss: 1.7049e-05 - val_mape: 0.3432\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3687e-05 - mape: 4001.9451 - val_loss: 5.0801e-05 - val_mape: 0.7831\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0157e-05 - mape: 7521.6118 - val_loss: 4.2318e-05 - val_mape: 0.7102\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5208e-05 - mape: 17871.8535 - val_loss: 1.7425e-05 - val_mape: 0.3632\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1369e-05 - mape: 252.8306 - val_loss: 1.7942e-05 - val_mape: 0.3681\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7579e-05 - mape: 3127.3364 - val_loss: 1.8382e-05 - val_mape: 0.3588\n",
      "--- 66/102 Training model for KDP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4216e-04 - mape: 6939.2783 - val_loss: 3.0845e-06 - val_mape: 0.1520\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8689e-04 - mape: 15193.6816 - val_loss: 5.2957e-05 - val_mape: 0.8153\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8996e-04 - mape: 34000.3984 - val_loss: 1.7608e-04 - val_mape: 1.7054\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1067e-04 - mape: 51290.0234 - val_loss: 9.6236e-05 - val_mape: 1.1553\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9689e-04 - mape: 8555.5469 - val_loss: 3.8782e-05 - val_mape: 0.6610\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0347e-04 - mape: 14978.5703 - val_loss: 9.4382e-05 - val_mape: 1.1211\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5348e-04 - mape: 70639.1875 - val_loss: 3.1604e-05 - val_mape: 0.5936\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6220e-04 - mape: 1771.8479 - val_loss: 1.2882e-04 - val_mape: 1.3339\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5767e-04 - mape: 35706.3047 - val_loss: 2.3512e-05 - val_mape: 0.5052\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0612e-04 - mape: 36465.8867 - val_loss: 1.3542e-05 - val_mape: 0.3648\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7064e-04 - mape: 41952.0352 - val_loss: 7.5254e-05 - val_mape: 1.0073\n",
      "--- 67/102 Training model for ODFL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9070e-04 - mape: 102001.6484 - val_loss: 5.2103e-05 - val_mape: 0.7352\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5625e-04 - mape: 16573.1660 - val_loss: 2.8260e-05 - val_mape: 0.5002\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 115756.2812 - val_loss: 5.2147e-04 - val_mape: 2.5163\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mape: 107756.1719 - val_loss: 7.9755e-04 - val_mape: 2.7871\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - mape: 350165.7188 - val_loss: 1.6730e-04 - val_mape: 1.3513\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3366e-04 - mape: 103769.1797 - val_loss: 3.9599e-05 - val_mape: 0.5662\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9902e-04 - mape: 34168.7305 - val_loss: 3.3062e-05 - val_mape: 0.5738\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3555e-04 - mape: 44953.6445 - val_loss: 1.3446e-04 - val_mape: 1.2701\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2272e-04 - mape: 29769.2070 - val_loss: 1.4885e-04 - val_mape: 1.3495\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6168e-04 - mape: 29971.1895 - val_loss: 9.3647e-05 - val_mape: 0.9840\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3762e-04 - mape: 72785.1562 - val_loss: 4.1208e-05 - val_mape: 0.5059\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5297e-04 - mape: 117272.4062 - val_loss: 3.1436e-04 - val_mape: 1.8955\n",
      "--- 68/102 Training model for ISRG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6708e-04 - mape: 39.1416 - val_loss: 3.7654e-05 - val_mape: 0.7087\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2437e-04 - mape: 19.4871 - val_loss: 1.5419e-05 - val_mape: 0.3686\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7859e-04 - mape: 17.7629 - val_loss: 1.4539e-05 - val_mape: 0.3403\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9030e-04 - mape: 18.5326 - val_loss: 2.0135e-05 - val_mape: 0.3736\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7002e-04 - mape: 16.7163 - val_loss: 2.8991e-05 - val_mape: 0.5022\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4562e-04 - mape: 16.3197 - val_loss: 1.2931e-05 - val_mape: 0.3101\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9787e-04 - mape: 19.2569 - val_loss: 2.8009e-05 - val_mape: 0.4986\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8768e-04 - mape: 18.0080 - val_loss: 2.7760e-05 - val_mape: 0.4841\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5668e-04 - mape: 16.2993 - val_loss: 2.5701e-05 - val_mape: 0.4102\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7232e-04 - mape: 16.7038 - val_loss: 3.9230e-05 - val_mape: 0.6098\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8022e-04 - mape: 17.8311 - val_loss: 1.3483e-05 - val_mape: 0.3278\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8178e-04 - mape: 17.7452 - val_loss: 1.2632e-05 - val_mape: 0.3033\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5798e-04 - mape: 16.1238 - val_loss: 1.4806e-05 - val_mape: 0.3227\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8490e-04 - mape: 17.9749 - val_loss: 2.1390e-05 - val_mape: 0.4776\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5513e-04 - mape: 15.5422 - val_loss: 1.4828e-05 - val_mape: 0.3424\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4619e-04 - mape: 16.1555 - val_loss: 2.2150e-05 - val_mape: 0.4457\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6171e-04 - mape: 16.4817 - val_loss: 3.6225e-05 - val_mape: 0.6274\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7848e-04 - mape: 16.1726 - val_loss: 4.0341e-05 - val_mape: 0.6531\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4891e-04 - mape: 15.8050 - val_loss: 5.5279e-05 - val_mape: 0.8109\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6924e-04 - mape: 16.2238 - val_loss: 1.3362e-05 - val_mape: 0.3277\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7122e-04 - mape: 16.5172 - val_loss: 8.8637e-05 - val_mape: 1.0374\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1132e-04 - mape: 18.5671 - val_loss: 6.3778e-05 - val_mape: 0.8600\n",
      "--- 69/102 Training model for TXN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9144e-04 - mape: 21.0155 - val_loss: 4.9439e-05 - val_mape: 0.6338\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9346e-04 - mape: 24.8161 - val_loss: 5.1490e-05 - val_mape: 0.7390\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9428e-04 - mape: 20.2063 - val_loss: 2.1989e-04 - val_mape: 1.6368\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5360e-04 - mape: 22.3210 - val_loss: 9.8829e-05 - val_mape: 0.9861\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1919e-04 - mape: 37.1033 - val_loss: 1.6836e-04 - val_mape: 1.5776\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3925e-04 - mape: 38.9769 - val_loss: 1.9252e-04 - val_mape: 1.2242\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 44.8231 - val_loss: 1.9483e-04 - val_mape: 1.7231\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2170e-04 - mape: 27.8955 - val_loss: 2.0839e-04 - val_mape: 1.3275\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7249e-04 - mape: 33.0364 - val_loss: 1.1520e-04 - val_mape: 1.2486\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6493e-04 - mape: 26.8375 - val_loss: 3.2035e-04 - val_mape: 1.9015\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4255e-04 - mape: 26.0796 - val_loss: 8.2320e-05 - val_mape: 0.9412\n",
      "--- 70/102 Training model for ARM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.4257e-04 - mape: 515316.7500 - val_loss: 9.9407e-05 - val_mape: 1.2458\n",
      "Epoch 2/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8280e-04 - mape: 469945.2188 - val_loss: 5.4490e-05 - val_mape: 1.0004\n",
      "Epoch 3/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7011e-04 - mape: 265124.6875 - val_loss: 1.1039e-04 - val_mape: 1.7636\n",
      "Epoch 4/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5805e-04 - mape: 390071.2812 - val_loss: 4.0825e-05 - val_mape: 1.0291\n",
      "Epoch 5/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2604e-04 - mape: 243500.3438 - val_loss: 6.9075e-05 - val_mape: 1.3606\n",
      "Epoch 6/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4367e-04 - mape: 122297.7422 - val_loss: 4.8861e-05 - val_mape: 1.0499\n",
      "Epoch 7/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3701e-04 - mape: 199394.6875 - val_loss: 5.1221e-05 - val_mape: 1.1486\n",
      "Epoch 8/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8390e-04 - mape: 87302.1484 - val_loss: 4.7924e-05 - val_mape: 1.1016\n",
      "Epoch 9/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3584e-04 - mape: 255578.1719 - val_loss: 3.9284e-05 - val_mape: 0.9533\n",
      "Epoch 10/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0235e-04 - mape: 8046.3066 - val_loss: 6.7657e-05 - val_mape: 1.3423\n",
      "Epoch 11/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0307e-04 - mape: 158425.3750 - val_loss: 7.7470e-05 - val_mape: 1.3835\n",
      "Epoch 12/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2626e-04 - mape: 276907.9062 - val_loss: 4.1745e-05 - val_mape: 0.9897\n",
      "Epoch 13/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9299e-04 - mape: 553399.8750 - val_loss: 8.1284e-05 - val_mape: 1.4813\n",
      "Epoch 14/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5651e-04 - mape: 184622.9688 - val_loss: 1.1300e-04 - val_mape: 1.7340\n",
      "Epoch 15/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2186e-04 - mape: 440567.1250 - val_loss: 5.5289e-05 - val_mape: 1.1448\n",
      "Epoch 16/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7878e-04 - mape: 27364.7852 - val_loss: 5.8314e-05 - val_mape: 1.1128\n",
      "Epoch 17/150\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2379e-04 - mape: 202587.2656 - val_loss: 5.0312e-05 - val_mape: 1.0292\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7303e-04 - mape: 5.9067 - val_loss: 3.7106e-04 - val_mape: 1.9610\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8504e-04 - mape: 5.0031 - val_loss: 2.1572e-04 - val_mape: 1.3208\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mape: 11.8043 - val_loss: 5.3386e-04 - val_mape: 2.3458\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0570e-04 - mape: 7.5728 - val_loss: 4.5332e-04 - val_mape: 2.1441\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4777e-04 - mape: 5.5529 - val_loss: 9.1475e-05 - val_mape: 0.8715\n",
      "--- 6/102 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1065e-04 - mape: 11.5920 - val_loss: 6.3388e-05 - val_mape: 0.8965\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6936e-04 - mape: 9.9541 - val_loss: 2.6052e-04 - val_mape: 2.1003\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8508e-04 - mape: 18.0711 - val_loss: 5.1455e-04 - val_mape: 3.1526\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8635e-04 - mape: 12.7327 - val_loss: 2.0254e-04 - val_mape: 1.8240\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7740e-04 - mape: 12.3571 - val_loss: 7.6956e-05 - val_mape: 1.0094\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3396e-04 - mape: 9.7856 - val_loss: 5.2360e-04 - val_mape: 3.1175\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6812e-04 - mape: 10.9540 - val_loss: 1.0422e-04 - val_mape: 1.1833\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3945e-04 - mape: 16.0104 - val_loss: 2.1151e-04 - val_mape: 1.7882\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3000e-04 - mape: 9.6087 - val_loss: 3.5600e-04 - val_mape: 2.4863\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6638e-04 - mape: 9.7101 - val_loss: 6.6781e-05 - val_mape: 0.8941\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5640e-04 - mape: 26.2199 - val_loss: 1.2260e-04 - val_mape: 1.3214\n",
      "--- 7/102 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1135e-04 - mape: 10.9399 - val_loss: 3.7052e-04 - val_mape: 1.9252\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3443e-04 - mape: 9.9799 - val_loss: 1.5856e-04 - val_mape: 1.3391\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6719e-04 - mape: 8.4741 - val_loss: 5.9428e-04 - val_mape: 2.6440\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8743e-04 - mape: 10.1440 - val_loss: 4.2805e-04 - val_mape: 2.0062\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8306e-04 - mape: 14.6851 - val_loss: 6.7790e-04 - val_mape: 2.9434\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6576e-04 - mape: 8.9668 - val_loss: 4.5282e-04 - val_mape: 2.1095\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2684e-04 - mape: 12.8190 - val_loss: 6.9513e-04 - val_mape: 2.7206\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7334e-04 - mape: 14.4322 - val_loss: 0.0013 - val_mape: 3.8567\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0065e-04 - mape: 23.1739 - val_loss: 0.0032 - val_mape: 6.6086\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mape: 37.2165 - val_loss: 0.0068 - val_mape: 9.5317\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - mape: 66.0387 - val_loss: 0.0081 - val_mape: 9.9279\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - mape: 83.5774 - val_loss: 0.0056 - val_mape: 7.3658\n",
      "--- 8/102 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3586e-04 - mape: 38.8574 - val_loss: 0.0032 - val_mape: 12.4336\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - mape: 210.5957 - val_loss: 0.0036 - val_mape: 14.1126\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mape: 149.9078 - val_loss: 0.0037 - val_mape: 14.6831\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - mape: 122.7439 - val_loss: 0.0036 - val_mape: 14.2840\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mape: 139.1849 - val_loss: 0.0029 - val_mape: 12.4066\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - mape: 174.9355 - val_loss: 0.0031 - val_mape: 12.9358\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - mape: 184.4362 - val_loss: 0.0026 - val_mape: 11.7664\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - mape: 175.7507 - val_loss: 0.0012 - val_mape: 7.5518\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - mape: 184.6017 - val_loss: 0.0010 - val_mape: 6.8094\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - mape: 176.8735 - val_loss: 5.0558e-04 - val_mape: 4.5191\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - mape: 178.0710 - val_loss: 1.3852e-04 - val_mape: 2.4934\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mape: 162.1056 - val_loss: 2.2798e-04 - val_mape: 3.4183\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mape: 140.8911 - val_loss: 4.0228e-04 - val_mape: 4.6392\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mape: 120.4731 - val_loss: 3.1405e-04 - val_mape: 3.9681\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2006e-04 - mape: 86.6866 - val_loss: 2.1688e-04 - val_mape: 3.0114\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4975e-04 - mape: 47.1152 - val_loss: 1.3514e-04 - val_mape: 2.3206\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7716e-04 - mape: 39.9959 - val_loss: 1.0787e-04 - val_mape: 2.0224\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7321e-04 - mape: 31.6591 - val_loss: 1.1504e-04 - val_mape: 2.0132\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6548e-04 - mape: 26.1614 - val_loss: 8.3099e-05 - val_mape: 1.7461\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5749e-04 - mape: 26.7468 - val_loss: 5.8182e-05 - val_mape: 1.5079\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8299e-04 - mape: 28.5826 - val_loss: 4.8306e-05 - val_mape: 1.3966\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7619e-04 - mape: 28.7061 - val_loss: 4.8333e-05 - val_mape: 1.4036\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6423e-04 - mape: 27.8144 - val_loss: 4.9803e-05 - val_mape: 1.4156\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0186e-04 - mape: 31.5499 - val_loss: 4.3641e-05 - val_mape: 1.3397\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9890e-04 - mape: 35.5242 - val_loss: 4.3139e-05 - val_mape: 1.3165\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3464e-04 - mape: 26.2525 - val_loss: 4.3099e-05 - val_mape: 1.3109\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7378e-04 - mape: 30.6235 - val_loss: 5.3209e-05 - val_mape: 1.4575\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6552e-04 - mape: 32.7146 - val_loss: 5.3633e-05 - val_mape: 1.4850\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7525e-04 - mape: 33.6460 - val_loss: 4.3142e-05 - val_mape: 1.3126\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8691e-04 - mape: 31.9668 - val_loss: 8.7994e-05 - val_mape: 1.9185\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0025e-04 - mape: 47.4373 - val_loss: 7.4006e-05 - val_mape: 1.7733\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6416e-04 - mape: 42.2890 - val_loss: 5.2224e-05 - val_mape: 1.4378\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4584e-04 - mape: 52.9679 - val_loss: 6.8235e-05 - val_mape: 1.6580\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0267e-04 - mape: 46.4429 - val_loss: 6.1312e-05 - val_mape: 1.5436\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8112e-04 - mape: 55.6916 - val_loss: 7.2205e-05 - val_mape: 1.6562\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3904e-04 - mape: 60.5800 - val_loss: 1.2731e-04 - val_mape: 2.3296\n",
      "--- 9/102 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0708e-04 - mape: 59110.9688 - val_loss: 0.0016 - val_mape: 4.6588\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5351e-04 - mape: 138535.1562 - val_loss: 2.3453e-04 - val_mape: 1.3433\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0008e-04 - mape: 37551.7539 - val_loss: 2.1267e-04 - val_mape: 1.2298\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5413e-04 - mape: 13891.5527 - val_loss: 2.0949e-04 - val_mape: 1.1850\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3761e-04 - mape: 14054.9395 - val_loss: 2.0185e-04 - val_mape: 1.1408\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6889e-04 - mape: 13379.4600 - val_loss: 2.0303e-04 - val_mape: 1.1953\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3634e-04 - mape: 30786.0312 - val_loss: 2.1108e-04 - val_mape: 1.1570\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8405e-04 - mape: 63527.2852 - val_loss: 1.8632e-04 - val_mape: 1.0789\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7410e-04 - mape: 16464.1875 - val_loss: 3.1137e-04 - val_mape: 1.5906\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8035e-04 - mape: 4354.9785 - val_loss: 2.2745e-04 - val_mape: 1.3123\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6566e-04 - mape: 25424.9141 - val_loss: 3.3449e-04 - val_mape: 1.7009\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9474e-04 - mape: 18452.3145 - val_loss: 2.2264e-04 - val_mape: 1.2748\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6602e-04 - mape: 22653.0508 - val_loss: 2.0432e-04 - val_mape: 1.1117\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8684e-04 - mape: 17406.0898 - val_loss: 5.4275e-04 - val_mape: 2.5053\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2910e-04 - mape: 24159.5273 - val_loss: 2.4056e-04 - val_mape: 1.3620\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8005e-04 - mape: 41541.7852 - val_loss: 5.5798e-04 - val_mape: 2.5424\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8598e-04 - mape: 32125.5312 - val_loss: 2.2215e-04 - val_mape: 1.1986\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1397e-04 - mape: 75508.2500 - val_loss: 0.0015 - val_mape: 4.4945\n",
      "--- 10/102 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5439e-04 - mape: 67.2795 - val_loss: 0.0014 - val_mape: 4.2598\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1599e-04 - mape: 74.3688 - val_loss: 0.0034 - val_mape: 7.2235\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0134e-04 - mape: 71.6517 - val_loss: 2.9995e-04 - val_mape: 1.4704\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4764e-04 - mape: 28.1348 - val_loss: 2.9827e-04 - val_mape: 1.5667\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4151e-04 - mape: 27.5058 - val_loss: 3.1838e-04 - val_mape: 1.5220\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2003e-04 - mape: 24.7009 - val_loss: 3.1819e-04 - val_mape: 1.5184\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2306e-04 - mape: 25.5049 - val_loss: 2.9274e-04 - val_mape: 1.4417\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1561e-04 - mape: 24.7139 - val_loss: 3.0270e-04 - val_mape: 1.4693\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2590e-04 - mape: 25.6289 - val_loss: 3.4449e-04 - val_mape: 1.6173\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1778e-04 - mape: 24.4739 - val_loss: 2.8863e-04 - val_mape: 1.4346\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0306e-04 - mape: 22.4006 - val_loss: 3.3699e-04 - val_mape: 1.6061\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1061e-04 - mape: 23.2456 - val_loss: 3.0423e-04 - val_mape: 1.4901\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1043e-04 - mape: 23.8058 - val_loss: 3.7991e-04 - val_mape: 1.7645\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2108e-04 - mape: 24.8172 - val_loss: 2.9773e-04 - val_mape: 1.4823\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1612e-04 - mape: 24.6689 - val_loss: 4.8345e-04 - val_mape: 2.1846\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1782e-04 - mape: 25.5128 - val_loss: 3.0209e-04 - val_mape: 1.4954\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7183e-05 - mape: 21.7762 - val_loss: 2.3762e-04 - val_mape: 1.2682\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0230e-04 - mape: 23.3435 - val_loss: 3.0451e-04 - val_mape: 1.5225\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6767e-05 - mape: 22.1448 - val_loss: 3.5203e-04 - val_mape: 1.6998\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0514e-04 - mape: 23.8943 - val_loss: 2.5980e-04 - val_mape: 1.3474\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0770e-04 - mape: 23.1252 - val_loss: 5.0270e-04 - val_mape: 2.2964\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1169e-04 - mape: 23.8142 - val_loss: 3.4315e-04 - val_mape: 1.6929\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9067e-05 - mape: 23.1266 - val_loss: 2.6489e-04 - val_mape: 1.3538\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0378e-04 - mape: 23.6589 - val_loss: 2.4808e-04 - val_mape: 1.3509\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5767e-04 - mape: 30.2910 - val_loss: 7.2204e-04 - val_mape: 2.8781\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4081e-04 - mape: 39.7122 - val_loss: 2.4909e-04 - val_mape: 1.3625\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2155e-04 - mape: 37.1486 - val_loss: 9.3611e-04 - val_mape: 3.3967\n",
      "--- 11/102 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2948e-04 - mape: 10.2980 - val_loss: 4.7490e-04 - val_mape: 2.0173\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8408e-04 - mape: 13.2775 - val_loss: 4.8609e-04 - val_mape: 2.0293\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6617e-04 - mape: 15.5027 - val_loss: 9.7758e-04 - val_mape: 3.1047\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8919e-04 - mape: 19.7433 - val_loss: 9.6478e-04 - val_mape: 3.2371\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - mape: 59.6227 - val_loss: 9.1102e-04 - val_mape: 2.9308\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mape: 41.6641 - val_loss: 0.0043 - val_mape: 7.2484\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0134 - mape: 107.5853 - val_loss: 5.5748e-04 - val_mape: 2.2274\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0522e-04 - mape: 13.8607 - val_loss: 0.0033 - val_mape: 6.3848\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - mape: 49.7885 - val_loss: 8.1841e-04 - val_mape: 2.7323\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mape: 47.7023 - val_loss: 0.0020 - val_mape: 4.8663\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - mape: 42.1288 - val_loss: 8.5100e-04 - val_mape: 2.8417\n",
      "--- 12/102 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1087e-04 - mape: 67.4531 - val_loss: 1.0777e-04 - val_mape: 0.9301\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8189e-04 - mape: 101.5117 - val_loss: 3.8768e-04 - val_mape: 1.9709\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3819e-04 - mape: 72.5530 - val_loss: 8.4530e-05 - val_mape: 0.8612\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 180.2080 - val_loss: 5.6516e-04 - val_mape: 2.3498\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - mape: 263.3038 - val_loss: 0.0015 - val_mape: 4.1366\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - mape: 322.7794 - val_loss: 2.8115e-04 - val_mape: 1.5209\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 190.2581 - val_loss: 0.0011 - val_mape: 3.6422\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - mape: 239.7527 - val_loss: 3.8555e-04 - val_mape: 1.9340\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9769e-04 - mape: 162.1259 - val_loss: 0.0031 - val_mape: 6.1814\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mape: 304.5554 - val_loss: 1.7253e-04 - val_mape: 1.1523\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2306e-04 - mape: 102.9343 - val_loss: 9.1731e-04 - val_mape: 3.2637\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 188.9388 - val_loss: 2.9908e-04 - val_mape: 1.6059\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7910e-04 - mape: 90.7451 - val_loss: 1.6857e-04 - val_mape: 1.2535\n",
      "--- 13/102 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mape: 106056.5391 - val_loss: 3.0221e-04 - val_mape: 2.2869\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6912e-04 - mape: 82432.7656 - val_loss: 1.1160e-04 - val_mape: 1.2248\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2469e-04 - mape: 49487.0430 - val_loss: 1.0120e-04 - val_mape: 1.0581\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5587e-04 - mape: 38340.7695 - val_loss: 9.0447e-05 - val_mape: 0.9879\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7980e-04 - mape: 20650.6855 - val_loss: 1.3240e-04 - val_mape: 1.4042\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6320e-04 - mape: 15405.9883 - val_loss: 1.2005e-04 - val_mape: 1.1849\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1127e-04 - mape: 13886.9219 - val_loss: 9.3149e-05 - val_mape: 1.0651\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4185e-04 - mape: 23438.5117 - val_loss: 1.5503e-04 - val_mape: 1.3924\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8329e-04 - mape: 42499.6914 - val_loss: 1.3426e-04 - val_mape: 1.3516\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4472e-04 - mape: 67120.3047 - val_loss: 7.2155e-05 - val_mape: 0.9150\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3607e-04 - mape: 11657.5596 - val_loss: 1.3796e-04 - val_mape: 1.2772\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2577e-04 - mape: 20388.0996 - val_loss: 2.8143e-04 - val_mape: 2.1973\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3267e-04 - mape: 44719.5547 - val_loss: 1.2767e-04 - val_mape: 1.2782\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2296e-04 - mape: 10142.5576 - val_loss: 6.9071e-05 - val_mape: 0.9100\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6741e-04 - mape: 59475.7344 - val_loss: 1.9377e-04 - val_mape: 1.7734\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5568e-04 - mape: 6232.7427 - val_loss: 7.1810e-05 - val_mape: 0.9067\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7359e-04 - mape: 28802.0918 - val_loss: 7.9953e-05 - val_mape: 0.9627\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5405e-04 - mape: 10523.3066 - val_loss: 1.1714e-04 - val_mape: 1.3576\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6864e-04 - mape: 3847.2346 - val_loss: 8.5592e-05 - val_mape: 1.0733\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8673e-04 - mape: 10674.3867 - val_loss: 6.6700e-05 - val_mape: 0.9035\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6232e-04 - mape: 18683.3848 - val_loss: 8.5893e-05 - val_mape: 1.0298\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3598e-04 - mape: 14317.8242 - val_loss: 2.0476e-04 - val_mape: 1.8233\n",
      "Epoch 23/150\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.data.make_dataset import load_list, get_stock_data\n",
    "from src.models.StockModel import StockModel\n",
    "window_size = 20\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2024-09-01'\n",
    "feature_columns = ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
    "target = \"Open\"\n",
    "\n",
    "# Load symbols\n",
    "nasdaq_symbols = load_list(\"NASDAQ\")\n",
    "sp500_symbols = load_list(\"SP500\")\n",
    "\n",
    "# Test tickers, sp500 symbols not also in nasdaq\n",
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:75]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC']\n",
    "train_tickers = ['^IXIC'] + nasdaq_symbols\n",
    "#train_tickers = train_tickers[:51]\n",
    "\n",
    "# Download data\n",
    "combined_data = get_stock_data(train_tickers, \"1d\", start_date, end_date)\n",
    "combined_data.info()\n",
    "# Test data\n",
    "test_data = get_stock_data(test_tickers, \"1d\", start_date, end_date)\n",
    "\n",
    "layer_config = [(1,32),(1,64),(1,96),(1,128)]\n",
    "for i in layer_config:\n",
    "    print(f\"XXXXXXXXXXXXXXXX Running {i[0]} {i[1]} layers XXXXXXXXXXXXXXXXXXXX\")\n",
    "    # Create and train model\n",
    "    stock_model = StockModel(window_size=window_size, feature_columns=feature_columns, target_name=target, export=True)\n",
    "    \n",
    "    stock_model.train(combined_data, patience=10, epochs=150, graph=False, layers=i[0], units_per_layer=i[1])\n",
    "    metrics_dict, metrics_summary = stock_model.evaluate_many(test_data, graph=False)\n",
    "    print(metrics_dict)\n",
    "    print(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:5]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC', '^DJI']\n",
    "# Test data\n",
    "test_data = get_stock_data([\"^GSPC\", \"^DJI\"], \"1d\", start_date, end_date)\n",
    "\n",
    "metrics_dict, mean_metrics = stock_model.evaluate_many(test_data, graph=True)\n",
    "print(metrics_dict)\n",
    "print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
