{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 186328 entries, 2017-01-03 00:00:00-05:00 to 2024-08-30 00:00:00-04:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Open          186328 non-null  float64\n",
      " 1   High          186328 non-null  float64\n",
      " 2   Low           186328 non-null  float64\n",
      " 3   Close         186328 non-null  float64\n",
      " 4   Volume        186328 non-null  int64  \n",
      " 5   Dividends     186328 non-null  float64\n",
      " 6   Stock Splits  186328 non-null  float64\n",
      " 7   Ticker        186328 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 12.8+ MB\n",
      "XXXXXXXXXXXXXXXX Running 1 90 layers XXXXXXXXXXXXXXXXXXXX\n",
      "Initializing model:\n",
      " - Window size: 20\n",
      " - Features: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
      " - Target: Open\n",
      "--- Preparing ^IXIC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.47700000e+03  5.44091016e+03  8.72110000e+08  1.43798828e+01\n",
      " -1.06362988e+03  1.16226960e+01 -6.03732918e+02 -1.85963467e+02]\n",
      "Feature max [1.86474492e+04 1.86592500e+04 1.19326000e+10 8.98230469e+02\n",
      " 5.16000000e+02 1.00000000e+02 3.79729000e+02 1.68559430e+02]\n",
      "Target min [5425.62011719]\n",
      "Target max [18659.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRTX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.70500031e+01  7.52200012e+01  3.00500000e+05  9.29992676e-01\n",
      " -4.39099884e+01  6.98832867e+00 -1.61057278e+01 -6.35634960e+00]\n",
      "Feature max [5.05779999e+02 5.07040009e+02 1.74930000e+07 3.32000122e+01\n",
      " 2.96399994e+01 1.00000000e+02 1.72224200e+01 7.01903411e+00]\n",
      "Target min [74.43000031]\n",
      "Target max [507.04000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PYPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93100014e+01  3.94000015e+01  1.68000000e+06  2.79998779e-01\n",
      " -3.59100037e+01  5.36242303e+00 -1.82619484e+01 -6.83508729e+00]\n",
      "Feature max [3.08529999e+02 3.09660004e+02 1.36264000e+08 2.25299988e+01\n",
      " 1.48899994e+01 1.00000000e+02 1.63896973e+01 4.70789452e+00]\n",
      "Target min [39.40000153]\n",
      "Target max [309.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GILD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.83768845e+01  4.84647878e+01  1.93100000e+06  3.33687038e-01\n",
      " -6.63972958e+00  5.76433902e+00 -2.31350268e+00 -8.99640056e-01]\n",
      "Feature max [8.53581619e+01 8.44682978e+01 9.43485000e+07 8.04050604e+00\n",
      " 7.22805860e+00 1.00000000e+02 4.20840158e+00 1.25684624e+00]\n",
      "Target min [48.46478775]\n",
      "Target max [84.46829781]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.10076208e+01  1.08333266e+01  2.58690000e+06  1.03459220e-01\n",
      " -2.80620786e+00  6.42017605e+00 -2.09796553e+00 -6.88387158e-01]\n",
      "Feature max [3.81064873e+01 3.81660578e+01 2.95518300e+08 2.47469104e+00\n",
      " 2.03002795e+00 1.00000000e+02 1.17294785e+00 5.41764434e-01]\n",
      "Target min [10.83332657]\n",
      "Target max [38.16605779]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing IDXX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.15949997e+02  1.15989998e+02  6.95000000e+04  1.01998901e+00\n",
      " -5.39599915e+01  0.00000000e+00 -4.51944855e+01 -1.18420530e+01]\n",
      "Feature max [7.05760010e+02 6.98869995e+02 2.06065000e+07 4.94200134e+01\n",
      " 2.44899902e+01 9.87477702e+01 2.80133056e+01 9.19398448e+00]\n",
      "Target min [115.98999786]\n",
      "Target max [698.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.72258110e+01  4.72942254e+01  4.40100000e+05  2.32199907e-01\n",
      " -6.70202272e+00  0.00000000e+00 -5.58792373e+00 -1.85080629e+00]\n",
      "Feature max [1.00876343e+02 1.03304346e+02 2.24557000e+07 1.05535615e+01\n",
      " 3.30010273e+00 1.00000000e+02 2.91608734e+00 1.39528387e+00]\n",
      "Target min [47.29422538]\n",
      "Target max [103.30434621]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TEAM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.47199993e+01  2.47299995e+01  2.10900000e+05  2.16999054e-01\n",
      " -4.31699982e+01  1.07833899e+01 -2.66488051e+01 -8.97255197e+00]\n",
      "Feature max [4.58130005e+02 4.55200012e+02 1.74562000e+07 4.22299805e+01\n",
      " 4.32099915e+01 1.00000000e+02 2.40637139e+01 8.94966359e+00]\n",
      "Target min [24.31999969]\n",
      "Target max [455.20001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PANW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.60033340e+01  3.61399994e+01  1.02260000e+06  3.56666565e-01\n",
      " -9.08899841e+01  3.81140920e+00 -1.38470391e+01 -1.22788064e+01]\n",
      "Feature max [3.76899994e+02 3.75450012e+02 6.53592000e+07 2.73699951e+01\n",
      " 2.68099976e+01 1.00000000e+02 1.51691964e+01 4.87990591e+00]\n",
      "Target min [36.13999939]\n",
      "Target max [375.45001221]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AVGO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.37303305e+01  1.37248117e+01  4.12300000e+06  1.24250219e-01\n",
      " -1.42100067e+01  0.00000000e+00 -5.06872189e+00 -3.00550723e+00]\n",
      "Feature max [1.82308105e+02 1.83376725e+02 4.35083000e+08 1.69199982e+01\n",
      " 2.13810994e+01 9.28312266e+01 1.05782566e+01 4.55284581e+00]\n",
      "Target min [13.72481175]\n",
      "Target max [183.37672469]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CEG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.08016396e+01  3.98784464e+01  2.35000000e+04  6.26233823e-01\n",
      " -1.08198405e+01  1.27016955e+01 -1.06308757e+01 -3.92755151e+00]\n",
      "Feature max [2.30487686e+02 2.31952715e+02 2.38609000e+07 2.15543379e+01\n",
      " 2.45442808e+01 1.00000000e+02 1.44754876e+01 4.38796603e+00]\n",
      "Target min [37.00564339]\n",
      "Target max [231.9527148]\n",
      "X_train shape: (637, 20, 8)\n",
      "Train_dates: 2022-01-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MSFT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.65738716e+01  5.64739814e+01  7.42560000e+06  2.90591337e-01\n",
      " -1.92852005e+01  0.00000000e+00 -1.18035322e+01 -4.62579684e+00]\n",
      "Feature max [4.66718781e+02 4.66159796e+02 1.11242100e+08 2.43750306e+01\n",
      " 2.10308153e+01 9.87202471e+01 1.16126215e+01 3.05457896e+00]\n",
      "Target min [56.4739814]\n",
      "Target max [466.15979612]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EXC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.82024422e+01  1.85263402e+01  2.00850500e+06  1.22239479e-01\n",
      " -1.93681974e+00  5.27402426e+00 -2.56103530e+00 -9.27310777e-01]\n",
      "Feature max [4.59507637e+01 4.58593208e+01 3.88453000e+07 4.14685335e+00\n",
      " 1.20619631e+00 1.00000000e+02 1.62739228e+00 5.65170397e-01]\n",
      "Target min [18.52634024]\n",
      "Target max [45.85932079]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DXCM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.11149998e+01  1.10325003e+01  8.61200000e+05  1.64999962e-01\n",
      " -4.18499985e+01  4.43708879e+00 -1.21858259e+01 -5.03116733e+00]\n",
      "Feature max [1.62815002e+02 1.64257507e+02 1.23168400e+08 1.88925018e+01\n",
      " 1.24700012e+01 1.00000000e+02 8.60785647e+00 2.40813081e+00]\n",
      "Target min [11.03250027]\n",
      "Target max [164.25750732]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FAST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65418377e+01  1.66370238e+01  7.04500000e+05  1.46829925e-01\n",
      " -3.17296715e+00  2.73464465e+00 -1.96586911e+00 -1.08293915e+00]\n",
      "Feature max [7.75266724e+01 7.77145119e+01 5.26096000e+07 4.66000366e+00\n",
      " 3.55978900e+00 1.00000000e+02 1.87048216e+00 8.56669819e-01]\n",
      "Target min [16.63702385]\n",
      "Target max [77.71451195]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ABNB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.24899979e+01  8.29700012e+01  1.72560000e+06  1.01499939e+00\n",
      " -1.80299988e+01  0.00000000e+00 -1.29513658e+01 -4.57280582e+00]\n",
      "Feature max [2.16839996e+02 2.16240005e+02 7.47864000e+07 3.05000000e+01\n",
      " 1.21199951e+01 9.29350181e+01 1.31150691e+01 3.98198040e+00]\n",
      "Target min [82.97000122]\n",
      "Target max [216.24000549]\n",
      "X_train shape: (915, 20, 8)\n",
      "Train_dates: 2020-12-11 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SNPS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.95699997e+01  5.93699989e+01  2.00200000e+05  2.60002136e-01\n",
      " -3.66699829e+01  7.61484664e+00 -2.46719247e+01 -8.22743530e+00]\n",
      "Feature max [6.21299988e+02 6.22929993e+02 3.02946000e+07 5.02700195e+01\n",
      " 4.64199829e+01 1.00000000e+02 2.12557667e+01 8.46134558e+00]\n",
      "Target min [59.27000046]\n",
      "Target max [622.92999268]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BIIB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [187.53999329 190.55999756   0.           0.         -98.07998657\n",
      "   4.79436191 -25.57434546 -11.64517675]\n",
      "Feature max [4.14709991e+02 4.23329987e+02 2.18431000e+07 1.82549988e+02\n",
      " 8.64900055e+01 1.00000000e+02 3.49582846e+01 1.62224245e+01]\n",
      "Target min [190.55999756]\n",
      "Target max [423.32998657]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing REGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.73459991e+02  2.74350006e+02  1.71600000e+05  2.76998901e+00\n",
      " -4.76300049e+01  6.11531109e+00 -2.90962700e+01 -1.14012185e+01]\n",
      "Feature max [1.20176001e+03 1.20471997e+03 7.86950000e+06 8.12899780e+01\n",
      " 9.05499878e+01 1.00000000e+02 3.48632110e+01 1.33649620e+01]\n",
      "Target min [274.3500061]\n",
      "Target max [1204.7199707]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing VRSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.40612259e+01  7.38682354e+01  1.45000000e+05  3.47388725e-01\n",
      " -1.39151498e+01  7.46558084e+00 -1.02972264e+01 -4.01614511e+00]\n",
      "Feature max [2.85989990e+02 2.85000000e+02 4.24820000e+06 1.72982793e+01\n",
      " 1.09380049e+01 1.00000000e+02 7.65714202e+00 3.71764315e+00]\n",
      "Target min [73.86823541]\n",
      "Target max [285.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TSLA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.19313326e+01  1.20733328e+01  2.94018000e+07  1.66667938e-01\n",
      " -2.41000061e+01  6.91932630e+00 -2.52713333e+01 -7.67848148e+00]\n",
      "Feature max [4.09970001e+02 4.11470001e+02 9.14082000e+08 5.43266602e+01\n",
      " 3.25100098e+01 1.00000000e+02 3.80679297e+01 1.02961745e+01]\n",
      "Target min [12.07333279]\n",
      "Target max [411.47000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NVDA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.35561442e+00  2.36844215e+00  9.78840000e+07  3.05890903e-02\n",
      " -1.52099991e+01  8.18789238e+00 -5.16786769e+00 -2.56494372e+00]\n",
      "Feature max [1.35580002e+02 1.39800003e+02 3.69292800e+09 1.33500061e+01\n",
      " 9.16999817e+00 1.00000000e+02 9.77617754e+00 2.89363431e+00]\n",
      "Target min [2.36844215]\n",
      "Target max [139.80000305]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CPRT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.95749998e+00  6.97499990e+00  1.16560000e+06  4.75001335e-02\n",
      " -2.40999985e+00  1.07028555e+01 -2.08288713e+00 -5.95224464e-01]\n",
      "Feature max [5.80699997e+01 5.81300011e+01 2.13690400e+08 3.43000031e+00\n",
      " 1.91999817e+00 1.00000000e+02 1.68053820e+00 5.29970520e-01]\n",
      "Target min [6.94750023]\n",
      "Target max [58.13000107]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ORLY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.72850006e+02  1.72839996e+02  9.76000000e+04  1.75000000e+00\n",
      " -7.26999512e+01  9.93704967e+00 -3.18757122e+01 -1.55376421e+01]\n",
      "Feature max [1.16753003e+03 1.16473999e+03 1.28304000e+07 6.14700928e+01\n",
      " 3.95399780e+01 1.00000000e+02 2.94044788e+01 1.46112531e+01]\n",
      "Target min [172.83999634]\n",
      "Target max [1164.73999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSGP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.90799999e+01  1.86439991e+01  4.31000000e+05  1.32999420e-01\n",
      " -1.35200005e+01  3.82196899e+00 -3.91839760e+00 -1.70338203e+00]\n",
      "Feature max [9.97399979e+01 9.96600037e+01 5.40349000e+07 1.53570023e+01\n",
      " 2.22259979e+01 1.00000000e+02 3.78952594e+00 1.64810768e+00]\n",
      "Target min [18.6439991]\n",
      "Target max [99.66000366]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PDD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.71499996e+01  1.72000008e+01  1.21070000e+06  3.10001373e-01\n",
      " -2.96699982e+01  0.00000000e+00 -1.20781712e+01 -6.25067404e+00]\n",
      "Feature max [2.02820007e+02 2.11600006e+02 1.03174600e+08 2.12799988e+01\n",
      " 2.67000046e+01 9.22446129e+01 1.43527401e+01 4.73466591e+00]\n",
      "Target min [17.20000076]\n",
      "Target max [211.6000061]\n",
      "X_train shape: (1514, 20, 8)\n",
      "Train_dates: 2018-07-27 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing HON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.46234360e+01  9.52324076e+01  6.25500000e+05  4.19023052e-01\n",
      " -1.95059619e+01  4.75205760e+00 -1.40929705e+01 -4.45801038e+00]\n",
      "Feature max [2.19502518e+02 2.19940311e+02 2.82371000e+07 2.09818749e+01\n",
      " 1.90409302e+01 1.00000000e+02 8.86860645e+00 3.23137391e+00]\n",
      "Target min [95.2324076]\n",
      "Target max [219.940311]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.14207573e+01  6.16446785e+01  4.66400000e+05  4.04764943e-01\n",
      " -1.59855034e+01  0.00000000e+00 -6.96255671e+00 -3.47483258e+00]\n",
      "Feature max [2.42376740e+02 2.39537898e+02 1.91564000e+07 1.54971600e+01\n",
      " 1.14345649e+01 9.47163396e+01 9.37402072e+00 2.80709341e+00]\n",
      "Target min [61.64467846]\n",
      "Target max [239.53789776]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing EA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.30818024e+01  7.35512640e+01  5.83900000e+05  5.47719891e-01\n",
      " -1.30866558e+01  5.85087242e+00 -5.68716314e+00 -2.63117529e+00]\n",
      "Feature max [1.51820007e+02 1.50807724e+02 3.87045000e+07 1.23726545e+01\n",
      " 1.06121148e+01 1.00000000e+02 4.99350015e+00 2.11381062e+00]\n",
      "Target min [73.55126402]\n",
      "Target max [150.80772389]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.64580746e+01  1.71472504e+01  1.14310000e+06  1.73414629e-01\n",
      " -9.42170924e+00  0.00000000e+00 -3.04021945e+00 -1.40459895e+00]\n",
      "Feature max [6.87902832e+01 6.75091394e+01 1.35204800e+08 4.21353693e+00\n",
      " 3.35944208e+00 9.56385384e+01 1.17085551e+00 5.30558430e-01]\n",
      "Target min [17.14725043]\n",
      "Target max [67.50913945]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WBD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.71000004e+00  6.67000008e+00  7.96300000e+05  1.29999638e-01\n",
      " -4.63999939e+00  7.36432776e+00 -5.62270475e+00 -4.52551421e+00]\n",
      "Feature max [7.72699966e+01 7.79800034e+01 1.58082500e+08 2.36100006e+01\n",
      " 3.59000015e+00 1.00000000e+02 7.78521295e+00 1.10191292e+00]\n",
      "Target min [6.67000008]\n",
      "Target max [77.98000336]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.77167358e+02  1.76918245e+02  1.00700000e+05  1.05556133e+00\n",
      " -7.16818629e+01  1.01355576e+01 -2.43843405e+01 -7.21921277e+00]\n",
      "Feature max [5.76549988e+02 5.77500000e+02 8.03490000e+06 6.23608511e+01\n",
      " 3.51599731e+01 1.00000000e+02 1.65133310e+01 6.23603547e+00]\n",
      "Target min [176.717941]\n",
      "Target max [577.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.15072727  8.44774983  0.          0.         -2.64122125  0.\n",
      " -2.42761198 -0.84240951]\n",
      "Feature max [3.84843826e+01 3.84346839e+01 7.90905000e+07 3.35121842e+00\n",
      " 2.26195987e+00 9.66590930e+01 2.24860664e+00 6.65253839e-01]\n",
      "Target min [8.44774983]\n",
      "Target max [38.43468386]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing COST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.34839996e+02  1.34849010e+02  5.43600000e+05  6.44244207e-01\n",
      " -2.94507165e+01  7.85634853e+00 -3.22091496e+01 -9.48258049e+00]\n",
      "Feature max [9.08900024e+02 9.10960022e+02 2.42330000e+07 4.41770966e+01\n",
      " 1.44716865e+01 1.00000000e+02 2.40226275e+01 6.93894981e+00]\n",
      "Target min [134.84900977]\n",
      "Target max [910.96002197]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.09898205e+01  2.08327117e+01  7.55800000e+05  1.13624053e-01\n",
      " -4.94520049e+00  1.11787150e+01 -2.60963577e+00 -8.58607930e-01]\n",
      "Feature max [8.76200027e+01 8.73300018e+01 6.55402000e+07 7.22391984e+00\n",
      " 4.14094804e+00 1.00000000e+02 2.45854720e+00 7.89947350e-01]\n",
      "Target min [20.83271174]\n",
      "Target max [87.33000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LRCX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.58611374e+01  9.56821168e+01  3.00600000e+05  6.44566123e-01\n",
      " -6.64899902e+01  8.02013648e+00 -6.76982729e+01 -2.23238752e+01]\n",
      "Feature max [1.12730005e+03 1.12977002e+03 1.34214000e+07 7.38499756e+01\n",
      " 3.86400146e+01 1.00000000e+02 3.73546174e+01 1.44478835e+01]\n",
      "Target min [95.50306606]\n",
      "Target max [1129.77001953]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MELI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.65434570e+02  1.61862890e+02  1.09000000e+05  1.65614500e+00\n",
      " -1.47979980e+02  6.42065563e+00 -1.26762239e+02 -4.86753050e+01]\n",
      "Feature max [2.06165991e+03 2.03525000e+03 4.29950000e+06 1.80000000e+02\n",
      " 1.14010010e+02 1.00000000e+02 9.65798543e+01 4.12565588e+01]\n",
      "Target min [158.54062541]\n",
      "Target max [2035.25]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDW data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.67368279e+01  4.67459815e+01  1.82100000e+05  3.48899275e-01\n",
      " -2.61500847e+01  1.10566139e+01 -1.16426997e+01 -2.77844166e+00]\n",
      "Feature max [2.56499237e+02 2.59970663e+02 2.45494000e+07 1.57643685e+01\n",
      " 1.15215877e+01 1.00000000e+02 6.29487691e+00 2.94088485e+00]\n",
      "Target min [46.74598155]\n",
      "Target max [259.97066279]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FANG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.26427383e+01  1.29027421e+01  2.62100000e+05  7.69125709e-01\n",
      " -1.58440536e+01  1.03155200e+00 -1.19967651e+01 -3.84871273e+00]\n",
      "Feature max [2.08427399e+02 2.08555865e+02 3.30497000e+07 1.22028993e+01\n",
      " 7.94710772e+00 1.00000000e+02 7.18674450e+00 2.89178311e+00]\n",
      "Target min [12.90274207]\n",
      "Target max [208.55586459]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ZS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.49500008e+01  2.50000000e+01  1.97200000e+05  3.79999161e-01\n",
      " -3.88899994e+01  0.00000000e+00 -2.36812080e+01 -8.89085502e+00]\n",
      "Feature max [3.68779999e+02 3.72500000e+02 2.68458000e+07 5.90399780e+01\n",
      " 2.63500061e+01 9.43483988e+01 1.81146072e+01 6.76156951e+00]\n",
      "Target min [25.]\n",
      "Target max [372.5]\n",
      "X_train shape: (1605, 20, 8)\n",
      "Train_dates: 2018-03-19 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADBE data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.04139999e+02  1.03739998e+02  5.89200000e+05  6.49993896e-01\n",
      " -7.08099976e+01  1.41851355e+00 -3.26176172e+01 -1.20971259e+01]\n",
      "Feature max [6.88369995e+02 6.96280029e+02 2.78402000e+07 5.77900391e+01\n",
      " 7.15100098e+01 1.00000000e+02 3.08100807e+01 9.11981859e+00]\n",
      "Target min [103.43000031]\n",
      "Target max [696.2800293]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.93002777e+01  3.92593243e+01  6.93600000e+06  1.63815054e-01\n",
      " -1.10299988e+01  1.33774083e+01 -5.19036880e+00 -2.41195015e+00]\n",
      "Feature max [1.92660004e+02 1.91750000e+02 1.24140000e+08 9.33999634e+00\n",
      " 1.80194956e+01 1.00000000e+02 5.21262163e+00 1.68897131e+00]\n",
      "Target min [38.8962372]\n",
      "Target max [191.75]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMAT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.72328224e+01  2.75991772e+01  1.40920000e+06  2.48054535e-01\n",
      " -1.45720706e+01  1.10478173e+01 -1.30488603e+01 -4.80425104e+00]\n",
      "Feature max [2.54482300e+02 2.55081164e+02 5.25842000e+07 1.67279368e+01\n",
      " 1.42822203e+01 1.00000000e+02 1.06164162e+01 3.45275434e+00]\n",
      "Target min [27.59917717]\n",
      "Target max [255.0811642]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.12595749e+01  8.12425126e+01  3.50200000e+05  3.94597488e-01\n",
      " -1.50322675e+01  3.70804535e+00 -1.35625548e+01 -3.90767376e+00]\n",
      "Feature max [2.75910004e+02 2.75790009e+02 2.98376000e+07 1.78119332e+01\n",
      " 1.03888355e+01 1.00000000e+02 1.01973422e+01 2.87688260e+00]\n",
      "Target min [81.24251262]\n",
      "Target max [275.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SBUX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.25571518e+01  4.21538439e+01  1.84780000e+06  2.41612756e-01\n",
      " -1.24990496e+01  3.06340275e+00 -6.61673865e+00 -1.77160430e+00]\n",
      "Feature max [1.17301460e+02 1.17320066e+02 1.57215500e+08 8.91208038e+00\n",
      " 1.39059501e+01 1.00000000e+02 5.32951402e+00 2.47897411e+00]\n",
      "Target min [42.15384393]\n",
      "Target max [117.32006556]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTWO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.93600006e+01  4.94000015e+01  2.11600000e+05  3.89999390e-01\n",
      " -1.71000061e+01  5.25756554e+00 -1.00961129e+01 -3.59837456e+00]\n",
      "Feature max [2.13339996e+02 2.10479996e+02 2.53857000e+07 1.86999969e+01\n",
      " 1.62300034e+01 1.00000000e+02 8.60457497e+00 3.04146889e+00]\n",
      "Target min [49.34999847]\n",
      "Target max [210.47999573]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TMUS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.45139313e+01  5.45139293e+01  4.70100000e+05  2.26488207e-01\n",
      " -9.75856794e+00  9.14566324e+00 -4.12801650e+00 -2.00070143e+00]\n",
      "Feature max [2.03367172e+02 2.04613114e+02 6.69031000e+07 1.24074312e+01\n",
      " 1.02607459e+01 1.00000000e+02 5.13087093e+00 2.60923874e+00]\n",
      "Target min [54.51392929]\n",
      "Target max [204.61311436]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing WDAY data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.13600006e+01  6.86699982e+01  3.69100000e+05  7.19993591e-01\n",
      " -2.87099915e+01  9.22365714e+00 -1.61351526e+01 -5.44748712e+00]\n",
      "Feature max [3.07209991e+02 3.09100006e+02 1.56112000e+07 2.13899994e+01\n",
      " 3.39099884e+01 1.00000000e+02 1.38299273e+01 6.22001392e+00]\n",
      "Target min [66.75]\n",
      "Target max [309.1000061]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CRWD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.30099983e+01  3.39300003e+01  8.04900000e+05  1.25000000e+00\n",
      " -4.85399780e+01  5.38771656e+00 -3.82154109e+01 -1.52669393e+01]\n",
      "Feature max [3.92149994e+02 3.92510010e+02 5.40774000e+07 4.09899902e+01\n",
      " 6.24899902e+01 1.00000000e+02 1.92436948e+01 8.51986054e+00]\n",
      "Target min [33.93000031]\n",
      "Target max [392.51000977]\n",
      "X_train shape: (1294, 20, 8)\n",
      "Train_dates: 2019-06-13 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DDOG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.80400009e+01  2.78999996e+01  5.74800000e+05  7.30003357e-01\n",
      " -2.19200058e+01  0.00000000e+00 -1.14620833e+01 -4.12330397e+00]\n",
      "Feature max [1.96559998e+02 1.97695999e+02 2.91348000e+07 2.36900024e+01\n",
      " 2.69400024e+01 9.94039849e+01 1.14713512e+01 4.87120929e+00]\n",
      "Target min [27.89999962]\n",
      "Target max [197.69599915]\n",
      "X_train shape: (1225, 20, 8)\n",
      "Train_dates: 2019-09-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PCAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.86600761e+01  2.83694093e+01  4.95450000e+05  1.76136997e-01\n",
      " -1.04065623e+01  7.26960805e+00 -3.26233711e+00 -1.44177861e+00]\n",
      "Feature max [1.23713150e+02 1.24249916e+02 1.21321500e+07 7.01745891e+00\n",
      " 3.03884672e+00 1.00000000e+02 4.25862741e+00 1.04586866e+00]\n",
      "Target min [28.36940931]\n",
      "Target max [124.24991579]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRNA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.22600002e+01  1.22600002e+01  2.72800000e+05  2.99999237e-01\n",
      " -5.01100159e+01  6.23065240e+00 -3.31765627e+01 -1.53366601e+01]\n",
      "Feature max [4.84470001e+02 4.85500000e+02 1.25130400e+08 8.40969849e+01\n",
      " 4.59499817e+01 1.00000000e+02 5.26756442e+01 1.60440938e+01]\n",
      "Target min [12.26000023]\n",
      "Target max [485.5]\n",
      "X_train shape: (1421, 20, 8)\n",
      "Train_dates: 2018-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing META data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.87276688e+01  8.98952675e+01  5.46750000e+06  5.18937895e-01\n",
      " -7.81893309e+01  9.76807065e+00 -2.89867461e+01 -9.55160496e+00]\n",
      "Feature max [5.39909973e+02 5.42349976e+02 2.32316600e+08 3.50699768e+01\n",
      " 6.46870787e+01 1.00000000e+02 2.92185320e+01 7.48696458e+00]\n",
      "Target min [89.89526752]\n",
      "Target max [542.34997559]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MNST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.07199993e+01  2.07049999e+01  9.22800000e+05  1.65000916e-01\n",
      " -5.64999771e+00  7.54052007e+00 -2.06519425e+00 -6.53749929e-01]\n",
      "Feature max [6.08499985e+01 6.10000000e+01 3.67095000e+07 4.27999878e+00\n",
      " 4.58000183e+00 1.00000000e+02 1.81693996e+00 9.25280916e-01]\n",
      "Target min [20.70499992]\n",
      "Target max [61.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.52999973e+00  9.07999992e+00  1.10358000e+07  1.19999886e-01\n",
      " -1.03399963e+01  0.00000000e+00 -9.13773987e+00 -3.97167693e+00]\n",
      "Feature max [2.11380005e+02 2.13410004e+02 3.25058400e+08 2.16999969e+01\n",
      " 1.31100006e+01 9.59459396e+01 1.14017298e+01 3.51085324e+00]\n",
      "Target min [9.07999992]\n",
      "Target max [213.41000366]\n",
      "X_train shape: (1906, 20, 8)\n",
      "Train_dates: 2017-01-05 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing QCOM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.10863228e+01  4.13346135e+01  2.12020000e+06  2.21164942e-01\n",
      " -1.19638954e+01  7.39833224e+00 -1.13783823e+01 -3.46840781e+00]\n",
      "Feature max [2.25922470e+02 2.25653869e+02 1.56019300e+08 1.56075679e+01\n",
      " 1.67030158e+01 1.00000000e+02 1.22270514e+01 3.97921977e+00]\n",
      "Target min [41.33461346]\n",
      "Target max [225.65386916]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CCEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55083275e+01  2.55731111e+01  2.18600000e+05  1.48332728e-01\n",
      " -5.48860077e+00  7.67579293e+00 -5.38139254e+00 -1.98555562e+00]\n",
      "Feature max [8.04899979e+01 8.02600021e+01 3.00719000e+07 5.47105928e+00\n",
      " 5.02391055e+00 1.00000000e+02 2.10718573e+00 1.58574605e+00]\n",
      "Target min [25.23299887]\n",
      "Target max [80.26000214]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PAYX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.40656853e+01  4.43662845e+01  4.22500000e+05  2.53874772e-01\n",
      " -6.98217401e+00  6.37100935e+00 -7.06664319e+00 -2.03882454e+00]\n",
      "Feature max [1.31301468e+02 1.30869995e+02 1.68049000e+07 1.40609665e+01\n",
      " 5.64424058e+00 1.00000000e+02 4.66590482e+00 1.34585597e+00]\n",
      "Target min [44.36628453]\n",
      "Target max [130.86999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CHTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.54610001e+02  2.38960007e+02  2.42700000e+05  1.79000854e+00\n",
      " -4.96099854e+01  1.00045832e+01 -3.55786821e+01 -1.27762515e+01]\n",
      "Feature max [8.21010010e+02 8.23080017e+02 1.55224000e+07 4.71099854e+01\n",
      " 4.25099792e+01 1.00000000e+02 2.18537876e+01 9.81964050e+00]\n",
      "Target min [238.96000671]\n",
      "Target max [823.08001709]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTAS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.05113632e+02  1.05187619e+02  1.12200000e+05  5.64083578e-01\n",
      " -4.39268149e+01  1.00216434e+01 -2.82557835e+01 -9.58054118e+00]\n",
      "Feature max [8.05119995e+02 8.04500000e+02 2.72700000e+06 4.61448665e+01\n",
      " 4.98478169e+01 1.00000000e+02 1.69135605e+01 6.24244697e+00]\n",
      "Target min [105.18761946]\n",
      "Target max [804.5]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GEHC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.58701477e+01  5.28771038e+01  2.22000000e+04  4.48496557e-01\n",
      " -7.89708004e+00  0.00000000e+00 -2.75575526e+00 -9.40397078e-01]\n",
      "Feature max [9.38021851e+01 9.37422203e+01 3.33385000e+07 1.07550019e+01\n",
      " 3.51607859e+00 8.71250606e+01 4.22888866e+00 9.98581599e-01]\n",
      "Target min [52.87710382]\n",
      "Target max [93.74222026]\n",
      "X_train shape: (408, 20, 8)\n",
      "Train_dates: 2022-12-16 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MRVL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.31523399e+01  1.32089125e+01  1.60940000e+06  9.52960595e-02\n",
      " -5.81999969e+00  1.28620113e+01 -4.44552133e+00 -2.03029603e+00]\n",
      "Feature max [9.03993835e+01 9.02215677e+01 9.43073000e+07 9.40218170e+00\n",
      " 1.46796512e+01 1.00000000e+02 5.29263864e+00 2.28143652e+00]\n",
      "Target min [13.13348662]\n",
      "Target max [90.2215677]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NXPI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.02686539e+01  6.05207162e+01  4.80500000e+05  1.27887259e-01\n",
      " -2.30199890e+01  8.16541241e+00 -1.30447485e+01 -4.12573840e+00]\n",
      "Feature max [2.90779999e+02 2.85390015e+02 5.31022000e+07 2.01099854e+01\n",
      " 1.25948901e+01 1.00000000e+02 9.68135940e+00 3.81693644e+00]\n",
      "Target min [60.5207162]\n",
      "Target max [285.39001465]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TTD data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.71000004e+00  2.69000006e+00  6.31000000e+05  5.90000153e-02\n",
      " -1.51449966e+01  1.02722976e+01 -7.73271712e+00 -2.83294696e+00]\n",
      "Feature max [1.11639999e+02 1.11089996e+02 1.27624000e+08 1.49599991e+01\n",
      " 1.57500000e+01 1.00000000e+02 8.65914541e+00 3.44913976e+00]\n",
      "Target min [2.69000006]\n",
      "Target max [111.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing BKNG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.14400647e+03  1.15864113e+03  7.94000000e+04  6.01675544e+00\n",
      " -3.51773988e+02  6.38670649e+00 -1.75455590e+02 -7.16432727e+01]\n",
      "Feature max [4.10955957e+03 4.10747456e+03 3.32510000e+06 2.15201169e+02\n",
      " 3.12838367e+02 1.00000000e+02 1.21803854e+02 4.94679458e+01]\n",
      "Target min [1158.64113293]\n",
      "Target max [4107.4745618]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KDP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.17389631e+01  1.13540118e+01  3.12600000e+05  5.19934738e-02\n",
      " -2.16673677e+00  5.47446166e+00 -1.84060841e+00 -7.08470514e-01]\n",
      "Feature max [3.81241417e+01 3.81621768e+01 1.43326600e+08 4.27929837e+00\n",
      " 4.32504697e+00 1.00000000e+02 1.24850237e+00 5.03789174e-01]\n",
      "Target min [11.35401184]\n",
      "Target max [38.16217682]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ODFL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.60743675e+01  2.62781823e+01  2.93800000e+05  2.29686485e-01\n",
      " -1.23647591e+01  9.60337192e+00 -9.47054036e+00 -4.03113179e+00]\n",
      "Feature max [2.24051163e+02 2.25128094e+02 4.64676000e+07 2.78705293e+01\n",
      " 9.12874927e+00 1.00000000e+02 9.61462411e+00 3.12346467e+00]\n",
      "Target min [26.27818228]\n",
      "Target max [225.12809388]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ISRG data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.99433365e+01  7.00211105e+01  4.89900000e+05  4.15557861e-01\n",
      " -1.95700073e+01  0.00000000e+00 -2.11512520e+01 -7.04575693e+00]\n",
      "Feature max [4.92630005e+02 4.92619995e+02 1.12668000e+07 2.48000031e+01\n",
      " 3.32899780e+01 9.95441593e+01 1.42319395e+01 6.40623327e+00]\n",
      "Target min [70.02111053]\n",
      "Target max [492.61999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing TXN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.90602341e+01  5.90278404e+01  1.04440000e+06  2.77121978e-01\n",
      " -1.04007959e+01  0.00000000e+00 -6.09191243e+00 -2.17086585e+00]\n",
      "Feature max [2.14339996e+02 2.12580002e+02 2.51217000e+07 1.31599884e+01\n",
      " 1.25867588e+01 9.74574577e+01 7.69273172e+00 2.34828465e+00]\n",
      "Target min [59.02784045]\n",
      "Target max [212.58000183]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ARM data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.78699989e+01  4.72200012e+01  2.26890000e+06  1.22000122e+00\n",
      " -2.08500061e+01  0.00000000e+00 -1.27820527e+01 -6.74110994e+00]\n",
      "Feature max [1.86460007e+02 1.86839996e+02 1.11349700e+08 4.53099976e+01\n",
      " 1.74000015e+01 9.62229824e+01 1.65008639e+01 6.88049836e+00]\n",
      "Target min [47.22000122]\n",
      "Target max [186.83999634]\n",
      "X_train shape: (222, 20, 8)\n",
      "Train_dates: 2023-09-15 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ROST data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.95189934e+01  4.98084665e+01  5.35700000e+05  4.09831331e-01\n",
      " -2.21022889e+01  7.32230178e+00 -1.31744929e+01 -4.43503125e+00]\n",
      "Feature max [1.55210007e+02 1.63559998e+02 3.45755000e+07 1.30095097e+01\n",
      " 1.65455419e+01 1.00000000e+02 7.20230574e+00 2.52539357e+00]\n",
      "Target min [49.80846647]\n",
      "Target max [163.55999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDLZ data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.26199188e+01  3.25591496e+01  1.83380000e+06  1.95484721e-01\n",
      " -4.06839147e+00  0.00000000e+00 -3.04621915e+00 -1.02893365e+00]\n",
      "Feature max [7.60628128e+01 7.61016456e+01 2.91974000e+07 4.50139843e+00\n",
      " 3.43486980e+00 9.24407477e+01 2.31448963e+00 8.04108193e-01]\n",
      "Target min [32.55914962]\n",
      "Target max [76.10164563]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LIN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01270142e+02  1.01313944e+02  2.76400000e+05  5.60332175e-01\n",
      " -2.60358760e+01  0.00000000e+00 -1.35822608e+01 -4.32009002e+00]\n",
      "Feature max [4.76847687e+02 4.73647108e+02 5.73756000e+07 2.50221223e+01\n",
      " 1.73250788e+01 9.79872343e+01 1.39092179e+01 4.41990105e+00]\n",
      "Target min [101.31394352]\n",
      "Target max [473.64710757]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CSCO data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.37586021e+01  2.37744560e+01  5.72050000e+06  1.35897100e-01\n",
      " -5.72839768e+00  0.00000000e+00 -2.51348595e+00 -7.94818516e-01]\n",
      "Feature max [5.87176704e+01 5.87911142e+01 1.06928300e+08 3.98683245e+00\n",
      " 3.31000137e+00 9.41027868e+01 1.74181680e+00 6.52277519e-01]\n",
      "Target min [23.77445599]\n",
      "Target max [58.79111417]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.08447899e+02  1.05853958e+02  4.17100000e+05  4.74368406e-01\n",
      " -4.12029187e+01  4.31352673e+00 -2.91569463e+01 -1.00687249e+01]\n",
      "Feature max [6.82518738e+02 7.03358031e+02 6.66440000e+06 4.95999756e+01\n",
      " 8.54105820e+01 1.00000000e+02 2.48427136e+01 9.59889374e+00]\n",
      "Target min [105.85395772]\n",
      "Target max [703.3580307]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing PEP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.95354233e+01  7.97587250e+01  8.83300000e+05  2.59117667e-01\n",
      " -1.12208456e+01  5.70029341e+00 -6.82845146e+00 -2.27586936e+00]\n",
      "Feature max [1.87563278e+02 1.87993660e+02 2.75597000e+07 1.49757783e+01\n",
      " 5.79653240e+00 1.00000000e+02 3.40029242e+00 2.27648764e+00]\n",
      "Target min [79.75872505]\n",
      "Target max [187.99366029]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ANSS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.32399979e+01  9.30100021e+01  1.40800000e+05  5.89996338e-01\n",
      " -3.09700012e+01  8.81775088e+00 -1.95951198e+01 -9.68954390e+00]\n",
      "Feature max [4.11220001e+02 4.13220001e+02 1.76134000e+07 5.81499939e+01\n",
      " 5.98500061e+01 1.00000000e+02 1.77876080e+01 8.00055630e+00]\n",
      "Target min [93.01000214]\n",
      "Target max [413.22000122]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing SMCI data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [  11.64999962   11.55000019 1300.            0.         -112.07000732\n",
      "    3.06121694  -80.8459551   -37.07896777]\n",
      "Feature max [1.18806995e+03 1.21200000e+03 3.69735000e+07 2.76719971e+02\n",
      " 1.33520020e+02 1.00000000e+02 1.39404960e+02 3.27849310e+01]\n",
      "Target min [11.55000019]\n",
      "Target max [1212.]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MCHP data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.59165306e+01  2.58235891e+01  9.03800000e+05  2.06648739e-01\n",
      " -4.89303413e+00  0.00000000e+00 -5.27414160e+00 -1.76700590e+00]\n",
      "Feature max [9.89445496e+01 9.94815944e+01 6.08822000e+07 6.51408535e+00\n",
      " 6.70936116e+00 9.91722396e+01 3.41370679e+00 1.65715953e+00]\n",
      "Target min [25.82358912]\n",
      "Target max [99.48159441]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DASH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.30600014e+01  4.40000000e+01  6.73000000e+05  1.04000092e+00\n",
      " -1.43899994e+01  0.00000000e+00 -1.42424126e+01 -6.22931087e+00]\n",
      "Feature max [2.45970001e+02 2.47520004e+02 4.74057000e+07 6.56900024e+01\n",
      " 3.15700073e+01 8.94834273e+01 1.00982520e+01 7.89917563e+00]\n",
      "Target min [44.]\n",
      "Target max [247.52000427]\n",
      "X_train shape: (916, 20, 8)\n",
      "Train_dates: 2020-12-10 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing LULU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.79099998e+01  4.80200005e+01  3.97400000e+05  5.40000916e-01\n",
      " -6.25899963e+01  5.58157336e+00 -2.90394509e+01 -9.98076840e+00]\n",
      "Feature max [5.11290009e+02 5.13239990e+02 4.96203000e+07 4.49899902e+01\n",
      " 5.28800049e+01 1.00000000e+02 2.51784526e+01 8.66763261e+00]\n",
      "Target min [48.02000046]\n",
      "Target max [513.23999023]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMGN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.20500969e+02  1.20691432e+02  6.12800000e+05  8.28945620e-01\n",
      " -1.51888274e+01  4.25199822e+00 -6.90048934e+00 -3.92935280e+00]\n",
      "Feature max [3.33829987e+02 3.35086817e+02 2.39368000e+07 2.95567858e+01\n",
      " 3.45128549e+01 1.00000000e+02 1.11182754e+01 4.56751051e+00]\n",
      "Target min [117.334683]\n",
      "Target max [335.08681669]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ADSK data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 7.69300003e+01  7.61900024e+01  2.56200000e+05  5.80001831e-01\n",
      " -4.11199951e+01  8.69419477e+00 -1.48270264e+01 -9.41658874e+00]\n",
      "Feature max [3.42269989e+02 3.42519989e+02 1.94870000e+07 2.90000076e+01\n",
      " 2.02900085e+01 1.00000000e+02 1.45651636e+01 4.69711212e+00]\n",
      "Target min [74.61000061]\n",
      "Target max [342.51998901]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CTSH data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88846664e+01  3.95294675e+01  6.22600000e+05  2.63455751e-01\n",
      " -7.87767379e+00  3.88424808e+00 -4.96337404e+00 -1.63582241e+00]\n",
      "Feature max [8.93110733e+01 8.89753804e+01 4.05510000e+07 7.35239068e+00\n",
      " 4.92299173e+00 1.00000000e+02 2.87894007e+00 1.48546423e+00]\n",
      "Target min [39.52946751]\n",
      "Target max [88.97538038]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CMCSA data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.63607178e+01  2.63434845e+01  3.87530000e+06  1.43293776e-01\n",
      " -4.19077588e+00  4.89615202e+00 -2.20475335e+00 -7.52468632e-01]\n",
      "Feature max [5.69077492e+01 5.66128390e+01 1.05512100e+08 5.02262469e+00\n",
      " 2.79151225e+00 1.00000000e+02 1.64204685e+00 6.64990265e-01]\n",
      "Target min [26.34348454]\n",
      "Target max [56.61283896]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AAPL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.68914146e+01  2.68520120e+01  2.40483000e+07  1.39069199e-01\n",
      " -2.07459821e+01  0.00000000e+00 -6.52546791e+00 -2.48303795e+00]\n",
      "Feature max [2.34548523e+02 2.36206595e+02 4.47940000e+08 1.74797677e+01\n",
      " 1.35858198e+01 9.66322867e+01 8.94504543e+00 2.34169517e+00]\n",
      "Target min [26.84042149]\n",
      "Target max [236.20659489]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing DLTR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.55699997e+01  6.56299973e+01  6.51800000e+05  6.50001526e-01\n",
      " -2.06100006e+01  5.95402131e+00 -8.27013588e+00 -4.05435465e+00]\n",
      "Feature max [1.74080002e+02 1.75119995e+02 2.64414000e+07 1.71399956e+01\n",
      " 2.62200012e+01 1.00000000e+02 1.03700274e+01 2.48843256e+00]\n",
      "Target min [65.62999725]\n",
      "Target max [175.11999512]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GFS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.88100014e+01  3.79099998e+01  4.52100000e+05  4.29996490e-01\n",
      " -4.36000061e+00  7.50238102e+00 -4.23886167e+00 -2.38196636e+00]\n",
      "Feature max [7.89400024e+01 7.86999969e+01 2.59534000e+07 9.84000015e+00\n",
      " 5.52999878e+00 1.00000000e+02 5.44023126e+00 1.92129480e+00]\n",
      "Target min [37.90999985]\n",
      "Target max [78.69999695]\n",
      "X_train shape: (693, 20, 8)\n",
      "Train_dates: 2021-10-29 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ON data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 8.44999981e+00  8.35999966e+00  1.22410000e+06  1.59999847e-01\n",
      " -1.02299957e+01  1.19369510e+01 -7.02511537e+00 -2.54591706e+00]\n",
      "Feature max [1.08089996e+02 1.09739998e+02 9.31809000e+07 8.59999847e+00\n",
      " 5.73000336e+00 1.00000000e+02 5.08121811e+00 1.91962014e+00]\n",
      "Target min [8.35999966]\n",
      "Target max [109.73999786]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing GOOGL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 4.03422012e+01  4.03287161e+01  9.31200000e+06  2.03764713e-01\n",
      " -1.11600037e+01  0.00000000e+00 -5.26264397e+00 -2.43230043e+00]\n",
      "Feature max [1.91179993e+02 1.90309998e+02 1.33178000e+08 9.50000000e+00\n",
      " 1.83489409e+01 9.87786722e+01 5.22104620e+00 1.70818585e+00]\n",
      "Target min [39.98510758]\n",
      "Target max [190.30999756]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MU data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.13033676e+01  2.10973018e+01  4.34960000e+06  2.94382095e-01\n",
      " -6.56426828e+00  0.00000000e+00 -1.04368766e+01 -2.87377563e+00]\n",
      "Feature max [1.53315903e+02 1.56872784e+02 1.42315800e+08 1.44873285e+01\n",
      " 1.70885413e+01 9.98188995e+01 9.21113766e+00 2.76849472e+00]\n",
      "Target min [21.09730184]\n",
      "Target max [156.87278409]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ILMN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 9.02626495e+01  9.14591446e+01  2.24207000e+05  1.42024231e+00\n",
      " -5.47957153e+01  1.07051311e+00 -2.98009348e+01 -1.18772369e+01]\n",
      "Feature max [5.10544739e+02 5.08336578e+02 3.66514900e+07 1.00622589e+02\n",
      " 3.87353821e+01 1.00000000e+02 2.65404856e+01 7.18644479e+00]\n",
      "Target min [91.45914459]\n",
      "Target max [508.33657837]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing CDNS data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.55699997e+01  2.53400002e+01  3.77200000e+05  1.30001068e-01\n",
      " -1.65799866e+01  6.34196911e+00 -1.44468346e+01 -5.97594400e+00]\n",
      "Feature max [3.26500000e+02 3.28790009e+02 5.72181000e+07 2.09400024e+01\n",
      " 1.50199890e+01 1.00000000e+02 8.60328681e+00 4.15512117e+00]\n",
      "Target min [25.34000015]\n",
      "Target max [328.79000854]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing FTNT data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.08400011e+00  6.03000021e+00  1.55300000e+06  5.60002327e-02\n",
      " -1.53400040e+01  3.96274759e+00 -4.72904041e+00 -2.60667325e+00]\n",
      "Feature max [8.02799988e+01 8.04499969e+01 1.66853000e+08 9.42400360e+00\n",
      " 9.86999893e+00 1.00000000e+02 4.39902634e+00 1.72982386e+00]\n",
      "Target min [6.03000021]\n",
      "Target max [80.44999695]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing NFLX data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.29179993e+02  1.27489998e+02  1.14400000e+06  8.99993896e-01\n",
      " -1.07820007e+02  2.54085690e+00 -5.92338064e+01 -1.83116588e+01]\n",
      "Feature max [7.01349976e+02 7.00359985e+02 1.33387500e+08 5.69599915e+01\n",
      " 6.36499939e+01 1.00000000e+02 2.49544334e+01 9.64348338e+00]\n",
      "Target min [124.95999908]\n",
      "Target max [700.35998535]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing ASML data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.01730980e+02  1.01656938e+02  1.91300000e+05  5.09020836e-01\n",
      " -8.94442496e+01  0.00000000e+00 -4.66577753e+01 -2.22673979e+01]\n",
      "Feature max [1.09691748e+03 1.10792721e+03 7.75430000e+06 7.14700317e+01\n",
      " 6.84131669e+01 9.61644506e+01 5.18699482e+01 1.62876849e+01]\n",
      "Target min [101.65693821]\n",
      "Target max [1107.92720614]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MDB data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 2.57600002e+01  2.56200008e+01  7.45000000e+04  3.59998703e-01\n",
      " -7.29299927e+01  0.00000000e+00 -4.01420346e+01 -1.51743729e+01]\n",
      "Feature max [5.85030029e+02 5.85030029e+02 1.25421000e+07 6.22800293e+01\n",
      " 9.26100159e+01 9.67312153e+01 3.60296232e+01 1.38232539e+01]\n",
      "Target min [25.62000084]\n",
      "Target max [585.0300293]\n",
      "X_train shape: (1706, 20, 8)\n",
      "Train_dates: 2017-10-20 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing MAR data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 5.76626625e+01  5.97122647e+01  4.45200000e+05  3.56550091e-01\n",
      " -1.06970511e+01  0.00000000e+00 -1.68949989e+01 -4.25844756e+00]\n",
      "Feature max [2.57128174e+02 2.54701584e+02 2.58818000e+07 2.13453368e+01\n",
      " 1.87003626e+01 9.38535946e+01 7.41175366e+00 3.17530449e+00]\n",
      "Target min [59.71226473]\n",
      "Target max [254.70158394]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing INTC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 1.89899998e+01  1.91000004e+01  6.31320000e+06  1.65667050e-01\n",
      " -7.35441144e+00  0.00000000e+00 -3.67962917e+00 -1.56579357e+00]\n",
      "Feature max [6.20833282e+01 6.20287604e+01 3.00895900e+08 7.64107673e+00\n",
      " 5.65919907e+00 9.56312147e+01 2.62854992e+00 1.12867580e+00]\n",
      "Target min [19.10000038]\n",
      "Target max [62.0287604]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing KLAC data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 6.84464874e+01  6.86297678e+01  2.57700000e+05  5.09411813e-01\n",
      " -4.98388271e+01  0.00000000e+00 -2.75021474e+01 -1.29123595e+01]\n",
      "Feature max [8.90720154e+02 8.94682933e+02 6.29590000e+06 7.53521125e+01\n",
      " 4.65248886e+01 9.61332745e+01 3.03164128e+01 1.17409375e+01]\n",
      "Target min [68.62976779]\n",
      "Target max [894.68293334]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing AMZN data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [ 3.78590012e+01  3.79194984e+01  1.76260000e+07  1.59500122e-01\n",
      " -1.73200073e+01  1.14353166e+01 -1.24315006e+01 -3.31749210e+00]\n",
      "Feature max [2.00000000e+02 2.00089996e+02 3.31300000e+08 1.37949982e+01\n",
      " 1.67610016e+01 1.00000000e+02 8.13447345e+00 3.39296647e+00]\n",
      "Target min [37.89599991]\n",
      "Target max [200.08999634]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n",
      "--- Preparing XEL data using 20 window---\n",
      "Feature columns: ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD', 'MACD_Hist']\n",
      "Target column: Open\n",
      "Feature min [32.11785126 32.15771459  0.          0.         -5.25528065  4.89746878\n",
      " -3.58270511 -1.54356204]\n",
      "Feature max [7.23329163e+01 7.20338972e+01 2.27822000e+07 8.42779954e+00\n",
      " 2.38429559e+00 1.00000000e+02 1.75878051e+00 1.02005413e+00]\n",
      "Target min [32.15771459]\n",
      "Target max [72.03389725]\n",
      "X_train shape: (1907, 20, 8)\n",
      "Train_dates: 2017-01-04 00:00:00 - 2024-08-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">35,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)                  │          \u001b[38;5;34m35,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m91\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,731</span> (139.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,731\u001b[0m (139.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,731</span> (139.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,731\u001b[0m (139.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/102 Training model for ^IXIC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0128 - mape: 127.1866 - val_loss: 0.0525 - val_mape: 25.4165\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0501 - mape: 327.3840 - val_loss: 0.0602 - val_mape: 28.6222\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mape: 183.3121 - val_loss: 0.0520 - val_mape: 26.6706\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - mape: 133.1213 - val_loss: 0.0436 - val_mape: 24.3670\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - mape: 101.4736 - val_loss: 0.0297 - val_mape: 19.9058\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - mape: 98.2311 - val_loss: 0.0295 - val_mape: 19.8622\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - mape: 86.8413 - val_loss: 0.0251 - val_mape: 18.2324\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - mape: 81.2112 - val_loss: 0.0225 - val_mape: 17.1493\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - mape: 87.3548 - val_loss: 0.0236 - val_mape: 17.6182\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - mape: 82.7176 - val_loss: 0.0196 - val_mape: 15.9529\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - mape: 80.2484 - val_loss: 0.0175 - val_mape: 14.9971\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - mape: 82.2776 - val_loss: 0.0181 - val_mape: 15.3358\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - mape: 72.6382 - val_loss: 0.0144 - val_mape: 13.4559\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - mape: 79.1371 - val_loss: 0.0124 - val_mape: 12.4371\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - mape: 72.1284 - val_loss: 0.0113 - val_mape: 11.7937\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - mape: 71.6133 - val_loss: 0.0096 - val_mape: 10.7637\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - mape: 69.6994 - val_loss: 0.0085 - val_mape: 10.0553\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mape: 63.8154 - val_loss: 0.0080 - val_mape: 9.7202\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mape: 61.8023 - val_loss: 0.0074 - val_mape: 9.2912\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - mape: 63.7406 - val_loss: 0.0071 - val_mape: 9.0842\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mape: 64.8536 - val_loss: 0.0066 - val_mape: 8.7613\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mape: 62.7531 - val_loss: 0.0062 - val_mape: 8.4035\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mape: 61.0427 - val_loss: 0.0057 - val_mape: 8.0481\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - mape: 49.2943 - val_loss: 0.0049 - val_mape: 7.3835\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - mape: 50.4636 - val_loss: 0.0050 - val_mape: 7.4645\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 50.3479 - val_loss: 0.0041 - val_mape: 6.6490\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mape: 48.0321 - val_loss: 0.0047 - val_mape: 7.2982\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mape: 45.5340 - val_loss: 0.0038 - val_mape: 6.4275\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 38.7851 - val_loss: 0.0048 - val_mape: 7.5060\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 37.7809 - val_loss: 0.0054 - val_mape: 7.9849\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 38.9436 - val_loss: 0.0046 - val_mape: 7.2443\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 44.8384 - val_loss: 0.0052 - val_mape: 7.7856\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 42.5402 - val_loss: 0.0045 - val_mape: 7.1080\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mape: 43.9733 - val_loss: 0.0058 - val_mape: 8.3062\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mape: 37.9026 - val_loss: 0.0051 - val_mape: 7.6606\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 42.1001 - val_loss: 0.0041 - val_mape: 6.7992\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 39.7942 - val_loss: 0.0049 - val_mape: 7.5475\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mape: 44.2852 - val_loss: 0.0052 - val_mape: 7.7975\n",
      "--- 2/102 Training model for VRTX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 21.9840 - val_loss: 0.0018 - val_mape: 4.5235\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 26.0836 - val_loss: 0.0011 - val_mape: 3.5091\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5505e-04 - mape: 15.9129 - val_loss: 8.8061e-04 - val_mape: 3.0722\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5084e-04 - mape: 16.7225 - val_loss: 8.0295e-04 - val_mape: 2.9476\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5072e-04 - mape: 13.8275 - val_loss: 5.8631e-04 - val_mape: 2.4420\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3412e-04 - mape: 13.1996 - val_loss: 6.2588e-04 - val_mape: 2.5712\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7272e-04 - mape: 10.9787 - val_loss: 4.2234e-04 - val_mape: 1.9938\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2863e-04 - mape: 12.9065 - val_loss: 3.7193e-04 - val_mape: 1.8437\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7857e-04 - mape: 15.2228 - val_loss: 2.9823e-04 - val_mape: 1.6025\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5989e-04 - mape: 11.7804 - val_loss: 2.3196e-04 - val_mape: 1.3203\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9712e-04 - mape: 12.7847 - val_loss: 1.4686e-04 - val_mape: 1.1873\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1878e-04 - mape: 8.5024 - val_loss: 1.3472e-04 - val_mape: 0.9913\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8786e-04 - mape: 13.1592 - val_loss: 2.6274e-04 - val_mape: 1.5015\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0692e-04 - mape: 10.0238 - val_loss: 1.3082e-04 - val_mape: 1.0676\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8265e-04 - mape: 8.8989 - val_loss: 2.5740e-04 - val_mape: 1.5131\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5542e-04 - mape: 7.5679 - val_loss: 5.4349e-04 - val_mape: 2.5121\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6309e-04 - mape: 8.8560 - val_loss: 2.6264e-04 - val_mape: 1.5578\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6620e-04 - mape: 8.3269 - val_loss: 1.7173e-04 - val_mape: 1.1599\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5295e-04 - mape: 8.0303 - val_loss: 1.3613e-04 - val_mape: 1.0226\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5107e-04 - mape: 7.3825 - val_loss: 5.6206e-04 - val_mape: 2.5879\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4514e-04 - mape: 7.5777 - val_loss: 1.3056e-04 - val_mape: 1.0128\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5206e-04 - mape: 7.5682 - val_loss: 1.0308e-04 - val_mape: 0.9439\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9896e-04 - mape: 10.0919 - val_loss: 3.3904e-04 - val_mape: 1.8372\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7291e-04 - mape: 9.2174 - val_loss: 3.7066e-04 - val_mape: 1.9545\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1207e-04 - mape: 6.9504 - val_loss: 1.0284e-04 - val_mape: 0.9400\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6266e-04 - mape: 8.6980 - val_loss: 1.6020e-04 - val_mape: 1.1097\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4414e-04 - mape: 8.4426 - val_loss: 1.0302e-04 - val_mape: 0.9226\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4070e-04 - mape: 7.4650 - val_loss: 1.3532e-04 - val_mape: 1.1771\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0019e-04 - mape: 8.2925 - val_loss: 1.9176e-04 - val_mape: 1.1994\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8707e-04 - mape: 9.0611 - val_loss: 2.5137e-04 - val_mape: 1.4313\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8892e-04 - mape: 7.9678 - val_loss: 1.4518e-04 - val_mape: 1.0447\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6332e-04 - mape: 8.6162 - val_loss: 7.1436e-04 - val_mape: 2.8686\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3705e-04 - mape: 7.9717 - val_loss: 3.3930e-04 - val_mape: 1.8284\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8858e-04 - mape: 6.4802 - val_loss: 2.1644e-04 - val_mape: 1.3585\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2973e-04 - mape: 8.2047 - val_loss: 1.3130e-04 - val_mape: 1.1345\n",
      "--- 3/102 Training model for PYPL ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7937e-04 - mape: 13311.7578 - val_loss: 1.6568e-05 - val_mape: 3.7240\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3371e-04 - mape: 15986.7559 - val_loss: 4.2543e-05 - val_mape: 6.8115\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5538e-04 - mape: 20652.6816 - val_loss: 4.2242e-05 - val_mape: 6.8102\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9593e-04 - mape: 2305.7910 - val_loss: 7.3593e-05 - val_mape: 9.7718\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5882e-04 - mape: 78228.9922 - val_loss: 8.8063e-06 - val_mape: 2.6922\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7636e-04 - mape: 13634.8311 - val_loss: 1.2668e-04 - val_mape: 12.6461\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8428e-04 - mape: 37474.6133 - val_loss: 5.9161e-04 - val_mape: 28.1091\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mape: 18107.8809 - val_loss: 8.5999e-04 - val_mape: 33.5877\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 14309.5576 - val_loss: 8.3492e-04 - val_mape: 32.9530\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - mape: 122047.3594 - val_loss: 0.0010 - val_mape: 36.7762\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mape: 106858.2734 - val_loss: 9.9696e-05 - val_mape: 9.2157\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mape: 46123.0078 - val_loss: 1.5503e-04 - val_mape: 12.0458\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - mape: 134355.5000 - val_loss: 3.3818e-04 - val_mape: 19.4984\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - mape: 91225.2344 - val_loss: 9.1787e-04 - val_mape: 32.1926\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mape: 28910.0469 - val_loss: 0.0010 - val_mape: 33.0815\n",
      "--- 4/102 Training model for GILD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1771e-04 - mape: 46446.2031 - val_loss: 4.3103e-04 - val_mape: 2.5915\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2400e-04 - mape: 19543.4590 - val_loss: 6.3785e-04 - val_mape: 3.3871\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8171e-04 - mape: 18397.8730 - val_loss: 7.5531e-04 - val_mape: 3.7990\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2091e-04 - mape: 23116.0801 - val_loss: 5.8700e-04 - val_mape: 3.2039\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2084e-04 - mape: 21419.9082 - val_loss: 8.1820e-04 - val_mape: 3.8488\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2137e-04 - mape: 25362.6914 - val_loss: 4.3186e-04 - val_mape: 2.5633\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0468e-04 - mape: 25379.9004 - val_loss: 2.2579e-04 - val_mape: 1.7396\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6806e-04 - mape: 17575.9082 - val_loss: 3.8711e-04 - val_mape: 2.4482\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0954e-04 - mape: 16610.4688 - val_loss: 3.2486e-04 - val_mape: 2.1230\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0921e-04 - mape: 37915.9336 - val_loss: 3.2425e-04 - val_mape: 2.1521\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9228e-04 - mape: 15364.6934 - val_loss: 2.1298e-04 - val_mape: 1.6682\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7274e-04 - mape: 16959.8184 - val_loss: 2.9995e-04 - val_mape: 2.0548\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5792e-04 - mape: 13798.2246 - val_loss: 2.8266e-04 - val_mape: 1.9937\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7905e-04 - mape: 30067.1309 - val_loss: 2.6165e-04 - val_mape: 1.8801\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4927e-04 - mape: 35173.5000 - val_loss: 2.1948e-04 - val_mape: 1.6904\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5572e-04 - mape: 34133.7422 - val_loss: 1.8600e-04 - val_mape: 1.6072\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5036e-04 - mape: 37888.2695 - val_loss: 3.4367e-04 - val_mape: 2.1948\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6486e-04 - mape: 14794.9941 - val_loss: 1.5444e-04 - val_mape: 1.4865\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7296e-04 - mape: 35645.1602 - val_loss: 3.9451e-04 - val_mape: 2.4576\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3866e-04 - mape: 24102.9395 - val_loss: 2.0883e-04 - val_mape: 1.7017\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2854e-04 - mape: 44290.7461 - val_loss: 1.5666e-04 - val_mape: 1.5317\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1663e-04 - mape: 25317.9766 - val_loss: 2.0856e-04 - val_mape: 1.6987\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5593e-04 - mape: 26414.4961 - val_loss: 2.8013e-04 - val_mape: 2.0075\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2096e-04 - mape: 21192.3359 - val_loss: 1.4427e-04 - val_mape: 1.4607\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1304e-04 - mape: 22957.6250 - val_loss: 2.3292e-04 - val_mape: 1.8103\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9692e-04 - mape: 23509.9746 - val_loss: 2.5224e-04 - val_mape: 1.9500\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3189e-04 - mape: 34247.6133 - val_loss: 1.6271e-04 - val_mape: 1.5243\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4018e-04 - mape: 26903.9980 - val_loss: 1.3706e-04 - val_mape: 1.4287\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3575e-04 - mape: 37330.4219 - val_loss: 1.4425e-04 - val_mape: 1.4576\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9726e-04 - mape: 33933.6875 - val_loss: 1.6011e-04 - val_mape: 1.5486\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0669e-04 - mape: 14017.4775 - val_loss: 1.4368e-04 - val_mape: 1.4991\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9680e-04 - mape: 29151.7246 - val_loss: 1.4981e-04 - val_mape: 1.5163\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2681e-04 - mape: 36137.3242 - val_loss: 1.4306e-04 - val_mape: 1.5110\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0236e-04 - mape: 35031.2422 - val_loss: 3.7365e-04 - val_mape: 2.5054\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3041e-04 - mape: 37003.2383 - val_loss: 2.7568e-04 - val_mape: 2.1350\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1116e-04 - mape: 25567.2246 - val_loss: 1.7313e-04 - val_mape: 1.6141\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2055e-04 - mape: 30631.9199 - val_loss: 2.1053e-04 - val_mape: 1.8457\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0780e-04 - mape: 25267.5039 - val_loss: 1.1857e-04 - val_mape: 1.3383\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7707e-04 - mape: 33187.8047 - val_loss: 2.9692e-04 - val_mape: 2.2633\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9845e-04 - mape: 18427.4746 - val_loss: 4.4902e-04 - val_mape: 3.0235\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2385e-04 - mape: 37042.0234 - val_loss: 2.1022e-04 - val_mape: 1.8408\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7248e-04 - mape: 28757.8223 - val_loss: 1.3234e-04 - val_mape: 1.4391\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7615e-04 - mape: 29216.8105 - val_loss: 2.7254e-04 - val_mape: 2.1635\n",
      "Epoch 44/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9282e-04 - mape: 18742.6523 - val_loss: 1.0425e-04 - val_mape: 1.2719\n",
      "Epoch 45/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5415e-04 - mape: 39253.3633 - val_loss: 2.6690e-04 - val_mape: 2.1626\n",
      "Epoch 46/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7021e-04 - mape: 9756.5254 - val_loss: 1.0846e-04 - val_mape: 1.2994\n",
      "Epoch 47/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6333e-04 - mape: 11084.8369 - val_loss: 1.1323e-04 - val_mape: 1.3146\n",
      "Epoch 48/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4505e-04 - mape: 32953.9336 - val_loss: 1.4130e-04 - val_mape: 1.4669\n",
      "Epoch 49/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5342e-04 - mape: 12978.4404 - val_loss: 1.1071e-04 - val_mape: 1.3436\n",
      "Epoch 50/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8451e-04 - mape: 5631.5093 - val_loss: 1.3434e-04 - val_mape: 1.4312\n",
      "Epoch 51/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6809e-04 - mape: 27529.7148 - val_loss: 1.0409e-04 - val_mape: 1.2887\n",
      "Epoch 52/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0842e-04 - mape: 30778.1445 - val_loss: 1.3210e-04 - val_mape: 1.4116\n",
      "Epoch 53/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5103e-04 - mape: 24153.0625 - val_loss: 1.1412e-04 - val_mape: 1.3659\n",
      "Epoch 54/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1451e-04 - mape: 31571.9727 - val_loss: 1.5694e-04 - val_mape: 1.5239\n",
      "Epoch 55/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1492e-04 - mape: 38171.0391 - val_loss: 1.3603e-04 - val_mape: 1.5059\n",
      "Epoch 56/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4027e-04 - mape: 37066.6719 - val_loss: 6.3115e-04 - val_mape: 3.4765\n",
      "Epoch 57/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1967e-04 - mape: 19534.1660 - val_loss: 1.1105e-04 - val_mape: 1.3193\n",
      "Epoch 58/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9978e-04 - mape: 22729.3887 - val_loss: 1.0710e-04 - val_mape: 1.3112\n",
      "Epoch 59/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7367e-04 - mape: 20301.9082 - val_loss: 1.6478e-04 - val_mape: 1.5467\n",
      "Epoch 60/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1207e-04 - mape: 5528.1006 - val_loss: 1.1020e-04 - val_mape: 1.3497\n",
      "Epoch 61/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5886e-04 - mape: 30606.3848 - val_loss: 6.6873e-04 - val_mape: 3.6101\n",
      "--- 5/102 Training model for CSX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5454e-04 - mape: 6.2254 - val_loss: 2.0462e-04 - val_mape: 1.3693\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 11.6348 - val_loss: 3.4868e-04 - val_mape: 1.8722\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - mape: 13.3603 - val_loss: 2.3174e-04 - val_mape: 1.5028\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4552e-04 - mape: 10.6420 - val_loss: 2.7802e-04 - val_mape: 1.7279\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5164e-04 - mape: 5.5187 - val_loss: 4.6214e-05 - val_mape: 0.6126\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3868e-04 - mape: 4.8886 - val_loss: 3.1760e-04 - val_mape: 1.9085\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4382e-04 - mape: 6.8639 - val_loss: 8.1305e-05 - val_mape: 0.8398\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1098e-04 - mape: 9.1450 - val_loss: 9.4110e-05 - val_mape: 0.9271\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8508e-04 - mape: 6.1884 - val_loss: 4.0979e-05 - val_mape: 0.5881\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8488e-04 - mape: 7.9297 - val_loss: 3.3938e-05 - val_mape: 0.5299\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6002e-04 - mape: 6.2922 - val_loss: 2.4353e-04 - val_mape: 1.5895\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8833e-04 - mape: 4.9828 - val_loss: 6.4104e-05 - val_mape: 0.7457\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2412e-04 - mape: 7.1608 - val_loss: 1.2320e-04 - val_mape: 1.1618\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9609e-04 - mape: 5.4009 - val_loss: 5.5498e-05 - val_mape: 0.7368\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0655e-04 - mape: 9.1034 - val_loss: 6.8414e-05 - val_mape: 0.8166\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3117e-04 - mape: 4.5135 - val_loss: 3.4623e-05 - val_mape: 0.5210\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4500e-04 - mape: 6.2622 - val_loss: 3.5401e-05 - val_mape: 0.5415\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3079e-04 - mape: 4.3987 - val_loss: 4.9964e-05 - val_mape: 0.6466\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2045e-04 - mape: 6.1406 - val_loss: 1.1751e-04 - val_mape: 1.0816\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0857e-04 - mape: 4.2204 - val_loss: 3.4469e-05 - val_mape: 0.5384\n",
      "--- 6/102 Training model for IDXX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7727e-04 - mape: 20.1718 - val_loss: 3.1540e-04 - val_mape: 2.4732\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1526e-04 - mape: 14.5367 - val_loss: 5.0485e-05 - val_mape: 0.7998\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7879e-04 - mape: 22.6623 - val_loss: 7.7738e-05 - val_mape: 1.1140\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2944e-04 - mape: 10.7848 - val_loss: 1.1774e-04 - val_mape: 1.4032\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3596e-04 - mape: 17.5179 - val_loss: 8.6662e-05 - val_mape: 1.1695\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0857e-04 - mape: 9.8331 - val_loss: 6.0102e-05 - val_mape: 0.9119\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0225e-04 - mape: 16.9946 - val_loss: 6.4229e-04 - val_mape: 3.6277\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6680e-04 - mape: 20.2389 - val_loss: 5.4419e-04 - val_mape: 3.3074\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 28.9775 - val_loss: 0.0012 - val_mape: 4.8956\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mape: 37.6975 - val_loss: 5.5573e-05 - val_mape: 0.9203\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 31.0544 - val_loss: 0.0011 - val_mape: 4.6783\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mape: 28.8668 - val_loss: 5.8398e-05 - val_mape: 0.8829\n",
      "--- 7/102 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9117e-04 - mape: 17.7224 - val_loss: 1.2919e-04 - val_mape: 1.3545\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - mape: 34.3065 - val_loss: 8.0657e-05 - val_mape: 0.9996\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8180e-04 - mape: 17.7743 - val_loss: 7.7518e-05 - val_mape: 0.9732\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6509e-04 - mape: 15.3655 - val_loss: 1.7900e-04 - val_mape: 1.6427\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0683e-04 - mape: 15.8068 - val_loss: 9.5435e-05 - val_mape: 1.1031\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1718e-04 - mape: 17.6920 - val_loss: 8.9763e-05 - val_mape: 1.1092\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1937e-04 - mape: 17.8479 - val_loss: 1.2458e-04 - val_mape: 1.3060\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0855e-04 - mape: 16.8578 - val_loss: 3.4464e-04 - val_mape: 2.2990\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0193e-04 - mape: 16.3436 - val_loss: 7.6905e-05 - val_mape: 0.9948\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4269e-04 - mape: 11.3532 - val_loss: 1.4838e-04 - val_mape: 1.5301\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4704e-04 - mape: 15.7323 - val_loss: 7.7090e-05 - val_mape: 1.0229\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9677e-04 - mape: 10.8181 - val_loss: 1.2191e-04 - val_mape: 1.3144\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5071e-04 - mape: 11.8863 - val_loss: 2.1988e-04 - val_mape: 1.8501\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6219e-04 - mape: 12.3896 - val_loss: 2.8059e-04 - val_mape: 1.8427\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3789e-04 - mape: 19.9243 - val_loss: 3.6941e-04 - val_mape: 2.1135\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5729e-04 - mape: 20.2323 - val_loss: 4.8189e-04 - val_mape: 2.3418\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8021e-04 - mape: 19.9774 - val_loss: 5.0098e-04 - val_mape: 2.4769\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3369e-04 - mape: 18.1808 - val_loss: 2.4400e-04 - val_mape: 1.7408\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2097e-04 - mape: 13.3547 - val_loss: 1.0473e-04 - val_mape: 1.2442\n",
      "--- 8/102 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3509e-04 - mape: 35.4677 - val_loss: 3.0372e-04 - val_mape: 4.0608\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4678e-04 - mape: 62.6688 - val_loss: 1.9930e-04 - val_mape: 2.8665\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8696e-04 - mape: 58.9200 - val_loss: 7.7150e-05 - val_mape: 1.9204\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7957e-04 - mape: 34.3095 - val_loss: 3.2949e-05 - val_mape: 1.2032\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5504e-04 - mape: 32.6958 - val_loss: 2.8520e-05 - val_mape: 1.1499\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7608e-04 - mape: 34.3821 - val_loss: 4.7773e-05 - val_mape: 1.5404\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1517e-04 - mape: 36.8357 - val_loss: 1.8643e-05 - val_mape: 0.8340\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9758e-04 - mape: 36.2366 - val_loss: 1.0687e-04 - val_mape: 2.1438\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5928e-04 - mape: 45.6787 - val_loss: 8.9465e-05 - val_mape: 2.0163\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7887e-04 - mape: 46.4384 - val_loss: 5.8109e-05 - val_mape: 1.6105\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8851e-04 - mape: 35.5629 - val_loss: 1.0777e-04 - val_mape: 2.3313\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9928e-04 - mape: 37.7924 - val_loss: 2.8673e-05 - val_mape: 1.1810\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7034e-04 - mape: 35.2945 - val_loss: 1.7076e-05 - val_mape: 0.8503\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5965e-04 - mape: 33.1581 - val_loss: 6.9317e-05 - val_mape: 1.8019\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1546e-04 - mape: 42.7558 - val_loss: 1.8378e-05 - val_mape: 0.8323\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4910e-04 - mape: 31.9816 - val_loss: 1.8674e-05 - val_mape: 0.8740\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0260e-04 - mape: 36.7235 - val_loss: 1.8907e-05 - val_mape: 0.8507\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9355e-04 - mape: 35.7996 - val_loss: 3.2508e-05 - val_mape: 1.2037\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6353e-04 - mape: 33.6909 - val_loss: 6.7312e-05 - val_mape: 1.8501\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0103e-04 - mape: 38.0773 - val_loss: 4.4150e-05 - val_mape: 1.3804\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0085e-04 - mape: 37.8076 - val_loss: 2.7235e-05 - val_mape: 1.0355\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5450e-04 - mape: 32.4039 - val_loss: 3.2031e-05 - val_mape: 1.1476\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6353e-04 - mape: 34.1259 - val_loss: 1.5618e-05 - val_mape: 0.7681\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6851e-04 - mape: 35.4319 - val_loss: 1.2398e-05 - val_mape: 0.6926\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2530e-04 - mape: 40.0801 - val_loss: 2.3127e-05 - val_mape: 0.9894\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8080e-04 - mape: 50.6169 - val_loss: 1.4404e-05 - val_mape: 0.7619\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7038e-04 - mape: 33.2441 - val_loss: 3.4410e-05 - val_mape: 1.1929\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8492e-04 - mape: 36.9626 - val_loss: 1.9994e-05 - val_mape: 0.9047\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8539e-04 - mape: 34.2721 - val_loss: 2.7610e-05 - val_mape: 1.0094\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0792e-04 - mape: 38.8666 - val_loss: 1.7329e-05 - val_mape: 0.8297\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3076e-04 - mape: 40.7588 - val_loss: 3.7386e-05 - val_mape: 1.1945\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2981e-04 - mape: 51.5541 - val_loss: 2.0319e-05 - val_mape: 0.9695\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9987e-04 - mape: 36.7241 - val_loss: 3.4295e-05 - val_mape: 1.3151\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2479e-04 - mape: 54.4590 - val_loss: 4.7603e-05 - val_mape: 1.3582\n",
      "--- 9/102 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4465e-04 - mape: 4896.8379 - val_loss: 6.0628e-04 - val_mape: 2.8323\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6387e-04 - mape: 34758.0664 - val_loss: 9.3111e-05 - val_mape: 0.8791\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3791e-04 - mape: 97263.9375 - val_loss: 6.6494e-04 - val_mape: 2.9690\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5419e-04 - mape: 4360.5713 - val_loss: 7.7827e-04 - val_mape: 3.0815\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 180903.1250 - val_loss: 7.4709e-04 - val_mape: 3.1776\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0966e-04 - mape: 51062.0273 - val_loss: 0.0038 - val_mape: 7.2312\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - mape: 294616.7500 - val_loss: 1.4571e-04 - val_mape: 1.0779\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7481e-04 - mape: 121665.2500 - val_loss: 9.1396e-05 - val_mape: 0.9066\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0970e-04 - mape: 40385.1172 - val_loss: 1.0006e-04 - val_mape: 0.8225\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0461e-04 - mape: 4835.2280 - val_loss: 0.0020 - val_mape: 5.2544\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - mape: 221697.6250 - val_loss: 1.9006e-04 - val_mape: 1.1857\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6196e-04 - mape: 3731.8333 - val_loss: 9.7243e-04 - val_mape: 3.6133\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 57212.6953 - val_loss: 2.7315e-04 - val_mape: 1.5385\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8228e-04 - mape: 51159.7617 - val_loss: 0.0020 - val_mape: 5.1884\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mape: 147883.1875 - val_loss: 4.2589e-04 - val_mape: 2.0952\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7434e-04 - mape: 177938.5625 - val_loss: 0.0011 - val_mape: 3.8853\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 139044.0625 - val_loss: 1.4715e-04 - val_mape: 0.9665\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0676e-04 - mape: 46582.5430 - val_loss: 0.0016 - val_mape: 4.6111\n",
      "--- 10/102 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8803e-04 - mape: 84.2727 - val_loss: 0.0012 - val_mape: 4.0089\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0014e-04 - mape: 56.3072 - val_loss: 0.0017 - val_mape: 5.1357\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5266e-04 - mape: 66.1911 - val_loss: 3.1414e-04 - val_mape: 1.8972\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3995e-04 - mape: 35.1029 - val_loss: 8.1498e-04 - val_mape: 3.4877\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4861e-04 - mape: 54.8100 - val_loss: 4.5588e-04 - val_mape: 2.3969\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5397e-04 - mape: 37.8736 - val_loss: 1.9292e-04 - val_mape: 1.4677\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8280e-04 - mape: 41.2755 - val_loss: 2.7164e-04 - val_mape: 1.7629\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0179e-04 - mape: 32.6759 - val_loss: 1.8267e-04 - val_mape: 1.4285\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5966e-04 - mape: 39.0427 - val_loss: 2.9759e-04 - val_mape: 1.8775\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9331e-04 - mape: 32.0113 - val_loss: 2.5403e-04 - val_mape: 1.8006\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0839e-04 - mape: 44.1139 - val_loss: 2.3246e-04 - val_mape: 1.5999\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8179e-04 - mape: 30.7580 - val_loss: 2.5524e-04 - val_mape: 1.8235\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2592e-04 - mape: 36.0388 - val_loss: 1.7378e-04 - val_mape: 1.3526\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7615e-04 - mape: 30.0122 - val_loss: 1.8159e-04 - val_mape: 1.4573\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4039e-04 - mape: 37.3075 - val_loss: 1.8796e-04 - val_mape: 1.4009\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8099e-04 - mape: 31.5288 - val_loss: 2.4293e-04 - val_mape: 1.7740\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5427e-04 - mape: 38.2736 - val_loss: 1.3424e-04 - val_mape: 1.1057\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5068e-04 - mape: 26.7735 - val_loss: 1.9210e-04 - val_mape: 1.5410\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3527e-04 - mape: 36.2501 - val_loss: 1.4396e-04 - val_mape: 1.1592\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7646e-04 - mape: 30.6813 - val_loss: 4.9977e-04 - val_mape: 2.7108\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9640e-04 - mape: 43.9906 - val_loss: 2.3370e-04 - val_mape: 1.6004\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8021e-04 - mape: 30.8443 - val_loss: 2.7984e-04 - val_mape: 1.8932\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8516e-04 - mape: 42.3678 - val_loss: 9.8240e-05 - val_mape: 0.9594\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8126e-04 - mape: 30.9416 - val_loss: 7.6039e-04 - val_mape: 3.3401\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3474e-04 - mape: 55.5686 - val_loss: 2.7585e-04 - val_mape: 1.6752\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7719e-04 - mape: 39.6579 - val_loss: 0.0018 - val_mape: 5.2862\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0039e-04 - mape: 71.8893 - val_loss: 3.3853e-04 - val_mape: 1.9234\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2753e-04 - mape: 36.8560 - val_loss: 8.0805e-04 - val_mape: 3.4798\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3749e-04 - mape: 62.1824 - val_loss: 3.7807e-04 - val_mape: 2.0290\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8228e-04 - mape: 40.9266 - val_loss: 0.0016 - val_mape: 5.0046\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0328e-04 - mape: 66.8051 - val_loss: 3.0247e-04 - val_mape: 1.7759\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5438e-04 - mape: 39.1617 - val_loss: 8.7759e-04 - val_mape: 3.6113\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2709e-04 - mape: 62.0059 - val_loss: 2.9328e-04 - val_mape: 1.7323\n",
      "--- 11/102 Training model for CEG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2534e-04 - mape: 16.8665 - val_loss: 2.1644e-04 - val_mape: 1.4846\n",
      "Epoch 2/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - mape: 32.9688 - val_loss: 5.7897e-04 - val_mape: 2.5208\n",
      "Epoch 3/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mape: 30.6185 - val_loss: 0.0010 - val_mape: 3.4461\n",
      "Epoch 4/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - mape: 104.1968 - val_loss: 5.4566e-04 - val_mape: 2.2536\n",
      "Epoch 5/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9116e-04 - mape: 15.7215 - val_loss: 4.1227e-04 - val_mape: 1.9140\n",
      "Epoch 6/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4687e-04 - mape: 13.3889 - val_loss: 3.5379e-04 - val_mape: 1.8463\n",
      "Epoch 7/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8330e-04 - mape: 17.2545 - val_loss: 5.0605e-04 - val_mape: 2.2489\n",
      "Epoch 8/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mape: 34.8677 - val_loss: 4.9380e-04 - val_mape: 2.1961\n",
      "Epoch 9/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mape: 45.0580 - val_loss: 0.0032 - val_mape: 6.4804\n",
      "Epoch 10/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - mape: 66.8110 - val_loss: 4.0770e-04 - val_mape: 1.9746\n",
      "Epoch 11/150\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 27.9858 - val_loss: 3.8611e-04 - val_mape: 1.9268\n",
      "--- 12/102 Training model for MSFT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - mape: 192.8667 - val_loss: 1.1417e-04 - val_mape: 1.0099\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3334e-04 - mape: 102.0434 - val_loss: 0.0011 - val_mape: 3.5107\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - mape: 212.7154 - val_loss: 0.0012 - val_mape: 3.7486\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - mape: 360.5802 - val_loss: 2.1091e-04 - val_mape: 1.3055\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 178.9477 - val_loss: 0.0026 - val_mape: 5.7861\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mape: 289.0448 - val_loss: 2.2990e-04 - val_mape: 1.3404\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6751e-04 - mape: 110.0472 - val_loss: 0.0012 - val_mape: 3.8982\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mape: 240.3686 - val_loss: 3.8692e-04 - val_mape: 1.8907\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7796e-04 - mape: 82.2950 - val_loss: 5.6501e-04 - val_mape: 2.5918\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0662e-04 - mape: 142.9030 - val_loss: 7.3700e-04 - val_mape: 2.8653\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2563e-04 - mape: 71.4255 - val_loss: 7.4631e-04 - val_mape: 3.0185\n",
      "--- 13/102 Training model for EXC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0109e-04 - mape: 65941.4219 - val_loss: 6.7062e-04 - val_mape: 3.9056\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2576e-04 - mape: 22758.7109 - val_loss: 6.1445e-05 - val_mape: 0.8068\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8076e-04 - mape: 23153.6602 - val_loss: 4.5449e-04 - val_mape: 3.0901\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4688e-04 - mape: 54763.9727 - val_loss: 7.7946e-05 - val_mape: 0.8899\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7069e-04 - mape: 71604.7969 - val_loss: 1.9682e-04 - val_mape: 1.8203\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0593e-04 - mape: 23535.7266 - val_loss: 6.9679e-05 - val_mape: 0.8307\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2456e-04 - mape: 125756.8750 - val_loss: 7.8578e-05 - val_mape: 1.0372\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8353e-04 - mape: 7570.7603 - val_loss: 5.3524e-05 - val_mape: 0.7770\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1803e-04 - mape: 18949.0840 - val_loss: 9.2033e-05 - val_mape: 1.1791\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3168e-04 - mape: 38446.1094 - val_loss: 7.5373e-05 - val_mape: 1.1059\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4052e-04 - mape: 49969.5898 - val_loss: 2.9246e-04 - val_mape: 2.4269\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2138e-04 - mape: 4317.2612 - val_loss: 5.3397e-05 - val_mape: 0.7808\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2317e-04 - mape: 55644.3594 - val_loss: 1.7054e-04 - val_mape: 1.7321\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5829e-04 - mape: 65968.5625 - val_loss: 1.0861e-04 - val_mape: 1.2532\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5722e-04 - mape: 55395.4531 - val_loss: 1.3167e-04 - val_mape: 1.4285\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3349e-04 - mape: 20935.0234 - val_loss: 5.7812e-05 - val_mape: 0.7931\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2274e-04 - mape: 5871.5498 - val_loss: 6.9113e-05 - val_mape: 1.0018\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3997e-04 - mape: 22102.2617 - val_loss: 5.1265e-05 - val_mape: 0.8119\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1816e-04 - mape: 115279.1797 - val_loss: 5.7149e-05 - val_mape: 0.8474\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2736e-04 - mape: 1877.3480 - val_loss: 1.0172e-04 - val_mape: 1.2161\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5165e-04 - mape: 12690.9160 - val_loss: 5.3203e-05 - val_mape: 0.7873\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8351e-04 - mape: 51426.9023 - val_loss: 5.6634e-05 - val_mape: 0.8357\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0925e-04 - mape: 15026.1240 - val_loss: 3.0674e-04 - val_mape: 2.4441\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7774e-04 - mape: 1718.5956 - val_loss: 2.5643e-04 - val_mape: 2.0815\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8417e-04 - mape: 90105.0859 - val_loss: 8.9425e-05 - val_mape: 1.0657\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5070e-04 - mape: 25692.3301 - val_loss: 5.2833e-05 - val_mape: 0.7775\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0480e-04 - mape: 3233.8359 - val_loss: 2.1181e-04 - val_mape: 2.0050\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6539e-04 - mape: 22942.8574 - val_loss: 5.6462e-05 - val_mape: 0.8274\n",
      "--- 14/102 Training model for DXCM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1960e-04 - mape: 10313.3232 - val_loss: 5.6198e-05 - val_mape: 0.8285\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5864e-04 - mape: 37687.0859 - val_loss: 1.8578e-04 - val_mape: 1.9211\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7660e-04 - mape: 8735.0029 - val_loss: 4.7746e-05 - val_mape: 0.6686\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1434e-04 - mape: 25849.2246 - val_loss: 1.0233e-04 - val_mape: 1.3067\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4404e-04 - mape: 24616.4414 - val_loss: 7.7203e-05 - val_mape: 1.0702\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5701e-04 - mape: 7343.7563 - val_loss: 2.0762e-04 - val_mape: 1.8267\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8386e-04 - mape: 26431.9785 - val_loss: 6.7698e-05 - val_mape: 0.8796\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0443e-04 - mape: 2577.3264 - val_loss: 7.1094e-05 - val_mape: 0.8906\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1034e-04 - mape: 19093.3770 - val_loss: 7.9417e-05 - val_mape: 1.0085\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4252e-04 - mape: 75377.3828 - val_loss: 7.0480e-05 - val_mape: 0.9758\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7868e-04 - mape: 58914.3359 - val_loss: 8.5638e-05 - val_mape: 1.1006\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0626e-04 - mape: 18392.2207 - val_loss: 7.0043e-05 - val_mape: 0.8627\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4664e-04 - mape: 32686.4160 - val_loss: 9.4612e-05 - val_mape: 1.0517\n",
      "--- 15/102 Training model for FAST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2232e-04 - mape: 129.6159 - val_loss: 2.3289e-04 - val_mape: 1.5825\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3232e-04 - mape: 30597.6309 - val_loss: 1.3610e-04 - val_mape: 1.0471\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3250e-04 - mape: 34278.8125 - val_loss: 1.0387e-04 - val_mape: 1.0714\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7775e-04 - mape: 48609.0664 - val_loss: 9.0014e-05 - val_mape: 0.8585\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8120e-04 - mape: 7719.8496 - val_loss: 6.8924e-05 - val_mape: 0.7145\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7590e-04 - mape: 2478.4668 - val_loss: 9.5709e-05 - val_mape: 0.8633\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1743e-04 - mape: 6447.0381 - val_loss: 2.4647e-04 - val_mape: 1.6458\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2991e-04 - mape: 5234.0166 - val_loss: 1.5710e-04 - val_mape: 1.1153\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2324e-04 - mape: 6099.2275 - val_loss: 1.3410e-04 - val_mape: 1.1436\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2796e-04 - mape: 29078.9570 - val_loss: 1.1225e-04 - val_mape: 0.9360\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0639e-04 - mape: 127.7307 - val_loss: 2.1580e-04 - val_mape: 1.5381\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2750e-04 - mape: 35889.9023 - val_loss: 1.3359e-04 - val_mape: 1.1352\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1768e-04 - mape: 28308.6289 - val_loss: 2.2938e-04 - val_mape: 1.5566\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5459e-04 - mape: 38726.8438 - val_loss: 1.1961e-04 - val_mape: 0.9903\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0992e-04 - mape: 15573.5303 - val_loss: 2.4484e-04 - val_mape: 1.6204\n",
      "--- 16/102 Training model for ABNB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mape: 17289.0723 - val_loss: 4.8294e-05 - val_mape: 1.2957\n",
      "Epoch 2/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - mape: 19736.8164 - val_loss: 9.0685e-05 - val_mape: 2.0000\n",
      "Epoch 3/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mape: 5933.6216 - val_loss: 3.0224e-04 - val_mape: 3.7784\n",
      "Epoch 4/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mape: 63764.2578 - val_loss: 0.0013 - val_mape: 6.8029\n",
      "Epoch 5/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - mape: 42666.4961 - val_loss: 0.0019 - val_mape: 7.9341\n",
      "Epoch 6/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - mape: 58111.5039 - val_loss: 0.0030 - val_mape: 10.2386\n",
      "Epoch 7/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - mape: 23670.5859 - val_loss: 0.0023 - val_mape: 9.8495\n",
      "Epoch 8/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - mape: 40591.8125 - val_loss: 0.0013 - val_mape: 7.6432\n",
      "Epoch 9/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 9250.2568 - val_loss: 3.8757e-04 - val_mape: 4.4092\n",
      "Epoch 10/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 8639.2402 - val_loss: 1.0418e-04 - val_mape: 2.0982\n",
      "Epoch 11/150\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8609e-04 - mape: 21875.4023 - val_loss: 7.8589e-05 - val_mape: 1.8113\n",
      "--- 17/102 Training model for SNPS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4364e-04 - mape: 39.9690 - val_loss: 3.8845e-04 - val_mape: 1.9495\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1159e-04 - mape: 47.7066 - val_loss: 1.3679e-04 - val_mape: 1.0522\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6413e-04 - mape: 33.5300 - val_loss: 1.1652e-04 - val_mape: 0.9359\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5457e-04 - mape: 31.1066 - val_loss: 2.2668e-04 - val_mape: 1.4306\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4073e-04 - mape: 46.8461 - val_loss: 2.8391e-04 - val_mape: 1.6792\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7687e-04 - mape: 43.4990 - val_loss: 1.7589e-04 - val_mape: 1.2389\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3719e-04 - mape: 29.8888 - val_loss: 1.8232e-04 - val_mape: 1.2975\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8482e-04 - mape: 43.0919 - val_loss: 2.2430e-04 - val_mape: 1.4518\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2164e-04 - mape: 39.1100 - val_loss: 9.9098e-05 - val_mape: 0.8616\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7086e-04 - mape: 34.3784 - val_loss: 6.9351e-05 - val_mape: 0.6881\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0776e-04 - mape: 28.5170 - val_loss: 6.5067e-05 - val_mape: 0.6677\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0871e-04 - mape: 28.7153 - val_loss: 9.2659e-05 - val_mape: 0.8379\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7648e-04 - mape: 33.6779 - val_loss: 1.5090e-04 - val_mape: 1.1740\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2216e-04 - mape: 39.6717 - val_loss: 1.5114e-04 - val_mape: 1.1478\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9565e-04 - mape: 37.0376 - val_loss: 6.6910e-05 - val_mape: 0.7170\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4284e-04 - mape: 30.6515 - val_loss: 8.5893e-05 - val_mape: 0.7694\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7553e-04 - mape: 49.9648 - val_loss: 1.5915e-04 - val_mape: 1.2226\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mape: 83.4085 - val_loss: 8.4446e-05 - val_mape: 0.7763\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4566e-04 - mape: 39.3355 - val_loss: 6.7633e-05 - val_mape: 0.6917\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5740e-04 - mape: 47.8732 - val_loss: 1.1820e-04 - val_mape: 0.9413\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8446e-04 - mape: 62.4379 - val_loss: 5.2198e-05 - val_mape: 0.5863\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 88.0199 - val_loss: 1.2541e-04 - val_mape: 0.9566\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mape: 78.1466 - val_loss: 6.8134e-04 - val_mape: 2.8369\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 122.9672 - val_loss: 1.2836e-04 - val_mape: 1.0315\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8133e-04 - mape: 53.4231 - val_loss: 7.9192e-04 - val_mape: 3.0507\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mape: 142.6646 - val_loss: 1.9903e-04 - val_mape: 1.2604\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3819e-04 - mape: 56.8598 - val_loss: 3.2079e-04 - val_mape: 1.8613\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - mape: 99.5769 - val_loss: 1.5982e-04 - val_mape: 1.1026\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3736e-04 - mape: 46.1690 - val_loss: 3.1075e-04 - val_mape: 1.8401\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 85.3229 - val_loss: 1.9619e-04 - val_mape: 1.3200\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2787e-04 - mape: 29.0678 - val_loss: 8.3669e-05 - val_mape: 0.8152\n",
      "--- 18/102 Training model for BIIB ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8093e-04 - mape: 35.4106 - val_loss: 5.3899e-05 - val_mape: 7.5242\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3182e-04 - mape: 395.4948 - val_loss: 2.4520e-05 - val_mape: 6.8535\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4751e-04 - mape: 61.0203 - val_loss: 3.6558e-05 - val_mape: 10.9921\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2325e-04 - mape: 4213.9546 - val_loss: 2.3655e-05 - val_mape: 4.6022\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2135e-04 - mape: 970.5097 - val_loss: 4.8114e-05 - val_mape: 14.4782\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8198e-04 - mape: 2110.8894 - val_loss: 4.3409e-05 - val_mape: 8.4836\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7035e-04 - mape: 6255.0083 - val_loss: 2.9061e-05 - val_mape: 8.9657\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1854e-04 - mape: 1733.8882 - val_loss: 1.8605e-05 - val_mape: 5.8206\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7761e-04 - mape: 1099.0697 - val_loss: 2.2590e-05 - val_mape: 4.9935\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7786e-04 - mape: 4016.0632 - val_loss: 3.7202e-05 - val_mape: 6.8957\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0297e-04 - mape: 4822.7275 - val_loss: 2.0629e-05 - val_mape: 4.8020\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9607e-04 - mape: 100.5685 - val_loss: 1.6997e-05 - val_mape: 5.5734\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7737e-04 - mape: 283.5776 - val_loss: 1.8060e-05 - val_mape: 4.1421\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5923e-04 - mape: 4460.2983 - val_loss: 6.3042e-05 - val_mape: 13.3780\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9116e-04 - mape: 2753.5654 - val_loss: 7.4685e-05 - val_mape: 15.4339\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9770e-04 - mape: 2269.3398 - val_loss: 2.6109e-04 - val_mape: 26.9930\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1304e-04 - mape: 3687.3293 - val_loss: 2.4310e-05 - val_mape: 3.9863\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6004e-04 - mape: 21.3038 - val_loss: 3.6986e-05 - val_mape: 10.3322\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9283e-04 - mape: 2743.9236 - val_loss: 1.6395e-04 - val_mape: 19.8385\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2590e-04 - mape: 4548.1406 - val_loss: 2.2373e-05 - val_mape: 4.3632\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7995e-04 - mape: 2612.7085 - val_loss: 1.2671e-04 - val_mape: 19.1612\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6104e-04 - mape: 2697.1970 - val_loss: 7.6913e-05 - val_mape: 16.6009\n",
      "--- 19/102 Training model for REGN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0269e-04 - mape: 18147.5996 - val_loss: 2.2319e-04 - val_mape: 1.7435\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7600e-04 - mape: 1057.3577 - val_loss: 2.3451e-05 - val_mape: 0.5318\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6536e-04 - mape: 8261.7666 - val_loss: 2.5069e-05 - val_mape: 0.5350\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7190e-04 - mape: 11728.1816 - val_loss: 3.9947e-05 - val_mape: 0.6864\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6379e-04 - mape: 1763.2273 - val_loss: 1.5417e-05 - val_mape: 0.4141\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5633e-04 - mape: 2157.7056 - val_loss: 5.8259e-05 - val_mape: 0.8808\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6002e-04 - mape: 13016.0576 - val_loss: 4.8798e-05 - val_mape: 0.8196\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6369e-04 - mape: 2223.2590 - val_loss: 1.5665e-05 - val_mape: 0.4262\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4291e-04 - mape: 13067.6670 - val_loss: 1.2947e-05 - val_mape: 0.3820\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5044e-04 - mape: 4432.4404 - val_loss: 4.2995e-05 - val_mape: 0.7473\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5984e-04 - mape: 22921.0508 - val_loss: 1.5128e-05 - val_mape: 0.4025\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5830e-04 - mape: 2884.0176 - val_loss: 1.3547e-05 - val_mape: 0.3791\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7277e-04 - mape: 223.0005 - val_loss: 1.5817e-05 - val_mape: 0.4201\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7585e-04 - mape: 8348.7559 - val_loss: 4.5026e-05 - val_mape: 0.7418\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7933e-04 - mape: 9882.9326 - val_loss: 6.9356e-05 - val_mape: 0.9826\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4159e-04 - mape: 825.1925 - val_loss: 1.8849e-05 - val_mape: 0.4610\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4465e-04 - mape: 1415.7004 - val_loss: 2.1187e-05 - val_mape: 0.4752\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5026e-04 - mape: 14468.4434 - val_loss: 2.8622e-04 - val_mape: 2.1632\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6356e-04 - mape: 9283.0332 - val_loss: 2.6270e-05 - val_mape: 0.5712\n",
      "--- 20/102 Training model for VRSK ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6671e-04 - mape: 16884.1699 - val_loss: 1.7931e-04 - val_mape: 1.4746\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8391e-04 - mape: 65895.0703 - val_loss: 2.6180e-05 - val_mape: 0.4965\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0000e-04 - mape: 53737.1602 - val_loss: 5.9296e-05 - val_mape: 0.8098\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4330e-04 - mape: 48441.9297 - val_loss: 6.7965e-05 - val_mape: 0.8461\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8531e-04 - mape: 35395.3906 - val_loss: 2.1323e-04 - val_mape: 1.6654\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7052e-04 - mape: 31542.4062 - val_loss: 4.8290e-05 - val_mape: 0.6373\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3908e-04 - mape: 4226.1978 - val_loss: 3.9908e-05 - val_mape: 0.6295\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0685e-04 - mape: 10864.1445 - val_loss: 2.5400e-04 - val_mape: 1.8627\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5675e-04 - mape: 3229.1462 - val_loss: 2.6008e-05 - val_mape: 0.4670\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8764e-04 - mape: 15401.0029 - val_loss: 2.0331e-04 - val_mape: 1.5330\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8325e-04 - mape: 85265.8984 - val_loss: 4.0640e-04 - val_mape: 2.3864\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8610e-04 - mape: 56713.3828 - val_loss: 1.8485e-04 - val_mape: 1.4399\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0911e-04 - mape: 8675.9609 - val_loss: 3.2008e-05 - val_mape: 0.5656\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0251e-04 - mape: 65027.5156 - val_loss: 1.2084e-04 - val_mape: 1.1446\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0635e-04 - mape: 84833.1094 - val_loss: 3.8893e-04 - val_mape: 2.3435\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7425e-04 - mape: 41322.1797 - val_loss: 3.4647e-04 - val_mape: 2.0960\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0781e-04 - mape: 48842.5469 - val_loss: 5.5732e-04 - val_mape: 2.8169\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1122e-04 - mape: 18913.8164 - val_loss: 2.7152e-04 - val_mape: 1.7880\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1817e-04 - mape: 79501.7344 - val_loss: 1.6849e-04 - val_mape: 1.5133\n",
      "--- 21/102 Training model for TSLA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8868e-04 - mape: 18699.7617 - val_loss: 7.9860e-05 - val_mape: 1.5429\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2865e-04 - mape: 13116.7051 - val_loss: 3.5875e-05 - val_mape: 1.0903\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0344e-04 - mape: 3448.4634 - val_loss: 8.7446e-05 - val_mape: 1.4130\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6120e-04 - mape: 1358.9088 - val_loss: 2.4883e-05 - val_mape: 0.8848\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3108e-04 - mape: 1744.5833 - val_loss: 8.1676e-05 - val_mape: 1.4643\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4840e-04 - mape: 17168.6836 - val_loss: 4.9200e-05 - val_mape: 1.3486\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9670e-04 - mape: 9964.9229 - val_loss: 3.1629e-05 - val_mape: 1.0112\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7609e-04 - mape: 20167.1836 - val_loss: 7.1377e-05 - val_mape: 1.6382\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3233e-04 - mape: 6762.0210 - val_loss: 6.3314e-05 - val_mape: 1.5331\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8653e-04 - mape: 25031.4531 - val_loss: 1.8126e-04 - val_mape: 2.0679\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mape: 12788.6162 - val_loss: 1.8244e-05 - val_mape: 0.7130\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1374e-04 - mape: 22693.8691 - val_loss: 1.8334e-05 - val_mape: 0.7210\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9557e-04 - mape: 38716.5547 - val_loss: 2.8435e-05 - val_mape: 0.8391\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2272e-04 - mape: 19102.6816 - val_loss: 2.7922e-05 - val_mape: 0.9269\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5550e-04 - mape: 16638.2305 - val_loss: 3.9015e-05 - val_mape: 1.0147\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6097e-04 - mape: 455.7761 - val_loss: 2.0802e-05 - val_mape: 0.8170\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8153e-04 - mape: 7977.7031 - val_loss: 2.2396e-05 - val_mape: 0.7593\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8270e-04 - mape: 739.5465 - val_loss: 1.9991e-05 - val_mape: 0.7274\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9932e-04 - mape: 10149.5430 - val_loss: 1.6767e-05 - val_mape: 0.6523\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2351e-04 - mape: 7745.0522 - val_loss: 7.3839e-05 - val_mape: 1.6839\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3919e-04 - mape: 4954.6655 - val_loss: 2.6352e-05 - val_mape: 0.8874\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1611e-04 - mape: 20082.3320 - val_loss: 4.7135e-05 - val_mape: 1.2728\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6254e-04 - mape: 4023.7854 - val_loss: 3.2508e-05 - val_mape: 0.9592\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0236e-04 - mape: 1038.6165 - val_loss: 3.3165e-05 - val_mape: 0.9700\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9664e-04 - mape: 15163.2500 - val_loss: 3.6024e-05 - val_mape: 1.1328\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8833e-04 - mape: 736.3356 - val_loss: 1.3716e-05 - val_mape: 0.6161\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9271e-04 - mape: 19896.7129 - val_loss: 3.5694e-05 - val_mape: 1.0119\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9109e-04 - mape: 17899.3047 - val_loss: 1.7613e-05 - val_mape: 0.7121\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1407e-04 - mape: 24172.5312 - val_loss: 3.0917e-05 - val_mape: 1.0007\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9403e-04 - mape: 7792.9009 - val_loss: 3.0938e-05 - val_mape: 0.9491\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6797e-04 - mape: 2628.5454 - val_loss: 1.4397e-05 - val_mape: 0.6649\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9575e-04 - mape: 2354.7153 - val_loss: 2.1187e-05 - val_mape: 0.8256\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3328e-04 - mape: 4301.8916 - val_loss: 2.7290e-05 - val_mape: 0.9629\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9068e-04 - mape: 10076.2100 - val_loss: 6.7797e-05 - val_mape: 1.4062\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9875e-04 - mape: 5431.0508 - val_loss: 2.4656e-05 - val_mape: 0.8063\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6116e-04 - mape: 26735.6602 - val_loss: 9.3835e-05 - val_mape: 1.4459\n",
      "--- 22/102 Training model for NVDA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8498e-04 - mape: 41846.3555 - val_loss: 6.2109e-04 - val_mape: 3.3499\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9936e-04 - mape: 108513.5703 - val_loss: 3.3053e-04 - val_mape: 2.1752\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3547e-04 - mape: 29666.1250 - val_loss: 4.8381e-05 - val_mape: 0.7605\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1454e-04 - mape: 2200.3345 - val_loss: 3.4832e-05 - val_mape: 0.6044\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8742e-04 - mape: 46298.8125 - val_loss: 6.7527e-05 - val_mape: 0.8889\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8942e-04 - mape: 34769.2383 - val_loss: 9.4951e-05 - val_mape: 1.1745\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9051e-04 - mape: 56817.4375 - val_loss: 5.2194e-05 - val_mape: 0.8132\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8388e-04 - mape: 34877.5352 - val_loss: 3.5657e-05 - val_mape: 0.6189\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5096e-04 - mape: 12697.2529 - val_loss: 3.2437e-05 - val_mape: 0.6468\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3462e-04 - mape: 419.5148 - val_loss: 4.3716e-05 - val_mape: 0.7299\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1801e-04 - mape: 11186.3457 - val_loss: 6.9456e-05 - val_mape: 1.0233\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4757e-04 - mape: 14672.1543 - val_loss: 2.3441e-05 - val_mape: 0.5633\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3994e-04 - mape: 23033.1289 - val_loss: 9.0135e-05 - val_mape: 1.2453\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3071e-04 - mape: 48292.7070 - val_loss: 2.9641e-05 - val_mape: 0.6303\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1707e-04 - mape: 2921.8821 - val_loss: 3.2878e-05 - val_mape: 0.6283\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9204e-04 - mape: 5926.9346 - val_loss: 2.2508e-05 - val_mape: 0.5465\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0045e-04 - mape: 8990.4648 - val_loss: 8.1171e-05 - val_mape: 1.1301\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9574e-04 - mape: 44302.2227 - val_loss: 5.1229e-05 - val_mape: 0.7970\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0607e-04 - mape: 376.9010 - val_loss: 9.2065e-05 - val_mape: 1.1583\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6649e-04 - mape: 52220.9570 - val_loss: 2.2330e-05 - val_mape: 0.5580\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6530e-04 - mape: 34185.0938 - val_loss: 2.2490e-05 - val_mape: 0.5760\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5345e-04 - mape: 41054.7695 - val_loss: 2.4980e-05 - val_mape: 0.6087\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4583e-04 - mape: 12119.1719 - val_loss: 2.5495e-05 - val_mape: 0.5863\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3535e-04 - mape: 31685.8652 - val_loss: 2.7079e-05 - val_mape: 0.6960\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5534e-04 - mape: 32797.7109 - val_loss: 4.0423e-05 - val_mape: 0.7313\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3597e-04 - mape: 5504.2515 - val_loss: 1.4827e-04 - val_mape: 1.3395\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3712e-04 - mape: 4233.6348 - val_loss: 5.0872e-05 - val_mape: 0.8567\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3193e-04 - mape: 41574.3203 - val_loss: 1.6636e-04 - val_mape: 1.4157\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3938e-04 - mape: 2213.0427 - val_loss: 2.5507e-04 - val_mape: 1.9793\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8299e-04 - mape: 40712.3789 - val_loss: 1.6070e-04 - val_mape: 1.4139\n",
      "--- 23/102 Training model for CPRT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4242e-04 - mape: 52.5066 - val_loss: 4.6918e-05 - val_mape: 0.6154\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3650e-04 - mape: 131.2905 - val_loss: 5.9146e-04 - val_mape: 2.5856\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 170.7939 - val_loss: 5.8186e-05 - val_mape: 0.6958\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2833e-04 - mape: 62.1036 - val_loss: 7.5253e-05 - val_mape: 0.7532\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7821e-04 - mape: 92.8138 - val_loss: 3.9725e-04 - val_mape: 2.1427\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7392e-04 - mape: 73.7548 - val_loss: 5.6759e-05 - val_mape: 0.6720\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0198e-04 - mape: 47.9032 - val_loss: 1.0493e-04 - val_mape: 1.0179\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0513e-04 - mape: 62.0631 - val_loss: 4.4992e-05 - val_mape: 0.6024\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1075e-04 - mape: 45.2815 - val_loss: 2.6894e-04 - val_mape: 1.6233\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6782e-04 - mape: 84.6287 - val_loss: 3.0237e-05 - val_mape: 0.4931\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3601e-04 - mape: 80.4866 - val_loss: 1.4747e-04 - val_mape: 1.2531\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0374e-04 - mape: 103.5879 - val_loss: 8.2233e-05 - val_mape: 0.8576\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9772e-04 - mape: 60.5140 - val_loss: 4.3072e-04 - val_mape: 2.2394\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9692e-04 - mape: 56.0398 - val_loss: 1.8736e-04 - val_mape: 1.3860\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9560e-04 - mape: 47.6488 - val_loss: 1.5831e-04 - val_mape: 1.2379\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1364e-04 - mape: 56.1077 - val_loss: 5.0962e-05 - val_mape: 0.6208\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1611e-04 - mape: 54.5501 - val_loss: 4.0789e-04 - val_mape: 2.0801\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0103e-04 - mape: 63.0843 - val_loss: 1.2628e-04 - val_mape: 1.0860\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0176e-04 - mape: 52.9368 - val_loss: 3.1987e-05 - val_mape: 0.4923\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2056e-04 - mape: 52.5542 - val_loss: 1.0954e-04 - val_mape: 0.9644\n",
      "--- 24/102 Training model for ORLY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8024e-04 - mape: 306.8869 - val_loss: 9.2103e-05 - val_mape: 0.8726\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7895e-04 - mape: 37271.7812 - val_loss: 4.7451e-04 - val_mape: 2.3909\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4548e-04 - mape: 30663.2598 - val_loss: 3.5075e-05 - val_mape: 0.4834\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6214e-04 - mape: 78856.9219 - val_loss: 3.8427e-05 - val_mape: 0.5294\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6091e-04 - mape: 20883.5273 - val_loss: 2.6353e-05 - val_mape: 0.3895\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5918e-04 - mape: 8826.6816 - val_loss: 4.5569e-05 - val_mape: 0.5043\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6480e-04 - mape: 20937.7930 - val_loss: 3.8424e-04 - val_mape: 2.0111\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1163e-04 - mape: 54549.6289 - val_loss: 7.9221e-05 - val_mape: 0.7020\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5112e-04 - mape: 28444.2363 - val_loss: 1.0905e-04 - val_mape: 0.8911\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4593e-04 - mape: 18204.9004 - val_loss: 7.8841e-05 - val_mape: 0.8131\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3080e-04 - mape: 6263.3018 - val_loss: 1.6566e-04 - val_mape: 1.2698\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6880e-04 - mape: 19007.1484 - val_loss: 2.9075e-04 - val_mape: 1.7825\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4994e-04 - mape: 5714.0127 - val_loss: 5.2471e-05 - val_mape: 0.6556\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2830e-04 - mape: 19899.4746 - val_loss: 3.9515e-04 - val_mape: 2.1590\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2456e-04 - mape: 108619.5312 - val_loss: 6.0435e-05 - val_mape: 0.7155\n",
      "--- 25/102 Training model for CSGP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1570e-04 - mape: 20.8358 - val_loss: 9.7190e-05 - val_mape: 1.0071\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8529e-04 - mape: 22.8000 - val_loss: 3.1517e-05 - val_mape: 0.5896\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5532e-04 - mape: 12.2042 - val_loss: 2.6163e-04 - val_mape: 1.8571\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4300e-04 - mape: 22.6974 - val_loss: 9.4509e-05 - val_mape: 1.0149\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7865e-04 - mape: 22.0266 - val_loss: 4.0164e-04 - val_mape: 2.3876\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8162e-04 - mape: 12.9964 - val_loss: 1.7595e-05 - val_mape: 0.3803\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2621e-04 - mape: 23.1365 - val_loss: 6.9132e-05 - val_mape: 0.8483\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8654e-04 - mape: 14.1409 - val_loss: 1.7587e-05 - val_mape: 0.4294\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2405e-04 - mape: 24.9437 - val_loss: 2.6670e-04 - val_mape: 1.8593\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9548e-04 - mape: 18.1367 - val_loss: 4.4659e-05 - val_mape: 0.7127\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mape: 40.5066 - val_loss: 2.1414e-05 - val_mape: 0.4586\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6221e-04 - mape: 12.4068 - val_loss: 4.9149e-05 - val_mape: 0.6645\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3566e-04 - mape: 15.9482 - val_loss: 2.4841e-05 - val_mape: 0.4976\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6630e-04 - mape: 21.5808 - val_loss: 2.5100e-05 - val_mape: 0.5492\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2461e-04 - mape: 15.5208 - val_loss: 3.4039e-04 - val_mape: 2.1799\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1837e-04 - mape: 26.0287 - val_loss: 1.6564e-04 - val_mape: 1.4503\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5598e-04 - mape: 14.9003 - val_loss: 4.7739e-05 - val_mape: 0.6830\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8545e-04 - mape: 16.9759 - val_loss: 2.1836e-05 - val_mape: 0.4452\n",
      "--- 26/102 Training model for PDD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3926e-04 - mape: 69088.2969 - val_loss: 1.7657e-04 - val_mape: 1.7204\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8425e-04 - mape: 146444.3438 - val_loss: 3.7686e-04 - val_mape: 2.5427\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4588e-04 - mape: 70583.1719 - val_loss: 9.4894e-05 - val_mape: 1.0732\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0544e-04 - mape: 127759.6328 - val_loss: 1.2844e-04 - val_mape: 1.4366\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7391e-04 - mape: 27936.0156 - val_loss: 4.3797e-05 - val_mape: 0.7711\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2695e-04 - mape: 69186.7266 - val_loss: 8.1492e-05 - val_mape: 1.3009\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5190e-04 - mape: 50482.7930 - val_loss: 7.1871e-05 - val_mape: 1.1450\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3854e-04 - mape: 39101.8086 - val_loss: 7.5195e-05 - val_mape: 1.1192\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9421e-04 - mape: 50018.1484 - val_loss: 1.3402e-04 - val_mape: 1.5649\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1663e-04 - mape: 16849.4062 - val_loss: 7.4170e-05 - val_mape: 1.1087\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8074e-04 - mape: 92813.6016 - val_loss: 6.8508e-05 - val_mape: 1.0206\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3420e-04 - mape: 116823.3438 - val_loss: 7.9024e-05 - val_mape: 1.0545\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9169e-04 - mape: 21074.3906 - val_loss: 7.2519e-05 - val_mape: 1.0747\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1627e-04 - mape: 18383.7480 - val_loss: 1.5822e-04 - val_mape: 1.7579\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9292e-04 - mape: 81960.5312 - val_loss: 1.5013e-04 - val_mape: 1.7199\n",
      "--- 27/102 Training model for HON ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6198e-04 - mape: 9.6827 - val_loss: 2.7675e-05 - val_mape: 0.5153\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4982e-04 - mape: 7.9996 - val_loss: 1.5232e-05 - val_mape: 0.3733\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1377e-04 - mape: 8.5332 - val_loss: 1.3850e-04 - val_mape: 1.3027\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9339e-04 - mape: 7.5416 - val_loss: 2.2963e-05 - val_mape: 0.4744\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4234e-04 - mape: 10.0353 - val_loss: 2.7031e-04 - val_mape: 1.8654\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6427e-04 - mape: 9.6115 - val_loss: 4.4864e-05 - val_mape: 0.6589\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3561e-04 - mape: 7.7687 - val_loss: 2.4855e-04 - val_mape: 1.7376\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0123e-04 - mape: 12.6179 - val_loss: 2.5013e-05 - val_mape: 0.4695\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0103e-04 - mape: 12.5470 - val_loss: 5.7288e-05 - val_mape: 0.7895\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0288e-04 - mape: 12.5531 - val_loss: 4.6002e-05 - val_mape: 0.6828\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2042e-04 - mape: 10.6864 - val_loss: 2.1160e-05 - val_mape: 0.4375\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7475e-04 - mape: 9.2639 - val_loss: 1.6889e-05 - val_mape: 0.3831\n",
      "--- 28/102 Training model for ADI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2006e-04 - mape: 15.6319 - val_loss: 1.1815e-04 - val_mape: 0.8981\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9848e-04 - mape: 18.9312 - val_loss: 1.3972e-04 - val_mape: 1.0951\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1562e-04 - mape: 16.1345 - val_loss: 8.3526e-05 - val_mape: 0.7435\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5619e-04 - mape: 17.1512 - val_loss: 8.3598e-05 - val_mape: 0.7556\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3375e-04 - mape: 16.1927 - val_loss: 7.9448e-05 - val_mape: 0.7432\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3341e-04 - mape: 16.9472 - val_loss: 8.9992e-05 - val_mape: 0.8020\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4942e-04 - mape: 17.4603 - val_loss: 5.6653e-05 - val_mape: 0.6277\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1749e-04 - mape: 15.4544 - val_loss: 6.9625e-05 - val_mape: 0.6869\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6047e-04 - mape: 17.8346 - val_loss: 9.2419e-05 - val_mape: 0.8957\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1768e-04 - mape: 15.8808 - val_loss: 2.5676e-04 - val_mape: 1.7423\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4448e-04 - mape: 16.8090 - val_loss: 8.7970e-05 - val_mape: 0.8632\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2680e-04 - mape: 16.2345 - val_loss: 4.7032e-05 - val_mape: 0.5800\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5247e-04 - mape: 17.5478 - val_loss: 1.1934e-04 - val_mape: 1.1252\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3636e-04 - mape: 16.6475 - val_loss: 4.7541e-05 - val_mape: 0.5705\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3370e-04 - mape: 15.8296 - val_loss: 4.0001e-05 - val_mape: 0.5279\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4501e-04 - mape: 16.9726 - val_loss: 6.1549e-05 - val_mape: 0.7271\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1801e-04 - mape: 15.7228 - val_loss: 3.6571e-05 - val_mape: 0.5121\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4697e-04 - mape: 17.3845 - val_loss: 1.7766e-04 - val_mape: 1.4728\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5849e-04 - mape: 17.8826 - val_loss: 4.4689e-05 - val_mape: 0.5946\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0418e-04 - mape: 20.3014 - val_loss: 4.5596e-05 - val_mape: 0.5992\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3827e-04 - mape: 16.6032 - val_loss: 3.4714e-05 - val_mape: 0.5059\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9662e-04 - mape: 19.8492 - val_loss: 3.6157e-05 - val_mape: 0.5377\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4380e-04 - mape: 17.2256 - val_loss: 7.9538e-05 - val_mape: 0.9116\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4537e-04 - mape: 17.2133 - val_loss: 3.5915e-05 - val_mape: 0.5047\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2760e-04 - mape: 16.3819 - val_loss: 1.1961e-04 - val_mape: 1.1594\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3255e-04 - mape: 16.0371 - val_loss: 3.6883e-05 - val_mape: 0.5357\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5449e-04 - mape: 17.6096 - val_loss: 1.9040e-04 - val_mape: 1.5560\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8766e-04 - mape: 18.9631 - val_loss: 8.3785e-05 - val_mape: 0.9403\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4768e-04 - mape: 17.2504 - val_loss: 7.5100e-05 - val_mape: 0.8514\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4194e-04 - mape: 17.0795 - val_loss: 1.9267e-04 - val_mape: 1.5027\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4745e-04 - mape: 16.9313 - val_loss: 8.1737e-05 - val_mape: 0.8207\n",
      "--- 29/102 Training model for EA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0145e-04 - mape: 15987.0830 - val_loss: 2.2531e-05 - val_mape: 0.4453\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9051e-04 - mape: 4290.8242 - val_loss: 8.6316e-05 - val_mape: 1.0511\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7977e-04 - mape: 31252.9590 - val_loss: 5.5767e-05 - val_mape: 0.7966\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1038e-04 - mape: 21454.9258 - val_loss: 2.6476e-05 - val_mape: 0.5428\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6708e-04 - mape: 25191.2754 - val_loss: 1.8811e-05 - val_mape: 0.4022\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8099e-04 - mape: 24219.9336 - val_loss: 3.7310e-04 - val_mape: 2.3173\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0720e-04 - mape: 39421.6406 - val_loss: 1.4249e-04 - val_mape: 1.3768\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3837e-04 - mape: 4665.2124 - val_loss: 1.0340e-05 - val_mape: 0.2982\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7583e-04 - mape: 24794.6191 - val_loss: 4.0823e-04 - val_mape: 2.3950\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5681e-04 - mape: 76741.5547 - val_loss: 1.6278e-05 - val_mape: 0.3881\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4135e-04 - mape: 14815.6787 - val_loss: 8.5227e-06 - val_mape: 0.2770\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0555e-04 - mape: 15849.9160 - val_loss: 8.0347e-05 - val_mape: 0.8700\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3200e-04 - mape: 23230.7871 - val_loss: 1.7512e-05 - val_mape: 0.4021\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9175e-04 - mape: 5467.2451 - val_loss: 3.0697e-04 - val_mape: 1.8240\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0338e-04 - mape: 31150.9961 - val_loss: 1.4764e-04 - val_mape: 1.3291\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7521e-04 - mape: 40212.4570 - val_loss: 3.4969e-04 - val_mape: 1.9974\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1273e-04 - mape: 20803.6055 - val_loss: 4.4183e-04 - val_mape: 2.3588\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8749e-04 - mape: 19465.4473 - val_loss: 2.0568e-04 - val_mape: 1.5464\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0716e-04 - mape: 34705.8398 - val_loss: 3.2484e-05 - val_mape: 0.5535\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1395e-04 - mape: 29173.3750 - val_loss: 1.5670e-04 - val_mape: 1.3127\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1689e-04 - mape: 34403.6797 - val_loss: 1.4137e-04 - val_mape: 1.2376\n",
      "--- 30/102 Training model for KHC ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9084e-04 - mape: 1960.7539 - val_loss: 8.4256e-06 - val_mape: 0.6536\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mape: 20252.4160 - val_loss: 7.8809e-06 - val_mape: 0.6685\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9193e-04 - mape: 5458.1689 - val_loss: 5.2183e-06 - val_mape: 0.5302\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5209e-04 - mape: 7219.5156 - val_loss: 5.2554e-06 - val_mape: 0.5311\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3996e-04 - mape: 11030.4697 - val_loss: 4.3934e-06 - val_mape: 0.4819\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4272e-04 - mape: 17227.3379 - val_loss: 6.6433e-06 - val_mape: 0.6010\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 24265.9746 - val_loss: 5.0841e-06 - val_mape: 0.5311\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 4438.3325 - val_loss: 6.3723e-06 - val_mape: 0.6050\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mape: 9809.5264 - val_loss: 2.7274e-05 - val_mape: 1.2136\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 1829.7992 - val_loss: 1.1992e-05 - val_mape: 0.8360\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mape: 18306.3691 - val_loss: 1.3738e-05 - val_mape: 0.8869\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mape: 14071.1416 - val_loss: 1.4605e-05 - val_mape: 0.8983\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mape: 4694.6089 - val_loss: 1.3254e-05 - val_mape: 0.8233\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 6451.6152 - val_loss: 1.0870e-05 - val_mape: 0.7380\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mape: 2339.7610 - val_loss: 1.0371e-05 - val_mape: 0.7499\n",
      "--- 31/102 Training model for WBD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7626e-04 - mape: 4.4076 - val_loss: 3.2211e-06 - val_mape: 2207.8325\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0735e-04 - mape: 3.4876 - val_loss: 3.1208e-06 - val_mape: 15361.2236\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0747e-04 - mape: 3.4568 - val_loss: 5.6383e-06 - val_mape: 21680.0293\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2882e-05 - mape: 3.2085 - val_loss: 6.1672e-06 - val_mape: 435.2134\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9826e-05 - mape: 3.3570 - val_loss: 1.5735e-05 - val_mape: 12719.5625\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6063e-05 - mape: 3.1694 - val_loss: 1.9256e-05 - val_mape: 35791.7344\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0116e-05 - mape: 3.2274 - val_loss: 6.6500e-06 - val_mape: 27535.6387\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9409e-05 - mape: 3.1236 - val_loss: 4.0380e-06 - val_mape: 22286.6543\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6038e-05 - mape: 3.3336 - val_loss: 1.1235e-05 - val_mape: 29202.9258\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0376e-05 - mape: 2.9518 - val_loss: 7.4669e-06 - val_mape: 1795.7278\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9452e-05 - mape: 2.9809 - val_loss: 3.0453e-06 - val_mape: 12229.7490\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5443e-05 - mape: 3.2925 - val_loss: 4.5586e-06 - val_mape: 995.0156\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1023e-05 - mape: 2.9356 - val_loss: 2.9232e-06 - val_mape: 20252.2285\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8450e-05 - mape: 3.0128 - val_loss: 2.5115e-06 - val_mape: 18330.4238\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3583e-05 - mape: 2.8336 - val_loss: 2.0048e-06 - val_mape: 13742.2041\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6096e-05 - mape: 2.8409 - val_loss: 1.3278e-05 - val_mape: 10203.0156\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7229e-05 - mape: 2.9061 - val_loss: 1.1216e-05 - val_mape: 7013.5054\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0117e-04 - mape: 3.3432 - val_loss: 4.7280e-06 - val_mape: 20820.9531\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4592e-05 - mape: 2.6442 - val_loss: 1.6753e-06 - val_mape: 10829.4395\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8570e-05 - mape: 2.6448 - val_loss: 7.8842e-06 - val_mape: 6007.9775\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7180e-05 - mape: 2.4571 - val_loss: 1.1765e-05 - val_mape: 8437.1143\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2815e-05 - mape: 2.7417 - val_loss: 1.9131e-06 - val_mape: 12662.0879\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6290e-05 - mape: 2.6091 - val_loss: 2.7507e-06 - val_mape: 9460.1885\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6829e-05 - mape: 2.7693 - val_loss: 2.3526e-06 - val_mape: 13387.4316\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8636e-05 - mape: 2.9099 - val_loss: 3.0415e-06 - val_mape: 3336.9753\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3840e-05 - mape: 3.2218 - val_loss: 2.4164e-06 - val_mape: 20157.2695\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9084e-05 - mape: 2.6815 - val_loss: 5.0189e-06 - val_mape: 1759.1495\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0815e-05 - mape: 2.3781 - val_loss: 3.4075e-06 - val_mape: 23118.3203\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3467e-05 - mape: 2.5632 - val_loss: 1.7253e-06 - val_mape: 12159.2344\n",
      "--- 32/102 Training model for ROP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4924e-04 - mape: 9.2960 - val_loss: 3.3313e-05 - val_mape: 0.4686\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7469e-04 - mape: 13.3427 - val_loss: 4.5380e-05 - val_mape: 0.5722\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3816e-04 - mape: 9.0337 - val_loss: 3.6319e-05 - val_mape: 0.4499\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7260e-04 - mape: 11.0204 - val_loss: 7.9226e-05 - val_mape: 0.8595\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5906e-04 - mape: 12.6208 - val_loss: 4.4131e-05 - val_mape: 0.5472\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9477e-04 - mape: 11.8919 - val_loss: 5.4642e-05 - val_mape: 0.6593\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8375e-04 - mape: 10.2861 - val_loss: 3.4387e-05 - val_mape: 0.4747\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8857e-04 - mape: 11.2282 - val_loss: 4.5315e-05 - val_mape: 0.5772\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9368e-04 - mape: 11.4866 - val_loss: 2.7274e-05 - val_mape: 0.3547\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8188e-04 - mape: 10.6401 - val_loss: 2.9822e-04 - val_mape: 1.8361\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6920e-04 - mape: 10.7053 - val_loss: 4.2675e-05 - val_mape: 0.5383\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7883e-04 - mape: 14.8240 - val_loss: 3.8575e-05 - val_mape: 0.5087\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2394e-04 - mape: 15.6510 - val_loss: 8.3609e-05 - val_mape: 0.8634\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2297e-04 - mape: 16.8531 - val_loss: 2.0034e-04 - val_mape: 1.4729\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8562e-04 - mape: 14.6114 - val_loss: 3.8230e-05 - val_mape: 0.4528\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6866e-04 - mape: 20.4861 - val_loss: 2.3931e-04 - val_mape: 1.6169\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3935e-04 - mape: 15.3174 - val_loss: 3.9625e-05 - val_mape: 0.4865\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - mape: 30.8240 - val_loss: 3.3807e-05 - val_mape: 0.4399\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0894e-04 - mape: 13.2102 - val_loss: 2.2553e-04 - val_mape: 1.5279\n",
      "--- 33/102 Training model for BKR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1768e-04 - mape: 3344.3345 - val_loss: 8.4829e-05 - val_mape: 0.9897\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8606e-04 - mape: 2646.7495 - val_loss: 1.9967e-05 - val_mape: 0.4705\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0385e-04 - mape: 15367.2646 - val_loss: 1.6082e-04 - val_mape: 1.5007\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2283e-04 - mape: 20601.8184 - val_loss: 2.4872e-05 - val_mape: 0.5286\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4849e-04 - mape: 4863.6479 - val_loss: 3.5309e-05 - val_mape: 0.5903\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4175e-04 - mape: 14362.4365 - val_loss: 2.5757e-05 - val_mape: 0.5138\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9390e-04 - mape: 13468.3760 - val_loss: 8.8571e-05 - val_mape: 1.1213\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8677e-04 - mape: 43278.9727 - val_loss: 2.1479e-05 - val_mape: 0.4666\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9849e-04 - mape: 29878.0840 - val_loss: 1.0859e-05 - val_mape: 0.3187\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9551e-04 - mape: 7338.6377 - val_loss: 1.1584e-05 - val_mape: 0.3544\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7337e-04 - mape: 2238.2039 - val_loss: 1.0435e-05 - val_mape: 0.3298\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8178e-04 - mape: 511.1826 - val_loss: 5.5447e-05 - val_mape: 0.8138\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6162e-04 - mape: 3166.5413 - val_loss: 2.5055e-05 - val_mape: 0.5558\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3039e-04 - mape: 23288.0762 - val_loss: 1.8639e-05 - val_mape: 0.4142\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2820e-04 - mape: 1481.6467 - val_loss: 1.6245e-05 - val_mape: 0.3996\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0462e-04 - mape: 24200.0762 - val_loss: 8.6633e-05 - val_mape: 1.0997\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1978e-04 - mape: 132.6705 - val_loss: 4.1301e-05 - val_mape: 0.7167\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7301e-04 - mape: 31286.1133 - val_loss: 2.6390e-05 - val_mape: 0.4760\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8505e-04 - mape: 9314.4033 - val_loss: 1.7547e-05 - val_mape: 0.4427\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4630e-04 - mape: 8917.7725 - val_loss: 1.5373e-05 - val_mape: 0.4024\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6843e-04 - mape: 2380.7339 - val_loss: 1.8829e-05 - val_mape: 0.4302\n",
      "--- 34/102 Training model for COST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5225e-04 - mape: 35020.0273 - val_loss: 6.6220e-04 - val_mape: 2.8548\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8397e-04 - mape: 63230.6250 - val_loss: 4.8903e-04 - val_mape: 2.5623\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2413e-04 - mape: 2662.4302 - val_loss: 2.4236e-04 - val_mape: 1.7471\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3491e-04 - mape: 3723.0710 - val_loss: 1.9297e-04 - val_mape: 1.5272\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5389e-04 - mape: 9968.7881 - val_loss: 4.0264e-05 - val_mape: 0.5896\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1588e-04 - mape: 70862.6250 - val_loss: 5.8079e-05 - val_mape: 0.7694\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4366e-04 - mape: 18355.3203 - val_loss: 4.2390e-05 - val_mape: 0.6091\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6288e-04 - mape: 4095.1746 - val_loss: 3.4623e-05 - val_mape: 0.5128\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3673e-04 - mape: 63568.8711 - val_loss: 2.9160e-05 - val_mape: 0.4706\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8465e-04 - mape: 19153.3223 - val_loss: 2.7276e-05 - val_mape: 0.4476\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3579e-04 - mape: 82369.6875 - val_loss: 2.7949e-05 - val_mape: 0.4355\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5485e-04 - mape: 12721.0400 - val_loss: 2.9131e-05 - val_mape: 0.4754\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2416e-04 - mape: 23397.1543 - val_loss: 2.4267e-05 - val_mape: 0.4203\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5744e-04 - mape: 39155.9258 - val_loss: 1.0611e-04 - val_mape: 1.0333\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7904e-04 - mape: 3270.4629 - val_loss: 1.0347e-04 - val_mape: 1.1312\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7403e-04 - mape: 17103.1016 - val_loss: 7.9745e-05 - val_mape: 0.9011\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9418e-04 - mape: 3932.8044 - val_loss: 2.2191e-05 - val_mape: 0.4119\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1720e-04 - mape: 39533.1992 - val_loss: 2.7525e-05 - val_mape: 0.4611\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4375e-04 - mape: 22579.2520 - val_loss: 7.4845e-05 - val_mape: 0.9136\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1182e-04 - mape: 4346.4023 - val_loss: 5.4753e-05 - val_mape: 0.6994\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3953e-04 - mape: 14014.3447 - val_loss: 2.7594e-04 - val_mape: 1.8860\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4470e-04 - mape: 36678.8594 - val_loss: 3.6630e-05 - val_mape: 0.5286\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2700e-04 - mape: 61350.5820 - val_loss: 3.8315e-04 - val_mape: 2.2199\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1622e-04 - mape: 12893.4746 - val_loss: 1.2500e-04 - val_mape: 1.1908\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0220e-04 - mape: 37876.2031 - val_loss: 1.2151e-04 - val_mape: 1.2125\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6785e-04 - mape: 44894.2305 - val_loss: 1.0059e-04 - val_mape: 1.0464\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0275e-04 - mape: 25558.1094 - val_loss: 4.9582e-05 - val_mape: 0.7177\n",
      "--- 35/102 Training model for AZN ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5824e-04 - mape: 14.6010 - val_loss: 3.4384e-05 - val_mape: 0.5765\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4416e-04 - mape: 13.6643 - val_loss: 1.8405e-04 - val_mape: 1.6746\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3750e-04 - mape: 14.7685 - val_loss: 1.9958e-04 - val_mape: 1.4767\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1453e-04 - mape: 27.3783 - val_loss: 8.6424e-05 - val_mape: 0.9392\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4833e-04 - mape: 18.8677 - val_loss: 7.9353e-05 - val_mape: 1.0143\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3233e-04 - mape: 14.0945 - val_loss: 1.0834e-04 - val_mape: 0.9796\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7426e-04 - mape: 22.1802 - val_loss: 1.3953e-04 - val_mape: 1.1991\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9148e-04 - mape: 21.0279 - val_loss: 8.6280e-05 - val_mape: 0.9976\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5983e-04 - mape: 16.0896 - val_loss: 6.7522e-05 - val_mape: 0.8279\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6073e-04 - mape: 15.7657 - val_loss: 6.5769e-05 - val_mape: 0.8045\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4806e-04 - mape: 20.8174 - val_loss: 3.2585e-05 - val_mape: 0.6757\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9372e-04 - mape: 16.5116 - val_loss: 2.0567e-05 - val_mape: 0.4561\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3589e-04 - mape: 17.9870 - val_loss: 3.1853e-05 - val_mape: 0.5964\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8329e-04 - mape: 16.5227 - val_loss: 1.4778e-04 - val_mape: 1.2372\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6499e-04 - mape: 13.3197 - val_loss: 5.3997e-05 - val_mape: 0.8858\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0428e-04 - mape: 18.4739 - val_loss: 2.3296e-05 - val_mape: 0.4669\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0909e-04 - mape: 15.7835 - val_loss: 1.0216e-04 - val_mape: 0.9113\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7079e-04 - mape: 17.4867 - val_loss: 5.6354e-05 - val_mape: 0.7126\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8063e-04 - mape: 15.2680 - val_loss: 1.0111e-04 - val_mape: 0.8917\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2344e-04 - mape: 17.7656 - val_loss: 9.5206e-05 - val_mape: 0.9225\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2394e-04 - mape: 15.0585 - val_loss: 7.4261e-05 - val_mape: 0.8210\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9605e-04 - mape: 16.7687 - val_loss: 1.4274e-04 - val_mape: 1.1636\n",
      "--- 36/102 Training model for LRCX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5400e-04 - mape: 53.7602 - val_loss: 0.0035 - val_mape: 7.1093\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - mape: 89.9908 - val_loss: 4.5323e-04 - val_mape: 2.5812\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mape: 92.0702 - val_loss: 0.0202 - val_mape: 17.3476\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - mape: 213.2036 - val_loss: 0.0023 - val_mape: 5.8923\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8118e-04 - mape: 51.0782 - val_loss: 1.4893e-04 - val_mape: 1.3984\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9981e-04 - mape: 35.3048 - val_loss: 9.3243e-05 - val_mape: 1.0266\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1830e-04 - mape: 38.2640 - val_loss: 9.5764e-05 - val_mape: 1.0185\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0939e-04 - mape: 39.1008 - val_loss: 5.4976e-05 - val_mape: 0.7178\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0751e-04 - mape: 38.0091 - val_loss: 7.4026e-05 - val_mape: 0.8270\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1441e-04 - mape: 36.8835 - val_loss: 5.5672e-05 - val_mape: 0.7395\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0553e-04 - mape: 39.2407 - val_loss: 9.2973e-05 - val_mape: 0.9549\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9644e-04 - mape: 37.4725 - val_loss: 8.6667e-05 - val_mape: 0.9211\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0740e-04 - mape: 40.3511 - val_loss: 7.7708e-05 - val_mape: 0.8707\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9597e-04 - mape: 37.3451 - val_loss: 5.8030e-05 - val_mape: 0.7428\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8155e-04 - mape: 38.4371 - val_loss: 6.1572e-05 - val_mape: 0.7618\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1371e-04 - mape: 36.6746 - val_loss: 1.3047e-04 - val_mape: 1.2079\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9062e-04 - mape: 37.5427 - val_loss: 1.0735e-04 - val_mape: 1.0495\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9630e-04 - mape: 38.3552 - val_loss: 5.4909e-05 - val_mape: 0.6989\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7148e-04 - mape: 33.2831 - val_loss: 2.6041e-04 - val_mape: 1.8520\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0833e-04 - mape: 36.1803 - val_loss: 7.3196e-05 - val_mape: 0.8130\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1964e-04 - mape: 41.4846 - val_loss: 1.5165e-04 - val_mape: 1.3467\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9002e-04 - mape: 37.4340 - val_loss: 6.5579e-05 - val_mape: 0.7585\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6769e-04 - mape: 35.7725 - val_loss: 1.8939e-04 - val_mape: 1.5321\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9913e-04 - mape: 32.8603 - val_loss: 7.9411e-05 - val_mape: 0.8236\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6442e-04 - mape: 41.4935 - val_loss: 0.0011 - val_mape: 4.0911\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0920e-04 - mape: 44.8284 - val_loss: 8.5069e-05 - val_mape: 0.8260\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8315e-04 - mape: 50.9489 - val_loss: 0.0061 - val_mape: 9.6553\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mape: 92.1036 - val_loss: 1.5083e-04 - val_mape: 1.1421\n",
      "--- 37/102 Training model for MELI ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0082e-04 - mape: 21.4028 - val_loss: 9.1439e-05 - val_mape: 1.0300\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7157e-04 - mape: 42.4333 - val_loss: 3.3791e-04 - val_mape: 2.1925\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mape: 59.0378 - val_loss: 0.0053 - val_mape: 8.9517\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mape: 89.0328 - val_loss: 6.8168e-05 - val_mape: 0.8064\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - mape: 47.4607 - val_loss: 0.0020 - val_mape: 5.5376\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3432e-04 - mape: 33.7796 - val_loss: 3.9777e-05 - val_mape: 0.6136\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6802e-04 - mape: 21.0021 - val_loss: 1.6355e-04 - val_mape: 1.5343\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6089e-04 - mape: 20.3082 - val_loss: 2.4125e-05 - val_mape: 0.4613\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7914e-04 - mape: 22.6386 - val_loss: 6.5799e-05 - val_mape: 0.9276\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9703e-04 - mape: 24.0114 - val_loss: 1.8384e-05 - val_mape: 0.4068\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1987e-04 - mape: 19.9632 - val_loss: 6.5353e-05 - val_mape: 0.9061\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4506e-04 - mape: 21.3222 - val_loss: 3.7719e-05 - val_mape: 0.6232\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1524e-04 - mape: 20.2621 - val_loss: 5.6614e-05 - val_mape: 0.8440\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3112e-04 - mape: 21.2076 - val_loss: 2.7227e-05 - val_mape: 0.5401\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0543e-04 - mape: 22.3613 - val_loss: 6.7375e-05 - val_mape: 0.9111\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4135e-04 - mape: 24.6189 - val_loss: 1.3647e-04 - val_mape: 1.3791\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7233e-04 - mape: 25.5308 - val_loss: 9.5318e-05 - val_mape: 1.0782\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7034e-04 - mape: 35.3741 - val_loss: 0.0014 - val_mape: 4.5502\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1098e-04 - mape: 42.9941 - val_loss: 1.5412e-04 - val_mape: 1.4689\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1207e-04 - mape: 29.5792 - val_loss: 6.5453e-04 - val_mape: 3.1368\n",
      "--- 38/102 Training model for CDW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3150e-04 - mape: 22.7320 - val_loss: 1.8220e-04 - val_mape: 1.2299\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4416e-04 - mape: 37.0647 - val_loss: 1.8176e-04 - val_mape: 1.4350\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4660e-04 - mape: 23.4754 - val_loss: 6.0855e-05 - val_mape: 0.6340\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5443e-04 - mape: 18.6966 - val_loss: 9.6395e-05 - val_mape: 0.9930\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8693e-04 - mape: 23.3656 - val_loss: 8.6386e-05 - val_mape: 0.8319\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6851e-04 - mape: 20.5175 - val_loss: 5.3992e-05 - val_mape: 0.6908\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6556e-04 - mape: 19.6612 - val_loss: 4.2800e-05 - val_mape: 0.5750\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4258e-04 - mape: 17.9764 - val_loss: 3.2547e-05 - val_mape: 0.4272\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6246e-04 - mape: 20.7134 - val_loss: 1.4428e-04 - val_mape: 1.2895\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8839e-04 - mape: 20.1098 - val_loss: 3.2913e-05 - val_mape: 0.4126\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9195e-04 - mape: 21.0042 - val_loss: 1.7193e-04 - val_mape: 1.4266\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2640e-04 - mape: 25.5224 - val_loss: 4.1079e-05 - val_mape: 0.5293\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0326e-04 - mape: 22.3238 - val_loss: 3.5473e-05 - val_mape: 0.4614\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7277e-04 - mape: 19.0651 - val_loss: 4.6591e-05 - val_mape: 0.4982\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3617e-04 - mape: 22.6486 - val_loss: 2.4896e-04 - val_mape: 1.7342\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1708e-04 - mape: 32.4258 - val_loss: 3.6802e-05 - val_mape: 0.4644\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7637e-04 - mape: 24.2731 - val_loss: 1.1749e-04 - val_mape: 1.1417\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3031e-04 - mape: 27.8950 - val_loss: 4.5629e-05 - val_mape: 0.5706\n",
      "--- 39/102 Training model for FANG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4154e-04 - mape: 10584.3555 - val_loss: 3.5117e-04 - val_mape: 1.9598\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3154e-04 - mape: 11242.5039 - val_loss: 1.4953e-04 - val_mape: 1.3027\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0605e-05 - mape: 3510.6355 - val_loss: 1.6452e-04 - val_mape: 1.3030\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1655e-05 - mape: 5866.6143 - val_loss: 2.1651e-05 - val_mape: 0.4038\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0679e-05 - mape: 12821.2529 - val_loss: 3.1979e-05 - val_mape: 0.4755\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9689e-05 - mape: 17693.0391 - val_loss: 6.4310e-05 - val_mape: 0.7530\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1868e-05 - mape: 12945.2051 - val_loss: 4.7252e-05 - val_mape: 0.6463\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5610e-05 - mape: 10059.2939 - val_loss: 7.5580e-05 - val_mape: 0.8971\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7264e-05 - mape: 14170.1914 - val_loss: 1.4608e-04 - val_mape: 1.2690\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5811e-05 - mape: 5001.5161 - val_loss: 4.6149e-05 - val_mape: 0.6089\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6759e-05 - mape: 2959.0913 - val_loss: 6.3391e-05 - val_mape: 0.7252\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1926e-05 - mape: 1588.3342 - val_loss: 5.9771e-05 - val_mape: 0.7572\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5994e-05 - mape: 2233.5967 - val_loss: 4.2722e-05 - val_mape: 0.6044\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0030e-04 - mape: 2369.3821 - val_loss: 7.6878e-05 - val_mape: 0.8001\n",
      "--- 40/102 Training model for ZS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4758e-04 - mape: 80282.9141 - val_loss: 9.5070e-05 - val_mape: 1.7733\n",
      "Epoch 2/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6643e-04 - mape: 51563.9805 - val_loss: 9.5801e-05 - val_mape: 1.5962\n",
      "Epoch 3/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7998e-04 - mape: 83286.9922 - val_loss: 1.2690e-04 - val_mape: 2.0778\n",
      "Epoch 4/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8038e-04 - mape: 94704.7266 - val_loss: 1.9995e-05 - val_mape: 0.6571\n",
      "Epoch 5/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7394e-04 - mape: 26700.0566 - val_loss: 2.2616e-04 - val_mape: 2.6920\n",
      "Epoch 6/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4415e-04 - mape: 125377.8906 - val_loss: 3.2407e-05 - val_mape: 0.7966\n",
      "Epoch 7/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7359e-04 - mape: 33012.8633 - val_loss: 4.8537e-04 - val_mape: 4.1356\n",
      "Epoch 8/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1666e-04 - mape: 44355.9570 - val_loss: 6.1897e-05 - val_mape: 1.4872\n",
      "Epoch 9/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9334e-04 - mape: 89529.0703 - val_loss: 3.3808e-05 - val_mape: 0.9941\n",
      "Epoch 10/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5163e-04 - mape: 81853.7109 - val_loss: 1.2843e-04 - val_mape: 2.2132\n",
      "Epoch 11/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8057e-04 - mape: 73257.5547 - val_loss: 2.9585e-05 - val_mape: 0.9296\n",
      "Epoch 12/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0356e-04 - mape: 43442.3047 - val_loss: 2.1602e-04 - val_mape: 2.8282\n",
      "Epoch 13/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7855e-04 - mape: 22193.2129 - val_loss: 2.6122e-05 - val_mape: 0.8659\n",
      "Epoch 14/150\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3974e-04 - mape: 21810.6641 - val_loss: 1.5151e-04 - val_mape: 2.3719\n",
      "--- 41/102 Training model for ADBE ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9236e-04 - mape: 14.3862 - val_loss: 1.6071e-04 - val_mape: 1.5172\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3698e-04 - mape: 16.7821 - val_loss: 9.4046e-04 - val_mape: 3.6099\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mape: 64.4139 - val_loss: 5.3455e-04 - val_mape: 2.9265\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mape: 26.2438 - val_loss: 0.0062 - val_mape: 9.9940\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mape: 65.9163 - val_loss: 1.0270e-04 - val_mape: 1.0335\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2109e-04 - mape: 29.0422 - val_loss: 0.0013 - val_mape: 4.5368\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1249e-04 - mape: 30.3792 - val_loss: 8.1942e-05 - val_mape: 0.9485\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6721e-04 - mape: 15.3781 - val_loss: 1.4749e-04 - val_mape: 1.4079\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6920e-04 - mape: 21.1156 - val_loss: 3.3125e-04 - val_mape: 2.2257\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0817e-04 - mape: 15.8201 - val_loss: 4.0516e-05 - val_mape: 0.5659\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3508e-04 - mape: 16.9324 - val_loss: 6.1045e-05 - val_mape: 0.7880\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3384e-04 - mape: 16.8552 - val_loss: 3.6662e-05 - val_mape: 0.5334\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4006e-04 - mape: 18.7949 - val_loss: 6.4735e-05 - val_mape: 0.8518\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1164e-04 - mape: 16.6114 - val_loss: 4.3779e-05 - val_mape: 0.6481\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2650e-04 - mape: 15.6068 - val_loss: 7.4838e-05 - val_mape: 0.9251\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9324e-04 - mape: 20.5772 - val_loss: 2.1321e-04 - val_mape: 1.7732\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6919e-04 - mape: 17.9556 - val_loss: 4.0541e-05 - val_mape: 0.6096\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9124e-04 - mape: 19.4868 - val_loss: 2.6912e-04 - val_mape: 2.0357\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9751e-04 - mape: 14.8322 - val_loss: 3.7994e-05 - val_mape: 0.5670\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6750e-04 - mape: 17.6026 - val_loss: 7.5273e-05 - val_mape: 0.9699\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1525e-04 - mape: 16.1263 - val_loss: 4.5492e-05 - val_mape: 0.6464\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4470e-04 - mape: 20.6292 - val_loss: 6.6638e-04 - val_mape: 3.2746\n",
      "--- 42/102 Training model for GOOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5698e-04 - mape: 33.7925 - val_loss: 3.0105e-04 - val_mape: 1.9322\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8099e-04 - mape: 35.8433 - val_loss: 8.3168e-05 - val_mape: 0.7568\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2955e-04 - mape: 36.8629 - val_loss: 1.6271e-04 - val_mape: 1.2687\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4040e-04 - mape: 30.2386 - val_loss: 1.0478e-04 - val_mape: 0.9475\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9911e-04 - mape: 38.5210 - val_loss: 2.0380e-04 - val_mape: 1.5144\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3005e-04 - mape: 30.8573 - val_loss: 1.4000e-04 - val_mape: 1.2024\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0540e-04 - mape: 30.0741 - val_loss: 1.9395e-04 - val_mape: 1.4961\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2436e-04 - mape: 28.5537 - val_loss: 9.9038e-05 - val_mape: 0.9692\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8596e-04 - mape: 32.9457 - val_loss: 2.4708e-04 - val_mape: 1.7491\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0455e-04 - mape: 29.8272 - val_loss: 1.3291e-04 - val_mape: 1.2052\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1553e-04 - mape: 28.0806 - val_loss: 3.1913e-04 - val_mape: 2.0739\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5661e-04 - mape: 31.7888 - val_loss: 3.2904e-04 - val_mape: 2.1143\n",
      "--- 43/102 Training model for AMAT ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5799e-04 - mape: 6866.2119 - val_loss: 7.1960e-04 - val_mape: 3.1993\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9854e-04 - mape: 6769.0513 - val_loss: 1.3454e-04 - val_mape: 1.1577\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4076e-04 - mape: 1965.7688 - val_loss: 1.2282e-04 - val_mape: 1.0749\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5437e-04 - mape: 12828.8066 - val_loss: 2.1194e-04 - val_mape: 1.5725\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5959e-04 - mape: 7487.2715 - val_loss: 1.1540e-04 - val_mape: 0.9994\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6642e-04 - mape: 6404.8574 - val_loss: 1.8360e-04 - val_mape: 1.4555\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1728e-04 - mape: 30050.4609 - val_loss: 3.3311e-04 - val_mape: 2.1005\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1300e-04 - mape: 9342.8730 - val_loss: 2.2037e-04 - val_mape: 1.6260\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0424e-04 - mape: 21416.2188 - val_loss: 1.4020e-04 - val_mape: 1.1681\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9959e-04 - mape: 4452.0093 - val_loss: 1.3473e-04 - val_mape: 1.1464\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2664e-04 - mape: 15001.9883 - val_loss: 1.4541e-04 - val_mape: 1.2136\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0769e-04 - mape: 23996.6309 - val_loss: 1.0803e-04 - val_mape: 0.9901\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0236e-04 - mape: 2567.6851 - val_loss: 1.4459e-04 - val_mape: 1.2562\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0242e-04 - mape: 23997.0195 - val_loss: 1.5538e-04 - val_mape: 1.3078\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1093e-04 - mape: 7148.3511 - val_loss: 1.8519e-04 - val_mape: 1.5043\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0531e-04 - mape: 20551.8750 - val_loss: 1.6791e-04 - val_mape: 1.3633\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7230e-04 - mape: 14994.5352 - val_loss: 9.7331e-05 - val_mape: 0.9456\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1295e-04 - mape: 11831.1006 - val_loss: 1.5668e-04 - val_mape: 1.3377\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8958e-04 - mape: 20172.6230 - val_loss: 2.7885e-04 - val_mape: 1.9322\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6825e-04 - mape: 16792.1309 - val_loss: 7.5124e-05 - val_mape: 0.7460\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5768e-04 - mape: 20525.0684 - val_loss: 2.1078e-04 - val_mape: 1.6657\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4533e-04 - mape: 18299.7402 - val_loss: 1.2004e-04 - val_mape: 1.1060\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5361e-04 - mape: 332.9599 - val_loss: 7.3297e-05 - val_mape: 0.7269\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2564e-04 - mape: 1483.1271 - val_loss: 8.7141e-05 - val_mape: 0.8882\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6084e-04 - mape: 378.0880 - val_loss: 8.5505e-05 - val_mape: 0.8677\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3782e-04 - mape: 23925.8574 - val_loss: 7.1595e-05 - val_mape: 0.7292\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3912e-04 - mape: 37526.1367 - val_loss: 7.7395e-05 - val_mape: 0.8189\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8515e-04 - mape: 2123.1958 - val_loss: 6.8908e-05 - val_mape: 0.7091\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3856e-04 - mape: 12087.2959 - val_loss: 8.1239e-05 - val_mape: 0.8750\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5332e-04 - mape: 14809.4248 - val_loss: 0.0014 - val_mape: 4.7361\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8933e-04 - mape: 15544.1836 - val_loss: 9.0030e-05 - val_mape: 0.8223\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8807e-04 - mape: 14925.8223 - val_loss: 0.0017 - val_mape: 5.2680\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7308e-04 - mape: 3135.0571 - val_loss: 1.3812e-04 - val_mape: 1.1398\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3577e-04 - mape: 13720.3203 - val_loss: 4.3601e-04 - val_mape: 2.5114\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0463e-04 - mape: 5138.6724 - val_loss: 1.5824e-04 - val_mape: 1.2265\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5761e-04 - mape: 7953.3403 - val_loss: 2.2717e-04 - val_mape: 1.7423\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3784e-04 - mape: 21154.8320 - val_loss: 1.1114e-04 - val_mape: 0.9240\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6390e-04 - mape: 16647.5547 - val_loss: 6.1499e-04 - val_mape: 3.1113\n",
      "--- 44/102 Training model for ADP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3271e-04 - mape: 47355.3281 - val_loss: 2.4302e-04 - val_mape: 1.8158\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6065e-04 - mape: 112751.0469 - val_loss: 1.3867e-04 - val_mape: 1.3437\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4646e-04 - mape: 123254.6484 - val_loss: 6.1046e-05 - val_mape: 0.8612\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2597e-04 - mape: 13279.3174 - val_loss: 2.4953e-05 - val_mape: 0.4941\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2570e-04 - mape: 72772.9766 - val_loss: 1.7609e-05 - val_mape: 0.3565\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6820e-04 - mape: 8423.0098 - val_loss: 1.7129e-04 - val_mape: 1.5046\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4169e-04 - mape: 31659.9238 - val_loss: 3.5045e-05 - val_mape: 0.6045\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5475e-04 - mape: 4785.9717 - val_loss: 1.4912e-05 - val_mape: 0.3261\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6271e-04 - mape: 14974.2705 - val_loss: 1.7252e-05 - val_mape: 0.3745\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6986e-04 - mape: 29981.0391 - val_loss: 1.3317e-04 - val_mape: 1.3060\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1087e-04 - mape: 25515.6270 - val_loss: 6.2803e-05 - val_mape: 0.8687\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0765e-04 - mape: 31514.3359 - val_loss: 1.8017e-04 - val_mape: 1.5559\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8396e-04 - mape: 44705.8867 - val_loss: 3.2414e-05 - val_mape: 0.5970\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1086e-04 - mape: 101957.8594 - val_loss: 1.0977e-05 - val_mape: 0.3076\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7795e-04 - mape: 71251.0391 - val_loss: 7.1865e-05 - val_mape: 0.9463\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1226e-04 - mape: 13464.4463 - val_loss: 1.1383e-04 - val_mape: 1.2193\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7372e-04 - mape: 25180.2109 - val_loss: 3.1185e-04 - val_mape: 2.0237\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2203e-04 - mape: 171493.1875 - val_loss: 1.1646e-05 - val_mape: 0.3129\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8178e-04 - mape: 8958.2988 - val_loss: 6.7914e-05 - val_mape: 0.9157\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2001e-04 - mape: 60607.2930 - val_loss: 3.8218e-05 - val_mape: 0.6556\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2630e-04 - mape: 102284.0078 - val_loss: 1.7983e-04 - val_mape: 1.5637\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2901e-04 - mape: 98832.4609 - val_loss: 1.5480e-04 - val_mape: 1.4293\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3343e-04 - mape: 113930.6094 - val_loss: 2.1466e-05 - val_mape: 0.4255\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0630e-04 - mape: 26390.2285 - val_loss: 1.1054e-05 - val_mape: 0.3027\n",
      "--- 45/102 Training model for SBUX ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6743e-04 - mape: 9958.7900 - val_loss: 3.1610e-05 - val_mape: 0.6756\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7176e-04 - mape: 36518.9531 - val_loss: 1.1273e-04 - val_mape: 1.7568\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8865e-04 - mape: 23740.3516 - val_loss: 2.9945e-04 - val_mape: 3.0782\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2822e-04 - mape: 2070.2156 - val_loss: 1.9969e-04 - val_mape: 2.4100\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2761e-04 - mape: 27042.1426 - val_loss: 2.2545e-04 - val_mape: 2.6397\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1502e-04 - mape: 7037.5967 - val_loss: 1.1241e-04 - val_mape: 1.7359\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6713e-04 - mape: 20602.4375 - val_loss: 4.9931e-05 - val_mape: 0.7676\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7211e-04 - mape: 14458.1709 - val_loss: 1.7532e-04 - val_mape: 1.8482\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3606e-04 - mape: 5186.0791 - val_loss: 4.4988e-05 - val_mape: 0.6521\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1485e-04 - mape: 9553.2773 - val_loss: 6.3919e-05 - val_mape: 0.8578\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7995e-04 - mape: 22605.6992 - val_loss: 1.5380e-04 - val_mape: 1.6542\n",
      "--- 46/102 Training model for TTWO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6101e-04 - mape: 7.1521 - val_loss: 2.2471e-05 - val_mape: 0.6160\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6473e-04 - mape: 6.8981 - val_loss: 2.5247e-05 - val_mape: 0.6560\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5172e-04 - mape: 7.0690 - val_loss: 1.0464e-05 - val_mape: 0.3689\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8687e-04 - mape: 7.4573 - val_loss: 2.9249e-05 - val_mape: 0.7200\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5529e-04 - mape: 7.0167 - val_loss: 7.0218e-05 - val_mape: 1.2275\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9885e-04 - mape: 8.2314 - val_loss: 1.2754e-04 - val_mape: 1.5779\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0287e-04 - mape: 13.4592 - val_loss: 5.2986e-05 - val_mape: 0.9668\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4046e-04 - mape: 15.9426 - val_loss: 0.0016 - val_mape: 6.0338\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - mape: 25.5358 - val_loss: 1.7163e-04 - val_mape: 1.9110\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9747e-04 - mape: 14.2344 - val_loss: 7.1388e-04 - val_mape: 4.0035\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6222e-04 - mape: 16.3405 - val_loss: 5.9399e-05 - val_mape: 1.0864\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4510e-04 - mape: 9.4721 - val_loss: 3.3888e-04 - val_mape: 2.7302\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6115e-04 - mape: 12.1313 - val_loss: 3.4443e-05 - val_mape: 0.7762\n",
      "--- 47/102 Training model for TMUS ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2060e-04 - mape: 1511.2170 - val_loss: 1.1447e-04 - val_mape: 1.2346\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4402e-04 - mape: 12157.4648 - val_loss: 3.3085e-05 - val_mape: 0.5708\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0666e-04 - mape: 36116.8828 - val_loss: 7.7266e-05 - val_mape: 1.0299\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3465e-04 - mape: 22201.1914 - val_loss: 2.1183e-05 - val_mape: 0.4357\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2353e-04 - mape: 1353.9130 - val_loss: 2.5495e-05 - val_mape: 0.5242\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2450e-04 - mape: 48769.2266 - val_loss: 1.7836e-05 - val_mape: 0.4085\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5192e-04 - mape: 9461.8857 - val_loss: 4.2094e-05 - val_mape: 0.7433\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5398e-04 - mape: 2513.7239 - val_loss: 2.3510e-05 - val_mape: 0.4531\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1076e-04 - mape: 16721.4297 - val_loss: 4.6774e-05 - val_mape: 0.7971\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1300e-04 - mape: 29432.8809 - val_loss: 1.6612e-05 - val_mape: 0.3658\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6997e-04 - mape: 4533.0728 - val_loss: 3.2414e-05 - val_mape: 0.5592\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4451e-04 - mape: 38802.8945 - val_loss: 1.0781e-05 - val_mape: 0.3031\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1420e-04 - mape: 10862.9590 - val_loss: 1.2956e-05 - val_mape: 0.3367\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1781e-04 - mape: 1894.5861 - val_loss: 1.3087e-05 - val_mape: 0.3429\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9123e-04 - mape: 16357.9102 - val_loss: 3.2339e-05 - val_mape: 0.6008\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1735e-04 - mape: 47155.1445 - val_loss: 1.0702e-05 - val_mape: 0.3023\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8008e-04 - mape: 19245.9492 - val_loss: 1.3868e-05 - val_mape: 0.3377\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4414e-04 - mape: 24836.3457 - val_loss: 2.9680e-05 - val_mape: 0.5965\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2904e-04 - mape: 42157.3906 - val_loss: 8.0860e-05 - val_mape: 1.1023\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9157e-04 - mape: 9189.8984 - val_loss: 2.4071e-05 - val_mape: 0.4851\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4752e-04 - mape: 2072.4922 - val_loss: 1.3255e-05 - val_mape: 0.3342\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1339e-04 - mape: 59577.2109 - val_loss: 1.4204e-05 - val_mape: 0.3763\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0574e-04 - mape: 32407.6973 - val_loss: 9.8915e-06 - val_mape: 0.2906\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1598e-04 - mape: 27960.8594 - val_loss: 6.1130e-05 - val_mape: 0.9449\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0095e-04 - mape: 14081.7949 - val_loss: 1.3443e-05 - val_mape: 0.3623\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9892e-04 - mape: 1513.4364 - val_loss: 5.4404e-05 - val_mape: 0.9095\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1815e-04 - mape: 3075.8997 - val_loss: 3.9978e-05 - val_mape: 0.7131\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1499e-04 - mape: 65499.3867 - val_loss: 9.4959e-05 - val_mape: 1.2239\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0512e-04 - mape: 1581.8071 - val_loss: 1.4508e-05 - val_mape: 0.3550\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2972e-04 - mape: 60638.8984 - val_loss: 1.2494e-05 - val_mape: 0.3239\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1852e-04 - mape: 4457.4644 - val_loss: 8.5144e-05 - val_mape: 1.1339\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2058e-04 - mape: 15048.0000 - val_loss: 5.0196e-05 - val_mape: 0.7343\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3847e-04 - mape: 25204.2578 - val_loss: 3.0733e-05 - val_mape: 0.6045\n",
      "--- 48/102 Training model for WDAY ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6640e-04 - mape: 6.7140 - val_loss: 8.4312e-05 - val_mape: 1.0483\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0560e-04 - mape: 6.2298 - val_loss: 3.7777e-05 - val_mape: 0.6552\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2654e-04 - mape: 10.2255 - val_loss: 1.6962e-04 - val_mape: 1.4900\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1946e-04 - mape: 7.8862 - val_loss: 4.6017e-05 - val_mape: 0.6601\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7149e-04 - mape: 6.6297 - val_loss: 3.3840e-05 - val_mape: 0.5650\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1822e-04 - mape: 8.3787 - val_loss: 4.1834e-05 - val_mape: 0.5538\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4857e-04 - mape: 6.2856 - val_loss: 3.0934e-05 - val_mape: 0.4618\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8562e-04 - mape: 7.3279 - val_loss: 3.1585e-05 - val_mape: 0.4723\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6297e-04 - mape: 7.1267 - val_loss: 4.1197e-05 - val_mape: 0.5430\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2640e-04 - mape: 6.2759 - val_loss: 3.4451e-05 - val_mape: 0.5160\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5642e-04 - mape: 6.5710 - val_loss: 2.9899e-05 - val_mape: 0.5061\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6677e-04 - mape: 7.0117 - val_loss: 3.7269e-05 - val_mape: 0.5244\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5650e-04 - mape: 7.0778 - val_loss: 7.1295e-05 - val_mape: 0.9031\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9338e-04 - mape: 7.5610 - val_loss: 6.3512e-05 - val_mape: 0.7774\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6885e-04 - mape: 9.1161 - val_loss: 2.1314e-05 - val_mape: 0.4149\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3423e-04 - mape: 6.4686 - val_loss: 5.7549e-05 - val_mape: 0.7883\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4208e-04 - mape: 8.1716 - val_loss: 5.8036e-05 - val_mape: 0.7073\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6422e-04 - mape: 9.0744 - val_loss: 2.9579e-05 - val_mape: 0.5582\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3411e-04 - mape: 7.6991 - val_loss: 3.3818e-05 - val_mape: 0.5155\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5269e-04 - mape: 7.4644 - val_loss: 4.2056e-05 - val_mape: 0.6621\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1803e-04 - mape: 7.8542 - val_loss: 2.8410e-05 - val_mape: 0.4714\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7577e-04 - mape: 7.1737 - val_loss: 4.7511e-05 - val_mape: 0.6697\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0113e-04 - mape: 7.9298 - val_loss: 3.5893e-05 - val_mape: 0.5333\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8518e-04 - mape: 7.6907 - val_loss: 2.2973e-05 - val_mape: 0.4138\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6445e-04 - mape: 8.9289 - val_loss: 3.5850e-05 - val_mape: 0.5645\n",
      "--- 49/102 Training model for CRWD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9566e-04 - mape: 32630.2383 - val_loss: 2.3326e-04 - val_mape: 1.6049\n",
      "Epoch 2/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8567e-04 - mape: 10600.2500 - val_loss: 5.7496e-05 - val_mape: 0.7390\n",
      "Epoch 3/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9073e-04 - mape: 97589.3438 - val_loss: 7.0705e-04 - val_mape: 3.0912\n",
      "Epoch 4/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4684e-04 - mape: 11582.4707 - val_loss: 4.0351e-04 - val_mape: 2.3735\n",
      "Epoch 5/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mape: 37110.7188 - val_loss: 0.0100 - val_mape: 12.0073\n",
      "Epoch 6/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4285e-04 - mape: 18707.9023 - val_loss: 1.5472e-04 - val_mape: 1.2394\n",
      "Epoch 7/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9094e-04 - mape: 21529.8398 - val_loss: 8.3498e-05 - val_mape: 0.9811\n",
      "Epoch 8/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6754e-04 - mape: 17188.9375 - val_loss: 1.4149e-04 - val_mape: 1.2755\n",
      "Epoch 9/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8922e-04 - mape: 7406.4878 - val_loss: 1.1883e-04 - val_mape: 1.1408\n",
      "Epoch 10/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8894e-04 - mape: 37517.3711 - val_loss: 4.3955e-05 - val_mape: 0.6156\n",
      "Epoch 11/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8237e-04 - mape: 11365.6182 - val_loss: 4.3757e-05 - val_mape: 0.6274\n",
      "Epoch 12/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9496e-04 - mape: 9166.8193 - val_loss: 4.2229e-05 - val_mape: 0.5545\n",
      "Epoch 13/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1317e-04 - mape: 66568.0938 - val_loss: 1.1503e-04 - val_mape: 1.0998\n",
      "Epoch 14/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6118e-04 - mape: 29969.4863 - val_loss: 8.7177e-05 - val_mape: 0.8868\n",
      "Epoch 15/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6835e-04 - mape: 60313.5586 - val_loss: 1.0684e-04 - val_mape: 1.0329\n",
      "Epoch 16/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5486e-04 - mape: 28226.5352 - val_loss: 9.9089e-05 - val_mape: 0.9710\n",
      "Epoch 17/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6635e-04 - mape: 30128.9492 - val_loss: 7.8230e-05 - val_mape: 0.8052\n",
      "Epoch 18/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5819e-04 - mape: 82141.3594 - val_loss: 1.3780e-04 - val_mape: 1.2010\n",
      "Epoch 19/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4511e-04 - mape: 13296.3613 - val_loss: 5.0389e-05 - val_mape: 0.6246\n",
      "Epoch 20/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8954e-04 - mape: 48164.1133 - val_loss: 4.7308e-05 - val_mape: 0.5521\n",
      "Epoch 21/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5608e-04 - mape: 58282.1914 - val_loss: 5.4293e-05 - val_mape: 0.6006\n",
      "Epoch 22/150\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8321e-04 - mape: 35766.1602 - val_loss: 6.1530e-05 - val_mape: 0.6834\n",
      "--- 50/102 Training model for DDOG ---\n",
      "Epoch 1/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5236e-04 - mape: 191430.1406 - val_loss: 1.2543e-05 - val_mape: 0.5200\n",
      "Epoch 2/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0964e-04 - mape: 83641.2031 - val_loss: 9.7391e-06 - val_mape: 0.4558\n",
      "Epoch 3/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5067e-04 - mape: 32769.9141 - val_loss: 9.7566e-06 - val_mape: 0.4625\n",
      "Epoch 4/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7138e-04 - mape: 8948.0732 - val_loss: 7.3313e-06 - val_mape: 0.3810\n",
      "Epoch 5/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3592e-04 - mape: 39589.8477 - val_loss: 9.2965e-06 - val_mape: 0.4307\n",
      "Epoch 6/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9971e-04 - mape: 8220.9111 - val_loss: 9.0454e-06 - val_mape: 0.4328\n",
      "Epoch 7/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6965e-04 - mape: 25849.4609 - val_loss: 1.5336e-05 - val_mape: 0.5939\n",
      "Epoch 8/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6599e-04 - mape: 127291.1562 - val_loss: 1.6990e-05 - val_mape: 0.6414\n",
      "Epoch 9/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8507e-04 - mape: 41434.8125 - val_loss: 5.2130e-05 - val_mape: 1.2275\n",
      "Epoch 10/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0885e-04 - mape: 17115.6094 - val_loss: 1.3092e-05 - val_mape: 0.5299\n",
      "Epoch 11/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6807e-04 - mape: 1698.4369 - val_loss: 4.4395e-05 - val_mape: 1.1028\n",
      "Epoch 12/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3440e-04 - mape: 53260.5312 - val_loss: 6.2920e-05 - val_mape: 1.3756\n",
      "Epoch 13/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8232e-04 - mape: 4963.2363 - val_loss: 2.1744e-05 - val_mape: 0.7232\n",
      "Epoch 14/150\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0502e-04 - mape: 233554.5781 - val_loss: 5.2437e-05 - val_mape: 1.2159\n",
      "--- 51/102 Training model for PCAR ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0835e-04 - mape: 7455.0654 - val_loss: 9.3647e-05 - val_mape: 0.8282\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3827e-04 - mape: 5708.9082 - val_loss: 1.2895e-04 - val_mape: 0.9637\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7070e-04 - mape: 2608.3198 - val_loss: 6.9772e-05 - val_mape: 0.6959\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9510e-04 - mape: 41602.3906 - val_loss: 1.3363e-04 - val_mape: 0.9693\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6545e-04 - mape: 6561.9766 - val_loss: 6.2674e-05 - val_mape: 0.6807\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8266e-04 - mape: 6087.0508 - val_loss: 1.0618e-04 - val_mape: 0.8582\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7940e-04 - mape: 6749.7168 - val_loss: 7.5050e-05 - val_mape: 0.8244\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4312e-04 - mape: 42699.5781 - val_loss: 7.5507e-05 - val_mape: 0.7032\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4291e-04 - mape: 14179.4219 - val_loss: 6.4886e-05 - val_mape: 0.6881\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5683e-04 - mape: 8937.8477 - val_loss: 1.2761e-04 - val_mape: 0.9783\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9706e-04 - mape: 7892.2676 - val_loss: 4.8934e-05 - val_mape: 0.6104\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8249e-04 - mape: 1073.0052 - val_loss: 9.3229e-05 - val_mape: 0.8236\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3091e-04 - mape: 24086.6641 - val_loss: 4.5691e-05 - val_mape: 0.5871\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8195e-04 - mape: 5984.0122 - val_loss: 8.7914e-05 - val_mape: 0.8206\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3600e-04 - mape: 2377.5676 - val_loss: 4.8417e-05 - val_mape: 0.5991\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1981e-04 - mape: 33929.5977 - val_loss: 1.4532e-04 - val_mape: 1.0819\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2077e-04 - mape: 18860.5586 - val_loss: 4.5314e-05 - val_mape: 0.5807\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8827e-04 - mape: 9684.0303 - val_loss: 1.3133e-04 - val_mape: 1.0510\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4682e-04 - mape: 4054.3599 - val_loss: 4.3391e-05 - val_mape: 0.6125\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2011e-04 - mape: 18854.1035 - val_loss: 1.3942e-04 - val_mape: 1.0747\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4919e-04 - mape: 18798.6426 - val_loss: 5.4384e-05 - val_mape: 0.6900\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8135e-04 - mape: 26322.0820 - val_loss: 1.1356e-04 - val_mape: 1.0279\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5432e-04 - mape: 31823.1914 - val_loss: 5.5094e-05 - val_mape: 0.7099\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0807e-04 - mape: 12201.3545 - val_loss: 1.1636e-04 - val_mape: 0.9988\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1345e-04 - mape: 17373.5176 - val_loss: 4.1005e-05 - val_mape: 0.5775\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5866e-04 - mape: 25791.6543 - val_loss: 1.0275e-04 - val_mape: 1.0181\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0830e-04 - mape: 19925.9727 - val_loss: 6.2845e-05 - val_mape: 0.7685\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8995e-04 - mape: 9591.9180 - val_loss: 1.5669e-04 - val_mape: 1.1859\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6831e-04 - mape: 11829.1299 - val_loss: 5.4444e-05 - val_mape: 0.7275\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6361e-04 - mape: 34461.6016 - val_loss: 8.4863e-05 - val_mape: 0.8733\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5072e-04 - mape: 33119.6914 - val_loss: 9.4560e-05 - val_mape: 1.0258\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1604e-04 - mape: 23501.3574 - val_loss: 1.2851e-04 - val_mape: 1.0613\n",
      "Epoch 33/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6190e-04 - mape: 22537.8047 - val_loss: 4.0155e-05 - val_mape: 0.5972\n",
      "Epoch 34/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0693e-04 - mape: 21498.7324 - val_loss: 1.5460e-04 - val_mape: 1.1635\n",
      "Epoch 35/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7720e-04 - mape: 18863.7734 - val_loss: 4.1766e-05 - val_mape: 0.5783\n",
      "Epoch 36/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5798e-04 - mape: 10160.6084 - val_loss: 1.4061e-04 - val_mape: 1.0964\n",
      "Epoch 37/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1709e-04 - mape: 30128.0703 - val_loss: 4.1620e-05 - val_mape: 0.5589\n",
      "Epoch 38/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4238e-04 - mape: 18768.6719 - val_loss: 2.1011e-04 - val_mape: 1.3672\n",
      "Epoch 39/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3825e-04 - mape: 21241.7734 - val_loss: 4.2395e-05 - val_mape: 0.5887\n",
      "Epoch 40/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4387e-04 - mape: 45487.7656 - val_loss: 1.0496e-04 - val_mape: 0.9699\n",
      "Epoch 41/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3791e-04 - mape: 30139.5977 - val_loss: 8.0284e-05 - val_mape: 0.9064\n",
      "Epoch 42/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8042e-04 - mape: 1217.8815 - val_loss: 1.9168e-04 - val_mape: 1.2836\n",
      "Epoch 43/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7171e-04 - mape: 25205.0840 - val_loss: 4.5567e-05 - val_mape: 0.6143\n",
      "--- 52/102 Training model for MRNA ---\n",
      "Epoch 1/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4701e-04 - mape: 36908.8906 - val_loss: 4.6953e-04 - val_mape: 10.6274\n",
      "Epoch 2/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mape: 61676.3672 - val_loss: 2.5151e-04 - val_mape: 7.7682\n",
      "Epoch 3/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0161e-04 - mape: 25152.3594 - val_loss: 3.8589e-05 - val_mape: 2.8007\n",
      "Epoch 4/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9670e-04 - mape: 21137.6484 - val_loss: 5.6450e-05 - val_mape: 3.5522\n",
      "Epoch 5/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6939e-04 - mape: 37502.9414 - val_loss: 9.0605e-06 - val_mape: 1.0660\n",
      "Epoch 6/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0290e-04 - mape: 29729.5938 - val_loss: 1.4570e-05 - val_mape: 1.4525\n",
      "Epoch 7/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9665e-04 - mape: 21402.8262 - val_loss: 2.1665e-05 - val_mape: 2.0655\n",
      "Epoch 8/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1487e-04 - mape: 37370.6328 - val_loss: 1.2675e-05 - val_mape: 1.4769\n",
      "Epoch 9/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2723e-04 - mape: 48049.9961 - val_loss: 2.4874e-05 - val_mape: 2.2052\n",
      "Epoch 10/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4071e-04 - mape: 48181.4297 - val_loss: 1.6876e-05 - val_mape: 1.7285\n",
      "Epoch 11/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0423e-04 - mape: 5170.5161 - val_loss: 8.1918e-06 - val_mape: 0.9806\n",
      "Epoch 12/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1151e-04 - mape: 89706.2656 - val_loss: 9.3580e-06 - val_mape: 1.0315\n",
      "Epoch 13/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4473e-04 - mape: 24537.5527 - val_loss: 2.9337e-05 - val_mape: 2.3857\n",
      "Epoch 14/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0023e-04 - mape: 16650.5254 - val_loss: 1.3734e-05 - val_mape: 1.5586\n",
      "Epoch 15/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9869e-04 - mape: 3228.5398 - val_loss: 1.6116e-05 - val_mape: 1.7436\n",
      "Epoch 16/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3642e-04 - mape: 8988.1133 - val_loss: 8.3925e-06 - val_mape: 0.9608\n",
      "Epoch 17/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6362e-04 - mape: 10625.7744 - val_loss: 3.2900e-05 - val_mape: 2.7271\n",
      "Epoch 18/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9071e-04 - mape: 35701.8789 - val_loss: 2.7017e-05 - val_mape: 2.4186\n",
      "Epoch 19/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1322e-04 - mape: 10355.1816 - val_loss: 1.2160e-05 - val_mape: 1.4968\n",
      "Epoch 20/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1407e-04 - mape: 47813.5938 - val_loss: 5.0206e-05 - val_mape: 3.4109\n",
      "Epoch 21/150\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3703e-04 - mape: 75514.2578 - val_loss: 9.5779e-06 - val_mape: 1.1829\n",
      "--- 53/102 Training model for META ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6284e-05 - mape: 402.2836 - val_loss: 1.7509e-04 - val_mape: 1.0602\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5596e-05 - mape: 2576.0212 - val_loss: 1.4013e-04 - val_mape: 0.9273\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8636e-05 - mape: 283.4287 - val_loss: 2.1327e-04 - val_mape: 1.3377\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8352e-05 - mape: 1057.6234 - val_loss: 1.2184e-04 - val_mape: 0.8592\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2196e-05 - mape: 2362.9998 - val_loss: 1.5504e-04 - val_mape: 1.0621\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0534e-05 - mape: 1981.7139 - val_loss: 1.3206e-04 - val_mape: 0.9116\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3469e-05 - mape: 1796.2499 - val_loss: 1.9293e-04 - val_mape: 1.2542\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6374e-05 - mape: 3353.8811 - val_loss: 1.0568e-04 - val_mape: 0.7743\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8000e-05 - mape: 935.5187 - val_loss: 1.5072e-04 - val_mape: 1.1265\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2826e-04 - mape: 428.5645 - val_loss: 7.4142e-05 - val_mape: 0.6861\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1156e-04 - mape: 273.6508 - val_loss: 9.9171e-05 - val_mape: 0.8110\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0895e-04 - mape: 3673.9060 - val_loss: 7.4244e-05 - val_mape: 0.6108\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4804e-04 - mape: 3238.9146 - val_loss: 2.3047e-04 - val_mape: 1.5471\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6330e-04 - mape: 4260.2271 - val_loss: 1.5656e-04 - val_mape: 1.1417\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3820e-04 - mape: 2375.8401 - val_loss: 1.5389e-04 - val_mape: 1.1850\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1200e-04 - mape: 218.4320 - val_loss: 1.3218e-04 - val_mape: 1.0549\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9237e-04 - mape: 1200.4275 - val_loss: 2.1335e-04 - val_mape: 1.5301\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7802e-04 - mape: 577.3547 - val_loss: 7.2738e-05 - val_mape: 0.6771\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7819e-04 - mape: 1861.6636 - val_loss: 1.1185e-04 - val_mape: 0.9669\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9788e-04 - mape: 2636.6418 - val_loss: 5.6934e-05 - val_mape: 0.6196\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4416e-04 - mape: 3265.6304 - val_loss: 9.9037e-05 - val_mape: 0.9447\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2479e-04 - mape: 621.3533 - val_loss: 1.5542e-04 - val_mape: 1.1771\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1973e-04 - mape: 2995.5972 - val_loss: 7.1291e-05 - val_mape: 0.6624\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2680e-05 - mape: 4083.4868 - val_loss: 6.0287e-05 - val_mape: 0.5515\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9030e-05 - mape: 1158.4065 - val_loss: 9.6905e-05 - val_mape: 0.8520\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1446e-04 - mape: 2534.3213 - val_loss: 6.8118e-05 - val_mape: 0.6221\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7515e-04 - mape: 2270.4797 - val_loss: 9.7543e-05 - val_mape: 0.9066\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9952e-04 - mape: 141.5428 - val_loss: 1.2253e-04 - val_mape: 1.0461\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6480e-04 - mape: 653.3008 - val_loss: 8.8314e-05 - val_mape: 0.8595\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9464e-04 - mape: 4794.1738 - val_loss: 7.6421e-05 - val_mape: 0.7194\n",
      "--- 54/102 Training model for MNST ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5820e-04 - mape: 87845.1719 - val_loss: 1.6619e-04 - val_mape: 1.3240\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2646e-04 - mape: 67647.1172 - val_loss: 6.6845e-05 - val_mape: 0.7600\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9611e-04 - mape: 93918.6484 - val_loss: 2.9370e-04 - val_mape: 2.0402\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3148e-04 - mape: 797.5314 - val_loss: 5.2555e-05 - val_mape: 0.6336\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6186e-04 - mape: 16186.2314 - val_loss: 8.4782e-04 - val_mape: 3.5189\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6468e-04 - mape: 19149.7461 - val_loss: 4.0424e-05 - val_mape: 0.5575\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7011e-04 - mape: 20911.5117 - val_loss: 6.4902e-05 - val_mape: 0.8270\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3148e-04 - mape: 87585.3672 - val_loss: 7.9695e-05 - val_mape: 0.9688\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8968e-04 - mape: 8550.5703 - val_loss: 5.9590e-04 - val_mape: 2.8627\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7353e-04 - mape: 110367.6875 - val_loss: 2.8095e-05 - val_mape: 0.4422\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1453e-04 - mape: 334.9821 - val_loss: 3.4782e-04 - val_mape: 2.1297\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2840e-04 - mape: 73135.6484 - val_loss: 2.8101e-05 - val_mape: 0.4811\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5680e-04 - mape: 35954.5977 - val_loss: 2.0993e-05 - val_mape: 0.3860\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3972e-04 - mape: 72449.9062 - val_loss: 2.6650e-04 - val_mape: 1.8777\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1387e-04 - mape: 15689.4424 - val_loss: 4.2123e-05 - val_mape: 0.5784\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0695e-04 - mape: 31060.2930 - val_loss: 6.5520e-05 - val_mape: 0.8629\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0176e-04 - mape: 180.5323 - val_loss: 1.9255e-04 - val_mape: 1.5527\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2140e-04 - mape: 43617.8945 - val_loss: 3.4763e-05 - val_mape: 0.5363\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2991e-04 - mape: 24585.9922 - val_loss: 3.1526e-05 - val_mape: 0.4604\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9594e-04 - mape: 47024.3828 - val_loss: 5.4527e-05 - val_mape: 0.7377\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4217e-04 - mape: 128849.7891 - val_loss: 4.1821e-05 - val_mape: 0.6437\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7449e-04 - mape: 100557.2969 - val_loss: 6.2980e-05 - val_mape: 0.8461\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1623e-04 - mape: 10869.9268 - val_loss: 2.1902e-05 - val_mape: 0.4034\n",
      "--- 55/102 Training model for AMD ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9791e-04 - mape: 1684.1553 - val_loss: 6.0726e-04 - val_mape: 2.6940\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5231e-04 - mape: 10319.4854 - val_loss: 7.2301e-04 - val_mape: 2.9507\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6587e-04 - mape: 11627.0264 - val_loss: 2.6132e-04 - val_mape: 1.6955\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6863e-04 - mape: 10159.5166 - val_loss: 3.1343e-04 - val_mape: 1.8559\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5253e-04 - mape: 6135.7612 - val_loss: 2.3512e-04 - val_mape: 1.6036\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2573e-04 - mape: 25463.1094 - val_loss: 2.0141e-04 - val_mape: 1.4813\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3162e-04 - mape: 38665.0781 - val_loss: 1.8236e-04 - val_mape: 1.3922\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1636e-04 - mape: 2603.4419 - val_loss: 2.1884e-04 - val_mape: 1.5392\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4085e-04 - mape: 10275.0752 - val_loss: 2.2082e-04 - val_mape: 1.5384\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8963e-04 - mape: 30180.3242 - val_loss: 3.3601e-04 - val_mape: 1.9751\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5493e-04 - mape: 6531.8247 - val_loss: 2.1690e-04 - val_mape: 1.5049\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0404e-04 - mape: 1927.3113 - val_loss: 3.2014e-04 - val_mape: 1.8865\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0135e-04 - mape: 37703.0625 - val_loss: 2.4547e-04 - val_mape: 1.5941\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9559e-04 - mape: 10023.8027 - val_loss: 3.4597e-04 - val_mape: 1.9560\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2086e-04 - mape: 17995.6250 - val_loss: 3.1673e-04 - val_mape: 1.8375\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7271e-04 - mape: 26921.7031 - val_loss: 2.4869e-04 - val_mape: 1.5997\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7528e-04 - mape: 762.1913 - val_loss: 3.1489e-04 - val_mape: 1.8246\n",
      "--- 56/102 Training model for QCOM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0410e-04 - mape: 74921.8672 - val_loss: 2.6502e-04 - val_mape: 1.5398\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8965e-04 - mape: 17056.9707 - val_loss: 1.4892e-04 - val_mape: 1.1521\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6671e-04 - mape: 10145.0820 - val_loss: 1.0287e-04 - val_mape: 0.9406\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1917e-04 - mape: 10623.5918 - val_loss: 7.9314e-05 - val_mape: 0.8171\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0866e-04 - mape: 31718.0391 - val_loss: 8.2309e-05 - val_mape: 0.8511\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9396e-04 - mape: 22813.0625 - val_loss: 6.9949e-05 - val_mape: 0.8101\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5418e-04 - mape: 18991.7188 - val_loss: 5.1947e-05 - val_mape: 0.6599\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9628e-04 - mape: 1923.2866 - val_loss: 5.9363e-05 - val_mape: 0.7858\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7212e-04 - mape: 28034.2148 - val_loss: 4.8995e-05 - val_mape: 0.7843\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8158e-04 - mape: 58494.5586 - val_loss: 3.7436e-05 - val_mape: 0.5874\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5841e-04 - mape: 4334.9531 - val_loss: 3.3467e-05 - val_mape: 0.5835\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6086e-04 - mape: 36892.7617 - val_loss: 8.5100e-05 - val_mape: 1.0039\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7042e-04 - mape: 38417.2422 - val_loss: 1.0080e-04 - val_mape: 1.0042\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1259e-04 - mape: 19555.5059 - val_loss: 1.9447e-04 - val_mape: 1.4993\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2060e-04 - mape: 15467.4102 - val_loss: 4.9223e-05 - val_mape: 0.6164\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7652e-04 - mape: 12559.4697 - val_loss: 7.1684e-05 - val_mape: 0.8318\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6824e-04 - mape: 36617.7500 - val_loss: 9.0928e-05 - val_mape: 0.9902\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0020e-04 - mape: 12.1121 - val_loss: 2.2991e-04 - val_mape: 2.0046\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0941e-04 - mape: 15.3544 - val_loss: 1.0907e-04 - val_mape: 1.2632\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7301e-04 - mape: 15.0550 - val_loss: 2.7723e-04 - val_mape: 2.2262\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9473e-04 - mape: 23.8769 - val_loss: 8.2048e-05 - val_mape: 1.0621\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7588e-04 - mape: 9.5840 - val_loss: 1.1290e-04 - val_mape: 1.3222\n",
      "Epoch 31/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1864e-04 - mape: 10.0929 - val_loss: 1.4055e-04 - val_mape: 1.4479\n",
      "Epoch 32/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2878e-04 - mape: 21.7390 - val_loss: 5.1443e-05 - val_mape: 0.8202\n",
      "--- 7/102 Training model for AEP ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8382e-04 - mape: 8.3520 - val_loss: 3.2852e-04 - val_mape: 2.0907\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7640e-04 - mape: 8.0752 - val_loss: 2.2659e-04 - val_mape: 1.4819\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9379e-04 - mape: 9.1862 - val_loss: 4.9560e-04 - val_mape: 2.5564\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7172e-04 - mape: 8.1950 - val_loss: 4.5936e-04 - val_mape: 2.2941\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7059e-04 - mape: 13.3397 - val_loss: 6.3285e-04 - val_mape: 2.4885\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8643e-04 - mape: 23.8986 - val_loss: 0.0015 - val_mape: 4.4715\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mape: 26.6015 - val_loss: 0.0043 - val_mape: 7.8158\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - mape: 45.1931 - val_loss: 0.0092 - val_mape: 11.9357\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - mape: 58.5500 - val_loss: 0.0057 - val_mape: 7.8768\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mape: 79.1839 - val_loss: 0.0020 - val_mape: 5.3576\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mape: 92.6165 - val_loss: 0.0027 - val_mape: 7.4135\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mape: 95.8843 - val_loss: 0.0018 - val_mape: 6.0534\n",
      "--- 8/102 Training model for TEAM ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8307e-04 - mape: 36.7613 - val_loss: 0.0013 - val_mape: 8.7478\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5736e-04 - mape: 74.6182 - val_loss: 0.0012 - val_mape: 8.3228\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1135e-04 - mape: 42.2761 - val_loss: 0.0012 - val_mape: 8.4979\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4309e-04 - mape: 57.3172 - val_loss: 0.0013 - val_mape: 8.6349\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2456e-04 - mape: 69.7929 - val_loss: 0.0013 - val_mape: 8.5449\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mape: 81.2587 - val_loss: 0.0015 - val_mape: 9.2331\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mape: 103.7190 - val_loss: 0.0018 - val_mape: 10.1060\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mape: 125.3570 - val_loss: 0.0016 - val_mape: 9.1482\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 137.4523 - val_loss: 0.0015 - val_mape: 8.7225\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mape: 141.3671 - val_loss: 0.0019 - val_mape: 10.0306\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - mape: 147.5498 - val_loss: 0.0018 - val_mape: 9.5708\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - mape: 172.0387 - val_loss: 0.0019 - val_mape: 9.9355\n",
      "--- 9/102 Training model for PANW ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0104e-04 - mape: 920.8994 - val_loss: 0.0055 - val_mape: 8.8226\n",
      "Epoch 2/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mape: 161701.5469 - val_loss: 7.7460e-04 - val_mape: 3.0615\n",
      "Epoch 3/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6080e-04 - mape: 6306.6401 - val_loss: 2.8077e-04 - val_mape: 1.5552\n",
      "Epoch 4/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2849e-04 - mape: 23133.0527 - val_loss: 2.6558e-04 - val_mape: 1.4659\n",
      "Epoch 5/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4448e-04 - mape: 85184.3203 - val_loss: 0.0019 - val_mape: 5.0817\n",
      "Epoch 6/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5289e-04 - mape: 111003.7109 - val_loss: 2.1928e-04 - val_mape: 1.2472\n",
      "Epoch 7/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2780e-04 - mape: 8573.8799 - val_loss: 2.7175e-04 - val_mape: 1.5690\n",
      "Epoch 8/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6660e-04 - mape: 61437.2617 - val_loss: 1.8749e-04 - val_mape: 1.0379\n",
      "Epoch 9/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7449e-04 - mape: 57541.8633 - val_loss: 6.2832e-04 - val_mape: 2.7704\n",
      "Epoch 10/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3114e-04 - mape: 82328.8984 - val_loss: 2.0051e-04 - val_mape: 1.0234\n",
      "Epoch 11/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1517e-04 - mape: 23329.7129 - val_loss: 2.6537e-04 - val_mape: 1.5272\n",
      "Epoch 12/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3277e-04 - mape: 45901.7539 - val_loss: 3.1332e-04 - val_mape: 1.5109\n",
      "Epoch 13/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3993e-04 - mape: 54866.2695 - val_loss: 0.0012 - val_mape: 4.0524\n",
      "Epoch 14/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.8082e-04 - mape: 100075.3438 - val_loss: 2.0617e-04 - val_mape: 1.0841\n",
      "Epoch 15/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0177e-04 - mape: 80985.6328 - val_loss: 0.0013 - val_mape: 4.1224\n",
      "Epoch 16/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mape: 132465.8750 - val_loss: 1.8527e-04 - val_mape: 1.0373\n",
      "Epoch 17/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5732e-04 - mape: 40650.3516 - val_loss: 0.0014 - val_mape: 4.2976\n",
      "Epoch 18/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3200e-04 - mape: 56115.2031 - val_loss: 3.6264e-04 - val_mape: 1.7697\n",
      "Epoch 19/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7208e-04 - mape: 40638.6641 - val_loss: 4.8045e-04 - val_mape: 2.3976\n",
      "Epoch 20/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3347e-04 - mape: 38440.9141 - val_loss: 1.6409e-04 - val_mape: 0.9001\n",
      "Epoch 21/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4436e-04 - mape: 31082.3633 - val_loss: 3.6700e-04 - val_mape: 1.9979\n",
      "Epoch 22/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3217e-04 - mape: 84896.5156 - val_loss: 1.9540e-04 - val_mape: 1.0576\n",
      "Epoch 23/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8570e-04 - mape: 93118.4062 - val_loss: 0.0022 - val_mape: 5.5024\n",
      "Epoch 24/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mape: 152341.5625 - val_loss: 2.0103e-04 - val_mape: 1.0906\n",
      "Epoch 25/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1432e-04 - mape: 67990.4375 - val_loss: 0.0025 - val_mape: 5.8691\n",
      "Epoch 26/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mape: 87999.0391 - val_loss: 1.7821e-04 - val_mape: 1.0352\n",
      "Epoch 27/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0957e-04 - mape: 85003.6484 - val_loss: 0.0013 - val_mape: 4.1409\n",
      "Epoch 28/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3512e-04 - mape: 128087.5312 - val_loss: 1.9450e-04 - val_mape: 1.0527\n",
      "Epoch 29/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5589e-04 - mape: 53067.7773 - val_loss: 9.5652e-04 - val_mape: 3.5734\n",
      "Epoch 30/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9026e-04 - mape: 58237.4883 - val_loss: 1.9246e-04 - val_mape: 1.2190\n",
      "--- 10/102 Training model for AVGO ---\n",
      "Epoch 1/150\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6777e-04 - mape: 29.4979 - val_loss: 7.4344e-04 - val_mape: 2.8903\n",
      "Epoch 2/150\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9823e-04 - mape: 40.2375"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.data.make_dataset import load_list, get_stock_data\n",
    "from src.models.StockModel import StockModel\n",
    "window_size = 20\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2024-09-01'\n",
    "feature_columns = ['Close', 'Open', 'Volume', 'Range', 'Gap', 'RSI', 'MACD']\n",
    "target = \"Open\"\n",
    "\n",
    "# Load symbols\n",
    "nasdaq_symbols = load_list(\"NASDAQ\")\n",
    "sp500_symbols = load_list(\"SP500\")\n",
    "\n",
    "# Test tickers, sp500 symbols not also in nasdaq\n",
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:100]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC']\n",
    "train_tickers = ['^IXIC'] + nasdaq_symbols\n",
    "#train_tickers = train_tickers[:51]\n",
    "\n",
    "# Download data\n",
    "combined_data = get_stock_data(train_tickers, \"1d\", start_date, end_date)\n",
    "combined_data.info()\n",
    "# Test data\n",
    "test_data = get_stock_data(test_tickers, \"1d\", start_date, end_date)\n",
    "\n",
    "layer_config = [(1,90),(1,92),(1,94)]\n",
    "for i in layer_config:\n",
    "    print(f\"XXXXXXXXXXXXXXXX Running {i[0]} {i[1]} layers XXXXXXXXXXXXXXXXXXXX\")\n",
    "    # Create and train model\n",
    "    stock_model = StockModel(window_size=window_size, feature_columns=feature_columns, target_name=target, export=True)\n",
    "    \n",
    "    stock_model.train(combined_data, patience=10, epochs=150, graph=False, layers=i[0], units_per_layer=i[1])\n",
    "    metrics_dict, metrics_summary = stock_model.evaluate_many(test_data, graph=False)\n",
    "    print(metrics_dict)\n",
    "    print(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tickers = [item for item in sp500_symbols if item not in nasdaq_symbols]\n",
    "test_tickers = test_tickers[:5]\n",
    "\n",
    "#tickers = ['^GSPC', '^IXIC', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'AVGO', 'META', 'GOOGL', 'GOOG', 'MMM', 'ADBE', 'BWA', 'GD', 'IT']\n",
    "#tickers = ['^GSPC', '^IXIC', '^DJI']\n",
    "# Test data\n",
    "test_data = get_stock_data([\"^GSPC\", \"^DJI\"], \"1d\", start_date, end_date)\n",
    "\n",
    "metrics_dict, mean_metrics = stock_model.evaluate_many(test_data, graph=True)\n",
    "print(metrics_dict)\n",
    "print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
